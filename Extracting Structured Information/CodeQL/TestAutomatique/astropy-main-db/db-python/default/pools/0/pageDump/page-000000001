b'
    Converts input bit flags to a single integer value (bit mask) or `None`.

    When input is a list of flags (either a Python list of integer flags or a
    string of comma-, ``'|'``-, or ``'+'``-separated list of flags),
    the returned bit mask is obtained by summing input flags.

    .. note::
        In order to flip the bits of the returned bit mask,
        for input of `str` type, prepend '~' to the input string. '~' must
        be prepended to the *entire string* and not to each bit flag! For
        input that is already a bit mask or a Python list of bit flags, set
        ``flip_bits`` for `True` in order to flip the bits of the returned
        bit mask.

    Parameters
    ----------
    bit_flags : int, str, list, None
        An integer bit mask or flag, `None`, a string of comma-, ``'|'``- or
        ``'+'``-separated list of integer bit flags or mnemonic flag names,
        or a Python list of integer bit flags. If ``bit_flags`` is a `str`
        and if it is prepended with '~', then the output bit mask will have
        its bits flipped (compared to simple sum of input flags).
        For input ``bit_flags`` that is already a bit mask or a Python list
        of bit flags, bit-flipping can be controlled through ``flip_bits``
        parameter.

        .. note::
            When ``bit_flags`` is a list of flag names, the ``flag_name_map``
            parameter must be provided.

        .. note::
            Only one flag separator is supported at a time. ``bit_flags``
            string should not mix ``','``, ``'+'``, and ``'|'`` separators.

    flip_bits : bool, None
        Indicates whether or not to flip the bits of the returned bit mask
        obtained from input bit flags. This parameter must be set to `None`
        when input ``bit_flags`` is either `None` or a Python list of flags.

    flag_name_map : BitFlagNameMap
         A `BitFlagNameMap` object that provides mapping from mnemonic
         bit flag names to integer bit values in order to translate mnemonic
         flags to numeric values when ``bit_flags`` that are comma- or
         '+'-separated list of menmonic bit flag names.

    Returns
    -------
    bitmask : int or None
        Returns an integer bit mask formed from the input bit value or `None`
        if input ``bit_flags`` parameter is `None` or an empty string.
        If input string value was prepended with '~' (or ``flip_bits`` was set
        to `True`), then returned value will have its bits flipped
        (inverse mask).

    Examples
    --------
        >>> from astropy.nddata.bitmask import interpret_bit_flags, extend_bit_flag_map
        >>> ST_DQ = extend_bit_flag_map('ST_DQ', CR=1, CLOUDY=4, RAINY=8, HOT=16, DEAD=32)
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags(28))
        '0000000000011100'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('4,8,16'))
        '0000000000011100'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('CLOUDY,RAINY,HOT', flag_name_map=ST_DQ))
        '0000000000011100'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('~4,8,16'))
        '1111111111100011'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('~(4+8+16)'))
        '1111111111100011'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('~(CLOUDY+RAINY+HOT)',
        ... flag_name_map=ST_DQ))
        '1111111111100011'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags([4, 8, 16]))
        '0000000000011100'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags([4, 8, 16], flip_bits=True))
        '1111111111100011'

    'u'
    Converts input bit flags to a single integer value (bit mask) or `None`.

    When input is a list of flags (either a Python list of integer flags or a
    string of comma-, ``'|'``-, or ``'+'``-separated list of flags),
    the returned bit mask is obtained by summing input flags.

    .. note::
        In order to flip the bits of the returned bit mask,
        for input of `str` type, prepend '~' to the input string. '~' must
        be prepended to the *entire string* and not to each bit flag! For
        input that is already a bit mask or a Python list of bit flags, set
        ``flip_bits`` for `True` in order to flip the bits of the returned
        bit mask.

    Parameters
    ----------
    bit_flags : int, str, list, None
        An integer bit mask or flag, `None`, a string of comma-, ``'|'``- or
        ``'+'``-separated list of integer bit flags or mnemonic flag names,
        or a Python list of integer bit flags. If ``bit_flags`` is a `str`
        and if it is prepended with '~', then the output bit mask will have
        its bits flipped (compared to simple sum of input flags).
        For input ``bit_flags`` that is already a bit mask or a Python list
        of bit flags, bit-flipping can be controlled through ``flip_bits``
        parameter.

        .. note::
            When ``bit_flags`` is a list of flag names, the ``flag_name_map``
            parameter must be provided.

        .. note::
            Only one flag separator is supported at a time. ``bit_flags``
            string should not mix ``','``, ``'+'``, and ``'|'`` separators.

    flip_bits : bool, None
        Indicates whether or not to flip the bits of the returned bit mask
        obtained from input bit flags. This parameter must be set to `None`
        when input ``bit_flags`` is either `None` or a Python list of flags.

    flag_name_map : BitFlagNameMap
         A `BitFlagNameMap` object that provides mapping from mnemonic
         bit flag names to integer bit values in order to translate mnemonic
         flags to numeric values when ``bit_flags`` that are comma- or
         '+'-separated list of menmonic bit flag names.

    Returns
    -------
    bitmask : int or None
        Returns an integer bit mask formed from the input bit value or `None`
        if input ``bit_flags`` parameter is `None` or an empty string.
        If input string value was prepended with '~' (or ``flip_bits`` was set
        to `True`), then returned value will have its bits flipped
        (inverse mask).

    Examples
    --------
        >>> from astropy.nddata.bitmask import interpret_bit_flags, extend_bit_flag_map
        >>> ST_DQ = extend_bit_flag_map('ST_DQ', CR=1, CLOUDY=4, RAINY=8, HOT=16, DEAD=32)
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags(28))
        '0000000000011100'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('4,8,16'))
        '0000000000011100'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('CLOUDY,RAINY,HOT', flag_name_map=ST_DQ))
        '0000000000011100'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('~4,8,16'))
        '1111111111100011'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('~(4+8+16)'))
        '1111111111100011'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags('~(CLOUDY+RAINY+HOT)',
        ... flag_name_map=ST_DQ))
        '1111111111100011'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags([4, 8, 16]))
        '0000000000011100'
        >>> "{0:016b}".format(0xFFFF & interpret_bit_flags([4, 8, 16], flip_bits=True))
        '1111111111100011'

    'b'Keyword argument 'flip_bits' must be set to 'None' when input 'bit_flags' is None.'u'Keyword argument 'flip_bits' must be set to 'None' when input 'bit_flags' is None.'b'Keyword argument 'flip_bits' is not permitted for comma-separated string lists of bit flags. Prepend '~' to the string to indicate bit-flipping.'u'Keyword argument 'flip_bits' is not permitted for comma-separated string lists of bit flags. Prepend '~' to the string to indicate bit-flipping.'b'INDEF'u'INDEF'b'~'u'~'b'Bitwise-NOT must precede bit flag list.'u'Bitwise-NOT must precede bit flag list.'b'Unbalanced parentheses in bit flag list.'u'Unbalanced parentheses in bit flag list.'b'Incorrect syntax (incorrect use of parenthesis) in bit flag list.'u'Incorrect syntax (incorrect use of parenthesis) in bit flag list.'b'+,|'u'+,|'b'Only one type of bit flag separator may be used in one expression. Allowed separators are: '+', '|', or ','.'u'Only one type of bit flag separator may be used in one expression. Allowed separators are: '+', '|', or ','.'b'+'u'+'b'Empty bit flag lists not allowed when either bitwise-NOT or parenthesis are present.'u'Empty bit flag lists not allowed when either bitwise-NOT or parenthesis are present.'b'__iter__'u'__iter__'b'Every bit flag in a list must be either an integer flag value or a 'str' flag name.'u'Every bit flag in a list must be either an integer flag value or a 'str' flag name.'b'Unsupported type for argument 'bit_flags'.'u'Unsupported type for argument 'bit_flags'.'b'Duplicate bit flags will be ignored'u'Duplicate bit flags will be ignored'b'Input list contains invalid (not powers of two) bit flag: 'u'Input list contains invalid (not powers of two) bit flag: 'b'
    bitfield_to_boolean_mask(bitfield, ignore_flags=None, flip_bits=None, good_mask_value=False, dtype=numpy.bool_)
    Converts an array of bit fields to a boolean (or integer) mask array
    according to a bit mask constructed from the supplied bit flags (see
    ``ignore_flags`` parameter).

    This function is particularly useful to convert data quality arrays to
    boolean masks with selective filtering of DQ flags.

    Parameters
    ----------
    bitfield : ndarray
        An array of bit flags. By default, values different from zero are
        interpreted as "bad" values and values equal to zero are considered
        as "good" values. However, see ``ignore_flags`` parameter on how to
        selectively ignore some bits in the ``bitfield`` array data.

    ignore_flags : int, str, list, None (default = 0)
        An integer bit mask, `None`, a Python list of bit flags, a comma-,
        or ``'|'``-separated, ``'+'``-separated string list of integer
        bit flags or mnemonic flag names that indicate what bits in the input
        ``bitfield`` should be *ignored* (i.e., zeroed), or `None`.

        .. note::
            When ``bit_flags`` is a list of flag names, the ``flag_name_map``
            parameter must be provided.

        | Setting ``ignore_flags`` to `None` effectively will make
          `bitfield_to_boolean_mask` interpret all ``bitfield`` elements
          as "good" regardless of their value.

        | When ``ignore_flags`` argument is an integer bit mask, it will be
          combined using bitwise-NOT and bitwise-AND with each element of the
          input ``bitfield`` array (``~ignore_flags & bitfield``). If the
          resultant bitfield element is non-zero, that element will be
          interpreted as a "bad" in the output boolean mask and it will be
          interpreted as "good" otherwise. ``flip_bits`` parameter may be used
          to flip the bits (``bitwise-NOT``) of the bit mask thus effectively
          changing the meaning of the ``ignore_flags`` parameter from "ignore"
          to "use only" these flags.

        .. note::

            Setting ``ignore_flags`` to 0 effectively will assume that all
            non-zero elements in the input ``bitfield`` array are to be
            interpreted as "bad".

        | When ``ignore_flags`` argument is a Python list of integer bit
          flags, these flags are added together to create an integer bit mask.
          Each item in the list must be a flag, i.e., an integer that is an
          integer power of 2. In order to flip the bits of the resultant
          bit mask, use ``flip_bits`` parameter.

        | Alternatively, ``ignore_flags`` may be a string of comma- or
          ``'+'``(or ``'|'``)-separated list of integer bit flags that should
          be added (bitwise OR) together to create an integer bit mask.
          For example, both ``'4,8'``, ``'4|8'``, and ``'4+8'`` are equivalent
          and indicate that bit flags 4 and 8 in the input ``bitfield``
          array should be ignored when generating boolean mask.

        .. note::

            ``'None'``, ``'INDEF'``, and empty (or all white space) strings
            are special values of string ``ignore_flags`` that are
            interpreted as `None`.

        .. note::

            Each item in the list must be a flag, i.e., an integer that is an
            integer power of 2. In addition, for convenience, an arbitrary
            **single** integer is allowed and it will be interpreted as an
            integer bit mask. For example, instead of ``'4,8'`` one could
            simply provide string ``'12'``.

        .. note::
            Only one flag separator is supported at a time. ``ignore_flags``
            string should not mix ``','``, ``'+'``, and ``'|'`` separators.

        .. note::

            When ``ignore_flags`` is a `str` and when it is prepended with
            '~', then the meaning of ``ignore_flags`` parameters will be
            reversed: now it will be interpreted as a list of bit flags to be
            *used* (or *not ignored*) when deciding which elements of the
            input ``bitfield`` array are "bad". Following this convention,
            an ``ignore_flags`` string value of ``'~0'`` would be equivalent
            to setting ``ignore_flags=None``.

        .. warning::

            Because prepending '~' to a string ``ignore_flags`` is equivalent
            to setting ``flip_bits`` to `True`, ``flip_bits`` cannot be used
            with string ``ignore_flags`` and it must be set to `None`.

    flip_bits : bool, None (default = None)
        Specifies whether or not to invert the bits of the bit mask either
        supplied directly through ``ignore_flags`` parameter or built from the
        bit flags passed through ``ignore_flags`` (only when bit flags are
        passed as Python lists of integer bit flags). Occasionally, it may be
        useful to *consider only specific bit flags* in the ``bitfield``
        array when creating a boolean mask as opposed to *ignoring* specific
        bit flags as ``ignore_flags`` behaves by default. This can be achieved
        by inverting/flipping the bits of the bit mask created from
        ``ignore_flags`` flags which effectively changes the meaning of the
        ``ignore_flags`` parameter from "ignore" to "use only" these flags.
        Setting ``flip_bits`` to `None` means that no bit flipping will be
        performed. Bit flipping for string lists of bit flags must be
        specified by prepending '~' to string bit flag lists
        (see documentation for ``ignore_flags`` for more details).

        .. warning::
            This parameter can be set to either `True` or `False` **ONLY** when
            ``ignore_flags`` is either an integer bit mask or a Python
            list of integer bit flags. When ``ignore_flags`` is either
            `None` or a string list of flags, ``flip_bits`` **MUST** be set
            to `None`.

    good_mask_value : int, bool (default = False)
        This parameter is used to derive the values that will be assigned to
        the elements in the output boolean mask array that correspond to the
        "good" bit fields (that are 0 after zeroing bits specified by
        ``ignore_flags``) in the input ``bitfield`` array. When
        ``good_mask_value`` is non-zero or ``numpy.True_`` then values in the
        output boolean mask array corresponding to "good" bit fields in
        ``bitfield`` will be ``numpy.True_`` (if ``dtype`` is ``numpy.bool_``)
        or 1 (if ``dtype`` is of numerical type) and values of corresponding
        to "bad" flags will be ``numpy.False_`` (or 0). When
        ``good_mask_value`` is zero or ``numpy.False_`` then the values
        in the output boolean mask array corresponding to "good" bit fields
        in ``bitfield`` will be ``numpy.False_`` (if ``dtype`` is
        ``numpy.bool_``) or 0 (if ``dtype`` is of numerical type) and values
        of corresponding to "bad" flags will be ``numpy.True_`` (or 1).

    dtype : data-type (default = ``numpy.bool_``)
        The desired data-type for the output binary mask array.

    flag_name_map : BitFlagNameMap
         A `BitFlagNameMap` object that provides mapping from mnemonic
         bit flag names to integer bit values in order to translate mnemonic
         flags to numeric values when ``bit_flags`` that are comma- or
         '+'-separated list of menmonic bit flag names.

    Returns
    -------
    mask : ndarray
        Returns an array of the same dimensionality as the input ``bitfield``
        array whose elements can have two possible values,
        e.g., ``numpy.True_`` or ``numpy.False_`` (or 1 or 0 for integer
        ``dtype``) according to values of to the input ``bitfield`` elements,
        ``ignore_flags`` parameter, and the ``good_mask_value`` parameter.

    Examples
    --------
        >>> from astropy.nddata import bitmask
        >>> import numpy as np
        >>> dqarr = np.asarray([[0, 0, 1, 2, 0, 8, 12, 0],
        ...                     [10, 4, 0, 0, 0, 16, 6, 0]])
        >>> flag_map = bitmask.extend_bit_flag_map(
        ...     'ST_DQ', CR=2, CLOUDY=4, RAINY=8, HOT=16, DEAD=32
        ... )
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=0,
        ...                                  dtype=int)
        array([[0, 0, 1, 1, 0, 1, 1, 0],
               [1, 1, 0, 0, 0, 1, 1, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=0,
        ...                                  dtype=bool)
        array([[False, False,  True,  True, False,  True,  True, False],
               [ True,  True, False, False, False,  True,  True, False]]...)
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=6,
        ...                                  good_mask_value=0, dtype=int)
        array([[0, 0, 1, 0, 0, 1, 1, 0],
               [1, 0, 0, 0, 0, 1, 0, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=~6,
        ...                                  good_mask_value=0, dtype=int)
        array([[0, 0, 0, 1, 0, 0, 1, 0],
               [1, 1, 0, 0, 0, 0, 1, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=6, dtype=int,
        ...                                  flip_bits=True, good_mask_value=0)
        array([[0, 0, 0, 1, 0, 0, 1, 0],
               [1, 1, 0, 0, 0, 0, 1, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags='~(2+4)',
        ...                                  good_mask_value=0, dtype=int)
        array([[0, 0, 0, 1, 0, 0, 1, 0],
               [1, 1, 0, 0, 0, 0, 1, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=[2, 4],
        ...                                  flip_bits=True, good_mask_value=0,
        ...                                  dtype=int)
        array([[0, 0, 0, 1, 0, 0, 1, 0],
               [1, 1, 0, 0, 0, 0, 1, 0]])
        >>> bitmask.bitfield_to...u'
    bitfield_to_boolean_mask(bitfield, ignore_flags=None, flip_bits=None, good_mask_value=False, dtype=numpy.bool_)
    Converts an array of bit fields to a boolean (or integer) mask array
    according to a bit mask constructed from the supplied bit flags (see
    ``ignore_flags`` parameter).

    This function is particularly useful to convert data quality arrays to
    boolean masks with selective filtering of DQ flags.

    Parameters
    ----------
    bitfield : ndarray
        An array of bit flags. By default, values different from zero are
        interpreted as "bad" values and values equal to zero are considered
        as "good" values. However, see ``ignore_flags`` parameter on how to
        selectively ignore some bits in the ``bitfield`` array data.

    ignore_flags : int, str, list, None (default = 0)
        An integer bit mask, `None`, a Python list of bit flags, a comma-,
        or ``'|'``-separated, ``'+'``-separated string list of integer
        bit flags or mnemonic flag names that indicate what bits in the input
        ``bitfield`` should be *ignored* (i.e., zeroed), or `None`.

        .. note::
            When ``bit_flags`` is a list of flag names, the ``flag_name_map``
            parameter must be provided.

        | Setting ``ignore_flags`` to `None` effectively will make
          `bitfield_to_boolean_mask` interpret all ``bitfield`` elements
          as "good" regardless of their value.

        | When ``ignore_flags`` argument is an integer bit mask, it will be
          combined using bitwise-NOT and bitwise-AND with each element of the
          input ``bitfield`` array (``~ignore_flags & bitfield``). If the
          resultant bitfield element is non-zero, that element will be
          interpreted as a "bad" in the output boolean mask and it will be
          interpreted as "good" otherwise. ``flip_bits`` parameter may be used
          to flip the bits (``bitwise-NOT``) of the bit mask thus effectively
          changing the meaning of the ``ignore_flags`` parameter from "ignore"
          to "use only" these flags.

        .. note::

            Setting ``ignore_flags`` to 0 effectively will assume that all
            non-zero elements in the input ``bitfield`` array are to be
            interpreted as "bad".

        | When ``ignore_flags`` argument is a Python list of integer bit
          flags, these flags are added together to create an integer bit mask.
          Each item in the list must be a flag, i.e., an integer that is an
          integer power of 2. In order to flip the bits of the resultant
          bit mask, use ``flip_bits`` parameter.

        | Alternatively, ``ignore_flags`` may be a string of comma- or
          ``'+'``(or ``'|'``)-separated list of integer bit flags that should
          be added (bitwise OR) together to create an integer bit mask.
          For example, both ``'4,8'``, ``'4|8'``, and ``'4+8'`` are equivalent
          and indicate that bit flags 4 and 8 in the input ``bitfield``
          array should be ignored when generating boolean mask.

        .. note::

            ``'None'``, ``'INDEF'``, and empty (or all white space) strings
            are special values of string ``ignore_flags`` that are
            interpreted as `None`.

        .. note::

            Each item in the list must be a flag, i.e., an integer that is an
            integer power of 2. In addition, for convenience, an arbitrary
            **single** integer is allowed and it will be interpreted as an
            integer bit mask. For example, instead of ``'4,8'`` one could
            simply provide string ``'12'``.

        .. note::
            Only one flag separator is supported at a time. ``ignore_flags``
            string should not mix ``','``, ``'+'``, and ``'|'`` separators.

        .. note::

            When ``ignore_flags`` is a `str` and when it is prepended with
            '~', then the meaning of ``ignore_flags`` parameters will be
            reversed: now it will be interpreted as a list of bit flags to be
            *used* (or *not ignored*) when deciding which elements of the
            input ``bitfield`` array are "bad". Following this convention,
            an ``ignore_flags`` string value of ``'~0'`` would be equivalent
            to setting ``ignore_flags=None``.

        .. warning::

            Because prepending '~' to a string ``ignore_flags`` is equivalent
            to setting ``flip_bits`` to `True`, ``flip_bits`` cannot be used
            with string ``ignore_flags`` and it must be set to `None`.

    flip_bits : bool, None (default = None)
        Specifies whether or not to invert the bits of the bit mask either
        supplied directly through ``ignore_flags`` parameter or built from the
        bit flags passed through ``ignore_flags`` (only when bit flags are
        passed as Python lists of integer bit flags). Occasionally, it may be
        useful to *consider only specific bit flags* in the ``bitfield``
        array when creating a boolean mask as opposed to *ignoring* specific
        bit flags as ``ignore_flags`` behaves by default. This can be achieved
        by inverting/flipping the bits of the bit mask created from
        ``ignore_flags`` flags which effectively changes the meaning of the
        ``ignore_flags`` parameter from "ignore" to "use only" these flags.
        Setting ``flip_bits`` to `None` means that no bit flipping will be
        performed. Bit flipping for string lists of bit flags must be
        specified by prepending '~' to string bit flag lists
        (see documentation for ``ignore_flags`` for more details).

        .. warning::
            This parameter can be set to either `True` or `False` **ONLY** when
            ``ignore_flags`` is either an integer bit mask or a Python
            list of integer bit flags. When ``ignore_flags`` is either
            `None` or a string list of flags, ``flip_bits`` **MUST** be set
            to `None`.

    good_mask_value : int, bool (default = False)
        This parameter is used to derive the values that will be assigned to
        the elements in the output boolean mask array that correspond to the
        "good" bit fields (that are 0 after zeroing bits specified by
        ``ignore_flags``) in the input ``bitfield`` array. When
        ``good_mask_value`` is non-zero or ``numpy.True_`` then values in the
        output boolean mask array corresponding to "good" bit fields in
        ``bitfield`` will be ``numpy.True_`` (if ``dtype`` is ``numpy.bool_``)
        or 1 (if ``dtype`` is of numerical type) and values of corresponding
        to "bad" flags will be ``numpy.False_`` (or 0). When
        ``good_mask_value`` is zero or ``numpy.False_`` then the values
        in the output boolean mask array corresponding to "good" bit fields
        in ``bitfield`` will be ``numpy.False_`` (if ``dtype`` is
        ``numpy.bool_``) or 0 (if ``dtype`` is of numerical type) and values
        of corresponding to "bad" flags will be ``numpy.True_`` (or 1).

    dtype : data-type (default = ``numpy.bool_``)
        The desired data-type for the output binary mask array.

    flag_name_map : BitFlagNameMap
         A `BitFlagNameMap` object that provides mapping from mnemonic
         bit flag names to integer bit values in order to translate mnemonic
         flags to numeric values when ``bit_flags`` that are comma- or
         '+'-separated list of menmonic bit flag names.

    Returns
    -------
    mask : ndarray
        Returns an array of the same dimensionality as the input ``bitfield``
        array whose elements can have two possible values,
        e.g., ``numpy.True_`` or ``numpy.False_`` (or 1 or 0 for integer
        ``dtype``) according to values of to the input ``bitfield`` elements,
        ``ignore_flags`` parameter, and the ``good_mask_value`` parameter.

    Examples
    --------
        >>> from astropy.nddata import bitmask
        >>> import numpy as np
        >>> dqarr = np.asarray([[0, 0, 1, 2, 0, 8, 12, 0],
        ...                     [10, 4, 0, 0, 0, 16, 6, 0]])
        >>> flag_map = bitmask.extend_bit_flag_map(
        ...     'ST_DQ', CR=2, CLOUDY=4, RAINY=8, HOT=16, DEAD=32
        ... )
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=0,
        ...                                  dtype=int)
        array([[0, 0, 1, 1, 0, 1, 1, 0],
               [1, 1, 0, 0, 0, 1, 1, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=0,
        ...                                  dtype=bool)
        array([[False, False,  True,  True, False,  True,  True, False],
               [ True,  True, False, False, False,  True,  True, False]]...)
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=6,
        ...                                  good_mask_value=0, dtype=int)
        array([[0, 0, 1, 0, 0, 1, 1, 0],
               [1, 0, 0, 0, 0, 1, 0, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=~6,
        ...                                  good_mask_value=0, dtype=int)
        array([[0, 0, 0, 1, 0, 0, 1, 0],
               [1, 1, 0, 0, 0, 0, 1, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=6, dtype=int,
        ...                                  flip_bits=True, good_mask_value=0)
        array([[0, 0, 0, 1, 0, 0, 1, 0],
               [1, 1, 0, 0, 0, 0, 1, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags='~(2+4)',
        ...                                  good_mask_value=0, dtype=int)
        array([[0, 0, 0, 1, 0, 0, 1, 0],
               [1, 1, 0, 0, 0, 0, 1, 0]])
        >>> bitmask.bitfield_to_boolean_mask(dqarr, ignore_flags=[2, 4],
        ...                                  flip_bits=True, good_mask_value=0,
        ...                                  dtype=int)
        array([[0, 0, 0, 1, 0, 0, 1, 0],
               [1, 1, 0, 0, 0, 0, 1, 0]])
        >>> bitmask.bitfield_to...b'Input bitfield array must be of integer type.'u'Input bitfield array must be of integer type.'u'astropy.nddata.bitmask'u'nddata.bitmask'u'bitmask'
This module contains functions for computing robust statistics using
Tukey's biweight function.
astropy.stats.funcsmedian_absolute_deviationastropy.stats.nanfunctionsnanmediannansumbiweight_locationbiweight_midcorrelationbiweight_midcovariancebiweight_midvariancebiweight_scale_stat_functionsignore_nanmedianmedian_funcsum_func6.0
    Compute the biweight location.

    The biweight location is a robust statistic for determining the
    central location of a distribution.  It is given by:

    .. math::

        \zeta_{biloc}= M + \frac{\sum_{|u_i|<1} \ (x_i - M) (1 - u_i^2)^2}
            {\sum_{|u_i|<1} \ (1 - u_i^2)^2}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input initial location guess) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight location tuning constant ``c`` is typically 6.0 (the
    default).

    If :math:`MAD` is zero, then the median will be returned.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 6.0).
    M : float or array-like, optional
        Initial guess for the location.  If ``M`` is a scalar value,
        then its value will be used for the entire array (or along each
        ``axis``, if specified).  If ``M`` is an array, then its must be
        an array containing the initial location estimate along each
        ``axis`` of the input array.  If `None` (default), then the
        median of the input array will be used (or along each ``axis``,
        if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight locations are
        computed.  If `None` (default), then the biweight location of
        the flattened input array will be computed.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_location : float or `~numpy.ndarray`
        The biweight location of the input data.  If ``axis`` is `None`
        then a scalar will be returned, otherwise a `~numpy.ndarray`
        will be returned.

    See Also
    --------
    biweight_scale, biweight_midvariance, biweight_midcovariance

    References
    ----------
    .. [1] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    .. [2] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwloc.htm

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight location of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_location
    >>> rand = np.random.default_rng(12345)
    >>> biloc = biweight_location(rand.standard_normal(1000))
    >>> print(biloc)    # doctest: +FLOAT_CMP
    0.01535330525461019
    masked_whereasanyarraymadsqueezeinvalidwhere_func9.0modify_sample_size
    Compute the biweight scale.

    The biweight scale is a robust statistic for determining the
    standard deviation of a distribution.  It is the square root of the
    `biweight midvariance
    <https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance>`_.
    It is given by:

    .. math::

        \zeta_{biscl} = \sqrt{n} \ \frac{\sqrt{\sum_{|u_i| < 1} \
            (x_i - M)^2 (1 - u_i^2)^4}} {|(\sum_{|u_i| < 1} \
            (1 - u_i^2) (1 - 5u_i^2))|}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input location) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight midvariance tuning constant ``c`` is typically 9.0 (the
    default).

    If :math:`MAD` is zero, then zero will be returned.

    For the standard definition of biweight scale, :math:`n` is the
    total number of points in the array (or along the input ``axis``, if
    specified).  That definition is used if ``modify_sample_size`` is
    `False`, which is the default.

    However, if ``modify_sample_size = True``, then :math:`n` is the
    number of points for which :math:`|u_i| < 1` (i.e. the total number
    of non-rejected values), i.e.

    .. math::

        n = \sum_{|u_i| < 1} \ 1

    which results in a value closer to the true standard deviation for
    small sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight scales are computed.
        If `None` (default), then the biweight scale of the flattened
        input array will be computed.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        scale.  If `True`, then the sample size is reduced to correct
        for any rejected values (i.e. the sample size used includes only
        the non-rejected values), which results in a value closer to the
        true standard deviation for small sample sizes or for a large
        number of rejected values.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_scale : float or `~numpy.ndarray`
        The biweight scale of the input data.  If ``axis`` is `None`
        then a scalar will be returned, otherwise a `~numpy.ndarray`
        will be returned.

    See Also
    --------
    biweight_midvariance, biweight_midcovariance, biweight_location, astropy.stats.mad_std, astropy.stats.median_absolute_deviation

    References
    ----------
    .. [1] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    .. [2] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwscale.htm

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight scale of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_scale
    >>> rand = np.random.default_rng(12345)
    >>> biscl = biweight_scale(rand.standard_normal(1000))
    >>> print(biscl)    # doctest: +FLOAT_CMP
    1.0239311812635818
    
    Compute the biweight midvariance.

    The biweight midvariance is a robust statistic for determining the
    variance of a distribution.  Its square root is a robust estimator
    of scale (i.e. standard deviation).  It is given by:

    .. math::

        \zeta_{bivar} = n \ \frac{\sum_{|u_i| < 1} \
            (x_i - M)^2 (1 - u_i^2)^4} {(\sum_{|u_i| < 1} \
            (1 - u_i^2) (1 - 5u_i^2))^2}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input location) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight midvariance tuning constant ``c`` is typically 9.0 (the
    default).

    If :math:`MAD` is zero, then zero will be returned.

    For the standard definition of `biweight midvariance
    <https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance>`_,
    :math:`n` is the total number of points in the array (or along the
    input ``axis``, if specified).  That definition is used if
    ``modify_sample_size`` is `False`, which is the default.

    However, if ``modify_sample_size = True``, then :math:`n` is the
    number of points for which :math:`|u_i| < 1` (i.e. the total number
    of non-rejected values), i.e.

    .. math::

        n = \sum_{|u_i| < 1} \ 1

    which results in a value closer to the true variance for small
    sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight midvariances are
        computed.  If `None` (default), then the biweight midvariance of
        the flattened input array will be computed.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        midvariance.  If `True`, then the sample size is reduced to
        correct for any rejected values (i.e. the sample size used
        includes only the non-rejected values), which results in a value
        closer to the true variance for small sample sizes or for a
        large number of rejected values.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_midvariance : float or `~numpy.ndarray`
        The biweight midvariance of the input data.  If ``axis`` is
        `None` then a scalar will be returned, otherwise a
        `~numpy.ndarray` will be returned.

    See Also
    --------
    biweight_midcovariance, biweight_midcorrelation, astropy.stats.mad_std, astropy.stats.median_absolute_deviation

    References
    ----------
    .. [1] https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance

    .. [2] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight midvariance of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midvariance
    >>> rand = np.random.default_rng(12345)
    >>> bivar = biweight_midvariance(rand.standard_normal(1000))
    >>> print(bivar)    # doctest: +FLOAT_CMP
    1.0484350639638342
    filledfill_valueinclude_maskf1f2
    Compute the biweight midcovariance between pairs of multiple
    variables.

    The biweight midcovariance is a robust and resistant estimator of
    the covariance between two variables.

    This function computes the biweight midcovariance between all pairs
    of the input variables (rows) in the input data.  The output array
    will have a shape of (N_variables, N_variables).  The diagonal
    elements will be the biweight midvariances of each input variable
    (see :func:`biweight_midvariance`).  The off-diagonal elements will
    be the biweight midcovariances between each pair of input variables.

    For example, if the input array ``data`` contains three variables
    (rows) ``x``, ``y``, and ``z``, the output `~numpy.ndarray`
    midcovariance matrix will be:

    .. math::

         \begin{pmatrix}
         \zeta_{xx}  & \zeta_{xy}  & \zeta_{xz} \\
         \zeta_{yx}  & \zeta_{yy}  & \zeta_{yz} \\
         \zeta_{zx}  & \zeta_{zy}  & \zeta_{zz}
         \end{pmatrix}

    where :math:`\zeta_{xx}`, :math:`\zeta_{yy}`, and :math:`\zeta_{zz}`
    are the biweight midvariances of each variable.  The biweight
    midcovariance between :math:`x` and :math:`y` is :math:`\zeta_{xy}`
    (:math:`= \zeta_{yx}`).  The biweight midcovariance between
    :math:`x` and :math:`z` is :math:`\zeta_{xz}` (:math:`=
    \zeta_{zx}`).  The biweight midcovariance between :math:`y` and
    :math:`z` is :math:`\zeta_{yz}` (:math:`= \zeta_{zy}`).

    The biweight midcovariance between two variables :math:`x` and
    :math:`y` is given by:

    .. math::

        \zeta_{xy} = n_{xy} \ \frac{\sum_{|u_i| < 1, \ |v_i| < 1} \
            (x_i - M_x) (1 - u_i^2)^2 (y_i - M_y) (1 - v_i^2)^2}
            {(\sum_{|u_i| < 1} \ (1 - u_i^2) (1 - 5u_i^2))
            (\sum_{|v_i| < 1} \ (1 - v_i^2) (1 - 5v_i^2))}

    where :math:`M_x` and :math:`M_y` are the medians (or the input
    locations) of the two variables and :math:`u_i` and :math:`v_i` are
    given by:

    .. math::

        u_{i} = \frac{(x_i - M_x)}{c * MAD_x}

        v_{i} = \frac{(y_i - M_y)}{c * MAD_y}

    where :math:`c` is the biweight tuning constant and :math:`MAD_x`
    and :math:`MAD_y` are the `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_ of the
    :math:`x` and :math:`y` variables.  The biweight midvariance tuning
    constant ``c`` is typically 9.0 (the default).

    If :math:`MAD_x` or :math:`MAD_y` are zero, then zero will be
    returned for that element.

    For the standard definition of biweight midcovariance,
    :math:`n_{xy}` is the total number of observations of each variable.
    That definition is used if ``modify_sample_size`` is `False`, which
    is the default.

    However, if ``modify_sample_size = True``, then :math:`n_{xy}` is the
    number of observations for which :math:`|u_i| < 1` and/or :math:`|v_i|
    < 1`, i.e.

    .. math::

        n_{xx} = \sum_{|u_i| < 1} \ 1

    .. math::

        n_{xy} = n_{yx} = \sum_{|u_i| < 1, \ |v_i| < 1} \ 1

    .. math::

        n_{yy} = \sum_{|v_i| < 1} \ 1

    which results in a value closer to the true variance for small
    sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : 2D or 1D array-like
        Input data either as a 2D or 1D array.  For a 2D array, it
        should have a shape (N_variables, N_observations).  A 1D array
        may be input for observations of a single variable, in which
        case the biweight midvariance will be calculated (no
        covariance).  Each row of ``data`` represents a variable, and
        each column a single observation of all those variables (same as
        the `numpy.cov` convention).

    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).

    M : float or 1D array-like, optional
        The location estimate of each variable, either as a scalar or
        array.  If ``M`` is an array, then its must be a 1D array
        containing the location estimate of each row (i.e. ``a.ndim``
        elements).  If ``M`` is a scalar value, then its value will be
        used for each variable (row).  If `None` (default), then the
        median of each variable (row) will be used.

    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of observations of each variable, which follows the
        standard definition of biweight midcovariance.  If `True`, then
        the sample size is reduced to correct for any rejected values
        (see formula above), which results in a value closer to the true
        covariance for small sample sizes or for a large number of
        rejected values.

    Returns
    -------
    biweight_midcovariance : ndarray
        A 2D array representing the biweight midcovariances between each
        pair of the variables (rows) in the input array.  The output
        array will have a shape of (N_variables, N_variables).  The
        diagonal elements will be the biweight midvariances of each
        input variable.  The off-diagonal elements will be the biweight
        midcovariances between each pair of input variables.

    See Also
    --------
    biweight_midvariance, biweight_midcorrelation, biweight_scale, biweight_location

    References
    ----------
    .. [1] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwmidc.htm

    Examples
    --------
    Compute the biweight midcovariance between two random variables:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midcovariance
    >>> # Generate two random variables x and y
    >>> rng = np.random.default_rng(1)
    >>> x = rng.normal(0, 1, 200)
    >>> y = rng.normal(0, 3, 200)
    >>> # Introduce an obvious outlier
    >>> x[0] = 30.0
    >>> # Calculate the biweight midcovariances between x and y
    >>> bicov = biweight_midcovariance([x, y])
    >>> print(bicov)  # doctest: +FLOAT_CMP
    [[0.83435568 0.02379316]
     [0.02379316 7.15665769]]
    >>> # Print standard deviation estimates
    >>> print(np.sqrt(bicov.diagonal()))  # doctest: +FLOAT_CMP
    [0.91343072 2.67519302]
    newaxisThe input array must be 2D or 1D.M must be a scalar or 1D array.maskfinnerusub1usub5numerator_matrixdenominator_matrix
    Compute the biweight midcorrelation between two variables.

    The `biweight midcorrelation
    <https://en.wikipedia.org/wiki/Biweight_midcorrelation>`_ is a
    measure of similarity between samples.  It is given by:

    .. math::

        r_{bicorr} = \frac{\zeta_{xy}}{\sqrt{\zeta_{xx} \ \zeta_{yy}}}

    where :math:`\zeta_{xx}` is the biweight midvariance of :math:`x`,
    :math:`\zeta_{yy}` is the biweight midvariance of :math:`y`, and
    :math:`\zeta_{xy}` is the biweight midcovariance of :math:`x` and
    :math:`y`.

    Parameters
    ----------
    x, y : 1D array-like
        Input arrays for the two variables.  ``x`` and ``y`` must be 1D
        arrays and have the same number of elements.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).  See
        `biweight_midcovariance` for more details.
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).  See
        `biweight_midcovariance` for more details.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        midcovariance.  If `True`, then the sample size is reduced to
        correct for any rejected values (i.e. the sample size used
        includes only the non-rejected values), which results in a value
        closer to the true midcovariance for small sample sizes or for a
        large number of rejected values.  See `biweight_midcovariance`
        for more details.

    Returns
    -------
    biweight_midcorrelation : float
        The biweight midcorrelation between ``x`` and ``y``.

    See Also
    --------
    biweight_scale, biweight_midvariance, biweight_midcovariance, biweight_location

    References
    ----------
    .. [1] https://en.wikipedia.org/wiki/Biweight_midcorrelation

    Examples
    --------
    Calculate the biweight midcorrelation between two variables:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midcorrelation
    >>> rng = np.random.default_rng(12345)
    >>> x = rng.normal(0, 1, 200)
    >>> y = rng.normal(0, 3, 200)
    >>> # Introduce an obvious outlier
    >>> x[0] = 30.0
    >>> bicorr = biweight_midcorrelation(x, y)
    >>> print(bicorr)  # doctest: +FLOAT_CMP
    -0.09203238319481295
    x must be a 1D array.y must be a 1D array.x and y must have the same shape.bicorr# TODO: typing: update return Callables with custom callback protocol (https://mypy.readthedocs.io/en/stable/protocols.html#callback-protocols)# set up the differences# set up the weighting# np.ndim(mad) = 0 means axis is None or contains all axes# mad = 0 means data is constant or mostly constant# mad = np.nan means data contains NaNs and ignore_nan=False# now remove the outlier points# ignore RuntimeWarnings for comparisons with NaN data values# If mad == 0 along the specified ``axis`` in the input data, return# the median value along that axis.# Ignore RuntimeWarnings for divide by zero# return MaskedArray# variance units# exclude masked data values# set good values to 1, bad values to 0# 0.0 along that axis.# Ignore RuntimeWarnings for divide by zero.# ensure data is 2D# estimate location if not givenb'
This module contains functions for computing robust statistics using
Tukey's biweight function.
'u'
This module contains functions for computing robust statistics using
Tukey's biweight function.
'b'biweight_location'u'biweight_location'b'biweight_midcorrelation'u'biweight_midcorrelation'b'biweight_midcovariance'u'biweight_midcovariance'b'biweight_midvariance'u'biweight_midvariance'b'biweight_scale'u'biweight_scale'b'
    Compute the biweight location.

    The biweight location is a robust statistic for determining the
    central location of a distribution.  It is given by:

    .. math::

        \zeta_{biloc}= M + \frac{\sum_{|u_i|<1} \ (x_i - M) (1 - u_i^2)^2}
            {\sum_{|u_i|<1} \ (1 - u_i^2)^2}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input initial location guess) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight location tuning constant ``c`` is typically 6.0 (the
    default).

    If :math:`MAD` is zero, then the median will be returned.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 6.0).
    M : float or array-like, optional
        Initial guess for the location.  If ``M`` is a scalar value,
        then its value will be used for the entire array (or along each
        ``axis``, if specified).  If ``M`` is an array, then its must be
        an array containing the initial location estimate along each
        ``axis`` of the input array.  If `None` (default), then the
        median of the input array will be used (or along each ``axis``,
        if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight locations are
        computed.  If `None` (default), then the biweight location of
        the flattened input array will be computed.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_location : float or `~numpy.ndarray`
        The biweight location of the input data.  If ``axis`` is `None`
        then a scalar will be returned, otherwise a `~numpy.ndarray`
        will be returned.

    See Also
    --------
    biweight_scale, biweight_midvariance, biweight_midcovariance

    References
    ----------
    .. [1] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    .. [2] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwloc.htm

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight location of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_location
    >>> rand = np.random.default_rng(12345)
    >>> biloc = biweight_location(rand.standard_normal(1000))
    >>> print(biloc)    # doctest: +FLOAT_CMP
    0.01535330525461019
    'u'
    Compute the biweight location.

    The biweight location is a robust statistic for determining the
    central location of a distribution.  It is given by:

    .. math::

        \zeta_{biloc}= M + \frac{\sum_{|u_i|<1} \ (x_i - M) (1 - u_i^2)^2}
            {\sum_{|u_i|<1} \ (1 - u_i^2)^2}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input initial location guess) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight location tuning constant ``c`` is typically 6.0 (the
    default).

    If :math:`MAD` is zero, then the median will be returned.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 6.0).
    M : float or array-like, optional
        Initial guess for the location.  If ``M`` is a scalar value,
        then its value will be used for the entire array (or along each
        ``axis``, if specified).  If ``M`` is an array, then its must be
        an array containing the initial location estimate along each
        ``axis`` of the input array.  If `None` (default), then the
        median of the input array will be used (or along each ``axis``,
        if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight locations are
        computed.  If `None` (default), then the biweight location of
        the flattened input array will be computed.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_location : float or `~numpy.ndarray`
        The biweight location of the input data.  If ``axis`` is `None`
        then a scalar will be returned, otherwise a `~numpy.ndarray`
        will be returned.

    See Also
    --------
    biweight_scale, biweight_midvariance, biweight_midcovariance

    References
    ----------
    .. [1] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    .. [2] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwloc.htm

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight location of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_location
    >>> rand = np.random.default_rng(12345)
    >>> biloc = biweight_location(rand.standard_normal(1000))
    >>> print(biloc)    # doctest: +FLOAT_CMP
    0.01535330525461019
    'b'
    Compute the biweight scale.

    The biweight scale is a robust statistic for determining the
    standard deviation of a distribution.  It is the square root of the
    `biweight midvariance
    <https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance>`_.
    It is given by:

    .. math::

        \zeta_{biscl} = \sqrt{n} \ \frac{\sqrt{\sum_{|u_i| < 1} \
            (x_i - M)^2 (1 - u_i^2)^4}} {|(\sum_{|u_i| < 1} \
            (1 - u_i^2) (1 - 5u_i^2))|}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input location) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight midvariance tuning constant ``c`` is typically 9.0 (the
    default).

    If :math:`MAD` is zero, then zero will be returned.

    For the standard definition of biweight scale, :math:`n` is the
    total number of points in the array (or along the input ``axis``, if
    specified).  That definition is used if ``modify_sample_size`` is
    `False`, which is the default.

    However, if ``modify_sample_size = True``, then :math:`n` is the
    number of points for which :math:`|u_i| < 1` (i.e. the total number
    of non-rejected values), i.e.

    .. math::

        n = \sum_{|u_i| < 1} \ 1

    which results in a value closer to the true standard deviation for
    small sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight scales are computed.
        If `None` (default), then the biweight scale of the flattened
        input array will be computed.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        scale.  If `True`, then the sample size is reduced to correct
        for any rejected values (i.e. the sample size used includes only
        the non-rejected values), which results in a value closer to the
        true standard deviation for small sample sizes or for a large
        number of rejected values.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_scale : float or `~numpy.ndarray`
        The biweight scale of the input data.  If ``axis`` is `None`
        then a scalar will be returned, otherwise a `~numpy.ndarray`
        will be returned.

    See Also
    --------
    biweight_midvariance, biweight_midcovariance, biweight_location, astropy.stats.mad_std, astropy.stats.median_absolute_deviation

    References
    ----------
    .. [1] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    .. [2] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwscale.htm

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight scale of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_scale
    >>> rand = np.random.default_rng(12345)
    >>> biscl = biweight_scale(rand.standard_normal(1000))
    >>> print(biscl)    # doctest: +FLOAT_CMP
    1.0239311812635818
    'u'
    Compute the biweight scale.

    The biweight scale is a robust statistic for determining the
    standard deviation of a distribution.  It is the square root of the
    `biweight midvariance
    <https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance>`_.
    It is given by:

    .. math::

        \zeta_{biscl} = \sqrt{n} \ \frac{\sqrt{\sum_{|u_i| < 1} \
            (x_i - M)^2 (1 - u_i^2)^4}} {|(\sum_{|u_i| < 1} \
            (1 - u_i^2) (1 - 5u_i^2))|}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input location) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight midvariance tuning constant ``c`` is typically 9.0 (the
    default).

    If :math:`MAD` is zero, then zero will be returned.

    For the standard definition of biweight scale, :math:`n` is the
    total number of points in the array (or along the input ``axis``, if
    specified).  That definition is used if ``modify_sample_size`` is
    `False`, which is the default.

    However, if ``modify_sample_size = True``, then :math:`n` is the
    number of points for which :math:`|u_i| < 1` (i.e. the total number
    of non-rejected values), i.e.

    .. math::

        n = \sum_{|u_i| < 1} \ 1

    which results in a value closer to the true standard deviation for
    small sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight scales are computed.
        If `None` (default), then the biweight scale of the flattened
        input array will be computed.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        scale.  If `True`, then the sample size is reduced to correct
        for any rejected values (i.e. the sample size used includes only
        the non-rejected values), which results in a value closer to the
        true standard deviation for small sample sizes or for a large
        number of rejected values.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_scale : float or `~numpy.ndarray`
        The biweight scale of the input data.  If ``axis`` is `None`
        then a scalar will be returned, otherwise a `~numpy.ndarray`
        will be returned.

    See Also
    --------
    biweight_midvariance, biweight_midcovariance, biweight_location, astropy.stats.mad_std, astropy.stats.median_absolute_deviation

    References
    ----------
    .. [1] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    .. [2] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwscale.htm

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight scale of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_scale
    >>> rand = np.random.default_rng(12345)
    >>> biscl = biweight_scale(rand.standard_normal(1000))
    >>> print(biscl)    # doctest: +FLOAT_CMP
    1.0239311812635818
    'b'
    Compute the biweight midvariance.

    The biweight midvariance is a robust statistic for determining the
    variance of a distribution.  Its square root is a robust estimator
    of scale (i.e. standard deviation).  It is given by:

    .. math::

        \zeta_{bivar} = n \ \frac{\sum_{|u_i| < 1} \
            (x_i - M)^2 (1 - u_i^2)^4} {(\sum_{|u_i| < 1} \
            (1 - u_i^2) (1 - 5u_i^2))^2}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input location) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight midvariance tuning constant ``c`` is typically 9.0 (the
    default).

    If :math:`MAD` is zero, then zero will be returned.

    For the standard definition of `biweight midvariance
    <https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance>`_,
    :math:`n` is the total number of points in the array (or along the
    input ``axis``, if specified).  That definition is used if
    ``modify_sample_size`` is `False`, which is the default.

    However, if ``modify_sample_size = True``, then :math:`n` is the
    number of points for which :math:`|u_i| < 1` (i.e. the total number
    of non-rejected values), i.e.

    .. math::

        n = \sum_{|u_i| < 1} \ 1

    which results in a value closer to the true variance for small
    sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight midvariances are
        computed.  If `None` (default), then the biweight midvariance of
        the flattened input array will be computed.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        midvariance.  If `True`, then the sample size is reduced to
        correct for any rejected values (i.e. the sample size used
        includes only the non-rejected values), which results in a value
        closer to the true variance for small sample sizes or for a
        large number of rejected values.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_midvariance : float or `~numpy.ndarray`
        The biweight midvariance of the input data.  If ``axis`` is
        `None` then a scalar will be returned, otherwise a
        `~numpy.ndarray` will be returned.

    See Also
    --------
    biweight_midcovariance, biweight_midcorrelation, astropy.stats.mad_std, astropy.stats.median_absolute_deviation

    References
    ----------
    .. [1] https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance

    .. [2] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight midvariance of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midvariance
    >>> rand = np.random.default_rng(12345)
    >>> bivar = biweight_midvariance(rand.standard_normal(1000))
    >>> print(bivar)    # doctest: +FLOAT_CMP
    1.0484350639638342
    'u'
    Compute the biweight midvariance.

    The biweight midvariance is a robust statistic for determining the
    variance of a distribution.  Its square root is a robust estimator
    of scale (i.e. standard deviation).  It is given by:

    .. math::

        \zeta_{bivar} = n \ \frac{\sum_{|u_i| < 1} \
            (x_i - M)^2 (1 - u_i^2)^4} {(\sum_{|u_i| < 1} \
            (1 - u_i^2) (1 - 5u_i^2))^2}

    where :math:`x` is the input data, :math:`M` is the sample median
    (or the input location) and :math:`u_i` is given by:

    .. math::

        u_{i} = \frac{(x_i - M)}{c * MAD}

    where :math:`c` is the tuning constant and :math:`MAD` is the
    `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_.  The
    biweight midvariance tuning constant ``c`` is typically 9.0 (the
    default).

    If :math:`MAD` is zero, then zero will be returned.

    For the standard definition of `biweight midvariance
    <https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance>`_,
    :math:`n` is the total number of points in the array (or along the
    input ``axis``, if specified).  That definition is used if
    ``modify_sample_size`` is `False`, which is the default.

    However, if ``modify_sample_size = True``, then :math:`n` is the
    number of points for which :math:`|u_i| < 1` (i.e. the total number
    of non-rejected values), i.e.

    .. math::

        n = \sum_{|u_i| < 1} \ 1

    which results in a value closer to the true variance for small
    sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : array-like
        Input array or object that can be converted to an array.
        ``data`` can be a `~numpy.ma.MaskedArray`.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).
    axis : int or tuple of int, optional
        The axis or axes along which the biweight midvariances are
        computed.  If `None` (default), then the biweight midvariance of
        the flattened input array will be computed.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        midvariance.  If `True`, then the sample size is reduced to
        correct for any rejected values (i.e. the sample size used
        includes only the non-rejected values), which results in a value
        closer to the true variance for small sample sizes or for a
        large number of rejected values.
    ignore_nan : bool, optional
        Whether to ignore NaN values in the input ``data``.

    Returns
    -------
    biweight_midvariance : float or `~numpy.ndarray`
        The biweight midvariance of the input data.  If ``axis`` is
        `None` then a scalar will be returned, otherwise a
        `~numpy.ndarray` will be returned.

    See Also
    --------
    biweight_midcovariance, biweight_midcorrelation, astropy.stats.mad_std, astropy.stats.median_absolute_deviation

    References
    ----------
    .. [1] https://en.wikipedia.org/wiki/Robust_measures_of_scale#The_biweight_midvariance

    .. [2] Beers, Flynn, and Gebhardt (1990; AJ 100, 32) (https://ui.adsabs.harvard.edu/abs/1990AJ....100...32B)

    Examples
    --------
    Generate random variates from a Gaussian distribution and return the
    biweight midvariance of the distribution:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midvariance
    >>> rand = np.random.default_rng(12345)
    >>> bivar = biweight_midvariance(rand.standard_normal(1000))
    >>> print(bivar)    # doctest: +FLOAT_CMP
    1.0484350639638342
    'b'
    Compute the biweight midcovariance between pairs of multiple
    variables.

    The biweight midcovariance is a robust and resistant estimator of
    the covariance between two variables.

    This function computes the biweight midcovariance between all pairs
    of the input variables (rows) in the input data.  The output array
    will have a shape of (N_variables, N_variables).  The diagonal
    elements will be the biweight midvariances of each input variable
    (see :func:`biweight_midvariance`).  The off-diagonal elements will
    be the biweight midcovariances between each pair of input variables.

    For example, if the input array ``data`` contains three variables
    (rows) ``x``, ``y``, and ``z``, the output `~numpy.ndarray`
    midcovariance matrix will be:

    .. math::

         \begin{pmatrix}
         \zeta_{xx}  & \zeta_{xy}  & \zeta_{xz} \\
         \zeta_{yx}  & \zeta_{yy}  & \zeta_{yz} \\
         \zeta_{zx}  & \zeta_{zy}  & \zeta_{zz}
         \end{pmatrix}

    where :math:`\zeta_{xx}`, :math:`\zeta_{yy}`, and :math:`\zeta_{zz}`
    are the biweight midvariances of each variable.  The biweight
    midcovariance between :math:`x` and :math:`y` is :math:`\zeta_{xy}`
    (:math:`= \zeta_{yx}`).  The biweight midcovariance between
    :math:`x` and :math:`z` is :math:`\zeta_{xz}` (:math:`=
    \zeta_{zx}`).  The biweight midcovariance between :math:`y` and
    :math:`z` is :math:`\zeta_{yz}` (:math:`= \zeta_{zy}`).

    The biweight midcovariance between two variables :math:`x` and
    :math:`y` is given by:

    .. math::

        \zeta_{xy} = n_{xy} \ \frac{\sum_{|u_i| < 1, \ |v_i| < 1} \
            (x_i - M_x) (1 - u_i^2)^2 (y_i - M_y) (1 - v_i^2)^2}
            {(\sum_{|u_i| < 1} \ (1 - u_i^2) (1 - 5u_i^2))
            (\sum_{|v_i| < 1} \ (1 - v_i^2) (1 - 5v_i^2))}

    where :math:`M_x` and :math:`M_y` are the medians (or the input
    locations) of the two variables and :math:`u_i` and :math:`v_i` are
    given by:

    .. math::

        u_{i} = \frac{(x_i - M_x)}{c * MAD_x}

        v_{i} = \frac{(y_i - M_y)}{c * MAD_y}

    where :math:`c` is the biweight tuning constant and :math:`MAD_x`
    and :math:`MAD_y` are the `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_ of the
    :math:`x` and :math:`y` variables.  The biweight midvariance tuning
    constant ``c`` is typically 9.0 (the default).

    If :math:`MAD_x` or :math:`MAD_y` are zero, then zero will be
    returned for that element.

    For the standard definition of biweight midcovariance,
    :math:`n_{xy}` is the total number of observations of each variable.
    That definition is used if ``modify_sample_size`` is `False`, which
    is the default.

    However, if ``modify_sample_size = True``, then :math:`n_{xy}` is the
    number of observations for which :math:`|u_i| < 1` and/or :math:`|v_i|
    < 1`, i.e.

    .. math::

        n_{xx} = \sum_{|u_i| < 1} \ 1

    .. math::

        n_{xy} = n_{yx} = \sum_{|u_i| < 1, \ |v_i| < 1} \ 1

    .. math::

        n_{yy} = \sum_{|v_i| < 1} \ 1

    which results in a value closer to the true variance for small
    sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : 2D or 1D array-like
        Input data either as a 2D or 1D array.  For a 2D array, it
        should have a shape (N_variables, N_observations).  A 1D array
        may be input for observations of a single variable, in which
        case the biweight midvariance will be calculated (no
        covariance).  Each row of ``data`` represents a variable, and
        each column a single observation of all those variables (same as
        the `numpy.cov` convention).

    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).

    M : float or 1D array-like, optional
        The location estimate of each variable, either as a scalar or
        array.  If ``M`` is an array, then its must be a 1D array
        containing the location estimate of each row (i.e. ``a.ndim``
        elements).  If ``M`` is a scalar value, then its value will be
        used for each variable (row).  If `None` (default), then the
        median of each variable (row) will be used.

    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of observations of each variable, which follows the
        standard definition of biweight midcovariance.  If `True`, then
        the sample size is reduced to correct for any rejected values
        (see formula above), which results in a value closer to the true
        covariance for small sample sizes or for a large number of
        rejected values.

    Returns
    -------
    biweight_midcovariance : ndarray
        A 2D array representing the biweight midcovariances between each
        pair of the variables (rows) in the input array.  The output
        array will have a shape of (N_variables, N_variables).  The
        diagonal elements will be the biweight midvariances of each
        input variable.  The off-diagonal elements will be the biweight
        midcovariances between each pair of input variables.

    See Also
    --------
    biweight_midvariance, biweight_midcorrelation, biweight_scale, biweight_location

    References
    ----------
    .. [1] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwmidc.htm

    Examples
    --------
    Compute the biweight midcovariance between two random variables:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midcovariance
    >>> # Generate two random variables x and y
    >>> rng = np.random.default_rng(1)
    >>> x = rng.normal(0, 1, 200)
    >>> y = rng.normal(0, 3, 200)
    >>> # Introduce an obvious outlier
    >>> x[0] = 30.0
    >>> # Calculate the biweight midcovariances between x and y
    >>> bicov = biweight_midcovariance([x, y])
    >>> print(bicov)  # doctest: +FLOAT_CMP
    [[0.83435568 0.02379316]
     [0.02379316 7.15665769]]
    >>> # Print standard deviation estimates
    >>> print(np.sqrt(bicov.diagonal()))  # doctest: +FLOAT_CMP
    [0.91343072 2.67519302]
    'u'
    Compute the biweight midcovariance between pairs of multiple
    variables.

    The biweight midcovariance is a robust and resistant estimator of
    the covariance between two variables.

    This function computes the biweight midcovariance between all pairs
    of the input variables (rows) in the input data.  The output array
    will have a shape of (N_variables, N_variables).  The diagonal
    elements will be the biweight midvariances of each input variable
    (see :func:`biweight_midvariance`).  The off-diagonal elements will
    be the biweight midcovariances between each pair of input variables.

    For example, if the input array ``data`` contains three variables
    (rows) ``x``, ``y``, and ``z``, the output `~numpy.ndarray`
    midcovariance matrix will be:

    .. math::

         \begin{pmatrix}
         \zeta_{xx}  & \zeta_{xy}  & \zeta_{xz} \\
         \zeta_{yx}  & \zeta_{yy}  & \zeta_{yz} \\
         \zeta_{zx}  & \zeta_{zy}  & \zeta_{zz}
         \end{pmatrix}

    where :math:`\zeta_{xx}`, :math:`\zeta_{yy}`, and :math:`\zeta_{zz}`
    are the biweight midvariances of each variable.  The biweight
    midcovariance between :math:`x` and :math:`y` is :math:`\zeta_{xy}`
    (:math:`= \zeta_{yx}`).  The biweight midcovariance between
    :math:`x` and :math:`z` is :math:`\zeta_{xz}` (:math:`=
    \zeta_{zx}`).  The biweight midcovariance between :math:`y` and
    :math:`z` is :math:`\zeta_{yz}` (:math:`= \zeta_{zy}`).

    The biweight midcovariance between two variables :math:`x` and
    :math:`y` is given by:

    .. math::

        \zeta_{xy} = n_{xy} \ \frac{\sum_{|u_i| < 1, \ |v_i| < 1} \
            (x_i - M_x) (1 - u_i^2)^2 (y_i - M_y) (1 - v_i^2)^2}
            {(\sum_{|u_i| < 1} \ (1 - u_i^2) (1 - 5u_i^2))
            (\sum_{|v_i| < 1} \ (1 - v_i^2) (1 - 5v_i^2))}

    where :math:`M_x` and :math:`M_y` are the medians (or the input
    locations) of the two variables and :math:`u_i` and :math:`v_i` are
    given by:

    .. math::

        u_{i} = \frac{(x_i - M_x)}{c * MAD_x}

        v_{i} = \frac{(y_i - M_y)}{c * MAD_y}

    where :math:`c` is the biweight tuning constant and :math:`MAD_x`
    and :math:`MAD_y` are the `median absolute deviation
    <https://en.wikipedia.org/wiki/Median_absolute_deviation>`_ of the
    :math:`x` and :math:`y` variables.  The biweight midvariance tuning
    constant ``c`` is typically 9.0 (the default).

    If :math:`MAD_x` or :math:`MAD_y` are zero, then zero will be
    returned for that element.

    For the standard definition of biweight midcovariance,
    :math:`n_{xy}` is the total number of observations of each variable.
    That definition is used if ``modify_sample_size`` is `False`, which
    is the default.

    However, if ``modify_sample_size = True``, then :math:`n_{xy}` is the
    number of observations for which :math:`|u_i| < 1` and/or :math:`|v_i|
    < 1`, i.e.

    .. math::

        n_{xx} = \sum_{|u_i| < 1} \ 1

    .. math::

        n_{xy} = n_{yx} = \sum_{|u_i| < 1, \ |v_i| < 1} \ 1

    .. math::

        n_{yy} = \sum_{|v_i| < 1} \ 1

    which results in a value closer to the true variance for small
    sample sizes or for a large number of rejected values.

    Parameters
    ----------
    data : 2D or 1D array-like
        Input data either as a 2D or 1D array.  For a 2D array, it
        should have a shape (N_variables, N_observations).  A 1D array
        may be input for observations of a single variable, in which
        case the biweight midvariance will be calculated (no
        covariance).  Each row of ``data`` represents a variable, and
        each column a single observation of all those variables (same as
        the `numpy.cov` convention).

    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).

    M : float or 1D array-like, optional
        The location estimate of each variable, either as a scalar or
        array.  If ``M`` is an array, then its must be a 1D array
        containing the location estimate of each row (i.e. ``a.ndim``
        elements).  If ``M`` is a scalar value, then its value will be
        used for each variable (row).  If `None` (default), then the
        median of each variable (row) will be used.

    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of observations of each variable, which follows the
        standard definition of biweight midcovariance.  If `True`, then
        the sample size is reduced to correct for any rejected values
        (see formula above), which results in a value closer to the true
        covariance for small sample sizes or for a large number of
        rejected values.

    Returns
    -------
    biweight_midcovariance : ndarray
        A 2D array representing the biweight midcovariances between each
        pair of the variables (rows) in the input array.  The output
        array will have a shape of (N_variables, N_variables).  The
        diagonal elements will be the biweight midvariances of each
        input variable.  The off-diagonal elements will be the biweight
        midcovariances between each pair of input variables.

    See Also
    --------
    biweight_midvariance, biweight_midcorrelation, biweight_scale, biweight_location

    References
    ----------
    .. [1] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/biwmidc.htm

    Examples
    --------
    Compute the biweight midcovariance between two random variables:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midcovariance
    >>> # Generate two random variables x and y
    >>> rng = np.random.default_rng(1)
    >>> x = rng.normal(0, 1, 200)
    >>> y = rng.normal(0, 3, 200)
    >>> # Introduce an obvious outlier
    >>> x[0] = 30.0
    >>> # Calculate the biweight midcovariances between x and y
    >>> bicov = biweight_midcovariance([x, y])
    >>> print(bicov)  # doctest: +FLOAT_CMP
    [[0.83435568 0.02379316]
     [0.02379316 7.15665769]]
    >>> # Print standard deviation estimates
    >>> print(np.sqrt(bicov.diagonal()))  # doctest: +FLOAT_CMP
    [0.91343072 2.67519302]
    'b'The input array must be 2D or 1D.'u'The input array must be 2D or 1D.'b'M must be a scalar or 1D array.'u'M must be a scalar or 1D array.'b'
    Compute the biweight midcorrelation between two variables.

    The `biweight midcorrelation
    <https://en.wikipedia.org/wiki/Biweight_midcorrelation>`_ is a
    measure of similarity between samples.  It is given by:

    .. math::

        r_{bicorr} = \frac{\zeta_{xy}}{\sqrt{\zeta_{xx} \ \zeta_{yy}}}

    where :math:`\zeta_{xx}` is the biweight midvariance of :math:`x`,
    :math:`\zeta_{yy}` is the biweight midvariance of :math:`y`, and
    :math:`\zeta_{xy}` is the biweight midcovariance of :math:`x` and
    :math:`y`.

    Parameters
    ----------
    x, y : 1D array-like
        Input arrays for the two variables.  ``x`` and ``y`` must be 1D
        arrays and have the same number of elements.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).  See
        `biweight_midcovariance` for more details.
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).  See
        `biweight_midcovariance` for more details.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        midcovariance.  If `True`, then the sample size is reduced to
        correct for any rejected values (i.e. the sample size used
        includes only the non-rejected values), which results in a value
        closer to the true midcovariance for small sample sizes or for a
        large number of rejected values.  See `biweight_midcovariance`
        for more details.

    Returns
    -------
    biweight_midcorrelation : float
        The biweight midcorrelation between ``x`` and ``y``.

    See Also
    --------
    biweight_scale, biweight_midvariance, biweight_midcovariance, biweight_location

    References
    ----------
    .. [1] https://en.wikipedia.org/wiki/Biweight_midcorrelation

    Examples
    --------
    Calculate the biweight midcorrelation between two variables:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midcorrelation
    >>> rng = np.random.default_rng(12345)
    >>> x = rng.normal(0, 1, 200)
    >>> y = rng.normal(0, 3, 200)
    >>> # Introduce an obvious outlier
    >>> x[0] = 30.0
    >>> bicorr = biweight_midcorrelation(x, y)
    >>> print(bicorr)  # doctest: +FLOAT_CMP
    -0.09203238319481295
    'u'
    Compute the biweight midcorrelation between two variables.

    The `biweight midcorrelation
    <https://en.wikipedia.org/wiki/Biweight_midcorrelation>`_ is a
    measure of similarity between samples.  It is given by:

    .. math::

        r_{bicorr} = \frac{\zeta_{xy}}{\sqrt{\zeta_{xx} \ \zeta_{yy}}}

    where :math:`\zeta_{xx}` is the biweight midvariance of :math:`x`,
    :math:`\zeta_{yy}` is the biweight midvariance of :math:`y`, and
    :math:`\zeta_{xy}` is the biweight midcovariance of :math:`x` and
    :math:`y`.

    Parameters
    ----------
    x, y : 1D array-like
        Input arrays for the two variables.  ``x`` and ``y`` must be 1D
        arrays and have the same number of elements.
    c : float, optional
        Tuning constant for the biweight estimator (default = 9.0).  See
        `biweight_midcovariance` for more details.
    M : float or array-like, optional
        The location estimate.  If ``M`` is a scalar value, then its
        value will be used for the entire array (or along each ``axis``,
        if specified).  If ``M`` is an array, then its must be an array
        containing the location estimate along each ``axis`` of the
        input array.  If `None` (default), then the median of the input
        array will be used (or along each ``axis``, if specified).  See
        `biweight_midcovariance` for more details.
    modify_sample_size : bool, optional
        If `False` (default), then the sample size used is the total
        number of elements in the array (or along the input ``axis``, if
        specified), which follows the standard definition of biweight
        midcovariance.  If `True`, then the sample size is reduced to
        correct for any rejected values (i.e. the sample size used
        includes only the non-rejected values), which results in a value
        closer to the true midcovariance for small sample sizes or for a
        large number of rejected values.  See `biweight_midcovariance`
        for more details.

    Returns
    -------
    biweight_midcorrelation : float
        The biweight midcorrelation between ``x`` and ``y``.

    See Also
    --------
    biweight_scale, biweight_midvariance, biweight_midcovariance, biweight_location

    References
    ----------
    .. [1] https://en.wikipedia.org/wiki/Biweight_midcorrelation

    Examples
    --------
    Calculate the biweight midcorrelation between two variables:

    >>> import numpy as np
    >>> from astropy.stats import biweight_midcorrelation
    >>> rng = np.random.default_rng(12345)
    >>> x = rng.normal(0, 1, 200)
    >>> y = rng.normal(0, 3, 200)
    >>> # Introduce an obvious outlier
    >>> x[0] = 30.0
    >>> bicorr = biweight_midcorrelation(x, y)
    >>> print(bicorr)  # doctest: +FLOAT_CMP
    -0.09203238319481295
    'b'x must be a 1D array.'u'x must be a 1D array.'b'y must be a 1D array.'u'y must be a 1D array.'b'x and y must have the same shape.'u'x and y must have the same shape.'u'astropy.stats.biweight'u'stats.biweight'u'biweight'
This module includes helper functions for array operations.
block_reduceblock_replicatereshape_as_blocks_process_block_inputsblock_sizeatleast_1dblock_size elements must be strictly positiveblock_size must be a scalar or have the same length as the number of data dimensions"block_size must be a scalar or have the same ""length as the number of data dimensions"block_size_intblock_size elements must be integers
    Reshape a data array into blocks.

    This is useful to efficiently apply functions on block subsets of
    the data instead of using loops.  The reshaped array is a view of
    the input data array.

    .. versionadded:: 4.1

    Parameters
    ----------
    data : ndarray
        The input data array.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.  Each dimension
        of ``block_size`` must divide evenly into the corresponding
        dimension of ``data``.

    Returns
    -------
    output : ndarray
        The reshaped array as a view of the input ``data`` array.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import reshape_as_blocks
    >>> data = np.arange(16).reshape(4, 4)
    >>> data
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 8,  9, 10, 11],
           [12, 13, 14, 15]])
    >>> reshape_as_blocks(data, (2, 2))
    array([[[[ 0,  1],
             [ 4,  5]],
            [[ 2,  3],
             [ 6,  7]]],
           [[[ 8,  9],
             [12, 13]],
            [[10, 11],
             [14, 15]]]])
    modEach dimension of block_size must divide evenly into the corresponding dimension of data"Each dimension of block_size must divide evenly ""into the corresponding dimension of data"nblocksnblocks_idxblock_idxtranspose
    Downsample a data array by applying a function to local blocks.

    If ``data`` is not perfectly divisible by ``block_size`` along a
    given axis then the data will be trimmed (from the end) along that
    axis.

    Parameters
    ----------
    data : array-like
        The data to be resampled.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.

    func : callable, optional
        The method to use to downsample the data. Must be a callable
        that takes in a 4D `~numpy.ndarray` (the 2D `~numpy.ndarray`
        input into `block_reduce` gets reshaped as 4D) and has an
        ``axis`` keyword that accepts tuples. This function will be
        called with ``axis=(2, 3)`` and it should return a 2D array. The
        default is `~numpy.sum`, which provides block summation (and
        conserves the data sum).

    Returns
    -------
    output : array-like
        The resampled data. Note the depending on the input ``func``,
        the dtype of the output array may not match the input array.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import block_reduce
    >>> data = np.arange(16).reshape(4, 4)
    >>> block_reduce(data, 2)  # doctest: +FLOAT_CMP
    array([[10, 18],
           [42, 50]])

    >>> block_reduce(data, 2, func=np.mean)  # doctest: +FLOAT_CMP
    array([[  2.5,   4.5],
           [ 10.5,  12.5]])
    size_initswapaxesconserve_sum
    Upsample a data array by block replication.

    Parameters
    ----------
    data : array-like
        The data to be block replicated.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.

    conserve_sum : bool, optional
        If `True` (the default) then the sum of the output
        block-replicated data will equal the sum of the input ``data``.

    Returns
    -------
    output : array-like
        The block-replicated data. Note that when ``conserve_sum`` is
        `True`, the dtype of the output array will be float.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import block_replicate
    >>> data = np.array([[0., 1.], [2., 3.]])
    >>> block_replicate(data, 2)  # doctest: +FLOAT_CMP
    array([[0.  , 0.  , 0.25, 0.25],
           [0.  , 0.  , 0.25, 0.25],
           [0.5 , 0.5 , 0.75, 0.75],
           [0.5 , 0.5 , 0.75, 0.75]])

    >>> block_replicate(data, 2, conserve_sum=False)  # doctest: +FLOAT_CMP
    array([[0., 0., 1., 1.],
           [0., 0., 1., 1.],
           [2., 2., 3., 3.],
           [2., 2., 3., 3.]])
    # e.g., 2.0 is OK, 2.1 is not# even indices# odd indices# evenly-divisible size# trim data if necessary# in-place division can fail due to dtype casting ruleb'
This module includes helper functions for array operations.
'u'
This module includes helper functions for array operations.
'b'block_reduce'u'block_reduce'b'block_replicate'u'block_replicate'b'reshape_as_blocks'u'reshape_as_blocks'b'block_size elements must be strictly positive'u'block_size elements must be strictly positive'b'block_size must be a scalar or have the same length as the number of data dimensions'u'block_size must be a scalar or have the same length as the number of data dimensions'b'block_size elements must be integers'u'block_size elements must be integers'b'
    Reshape a data array into blocks.

    This is useful to efficiently apply functions on block subsets of
    the data instead of using loops.  The reshaped array is a view of
    the input data array.

    .. versionadded:: 4.1

    Parameters
    ----------
    data : ndarray
        The input data array.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.  Each dimension
        of ``block_size`` must divide evenly into the corresponding
        dimension of ``data``.

    Returns
    -------
    output : ndarray
        The reshaped array as a view of the input ``data`` array.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import reshape_as_blocks
    >>> data = np.arange(16).reshape(4, 4)
    >>> data
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 8,  9, 10, 11],
           [12, 13, 14, 15]])
    >>> reshape_as_blocks(data, (2, 2))
    array([[[[ 0,  1],
             [ 4,  5]],
            [[ 2,  3],
             [ 6,  7]]],
           [[[ 8,  9],
             [12, 13]],
            [[10, 11],
             [14, 15]]]])
    'u'
    Reshape a data array into blocks.

    This is useful to efficiently apply functions on block subsets of
    the data instead of using loops.  The reshaped array is a view of
    the input data array.

    .. versionadded:: 4.1

    Parameters
    ----------
    data : ndarray
        The input data array.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.  Each dimension
        of ``block_size`` must divide evenly into the corresponding
        dimension of ``data``.

    Returns
    -------
    output : ndarray
        The reshaped array as a view of the input ``data`` array.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import reshape_as_blocks
    >>> data = np.arange(16).reshape(4, 4)
    >>> data
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 8,  9, 10, 11],
           [12, 13, 14, 15]])
    >>> reshape_as_blocks(data, (2, 2))
    array([[[[ 0,  1],
             [ 4,  5]],
            [[ 2,  3],
             [ 6,  7]]],
           [[[ 8,  9],
             [12, 13]],
            [[10, 11],
             [14, 15]]]])
    'b'Each dimension of block_size must divide evenly into the corresponding dimension of data'u'Each dimension of block_size must divide evenly into the corresponding dimension of data'b'
    Downsample a data array by applying a function to local blocks.

    If ``data`` is not perfectly divisible by ``block_size`` along a
    given axis then the data will be trimmed (from the end) along that
    axis.

    Parameters
    ----------
    data : array-like
        The data to be resampled.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.

    func : callable, optional
        The method to use to downsample the data. Must be a callable
        that takes in a 4D `~numpy.ndarray` (the 2D `~numpy.ndarray`
        input into `block_reduce` gets reshaped as 4D) and has an
        ``axis`` keyword that accepts tuples. This function will be
        called with ``axis=(2, 3)`` and it should return a 2D array. The
        default is `~numpy.sum`, which provides block summation (and
        conserves the data sum).

    Returns
    -------
    output : array-like
        The resampled data. Note the depending on the input ``func``,
        the dtype of the output array may not match the input array.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import block_reduce
    >>> data = np.arange(16).reshape(4, 4)
    >>> block_reduce(data, 2)  # doctest: +FLOAT_CMP
    array([[10, 18],
           [42, 50]])

    >>> block_reduce(data, 2, func=np.mean)  # doctest: +FLOAT_CMP
    array([[  2.5,   4.5],
           [ 10.5,  12.5]])
    'u'
    Downsample a data array by applying a function to local blocks.

    If ``data`` is not perfectly divisible by ``block_size`` along a
    given axis then the data will be trimmed (from the end) along that
    axis.

    Parameters
    ----------
    data : array-like
        The data to be resampled.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.

    func : callable, optional
        The method to use to downsample the data. Must be a callable
        that takes in a 4D `~numpy.ndarray` (the 2D `~numpy.ndarray`
        input into `block_reduce` gets reshaped as 4D) and has an
        ``axis`` keyword that accepts tuples. This function will be
        called with ``axis=(2, 3)`` and it should return a 2D array. The
        default is `~numpy.sum`, which provides block summation (and
        conserves the data sum).

    Returns
    -------
    output : array-like
        The resampled data. Note the depending on the input ``func``,
        the dtype of the output array may not match the input array.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import block_reduce
    >>> data = np.arange(16).reshape(4, 4)
    >>> block_reduce(data, 2)  # doctest: +FLOAT_CMP
    array([[10, 18],
           [42, 50]])

    >>> block_reduce(data, 2, func=np.mean)  # doctest: +FLOAT_CMP
    array([[  2.5,   4.5],
           [ 10.5,  12.5]])
    'b'
    Upsample a data array by block replication.

    Parameters
    ----------
    data : array-like
        The data to be block replicated.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.

    conserve_sum : bool, optional
        If `True` (the default) then the sum of the output
        block-replicated data will equal the sum of the input ``data``.

    Returns
    -------
    output : array-like
        The block-replicated data. Note that when ``conserve_sum`` is
        `True`, the dtype of the output array will be float.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import block_replicate
    >>> data = np.array([[0., 1.], [2., 3.]])
    >>> block_replicate(data, 2)  # doctest: +FLOAT_CMP
    array([[0.  , 0.  , 0.25, 0.25],
           [0.  , 0.  , 0.25, 0.25],
           [0.5 , 0.5 , 0.75, 0.75],
           [0.5 , 0.5 , 0.75, 0.75]])

    >>> block_replicate(data, 2, conserve_sum=False)  # doctest: +FLOAT_CMP
    array([[0., 0., 1., 1.],
           [0., 0., 1., 1.],
           [2., 2., 3., 3.],
           [2., 2., 3., 3.]])
    'u'
    Upsample a data array by block replication.

    Parameters
    ----------
    data : array-like
        The data to be block replicated.

    block_size : int or array-like (int)
        The integer block size along each axis.  If ``block_size`` is a
        scalar and ``data`` has more than one dimension, then
        ``block_size`` will be used for for every axis.

    conserve_sum : bool, optional
        If `True` (the default) then the sum of the output
        block-replicated data will equal the sum of the input ``data``.

    Returns
    -------
    output : array-like
        The block-replicated data. Note that when ``conserve_sum`` is
        `True`, the dtype of the output array will be float.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.nddata import block_replicate
    >>> data = np.array([[0., 1.], [2., 3.]])
    >>> block_replicate(data, 2)  # doctest: +FLOAT_CMP
    array([[0.  , 0.  , 0.25, 0.25],
           [0.  , 0.  , 0.25, 0.25],
           [0.5 , 0.5 , 0.75, 0.75],
           [0.5 , 0.5 , 0.75, 0.75]])

    >>> block_replicate(data, 2, conserve_sum=False)  # doctest: +FLOAT_CMP
    array([[0., 0., 1., 1.],
           [0., 0., 1., 1.],
           [2., 2., 3., 3.],
           [2., 2., 3., 3.]])
    'u'astropy.nddata.blocks'u'nddata.blocks'u'blocks'
This module is to contain an improved bounding box.
isiterableCompoundBoundingBoxModelBoundingBox_BaseInterval_Interval
    A single input's bounding box interval.

    Parameters
    ----------
    lower : float
        The lower bound of the interval

    upper : float
        The upper bound of the interval

    Methods
    -------
    validate :
        Constructs a valid interval

    outside :
        Determine which parts of an input array are outside the interval.

    domain :
        Constructs a discretization of the points inside the interval.
    Interval(lower=, upper=_validate_shapeValidate the shape of an interval representation.An interval must be some sort of sequence of length 2MESSAGEto_valuevalid_shape_validate_boundsValidate the bounds are reasonable and construct an interval from them.Invalid interval: upper bound  is strictly less than lower bound "is strictly less than lower bound "
        Construct and validate an interval.

        Parameters
        ----------
        interval : iterable
            A representation of the interval.

        Returns
        -------
        A validated interval.
        outside_input
        Parameters
        ----------
        _input : np.ndarray
            The evaluation input in the form of an array.

        Returns
        -------
        Boolean array indicating which parts of _input are outside the interval:
            True  -> position outside interval
            False -> position inside  interval
        logical_ordomainresolution_ignored_intervalget_index
    Get the input index corresponding to the given key.
        Can pass in either:
            the string name of the input or
            the input index itself.
    ' is not one of the inputs: Integer key:  must be non-negative and < Key value:  must be string or integer.Get the input name corresponding to the input index._BoundingDomainABC
    Base class for ModelBoundingBox and CompoundBoundingBox.
        This is where all the `~astropy.modeling.core.Model` evaluation
        code for evaluating with a bounding box is because it is common
        to both types of bounding box.

    Parameters
    ----------
    model : `~astropy.modeling.Model`
        The Model this bounding domain is for.

    prepare_inputs :
        Generates the necessary input information so that model can
        be evaluated only for input points entirely inside bounding_box.
        This needs to be implemented by a subclass. Note that most of
        the implementation is in ModelBoundingBox.

    prepare_outputs :
        Fills the output values in for any input points outside the
        bounding_box.

    evaluate :
        Performs a complete model evaluation while enforcing the bounds
        on the inputs and returns a complete output.
    Cignoredorder_model_validate_ignored_ignored_get_order_order
        Get if bounding_box is C/python ordered or Fortran/mathematically
        ordered.
        Forder must be either 'C' (C/python order) or 'F' (Fortran/mathematical order), got: "order must be either 'C' (C/python order) or ""'F' (Fortran/mathematical order), got: "_get_index
        Get the input index corresponding to the given key.
            Can pass in either:
                the string name of the input or
                the input index itself.
        _get_nameignored_inputsThis bounding box is fixed by the model and does not have adjustable parameters."This bounding box is fixed by the model and does not have ""adjustable parameters."fixed_inputs
        Fix the bounding_box for a `fix_inputs` compound model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The new model for which this will be a bounding_box
        fixed_inputs : dict
            Dictionary of inputs which have been fixed by this bounding box.
        This should be implemented by a child class.prepare_inputsinput_shape
        Get prepare the inputs with respect to the bounding box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        valid_inputs : list
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : array_like
            array of all indices inside the bounding box
        all_out: bool
            if all of the inputs are outside the bounding_box
        This has not been implemented for BoundingDomain._base_output
        Create a baseline output, assuming that the entire input is outside
        the bounding box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        An array of the correct shape containing all fill_value
        _all_out_output
        Create output if all inputs are outside the domain.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        A full set of outputs for case that all inputs are outside domain.
        n_outputs_modify_outputvalid_outputvalid_index
        For a single output fill in all the parts corresponding to inputs
        outside the bounding box.

        Parameters
        ----------
        valid_output : numpy array
            The output from the model corresponding to inputs inside the
            bounding box
        valid_index : numpy array
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        An output array with all the indices corresponding to inputs
        outside the bounding box filled in by fill_value
        _prepare_outputsvalid_outputs
        Fill in all the outputs of the model corresponding to inputs
        outside the bounding_box.

        Parameters
        ----------
        valid_outputs : list of numpy array
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        valid_index : numpy array
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        List of filled in output arrays.
        prepare_outputs
        Fill in all the outputs of the model corresponding to inputs
        outside the bounding_box, adjusting any single output model so that
        its output becomes a list of containing that output.

        Parameters
        ----------
        valid_outputs : list
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        valid_index : array_like
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        _get_valid_outputs_unitwith_units
        Get the unit for outputs if one is required.

        Parameters
        ----------
        valid_outputs : list of numpy array
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        with_units : bool
            whether or not a unit is required
        _evaluate_modelevaluatevalid_inputs
        Evaluate the model using the given evaluate routine.

        Parameters
        ----------
        evaluate : Callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list of numpy arrays
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : numpy array
            array of all indices inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        with_units : bool
            whether or not a unit is required

        Returns
        -------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs
        valid_outputs_unit_evaluateEvaluate model with steps: prepare_inputs -> evaluate -> prepare_outputs.

        Parameters
        ----------
        evaluate : Callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list of numpy arrays
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : numpy array
            array of all indices inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        with_units : bool
            whether or not a unit is required

        Returns
        -------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs
        all_out_set_outputs_unit
        Set the units on the outputs
            prepare_inputs -> evaluate -> prepare_outputs -> set output units.

        Parameters
        ----------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs

        Returns
        -------
        List containing filled in output values and units
        
        Perform full model evaluation steps:
            prepare_inputs -> evaluate -> prepare_outputs -> set output units.

        Parameters
        ----------
        evaluate : callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : array_like
            array of all indices inside the bounding box
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        bbox_with_units
    A model's bounding box.

    Parameters
    ----------
    intervals : dict
        A dictionary containing all the intervals for each model input
            keys   -> input index
            values -> interval for that index

    model : `~astropy.modeling.Model`
        The Model this bounding_box is for.

    ignored : list
        A list containing all the inputs (index) which will not be
        checked for whether or not their elements are in/out of an interval.

    order : optional, str
        The ordering that is assumed for the tuple representation of this
        bounding_box. Options: 'C': C/Python order, e.g. z, y, x.
        (default), 'F': Fortran/mathematical notation order, e.g. x, y, z.
    _intervals_validateReturn bounding_box labeled using input positions.named_intervalsReturn bounding_box labeled using input names.bboxModelBoundingBox(    intervals={    }    ignored=    model=(inputs=    order='has_intervalGet bounding_box entries by either input name or input index.bounding_box
        Return the old tuple of tuples representation of the bounding_box
            order='C' corresponds to the old bounding_box ordering
            order='F' corresponds to the gwcs bounding_box ordering.
        input_nameNote equality can be either with old representation or new one.Validate and store interval under key (input index or input name).Delete stored interval.Cannot delete ignored input: _validate_dictValidate passing dictionary of intervals and setting them._available_input_indexmodel_input_index_validate_sequence
        Validate passing tuple of tuples representation (or related) and setting them.
        _n_inputs_validate_iterableValidate and set any iterable representation.Found  intervals, but must have exactly " intervals, ""but must have exactly "Validate and set any representation._preserve_ignore
        Construct a valid bounding box for a model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be a bounding_box
        bounding_box : dict, tuple
            A possible representation of the bounding box
        order : optional, str
            The order that a tuple representation will be assumed to be
                Default: 'C'
        _keep_ignored
        Fix the bounding_box for a `fix_inputs` compound model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The new model for which this will be a bounding_box
        fixed_inputs : dict
            Dictionary of inputs which have been fixed by this bounding box.
        keep_ignored : bool
            Keep the ignored inputs of the bounding box (internal argument only)
        dimension_outside
        Get all the input positions which are outside the bounding_box,
        so that the corresponding outputs can be filled with the fill
        value (default NaN).

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        outside_index : bool-numpy array
            True  -> position outside bounding_box
            False -> position inside  bounding_box
        all_out : bool
            if all of the inputs are outside the bounding_box
        outside_index_valid_index
        Get the indices of all the inputs inside the bounding_box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        valid_index : numpy array
            array of all indices inside the bounding box
        all_out : bool
            if all of the inputs are outside the bounding_box
        valid_input_BaseSelectorArgument_SelectorArgument
    Contains a single CompoundBoundingBox slicing input.

    Parameters
    ----------
    index : int
        The index of the input in the input list

    ignore : bool
        Whether or not this input will be ignored by the bounding box.

    Methods
    -------
    validate :
        Returns a valid SelectorArgument for a given model.

    get_selector :
        Returns the value of the input for use in finding the correct
        bounding_box.

    get_fixed_value :
        Gets the slicing value from a fix_inputs set of values.
    argument
        Construct a valid selector argument for a CompoundBoundingBox.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be an argument for.
        argument : int or str
            A representation of which evaluation input to use
        ignored : optional, bool
            Whether or not to ignore this argument in the ModelBoundingBox.

        Returns
        -------
        Validated selector_argument
        get_selector
        Get the selector value corresponding to this argument.

        Parameters
        ----------
        *inputs :
            All the processed model evaluation inputs.
        _selector
        Get the name of the input described by this selector argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        pretty_repr
        Get a pretty-print representation of this object.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        Argument(name='', ignore=get_fixed_value
        Gets the value fixed input corresponding to this argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.

        values : dict
            Dictionary of fixed inputs.
         was not found in is_argument
        Determine if passed argument is described by this selector argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.

        argument : int or str
            A representation of which evaluation input is being used
        named_tuple
        Get a tuple representation of this argument using the input
        name from the model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        _SelectorArguments
    Contains the CompoundBoundingBox slicing description.

    Parameters
    ----------
    input_ :
        The SelectorArgument values

    Methods
    -------
    validate :
        Returns a valid SelectorArguments for its model.

    get_selector :
        Returns the selector a set of inputs corresponds to.

    is_selector :
        Determines if a selector is correctly formatted for this CompoundBoundingBox.

    get_fixed_value :
        Gets the selector from a fix_inputs set of values.
    _kept_ignoreinput_kept_ignore
        Get a pretty-print representation of this object.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.
        SelectorArguments(Get the list of ignored inputs.The arguments to persist in ignoring.arguments
        Construct a valid Selector description for a CompoundBoundingBox.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        arguments :
            The individual argument information

        kept_ignore :
            Arguments to persist as ignored
        thisInput: '' has been repeated.There must be at least one selector argument.
        Get the selector corresponding to these inputs.

        Parameters
        ----------
        *inputs :
            All the processed model evaluation inputs.
        is_selector
        Determine if this is a reasonable selector.

        Parameters
        ----------
        _selector : tuple
            The selector to check
        get_fixed_values
        Gets the value fixed input corresponding to this argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        values : dict
            Dictionary of fixed inputs.
        
        Determine if passed argument is one of the selector arguments.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which evaluation input is being used
        selector_argselector_index
        Get the index of the argument passed in the selector tuples.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
         does not correspond to any selector argument.
        Reduce the selector arguments by the argument given.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
        add_ignore
        Add argument to the kept_ignore list.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
        : is a selector argument and cannot be ignored.
        Get a tuple of selector argument tuples using input names.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.
        
    A model's compound bounding box.

    Parameters
    ----------
    bounding_boxes : dict
        A dictionary containing all the ModelBoundingBoxes that are possible
            keys   -> _selector (extracted from model inputs)
            values -> ModelBoundingBox

    model : `~astropy.modeling.Model`
        The Model this compound bounding_box is for.

    selector_args : _SelectorArguments
        A description of how to extract the selectors from model inputs.

    create_selector : optional
        A method which takes in the selector and the model to return a
        valid bounding corresponding to that selector. This can be used
        to construct new bounding_boxes for previously undefined selectors.
        These new boxes are then stored for future lookups.

    order : optional, str
        The ordering that is assumed for the tuple representation of the
        bounding_boxes.
    bounding_boxesselector_argscreate_selector_create_selector_selector_args_bounding_boxesselectorCompoundBoundingBox(    bounding_boxes={bbox_repr = part            selector_args_repr    selector_args = Overriding selector_args may cause problems you should re-validate the compound bounding box before use!"Overriding selector_args may cause problems you should re-validate ""the compound bounding box before use!"named_selector_tuple_get_selector_key is not a selector!kwarg
        Construct a valid compound bounding box for a model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be a bounding_box
        bounding_box : dict
            Dictionary of possible bounding_box representations
        selector_args : optional
            Description of the selector arguments
        create_selector : optional, callable
            Method for generating new selectors
        order : optional, str
            The order that a tuple representation will be assumed to be
                Default: 'C'
        Selector arguments must be provided (can be passed as part of bounding_box argument)"Selector arguments must be provided ""(can be passed as part of bounding_box argument)"_create_bounding_boxNo bounding box is defined for selector: _select_bounding_box_matching_bounding_boxesselector_keynew_selector_keynew_bboxAttempting to fix input , but there are no bounding boxes for argument value ", but there are no ""bounding boxes for argument value "_fix_input_selector_argmatching_bounding_boxes_fix_input_bbox_argfixed_input_keysnew_fixed_inputsbbox_dict# np.shape does not work with lists of Quantities# The interval where all ignored inputs can be found.# NOTE: CompoundModel does not currently support units during#   evaluation for bounding_box so this feature is turned off#   for CompoundModel(s).# If bounding_box is C/python ordered, it needs to be reversed# to be in Fortran/mathematical/input order.# bounding_boxes# selector_argsb'
This module is to contain an improved bounding box.
'u'
This module is to contain an improved bounding box.
'b'CompoundBoundingBox'u'CompoundBoundingBox'b'ModelBoundingBox'u'ModelBoundingBox'b'
    A single input's bounding box interval.

    Parameters
    ----------
    lower : float
        The lower bound of the interval

    upper : float
        The upper bound of the interval

    Methods
    -------
    validate :
        Constructs a valid interval

    outside :
        Determine which parts of an input array are outside the interval.

    domain :
        Constructs a discretization of the points inside the interval.
    'u'
    A single input's bounding box interval.

    Parameters
    ----------
    lower : float
        The lower bound of the interval

    upper : float
        The upper bound of the interval

    Methods
    -------
    validate :
        Constructs a valid interval

    outside :
        Determine which parts of an input array are outside the interval.

    domain :
        Constructs a discretization of the points inside the interval.
    'b'Interval(lower='u'Interval(lower='b', upper='u', upper='b'Validate the shape of an interval representation.'u'Validate the shape of an interval representation.'b'An interval must be some sort of sequence of length 2'u'An interval must be some sort of sequence of length 2'b'Validate the bounds are reasonable and construct an interval from them.'u'Validate the bounds are reasonable and construct an interval from them.'b'Invalid interval: upper bound 'u'Invalid interval: upper bound 'b' is strictly less than lower bound 'u' is strictly less than lower bound 'b'
        Construct and validate an interval.

        Parameters
        ----------
        interval : iterable
            A representation of the interval.

        Returns
        -------
        A validated interval.
        'u'
        Construct and validate an interval.

        Parameters
        ----------
        interval : iterable
            A representation of the interval.

        Returns
        -------
        A validated interval.
        'b'
        Parameters
        ----------
        _input : np.ndarray
            The evaluation input in the form of an array.

        Returns
        -------
        Boolean array indicating which parts of _input are outside the interval:
            True  -> position outside interval
            False -> position inside  interval
        'u'
        Parameters
        ----------
        _input : np.ndarray
            The evaluation input in the form of an array.

        Returns
        -------
        Boolean array indicating which parts of _input are outside the interval:
            True  -> position outside interval
            False -> position inside  interval
        'b'
    Get the input index corresponding to the given key.
        Can pass in either:
            the string name of the input or
            the input index itself.
    'u'
    Get the input index corresponding to the given key.
        Can pass in either:
            the string name of the input or
            the input index itself.
    'b'' is not one of the inputs: 'u'' is not one of the inputs: 'b'Integer key: 'u'Integer key: 'b' must be non-negative and < 'u' must be non-negative and < 'b'Key value: 'u'Key value: 'b' must be string or integer.'u' must be string or integer.'b'Get the input name corresponding to the input index.'u'Get the input name corresponding to the input index.'b'
    Base class for ModelBoundingBox and CompoundBoundingBox.
        This is where all the `~astropy.modeling.core.Model` evaluation
        code for evaluating with a bounding box is because it is common
        to both types of bounding box.

    Parameters
    ----------
    model : `~astropy.modeling.Model`
        The Model this bounding domain is for.

    prepare_inputs :
        Generates the necessary input information so that model can
        be evaluated only for input points entirely inside bounding_box.
        This needs to be implemented by a subclass. Note that most of
        the implementation is in ModelBoundingBox.

    prepare_outputs :
        Fills the output values in for any input points outside the
        bounding_box.

    evaluate :
        Performs a complete model evaluation while enforcing the bounds
        on the inputs and returns a complete output.
    'u'
    Base class for ModelBoundingBox and CompoundBoundingBox.
        This is where all the `~astropy.modeling.core.Model` evaluation
        code for evaluating with a bounding box is because it is common
        to both types of bounding box.

    Parameters
    ----------
    model : `~astropy.modeling.Model`
        The Model this bounding domain is for.

    prepare_inputs :
        Generates the necessary input information so that model can
        be evaluated only for input points entirely inside bounding_box.
        This needs to be implemented by a subclass. Note that most of
        the implementation is in ModelBoundingBox.

    prepare_outputs :
        Fills the output values in for any input points outside the
        bounding_box.

    evaluate :
        Performs a complete model evaluation while enforcing the bounds
        on the inputs and returns a complete output.
    'b'C'u'C'b'
        Get if bounding_box is C/python ordered or Fortran/mathematically
        ordered.
        'u'
        Get if bounding_box is C/python ordered or Fortran/mathematically
        ordered.
        'b'F'u'F'b'order must be either 'C' (C/python order) or 'F' (Fortran/mathematical order), got: 'u'order must be either 'C' (C/python order) or 'F' (Fortran/mathematical order), got: 'b'
        Get the input index corresponding to the given key.
            Can pass in either:
                the string name of the input or
                the input index itself.
        'u'
        Get the input index corresponding to the given key.
            Can pass in either:
                the string name of the input or
                the input index itself.
        'b'This bounding box is fixed by the model and does not have adjustable parameters.'u'This bounding box is fixed by the model and does not have adjustable parameters.'b'
        Fix the bounding_box for a `fix_inputs` compound model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The new model for which this will be a bounding_box
        fixed_inputs : dict
            Dictionary of inputs which have been fixed by this bounding box.
        'u'
        Fix the bounding_box for a `fix_inputs` compound model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The new model for which this will be a bounding_box
        fixed_inputs : dict
            Dictionary of inputs which have been fixed by this bounding box.
        'b'This should be implemented by a child class.'u'This should be implemented by a child class.'b'
        Get prepare the inputs with respect to the bounding box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        valid_inputs : list
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : array_like
            array of all indices inside the bounding box
        all_out: bool
            if all of the inputs are outside the bounding_box
        'u'
        Get prepare the inputs with respect to the bounding box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        valid_inputs : list
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : array_like
            array of all indices inside the bounding box
        all_out: bool
            if all of the inputs are outside the bounding_box
        'b'This has not been implemented for BoundingDomain.'u'This has not been implemented for BoundingDomain.'b'
        Create a baseline output, assuming that the entire input is outside
        the bounding box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        An array of the correct shape containing all fill_value
        'u'
        Create a baseline output, assuming that the entire input is outside
        the bounding box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        An array of the correct shape containing all fill_value
        'b'
        Create output if all inputs are outside the domain.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        A full set of outputs for case that all inputs are outside domain.
        'u'
        Create output if all inputs are outside the domain.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        A full set of outputs for case that all inputs are outside domain.
        'b'
        For a single output fill in all the parts corresponding to inputs
        outside the bounding box.

        Parameters
        ----------
        valid_output : numpy array
            The output from the model corresponding to inputs inside the
            bounding box
        valid_index : numpy array
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        An output array with all the indices corresponding to inputs
        outside the bounding box filled in by fill_value
        'u'
        For a single output fill in all the parts corresponding to inputs
        outside the bounding box.

        Parameters
        ----------
        valid_output : numpy array
            The output from the model corresponding to inputs inside the
            bounding box
        valid_index : numpy array
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        An output array with all the indices corresponding to inputs
        outside the bounding box filled in by fill_value
        'b'
        Fill in all the outputs of the model corresponding to inputs
        outside the bounding_box.

        Parameters
        ----------
        valid_outputs : list of numpy array
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        valid_index : numpy array
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        List of filled in output arrays.
        'u'
        Fill in all the outputs of the model corresponding to inputs
        outside the bounding_box.

        Parameters
        ----------
        valid_outputs : list of numpy array
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        valid_index : numpy array
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box

        Returns
        -------
        List of filled in output arrays.
        'b'
        Fill in all the outputs of the model corresponding to inputs
        outside the bounding_box, adjusting any single output model so that
        its output becomes a list of containing that output.

        Parameters
        ----------
        valid_outputs : list
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        valid_index : array_like
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        'u'
        Fill in all the outputs of the model corresponding to inputs
        outside the bounding_box, adjusting any single output model so that
        its output becomes a list of containing that output.

        Parameters
        ----------
        valid_outputs : list
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        valid_index : array_like
            array of all indices of inputs inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        'b'
        Get the unit for outputs if one is required.

        Parameters
        ----------
        valid_outputs : list of numpy array
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        with_units : bool
            whether or not a unit is required
        'u'
        Get the unit for outputs if one is required.

        Parameters
        ----------
        valid_outputs : list of numpy array
            The list of outputs from the model corresponding to inputs
            inside the bounding box
        with_units : bool
            whether or not a unit is required
        'b'
        Evaluate the model using the given evaluate routine.

        Parameters
        ----------
        evaluate : Callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list of numpy arrays
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : numpy array
            array of all indices inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        with_units : bool
            whether or not a unit is required

        Returns
        -------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs
        'u'
        Evaluate the model using the given evaluate routine.

        Parameters
        ----------
        evaluate : Callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list of numpy arrays
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : numpy array
            array of all indices inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        with_units : bool
            whether or not a unit is required

        Returns
        -------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs
        'b'Evaluate model with steps: prepare_inputs -> evaluate -> prepare_outputs.

        Parameters
        ----------
        evaluate : Callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list of numpy arrays
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : numpy array
            array of all indices inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        with_units : bool
            whether or not a unit is required

        Returns
        -------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs
        'u'Evaluate model with steps: prepare_inputs -> evaluate -> prepare_outputs.

        Parameters
        ----------
        evaluate : Callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list of numpy arrays
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : numpy array
            array of all indices inside the bounding box
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        with_units : bool
            whether or not a unit is required

        Returns
        -------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs
        'b'
        Set the units on the outputs
            prepare_inputs -> evaluate -> prepare_outputs -> set output units.

        Parameters
        ----------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs

        Returns
        -------
        List containing filled in output values and units
        'u'
        Set the units on the outputs
            prepare_inputs -> evaluate -> prepare_outputs -> set output units.

        Parameters
        ----------
        outputs :
            list containing filled in output values
        valid_outputs_unit :
            the unit that will be attached to the outputs

        Returns
        -------
        List containing filled in output values and units
        'b'
        Perform full model evaluation steps:
            prepare_inputs -> evaluate -> prepare_outputs -> set output units.

        Parameters
        ----------
        evaluate : callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : array_like
            array of all indices inside the bounding box
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        'u'
        Perform full model evaluation steps:
            prepare_inputs -> evaluate -> prepare_outputs -> set output units.

        Parameters
        ----------
        evaluate : callable
            callable which takes in the valid inputs to evaluate model
        valid_inputs : list
            The inputs reduced to just those inputs which are all inside
            their respective bounding box intervals
        valid_index : array_like
            array of all indices inside the bounding box
        fill_value : float
            The value which will be assigned to inputs which are outside
            the bounding box
        'b'
    A model's bounding box.

    Parameters
    ----------
    intervals : dict
        A dictionary containing all the intervals for each model input
            keys   -> input index
            values -> interval for that index

    model : `~astropy.modeling.Model`
        The Model this bounding_box is for.

    ignored : list
        A list containing all the inputs (index) which will not be
        checked for whether or not their elements are in/out of an interval.

    order : optional, str
        The ordering that is assumed for the tuple representation of this
        bounding_box. Options: 'C': C/Python order, e.g. z, y, x.
        (default), 'F': Fortran/mathematical notation order, e.g. x, y, z.
    'u'
    A model's bounding box.

    Parameters
    ----------
    intervals : dict
        A dictionary containing all the intervals for each model input
            keys   -> input index
            values -> interval for that index

    model : `~astropy.modeling.Model`
        The Model this bounding_box is for.

    ignored : list
        A list containing all the inputs (index) which will not be
        checked for whether or not their elements are in/out of an interval.

    order : optional, str
        The ordering that is assumed for the tuple representation of this
        bounding_box. Options: 'C': C/Python order, e.g. z, y, x.
        (default), 'F': Fortran/mathematical notation order, e.g. x, y, z.
    'b'Return bounding_box labeled using input positions.'u'Return bounding_box labeled using input positions.'b'Return bounding_box labeled using input names.'u'Return bounding_box labeled using input names.'b'ModelBoundingBox('u'ModelBoundingBox('b'    intervals={'u'    intervals={'b'    }'u'    }'b'    ignored='u'    ignored='b'    model='u'    model='b'(inputs='u'(inputs='b'    order=''u'    order=''b'Get bounding_box entries by either input name or input index.'u'Get bounding_box entries by either input name or input index.'b'
        Return the old tuple of tuples representation of the bounding_box
            order='C' corresponds to the old bounding_box ordering
            order='F' corresponds to the gwcs bounding_box ordering.
        'u'
        Return the old tuple of tuples representation of the bounding_box
            order='C' corresponds to the old bounding_box ordering
            order='F' corresponds to the gwcs bounding_box ordering.
        'b'Note equality can be either with old representation or new one.'u'Note equality can be either with old representation or new one.'b'Validate and store interval under key (input index or input name).'u'Validate and store interval under key (input index or input name).'b'Delete stored interval.'u'Delete stored interval.'b'Cannot delete ignored input: 'u'Cannot delete ignored input: 'b'Validate passing dictionary of intervals and setting them.'u'Validate passing dictionary of intervals and setting them.'b'
        Validate passing tuple of tuples representation (or related) and setting them.
        'u'
        Validate passing tuple of tuples representation (or related) and setting them.
        'b'Validate and set any iterable representation.'u'Validate and set any iterable representation.'b'Found 'u'Found 'b' intervals, but must have exactly 'u' intervals, but must have exactly 'b'Validate and set any representation.'u'Validate and set any representation.'b'
        Construct a valid bounding box for a model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be a bounding_box
        bounding_box : dict, tuple
            A possible representation of the bounding box
        order : optional, str
            The order that a tuple representation will be assumed to be
                Default: 'C'
        'u'
        Construct a valid bounding box for a model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be a bounding_box
        bounding_box : dict, tuple
            A possible representation of the bounding box
        order : optional, str
            The order that a tuple representation will be assumed to be
                Default: 'C'
        'b'
        Fix the bounding_box for a `fix_inputs` compound model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The new model for which this will be a bounding_box
        fixed_inputs : dict
            Dictionary of inputs which have been fixed by this bounding box.
        keep_ignored : bool
            Keep the ignored inputs of the bounding box (internal argument only)
        'u'
        Fix the bounding_box for a `fix_inputs` compound model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The new model for which this will be a bounding_box
        fixed_inputs : dict
            Dictionary of inputs which have been fixed by this bounding box.
        keep_ignored : bool
            Keep the ignored inputs of the bounding box (internal argument only)
        'b'
        Get all the input positions which are outside the bounding_box,
        so that the corresponding outputs can be filled with the fill
        value (default NaN).

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        outside_index : bool-numpy array
            True  -> position outside bounding_box
            False -> position inside  bounding_box
        all_out : bool
            if all of the inputs are outside the bounding_box
        'u'
        Get all the input positions which are outside the bounding_box,
        so that the corresponding outputs can be filled with the fill
        value (default NaN).

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        outside_index : bool-numpy array
            True  -> position outside bounding_box
            False -> position inside  bounding_box
        all_out : bool
            if all of the inputs are outside the bounding_box
        'b'
        Get the indices of all the inputs inside the bounding_box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        valid_index : numpy array
            array of all indices inside the bounding box
        all_out : bool
            if all of the inputs are outside the bounding_box
        'u'
        Get the indices of all the inputs inside the bounding_box.

        Parameters
        ----------
        input_shape : tuple
            The shape that all inputs have be reshaped/broadcasted into
        inputs : list
            List of all the model inputs

        Returns
        -------
        valid_index : numpy array
            array of all indices inside the bounding box
        all_out : bool
            if all of the inputs are outside the bounding_box
        'b'
    Contains a single CompoundBoundingBox slicing input.

    Parameters
    ----------
    index : int
        The index of the input in the input list

    ignore : bool
        Whether or not this input will be ignored by the bounding box.

    Methods
    -------
    validate :
        Returns a valid SelectorArgument for a given model.

    get_selector :
        Returns the value of the input for use in finding the correct
        bounding_box.

    get_fixed_value :
        Gets the slicing value from a fix_inputs set of values.
    'u'
    Contains a single CompoundBoundingBox slicing input.

    Parameters
    ----------
    index : int
        The index of the input in the input list

    ignore : bool
        Whether or not this input will be ignored by the bounding box.

    Methods
    -------
    validate :
        Returns a valid SelectorArgument for a given model.

    get_selector :
        Returns the value of the input for use in finding the correct
        bounding_box.

    get_fixed_value :
        Gets the slicing value from a fix_inputs set of values.
    'b'
        Construct a valid selector argument for a CompoundBoundingBox.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be an argument for.
        argument : int or str
            A representation of which evaluation input to use
        ignored : optional, bool
            Whether or not to ignore this argument in the ModelBoundingBox.

        Returns
        -------
        Validated selector_argument
        'u'
        Construct a valid selector argument for a CompoundBoundingBox.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be an argument for.
        argument : int or str
            A representation of which evaluation input to use
        ignored : optional, bool
            Whether or not to ignore this argument in the ModelBoundingBox.

        Returns
        -------
        Validated selector_argument
        'b'
        Get the selector value corresponding to this argument.

        Parameters
        ----------
        *inputs :
            All the processed model evaluation inputs.
        'u'
        Get the selector value corresponding to this argument.

        Parameters
        ----------
        *inputs :
            All the processed model evaluation inputs.
        'b'
        Get the name of the input described by this selector argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        'u'
        Get the name of the input described by this selector argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        'b'
        Get a pretty-print representation of this object.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        'u'
        Get a pretty-print representation of this object.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        'b'Argument(name=''u'Argument(name=''b'', ignore='u'', ignore='b'
        Gets the value fixed input corresponding to this argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.

        values : dict
            Dictionary of fixed inputs.
        'u'
        Gets the value fixed input corresponding to this argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.

        values : dict
            Dictionary of fixed inputs.
        'b' was not found in 'u' was not found in 'b'
        Determine if passed argument is described by this selector argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.

        argument : int or str
            A representation of which evaluation input is being used
        'u'
        Determine if passed argument is described by this selector argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.

        argument : int or str
            A representation of which evaluation input is being used
        'b'
        Get a tuple representation of this argument using the input
        name from the model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        'u'
        Get a tuple representation of this argument using the input
        name from the model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model this selector argument is for.
        'b'
    Contains the CompoundBoundingBox slicing description.

    Parameters
    ----------
    input_ :
        The SelectorArgument values

    Methods
    -------
    validate :
        Returns a valid SelectorArguments for its model.

    get_selector :
        Returns the selector a set of inputs corresponds to.

    is_selector :
        Determines if a selector is correctly formatted for this CompoundBoundingBox.

    get_fixed_value :
        Gets the selector from a fix_inputs set of values.
    'u'
    Contains the CompoundBoundingBox slicing description.

    Parameters
    ----------
    input_ :
        The SelectorArgument values

    Methods
    -------
    validate :
        Returns a valid SelectorArguments for its model.

    get_selector :
        Returns the selector a set of inputs corresponds to.

    is_selector :
        Determines if a selector is correctly formatted for this CompoundBoundingBox.

    get_fixed_value :
        Gets the selector from a fix_inputs set of values.
    'b'
        Get a pretty-print representation of this object.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.
        'u'
        Get a pretty-print representation of this object.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.
        'b'SelectorArguments('u'SelectorArguments('b'Get the list of ignored inputs.'u'Get the list of ignored inputs.'b'The arguments to persist in ignoring.'u'The arguments to persist in ignoring.'b'
        Construct a valid Selector description for a CompoundBoundingBox.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        arguments :
            The individual argument information

        kept_ignore :
            Arguments to persist as ignored
        'u'
        Construct a valid Selector description for a CompoundBoundingBox.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        arguments :
            The individual argument information

        kept_ignore :
            Arguments to persist as ignored
        'b'Input: ''u'Input: ''b'' has been repeated.'u'' has been repeated.'b'There must be at least one selector argument.'u'There must be at least one selector argument.'b'
        Get the selector corresponding to these inputs.

        Parameters
        ----------
        *inputs :
            All the processed model evaluation inputs.
        'u'
        Get the selector corresponding to these inputs.

        Parameters
        ----------
        *inputs :
            All the processed model evaluation inputs.
        'b'
        Determine if this is a reasonable selector.

        Parameters
        ----------
        _selector : tuple
            The selector to check
        'u'
        Determine if this is a reasonable selector.

        Parameters
        ----------
        _selector : tuple
            The selector to check
        'b'
        Gets the value fixed input corresponding to this argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        values : dict
            Dictionary of fixed inputs.
        'u'
        Gets the value fixed input corresponding to this argument.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        values : dict
            Dictionary of fixed inputs.
        'b'
        Determine if passed argument is one of the selector arguments.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which evaluation input is being used
        'u'
        Determine if passed argument is one of the selector arguments.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which evaluation input is being used
        'b'
        Get the index of the argument passed in the selector tuples.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
        'u'
        Get the index of the argument passed in the selector tuples.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
        'b' does not correspond to any selector argument.'u' does not correspond to any selector argument.'b'
        Reduce the selector arguments by the argument given.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
        'u'
        Reduce the selector arguments by the argument given.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
        'b'
        Add argument to the kept_ignore list.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
        'u'
        Add argument to the kept_ignore list.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.

        argument : int or str
            A representation of which argument is being used
        'b': is a selector argument and cannot be ignored.'u': is a selector argument and cannot be ignored.'b'
        Get a tuple of selector argument tuples using input names.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.
        'u'
        Get a tuple of selector argument tuples using input names.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The Model these selector arguments are for.
        'b'
    A model's compound bounding box.

    Parameters
    ----------
    bounding_boxes : dict
        A dictionary containing all the ModelBoundingBoxes that are possible
            keys   -> _selector (extracted from model inputs)
            values -> ModelBoundingBox

    model : `~astropy.modeling.Model`
        The Model this compound bounding_box is for.

    selector_args : _SelectorArguments
        A description of how to extract the selectors from model inputs.

    create_selector : optional
        A method which takes in the selector and the model to return a
        valid bounding corresponding to that selector. This can be used
        to construct new bounding_boxes for previously undefined selectors.
        These new boxes are then stored for future lookups.

    order : optional, str
        The ordering that is assumed for the tuple representation of the
        bounding_boxes.
    'u'
    A model's compound bounding box.

    Parameters
    ----------
    bounding_boxes : dict
        A dictionary containing all the ModelBoundingBoxes that are possible
            keys   -> _selector (extracted from model inputs)
            values -> ModelBoundingBox

    model : `~astropy.modeling.Model`
        The Model this compound bounding_box is for.

    selector_args : _SelectorArguments
        A description of how to extract the selectors from model inputs.

    create_selector : optional
        A method which takes in the selector and the model to return a
        valid bounding corresponding to that selector. This can be used
        to construct new bounding_boxes for previously undefined selectors.
        These new boxes are then stored for future lookups.

    order : optional, str
        The ordering that is assumed for the tuple representation of the
        bounding_boxes.
    'b'CompoundBoundingBox('u'CompoundBoundingBox('b'    bounding_boxes={'u'    bounding_boxes={'b' = 'u' = 'b'            'u'            'b'    selector_args = 'u'    selector_args = 'b'Overriding selector_args may cause problems you should re-validate the compound bounding box before use!'u'Overriding selector_args may cause problems you should re-validate the compound bounding box before use!'b' is not a selector!'u' is not a selector!'b'
        Construct a valid compound bounding box for a model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be a bounding_box
        bounding_box : dict
            Dictionary of possible bounding_box representations
        selector_args : optional
            Description of the selector arguments
        create_selector : optional, callable
            Method for generating new selectors
        order : optional, str
            The order that a tuple representation will be assumed to be
                Default: 'C'
        'u'
        Construct a valid compound bounding box for a model.

        Parameters
        ----------
        model : `~astropy.modeling.Model`
            The model for which this will be a bounding_box
        bounding_box : dict
            Dictionary of possible bounding_box representations
        selector_args : optional
            Description of the selector arguments
        create_selector : optional, callable
            Method for generating new selectors
        order : optional, str
            The order that a tuple representation will be assumed to be
                Default: 'C'
        'b'Selector arguments must be provided (can be passed as part of bounding_box argument)'u'Selector arguments must be provided (can be passed as part of bounding_box argument)'b'No bounding box is defined for selector: 'u'No bounding box is defined for selector: 'b'Attempting to fix input 'u'Attempting to fix input 'b', but there are no bounding boxes for argument value 'u', but there are no bounding boxes for argument value 'u'astropy.modeling.bounding_box'u'modeling.bounding_box'u'bounding_box'MaxValue
    Represents an infinite value for purposes
    of tuple comparison.
    MAXMinValue
    The opposite of MaxValue, i.e. a representation of
    negative infinity.
    MINEpsilon
    Represents the "next largest" version of a given value,
    so that for all valid comparisons we have
    x < y < Epsilon(y) < z whenever x < y < z and x, z are
    not Epsilon objects.

    Parameters
    ----------
    val : object
        Original value
    __slots__ + epsilonNode
    An element in a binary search tree, containing
    a key, data, and references to children nodes and
    a parent node.

    Parameters
    ----------
    key : tuple
        Node key
    data : list or int
        Node data
    leftrightchildnew_child
        Replace this node's child with a new child.
        Cannot call replace() on non-child
        Remove the given child.
        
        Copy the given node.
        
    A basic binary search tree in pure Python, used
    as an engine for indexing.

    Parameters
    ----------
    data : Table
        Sorted columns of the original table
    row_index : Column object
        Row numbers corresponding to data columns
    unique : bool
        Whether the values of the index must be unique.
        Defaults to False.
    NodeClass
        Add a key, data pair.
        nodecurr_nodeCannot insert non-unique value
        Return all data values corresponding to a given key.

        Parameters
        ----------
        key : tuple
            Input key

        Returns
        -------
        data_vals : list
            List of rows corresponding to the input key
        find_node
        Find the node associated with the given key.
        _find_recursiveshift_left
        Decrement all rows larger than the given row.
        traverseshift_right
        Increment all rows greater than or equal to the given row.
        inorder
        Return nodes of the BST in the given order.

        Parameters
        ----------
        order : str
            The order in which to recursively search the BST.
            Possible values are:
            "preorder": current node, left subtree, right subtree
            "inorder": left subtree, current node, right subtree
            "postorder": left subtree, right subtree, current node
        preorder_preorder_inorderpostorder_postorderInvalid traversal method: "
        Return BST items in order as (key, data) pairs.
        
        Make row order align with key order.
        num_rowssorted_data
        Return BST rows sorted by key values.
        lst_substitutenew_node
        Remove data corresponding to the given key.

        Parameters
        ----------
        key : tuple
            The key to remove
        data : int or None
            If None, remove the node corresponding to the given key.
            If not None, remove only the given data value from the node.

        Returns
        -------
        successful : bool
            True if removal was successful, false otherwise
        Data does not belong to correct node
        Returns whether this is a valid BST.
        _is_validbounds
        Return all nodes with keys in the given range.

        Parameters
        ----------
        lower : tuple
            Lower bound
        upper : tuple
            Upper bound
        bounds : (2,) tuple of bool
            Indicates whether the search should be inclusive or
            exclusive with respect to the endpoints. The first
            argument corresponds to an inclusive lower bound,
            and the second argument to an inclusive upper bound.
        range_nodesnodes
        Return nodes in the given range.
        leltop1gegtop2_rangesame_prefix
        Assuming the given value has smaller length than keys, return
        nodes whose keys have this value as a prefix.
        _same_prefix_printheight
        Return the BST height.
        _heightreplace_rowsrow_map
        Replace all rows with the values they map to in the
        given dictionary. Any rows not present as keys in
        the dictionary will have their nodes deleted.

        Parameters
        ----------
        row_map : dict
            Mapping of row numbers to new row numbers
        # each node has a key and data list# add data to node# wrong key type# find largest element of left subtree# op1 is <= or <, op2 is >= or ># noqa: PERF102b'
    Represents an infinite value for purposes
    of tuple comparison.
    'u'
    Represents an infinite value for purposes
    of tuple comparison.
    'b'MAX'u'MAX'b'
    The opposite of MaxValue, i.e. a representation of
    negative infinity.
    'u'
    The opposite of MaxValue, i.e. a representation of
    negative infinity.
    'b'MIN'u'MIN'b'
    Represents the "next largest" version of a given value,
    so that for all valid comparisons we have
    x < y < Epsilon(y) < z whenever x < y < z and x, z are
    not Epsilon objects.

    Parameters
    ----------
    val : object
        Original value
    'u'
    Represents the "next largest" version of a given value,
    so that for all valid comparisons we have
    x < y < Epsilon(y) < z whenever x < y < z and x, z are
    not Epsilon objects.

    Parameters
    ----------
    val : object
        Original value
    'b'val'u'val'b' + epsilon'u' + epsilon'b'
    An element in a binary search tree, containing
    a key, data, and references to children nodes and
    a parent node.

    Parameters
    ----------
    key : tuple
        Node key
    data : list or int
        Node data
    'u'
    An element in a binary search tree, containing
    a key, data, and references to children nodes and
    a parent node.

    Parameters
    ----------
    key : tuple
        Node key
    data : list or int
        Node data
    'b'key'u'key'b'left'u'left'b'right'u'right'b'
        Replace this node's child with a new child.
        'u'
        Replace this node's child with a new child.
        'b'Cannot call replace() on non-child'u'Cannot call replace() on non-child'b'
        Remove the given child.
        'u'
        Remove the given child.
        'b'
        Copy the given node.
        'u'
        Copy the given node.
        'b'
    A basic binary search tree in pure Python, used
    as an engine for indexing.

    Parameters
    ----------
    data : Table
        Sorted columns of the original table
    row_index : Column object
        Row numbers corresponding to data columns
    unique : bool
        Whether the values of the index must be unique.
        Defaults to False.
    'u'
    A basic binary search tree in pure Python, used
    as an engine for indexing.

    Parameters
    ----------
    data : Table
        Sorted columns of the original table
    row_index : Column object
        Row numbers corresponding to data columns
    unique : bool
        Whether the values of the index must be unique.
        Defaults to False.
    'b'
        Add a key, data pair.
        'u'
        Add a key, data pair.
        'b'Cannot insert non-unique value'u'Cannot insert non-unique value'b'
        Return all data values corresponding to a given key.

        Parameters
        ----------
        key : tuple
            Input key

        Returns
        -------
        data_vals : list
            List of rows corresponding to the input key
        'u'
        Return all data values corresponding to a given key.

        Parameters
        ----------
        key : tuple
            Input key

        Returns
        -------
        data_vals : list
            List of rows corresponding to the input key
        'b'
        Find the node associated with the given key.
        'u'
        Find the node associated with the given key.
        'b'
        Decrement all rows larger than the given row.
        'u'
        Decrement all rows larger than the given row.
        'b'
        Increment all rows greater than or equal to the given row.
        'u'
        Increment all rows greater than or equal to the given row.
        'b'inorder'u'inorder'b'
        Return nodes of the BST in the given order.

        Parameters
        ----------
        order : str
            The order in which to recursively search the BST.
            Possible values are:
            "preorder": current node, left subtree, right subtree
            "inorder": left subtree, current node, right subtree
            "postorder": left subtree, right subtree, current node
        'u'
        Return nodes of the BST in the given order.

        Parameters
        ----------
        order : str
            The order in which to recursively search the BST.
            Possible values are:
            "preorder": current node, left subtree, right subtree
            "inorder": left subtree, current node, right subtree
            "postorder": left subtree, right subtree, current node
        'b'preorder'u'preorder'b'postorder'u'postorder'b'Invalid traversal method: "'u'Invalid traversal method: "'b'
        Return BST items in order as (key, data) pairs.
        'u'
        Return BST items in order as (key, data) pairs.
        'b'
        Make row order align with key order.
        'u'
        Make row order align with key order.
        'b'
        Return BST rows sorted by key values.
        'u'
        Return BST rows sorted by key values.
        'b'
        Remove data corresponding to the given key.

        Parameters
        ----------
        key : tuple
            The key to remove
        data : int or None
            If None, remove the node corresponding to the given key.
            If not None, remove only the given data value from the node.

        Returns
        -------
        successful : bool
            True if removal was successful, false otherwise
        'u'
        Remove data corresponding to the given key.

        Parameters
        ----------
        key : tuple
            The key to remove
        data : int or None
            If None, remove the node corresponding to the given key.
            If not None, remove only the given data value from the node.

        Returns
        -------
        successful : bool
            True if removal was successful, false otherwise
        'b'Data does not belong to correct node'u'Data does not belong to correct node'b'
        Returns whether this is a valid BST.
        'u'
        Returns whether this is a valid BST.
        'b'
        Return all nodes with keys in the given range.

        Parameters
        ----------
        lower : tuple
            Lower bound
        upper : tuple
            Upper bound
        bounds : (2,) tuple of bool
            Indicates whether the search should be inclusive or
            exclusive with respect to the endpoints. The first
            argument corresponds to an inclusive lower bound,
            and the second argument to an inclusive upper bound.
        'u'
        Return all nodes with keys in the given range.

        Parameters
        ----------
        lower : tuple
            Lower bound
        upper : tuple
            Upper bound
        bounds : (2,) tuple of bool
            Indicates whether the search should be inclusive or
            exclusive with respect to the endpoints. The first
            argument corresponds to an inclusive lower bound,
            and the second argument to an inclusive upper bound.
        'b'
        Return nodes in the given range.
        'u'
        Return nodes in the given range.
        'b'
        Assuming the given value has smaller length than keys, return
        nodes whose keys have this value as a prefix.
        'u'
        Assuming the given value has smaller length than keys, return
        nodes whose keys have this value as a prefix.
        'b'
        Return the BST height.
        'u'
        Return the BST height.
        'b'
        Replace all rows with the values they map to in the
        given dictionary. Any rows not present as keys in
        the dictionary will have their nodes deleted.

        Parameters
        ----------
        row_map : dict
            Mapping of row numbers to new row numbers
        'u'
        Replace all rows with the values they map to in the
        given dictionary. Any rows not present as keys in
        the dictionary will have their nodes deleted.

        Parameters
        ----------
        row_map : dict
            Mapping of row numbers to new row numbers
        'u'astropy.table.bst'u'table.bst'u'bst'urllib.requestRequesturlopenatimeastropy.utils.console_color_textcolor_printget_sunHumanErrorCelestialErrorget_signcapricornzodiac_signaquariuspiscesariestaurusgeminicancerleovirgolibrascorpiosagittarius_VALID_SIGNScapricornusscorpius_CONST_TO_SIGNSrat1901ox1902tiger1903rabbitdragon1905snake1906horse1907goat1908monkey1909rooster1910dog1911pig_ZODIAC_get_zodiachoroscopebirthdaycorrectedchinese
    Enter your birthday as an `astropy.time.Time` object and
    receive a mystical horoscope about things to come.

    Parameters
    ----------
    birthday : `astropy.time.Time` or str
        Your birthday as a `datetime.datetime` or `astropy.time.Time` object
        or "YYYY-MM-DD"string.
    corrected : bool
        Whether to account for the precession of the Earth instead of using the
        ancient Greek dates for the signs.  After all, you do want your *real*
        horoscope, not a cheap inaccurate approximation, right?

    chinese : bool
        Chinese annual zodiac wisdom instead of Western one.

    Returns
    -------
    Infinite wisdom, condensed into astrologically precise prose.

    Notes
    -----
    This function was implemented on April 1.  Take note of that date.
    bs4BeautifulSouptodayInvalid response from celestial gods (failed to load horoscope).foo/barUser-Agentheadersyellow([sS]tar[s^ ]*)magenta([yY]ou[^ ]*)blue([pP]lay[^ ]*)red([hH]eart)lightgreen([fF]ate)special_wordsstrptime%Y-%m-%dhttps://www.horoscope.com/us/horoscopes/yearly/"https://www.horoscope.com/us/horoscopes/yearly/"-chinese-horoscope-.aspxsumm_title_sfxhtml.parseroverviewgetTextdescget_constellationOn your birthday the sun was in , which is not a sign of the zodiac.  You must not exist.  Or maybe you can settle for corrected=False.", which is"" not a sign of the zodiac.  You must not exist.  Or maybe you can"" settle for corrected=False."to_datetimehttps://astrology.com/horoscope/daily/.htmlon divcontent79Horoscope for :greenwrapsplit_blockwordre_wordinject_horoscope_yourfuture# Standard library# Third-party# Some of the constellation names map to different astrological "sign names".# Astrologers really needs to talk to the IAU...# https://stackoverflow.com/questions/12791871/chinese-zodiac-python-program# TODO: Make this more accurate by using the actual date, not just year# Might need third-party tool like https://pypi.org/project/lunardate# TODO: Also include Love, Family & Friends, Work, Money, More?# Ignore ErfaWarningb'capricorn'u'capricorn'b'aquarius'u'aquarius'b'pisces'u'pisces'b'aries'u'aries'b'taurus'u'taurus'b'gemini'u'gemini'b'cancer'u'cancer'b'leo'u'leo'b'virgo'u'virgo'b'libra'u'libra'b'scorpio'u'scorpio'b'sagittarius'u'sagittarius'b'capricornus'u'capricornus'b'scorpius'u'scorpius'b'rat'u'rat'b'ox'u'ox'b'tiger'u'tiger'b'rabbit'u'rabbit'b'dragon'u'dragon'b'snake'u'snake'b'horse'u'horse'b'goat'u'goat'b'monkey'u'monkey'b'rooster'u'rooster'b'dog'u'dog'b'pig'u'pig'b'
    Enter your birthday as an `astropy.time.Time` object and
    receive a mystical horoscope about things to come.

    Parameters
    ----------
    birthday : `astropy.time.Time` or str
        Your birthday as a `datetime.datetime` or `astropy.time.Time` object
        or "YYYY-MM-DD"string.
    corrected : bool
        Whether to account for the precession of the Earth instead of using the
        ancient Greek dates for the signs.  After all, you do want your *real*
        horoscope, not a cheap inaccurate approximation, right?

    chinese : bool
        Chinese annual zodiac wisdom instead of Western one.

    Returns
    -------
    Infinite wisdom, condensed into astrologically precise prose.

    Notes
    -----
    This function was implemented on April 1.  Take note of that date.
    'u'
    Enter your birthday as an `astropy.time.Time` object and
    receive a mystical horoscope about things to come.

    Parameters
    ----------
    birthday : `astropy.time.Time` or str
        Your birthday as a `datetime.datetime` or `astropy.time.Time` object
        or "YYYY-MM-DD"string.
    corrected : bool
        Whether to account for the precession of the Earth instead of using the
        ancient Greek dates for the signs.  After all, you do want your *real*
        horoscope, not a cheap inaccurate approximation, right?

    chinese : bool
        Chinese annual zodiac wisdom instead of Western one.

    Returns
    -------
    Infinite wisdom, condensed into astrologically precise prose.

    Notes
    -----
    This function was implemented on April 1.  Take note of that date.
    'b'Invalid response from celestial gods (failed to load horoscope).'u'Invalid response from celestial gods (failed to load horoscope).'b'foo/bar'u'foo/bar'b'User-Agent'u'User-Agent'b'yellow'u'yellow'b'([sS]tar[s^ ]*)'u'([sS]tar[s^ ]*)'b'magenta'u'magenta'b'([yY]ou[^ ]*)'u'([yY]ou[^ ]*)'b'blue'u'blue'b'([pP]lay[^ ]*)'u'([pP]lay[^ ]*)'b'red'u'red'b'([hH]eart)'u'([hH]eart)'b'lightgreen'u'lightgreen'b'([fF]ate)'u'([fF]ate)'b'%Y-%m-%d'u'%Y-%m-%d'b'https://www.horoscope.com/us/horoscopes/yearly/'u'https://www.horoscope.com/us/horoscopes/yearly/'b'-chinese-horoscope-'u'-chinese-horoscope-'b'.aspx'u'.aspx'b'html.parser'u'html.parser'b'overview'u'overview'b'On your birthday the sun was in 'u'On your birthday the sun was in 'b', which is not a sign of the zodiac.  You must not exist.  Or maybe you can settle for corrected=False.'u', which is not a sign of the zodiac.  You must not exist.  Or maybe you can settle for corrected=False.'b'https://astrology.com/horoscope/daily/'u'https://astrology.com/horoscope/daily/'b'.html'u'.html'b'on 'u'on 'b'div'u'div'b'content'u'content'b'id'u'id'b'Horoscope for 'u'Horoscope for 'b':'u':'b'green'u'green'u'astropy.coordinates.calculation'u'coordinates.calculation'u'calculation'util_str_to_num_words_groupVerifyWarningUndefineddeDEFIX_FP_TABLEdDeEFIX_FP_TABLE2CARD_LENGTHBLANK_CARDKEYWORD_LENGTH= VALUE_INDICATORVALUE_INDICATOR_LENHIERARCH_VALUE_INDICATORUndefined value.UNDEFINEDThe length of a Card image; should always be 80 for valid FITS files.^[A-Z0-9_-]{0,%d}$_keywd_FSC_RE^(?:HIERARCH +)?(?:^[ -<>-~]+ ?)+$_keywd_hierarch_RE(\.\d+|\d+(\.\d*)?)([DE][+-]?\d+)?_digits_FSC(\.\d+|\d+(\.\d*)?) *([deDE] *[+-]? *\d+)?_digits_NFSC[+-]?_numr_FSC[+-]? *_numr_NFSC(?P<sign>[+-])?0*?(?P<digt>rf"_number_FSC_RE(?P<sign>[+-])? *0*?(?P<digt>_number_NFSC_RE\'(?P<strg>([ -~]+?|\'\'|) *?)\'(?=$|/| )_strg(?P<comm_field>(?P<sepr>/ *)(?P<comm>(.|\n)*))_comm_field)? *?$_strg_comment_RE[ -~]*\Z_ascii_text_re(?P<value_field> *(?P<value>r'(?P<value_field> *'r'(?P<value>'r''|(?P<bool>[FT])|(?P<numr>rf'r'|'r'(?P<bool>[FT])|'r'(?P<numr>')|(?P<cplx>\( *(?P<real>r')|'r'(?P<cplx>\( *'r'(?P<real>') *, *(?P<imag>r') *, *'r'(?P<imag>') *\)))? *)(?P<comm_field>(?P<sepr>/ *)(?P<comm>[!-~][ -~]*)?)?$r') *\))'r')? *)'r'(?P<comm_field>'r'(?P<sepr>/ *)'r'(?P<comm>[!-~][ -~]*)?'r')?$'_value_FSC_RE) *\)))? *)fr'_value_NFSC_RE[a-zA-Z_]\w*_rvkc_identifier(\.\d+)?_rvkc_field(\.)*_rvkc_field_specifier_s(?P<keyword>): +(?P<val>_rvkc_field_specifier_val\'(?P<rawval>)\'_rvkc_keyword_val * *(/ *(?P<comm>[ -~]*))?$_rvkc_keyword_val_comm_rvkc_field_specifier_val_RE)\.(?P<field_specifier>)$_rvkc_keyword_name_RE_rvkc_keyword_val_comm_RECOMMENTHISTORYEND_commentary_keywordsCONTINUE_special_keywords_value_indicator_keyword_comment_valuestring_image_verified_hierarch_invalid_field_specifier_rawkeyword_rawvalue_check_if_rvkc_valuemodifiedReturns the keyword name parsed from the card image._parse_keywordSet the key attribute; once set it cannot be modified.Once set, the Card keyword may not be modifiedkeyword_upperKeyword 'END' not allowed.HIERARCH Keyword name  is greater than 8 characters or contains characters not allowed by the FITS standard; a HIERARCH card will be created." is greater than 8 characters or ""contains characters not allowed by the FITS ""standard; a HIERARCH card will be created."Illegal keyword name:  is not a string.The value associated with the keyword stored in this card.field_specifier_parse_valueThe value of invalid/unparsable cards cannot set.  Either delete this card from the header or replace it."The value of invalid/unparsable cards cannot set.  Either ""delete this card from the header or replace it."floatingcomplexfloatingIllegal value: isinfFloating point  values are not allowed in FITS headers.FITS header values must contain standard printable ASCII characters; "FITS header values must contain standard printable ASCII ""characters; " contains characters not representable in ASCII or non-printable characters." contains characters not representable in ""ASCII or non-printable characters."different_int_or_floatvalue  is not a floatThe value of invalid/unparsable cards cannot deleted.  Either delete this card from the header or replace it."The value of invalid/unparsable cards cannot deleted.  ""Either delete this card from the header or replace it."Values cannot be deleted from record-valued keyword cardsrawkeywordOn record-valued keyword cards this is the name of the standard <= 8
        character FITS keyword that this RVKC is stored in.  Otherwise it is
        the card's normal keyword.
        rawvalueOn record-valued keyword cards this is the raw string value in
        the ``<field-specifier>: <value>`` format stored in the card in order
        to represent a RVKC.  Otherwise it is the card's normal value.
        Get the comment attribute from the card image if not already set._parse_commentThe comment of invalid/unparsable cards cannot set.  Either delete this card from the header or replace it."The comment of invalid/unparsable cards cannot set.  Either "FITS header comments must contain standard printable ASCII characters; "FITS header comments must contain standard printable ""ASCII characters; "" contains characters not ""representable in ASCII or non-printable characters."oldcommentThe comment of invalid/unparsable cards cannot deleted.  Either delete this card from the header or replace it."The comment of invalid/unparsable cards cannot deleted.  "
        The field-specifier of record-valued keyword cards; always `None` on
        normal cards.
        The field-specifier may not be blank in record-valued keyword cards.Cannot coerce cards to be record-valued keyword cards by setting the field_specifier attribute"Cannot coerce cards to be record-valued keyword cards by ""setting the field_specifier attribute"The field_specifier attribute may not be deleted from record-valued keyword cards."The field_specifier attribute may not be ""deleted from record-valued keyword cards."
        The card "image", that is, the 80 byte character string that represents
        this card in an actual FITS header.
        fix+warn_format_imageis_blank
        `True` if the card is completely blank--that is, it has no keyword,
        value, or comment.  It appears in the header as 80 spaces.

        Returns `False` otherwise.
        
        Construct a `Card` object from a (raw) string. It will pad the string
        if it is not the length of a card image (80 columns).  If the card
        image is longer than 80 columns, assume it contains ``CONTINUE``
        card(s).
        latin1_padnormalize_keyword
        `classmethod` to convert a keyword value that may contain a
        field-specifier to uppercase.  The effect is to raise the key to
        uppercase and leave the field specifier in its original case.

        Parameters
        ----------
        keyword : or str
            A keyword value or a ``keyword.field-specifier`` value
        
        Determine whether or not the card is a record-valued keyword card.

        If one argument is given, that argument is treated as a full card image
        and parsed as such.  If two arguments are given, the first is treated
        as the card keyword (including the field-specifier if the card is
        intended as a RVKC), and the second as the card value OR the first value
        can be the base keyword, and the second value the 'field-specifier:
        value' string.

        If the check passes the ._keyword, ._value, and .field_specifier
        keywords are set.

        Examples
        --------
        ::

            self._check_if_rvkc('DP1', 'AXIS.1: 2')
            self._check_if_rvkc('DP1.AXIS.1', 2)
            self._check_if_rvkc('DP1     = AXIS.1: 2')
        _check_if_rvkc_image_init_rvkc
        Implements `Card._check_if_rvkc` for the case of an unparsed card
        image.  If given one argument this is the full intact image.  If given
        two arguments the card has already been split between keyword and
        value+comment at the standard value indicator '= '.
        eq_idxrestrawval
        Sort of addendum to Card.__init__ to set the appropriate internal
        attributes if the card was determined to be a RVKC.
        HIERARCHval_ind_idxThe following header keyword is invalid or follows an unrecognized non-standard convention:
"The following header keyword is invalid or follows an ""unrecognized non-standard convention:\n"Extract the keyword value from the card image._splitUnparsable card (), fix it first with .verify('fix').strgnumrdigtcplxrdigtrsignidigtisign1jvaluecommentcomm
        Split the card image between the keyword and the rest of the card.
        _itersubcardsvc&' / delim_index_fix_keyword_fix_valueFix the card image for fixable non-standard compliance._format_keyword{:{len}}_format_valuefloat_types_format_commentis_commentarykeywordvalue_length_format_long_imageCard is too long, comment will be truncated.
        Break up long string value/comment into ``CONTINUE`` cards.
        This is a primitive implementation: it will put the value
        string in one block and the comment string in another.  Also,
        it does not break at the blank space between words.  So it may
        not look pretty.
        _format_long_commentary_image67value_lengthcomment_lengthheadstrfirst_value_lengthwordsCONTINUE  '{}'value_format'{}&'{}comment_formatCONTINUE  '' / CONTINUE  '&' / 
        If a commentary card's value is too long to fit on a single card, this
        will render the card as multiple consecutive commentary card of the
        same type.
        Fixed  card to meet the FITS standard.Card  is not FITS standard (equal sign not at column 8)." is not FITS standard (equal sign not ""at column 8)."Card keyword  is not upper case.Illegal keyword name Unprintable string ; commentary cards may only contain printable ASCII characters"; commentary ""cards may only contain printable ASCII characters" is not FITS standard (invalid value string: " is not FITS standard ""(invalid value string: "; header comments may only contain printable ASCII characters"; header comments ""may only contain printable ASCII characters"
        If the card image is greater than 80 characters, it should consist of a
        normal card followed by one or more CONTINUE card.  This method returns
        the subcards that make up this logical card.

        This can also support the case where a HISTORY or COMMENT card has a
        long value that is stored internally as multiple concatenated card
        images.
        ncardsLong card images must have CONTINUE cards after the first card or have commentary keywords like HISTORY or COMMENT."Long card images must have CONTINUE cards after ""the first card or have commentary keywords like ""HISTORY or COMMENT."CONTINUE cards must have string values.
    Converts an a string to an int if possible, or to a float.

    If the string is neither a string or a float a value error is raised.
    
    Converts a card value to its appropriate string representation as
    defined by the FITS format.
    exp_val_strval_str_format_floatFormat a floating number to make sure it is at most 20 characters.Evalue_strstr_lenPad blank space to the input string to be multiple of 80._lenstrlen# The max length for FITS-standard keywords# The standard FITS value indicator# HIERARCH cards may use a shortened indicator# This __init__ is required to be here for Sphinx documentation# String for a FITS standard compliant (FSC) keyword.# noqa: UP031, RUF100# This will match any printable ASCII character excluding '='# A number sub-string, either an integer or a float in fixed or# scientific notation.  One for FSC and one for non-FSC (NFSC) format:# NFSC allows lower case of DE for exponent, allows space between sign,# digits, exponent sign, and exponents# This regex helps delete leading zeros from numbers, otherwise# Python might evaluate them as octal values (this is not-greedy, however,# so it may not strip leading zeros from a float, which is fine)# Used in cards using the CONTINUE convention which expect a string# followed by an optional comment# FSC commentary card string which must contain printable ASCII characters.# Note: \Z matches the end of the string without allowing newlines# Checks for a valid value/comment string.  It returns a match object# for a valid value/comment string.# The value group will return a match if a FITS string, boolean,# number, or complex value is found, otherwise it will return# None, meaning the keyword is undefined.  The comment field will# return a match if the comment separator is found, though the# comment maybe an empty string.# fmt: off#  The <strg> regex is not correct for all cases, but#  it comes pretty darn close.  It appears to find the#  end of a string rather well, but will accept#  strings with an odd number of single quotes,#  instead of issuing an error.  The FITS standard#  appears vague on this issue and only states that a#  string should not end with two single quotes,#  whereas it should not end with an even number of#  quotes to be precise.#  Note that a non-greedy match is done for a string,#  since a greedy match will find a single-quote after#  the comment separator resulting in an incorrect#  match.# fmt: on# regular expression to extract the key and the field specifier from a# string that is being used to index into a card list that contains# record value keyword cards (ex. 'DP1.AXIS.1')# regular expression to extract the field specifier and value and comment# from the string value of a record value keyword card# (ex "'AXIS.1: 1' / a comment")# The default value indicator; may be changed if required by a convention# (namely HIERARCH cards)# For backwards compatibility, support the 'key' keyword argument:# This attribute is set to False when creating the card from a card# image to ensure that the contents of the image get verified at some# point# A flag to conveniently mark whether or not this was a valid HIERARCH# card# If the card could not be parsed according the FITS standard or# any recognized non-standard conventions, this will be True# These are used primarily only by RVKCs# If _check_if_rvkc passes, it will handle setting the keyword and# value# Be nice and remove trailing whitespace--some FITS code always# pads keywords out with spaces; leading whitespace, however,# should be strictly disallowed.# For keywords with length > 8 they will be HIERARCH cards,# and can have arbitrary case keywords# In prior versions of PyFITS (*) HIERARCH cards would only be# created if the user-supplied keyword explicitly started with# 'HIERARCH '.  Now we will create them automatically for long# keywords, but we still want to support the old behavior too;# the old behavior makes it possible to create HIERARCH cards# that would otherwise be recognized as RVKCs# (*) This has never affected Astropy, because it was changed# before PyFITS was merged into Astropy!# The user explicitly asked for a HIERARCH card, so don't# bug them about it...# We'll gladly create a HIERARCH card, but a warning is# also displayed# probably a parsing error, falling back to the internal _value# which should be None. This may happen while calling _fix_value.# value is checked for both float and np.float32 instances# since np.float32 is not considered a Python float.# Ignore extra whitespace when comparing the new value to the old# probably a parsing error, falling back to the internal _comment# which should be None.# Ensure that the keyword exists and has been parsed--the will set the# internal _field_specifier attribute if this is a RVKC.# The keyword need also be updated# The card image has not been parsed yet; compare directly with the# string representation of a blank card# If the keyword, value, and comment are all empty (for self.value# explicitly check that it is a string value, since a blank value is# returned as '')# FITS supports only ASCII, but decode as latin1 and just take all# bytes for now; if it results in mojibake due to e.g. UTF-8# encoded data in a FITS header that's OK because it shouldn't be# there in the first place# Test first for the most common case: a standard FITS keyword provided# in standard all-caps# Test if this is a record-valued keyword# Remove 'HIERARCH' from HIERARCH keywords; this could lead to# ambiguity if there is actually a keyword card containing# "HIERARCH HIERARCH", but shame on you if you do that.# A normal FITS keyword, but provided in non-standard case# Testing for ': ' is a quick way to avoid running the full regular# expression, speeding this up for the majority of cases# This test allows us to skip running the full regular expression for# the majority of cards that do not contain strings or that definitely# do not contain RVKC field-specifiers; it's very much a# micro-optimization but it does make a measurable difference# This is valid HIERARCH card as described by the HIERARCH keyword# convention:# http://fits.gsfc.nasa.gov/registry/hierarch_keyword.html# The value indicator should appear in byte 8, but we are# flexible and allow this to be fixed# So far this looks like a standard FITS keyword; check whether# the value represents a RVKC; if so then we pass things off to# the RVKC parser# for commentary cards, no need to parse further# Likewise for invalid cards#  Check for numbers with leading 0s.# likewise for invalid/unparsable cards# Don't combine this if statement with the one above, because# we only want the elif case to run if this was not a valid# card at all# The value in this FITS file was not in a valid/known format.  In# this case the best we can do is guess that everything after the# first / was meant to be the comment# If we already have a card image, don't try to rebuild a new card# image, which self.image would do# Split cards with CONTINUE cards or commentary keywords with long# Should match a string followed by a comment; if not it# might be an invalid Card, so we just take it verbatim# CONTINUE card# The equal sign may not be any higher than column 10; anything# past that must be considered part of the card value# for the unparsable case# The value itself has not been modified, but its serialized# representation (as stored in self._valuestring) has been changed, so# still set this card as having been modified (see ticket #137)# value string# Force the value to be parsed out first# But work with the underlying raw value instead (to preserve# whitespace, for now...)# The value of a commentary card must be just a raw unprocessed# string# Keep the existing formatting for float/complex numbers# For HIERARCH cards the value should be shortened to conserve space# equal sign string# by default use the standard value indicator even for HIERARCH cards;# later we may abbreviate it if necessary# put all parts together# For HIERARCH cards we can save a bit of space if necessary by# removing the space between the keyword and the equals sign; I'm# guessing this is part of the HIEARCH card specification# longstring case (CONTINUE card)# try not to use CONTINUE if the string value can fit in one line.# Instead, just truncate the comment# We have to be careful that the first line may be able to hold less# of the value, if it is a HIERARCH keyword.# do the value string# If this is the final CONTINUE remove the '&'# do the comment string# Don't try to verify cards that already don't meet any recognizable# standard# verify the equal sign position# verify the key, it is never fixable# always fix silently the case where "=" is before column 9,# since there is no way to communicate back to the _keys.# PyFITS will auto-uppercase any standard keyword, so lowercase# keywords can only occur if they came from the wild# Keyword should be uppercase unless it's a HIERARCH card# verify the value, it may be fixable# For commentary keywords all that needs to be ensured is that it# contains only printable ASCII characters# If the value of a card was replaced before the card was ever# even verified, the new value can be considered valid, so we# don't bother verifying the old value.  See# https://github.com/astropy/astropy/issues/5408# verify the comment (string), it is never fixable# Already a float so just pass through# string value should occupies at least 8 columns, unless it is# a null string# must be before int checking since bool is also int# T or F# Limit the value string to at most 20 characters.# No scientific notation, truncate decimal places# Scientific notation, truncate significand (mantissa)# minimum length is 80b'Undefined'u'Undefined'b'de'u'de'b'DE'u'DE'b'dD'u'dD'b'eE'u'eE'b'= 'u'= 'b'Undefined value.'u'Undefined value.'b'The length of a Card image; should always be 80 for valid FITS files.'u'The length of a Card image; should always be 80 for valid FITS files.'b'^[A-Z0-9_-]{0,%d}$'u'^[A-Z0-9_-]{0,%d}$'b'^(?:HIERARCH +)?(?:^[ -<>-~]+ ?)+$'u'^(?:HIERARCH +)?(?:^[ -<>-~]+ ?)+$'b'(\.\d+|\d+(\.\d*)?)([DE][+-]?\d+)?'u'(\.\d+|\d+(\.\d*)?)([DE][+-]?\d+)?'b'(\.\d+|\d+(\.\d*)?) *([deDE] *[+-]? *\d+)?'u'(\.\d+|\d+(\.\d*)?) *([deDE] *[+-]? *\d+)?'b'[+-]?'u'[+-]?'b'[+-]? *'u'[+-]? *'b'(?P<sign>[+-])?0*?(?P<digt>'u'(?P<sign>[+-])?0*?(?P<digt>'b'(?P<sign>[+-])? *0*?(?P<digt>'u'(?P<sign>[+-])? *0*?(?P<digt>'b'\'(?P<strg>([ -~]+?|\'\'|) *?)\'(?=$|/| )'u'\'(?P<strg>([ -~]+?|\'\'|) *?)\'(?=$|/| )'b'(?P<comm_field>(?P<sepr>/ *)(?P<comm>(.|\n)*))'u'(?P<comm_field>(?P<sepr>/ *)(?P<comm>(.|\n)*))'b')? *'u')? *'b'?$'u'?$'b'[ -~]*\Z'u'[ -~]*\Z'b'(?P<value_field> *(?P<value>'u'(?P<value_field> *(?P<value>'b'|(?P<bool>[FT])|(?P<numr>'u'|(?P<bool>[FT])|(?P<numr>'b')|(?P<cplx>\( *(?P<real>'u')|(?P<cplx>\( *(?P<real>'b') *, *(?P<imag>'u') *, *(?P<imag>'b') *\)))? *)(?P<comm_field>(?P<sepr>/ *)(?P<comm>[!-~][ -~]*)?)?$'u') *\)))? *)(?P<comm_field>(?P<sepr>/ *)(?P<comm>[!-~][ -~]*)?)?$'b') *\)))? *)'u') *\)))? *)'b'[a-zA-Z_]\w*'u'[a-zA-Z_]\w*'b'(\.\d+)?'u'(\.\d+)?'b'(\.'u'(\.'b')*'u')*'b'(?P<keyword>'u'(?P<keyword>'b'): +(?P<val>'u'): +(?P<val>'b'\'(?P<rawval>'u'\'(?P<rawval>'b')\''u')\''b' *'u' *'b' *(/ *(?P<comm>[ -~]*))?$'u' *(/ *(?P<comm>[ -~]*))?$'b'$'u'$'b')\.(?P<field_specifier>'u')\.(?P<field_specifier>'b')$'u')$'b'COMMENT'u'COMMENT'b'HISTORY'u'HISTORY'b'END'u'END'b'CONTINUE'u'CONTINUE'b'Returns the keyword name parsed from the card image.'u'Returns the keyword name parsed from the card image.'b'Set the key attribute; once set it cannot be modified.'u'Set the key attribute; once set it cannot be modified.'b'Once set, the Card keyword may not be modified'u'Once set, the Card keyword may not be modified'b'Keyword 'END' not allowed.'u'Keyword 'END' not allowed.'b'HIERARCH 'u'HIERARCH 'b'Keyword name 'u'Keyword name 'b' is greater than 8 characters or contains characters not allowed by the FITS standard; a HIERARCH card will be created.'u' is greater than 8 characters or contains characters not allowed by the FITS standard; a HIERARCH card will be created.'b'Illegal keyword name: 'u'Illegal keyword name: 'b' is not a string.'u' is not a string.'b'The value associated with the keyword stored in this card.'u'The value associated with the keyword stored in this card.'b'The value of invalid/unparsable cards cannot set.  Either delete this card from the header or replace it.'u'The value of invalid/unparsable cards cannot set.  Either delete this card from the header or replace it.'b'Illegal value: 'u'Illegal value: 'b'Floating point 'u'Floating point 'b' values are not allowed in FITS headers.'u' values are not allowed in FITS headers.'b'FITS header values must contain standard printable ASCII characters; 'u'FITS header values must contain standard printable ASCII characters; 'b' contains characters not representable in ASCII or non-printable characters.'u' contains characters not representable in ASCII or non-printable characters.'b'value 'u'value 'b' is not a float'u' is not a float'b'The value of invalid/unparsable cards cannot deleted.  Either delete this card from the header or replace it.'u'The value of invalid/unparsable cards cannot deleted.  Either delete this card from the header or replace it.'b'Values cannot be deleted from record-valued keyword cards'u'Values cannot be deleted from record-valued keyword cards'b'On record-valued keyword cards this is the name of the standard <= 8
        character FITS keyword that this RVKC is stored in.  Otherwise it is
        the card's normal keyword.
        'u'On record-valued keyword cards this is the name of the standard <= 8
        character FITS keyword that this RVKC is stored in.  Otherwise it is
        the card's normal keyword.
        'b'On record-valued keyword cards this is the raw string value in
        the ``<field-specifier>: <value>`` format stored in the card in order
        to represent a RVKC.  Otherwise it is the card's normal value.
        'u'On record-valued keyword cards this is the raw string value in
        the ``<field-specifier>: <value>`` format stored in the card in order
        to represent a RVKC.  Otherwise it is the card's normal value.
        'b'Get the comment attribute from the card image if not already set.'u'Get the comment attribute from the card image if not already set.'b'The comment of invalid/unparsable cards cannot set.  Either delete this card from the header or replace it.'u'The comment of invalid/unparsable cards cannot set.  Either delete this card from the header or replace it.'b'FITS header comments must contain standard printable ASCII characters; 'u'FITS header comments must contain standard printable ASCII characters; 'b'The comment of invalid/unparsable cards cannot deleted.  Either delete this card from the header or replace it.'u'The comment of invalid/unparsable cards cannot deleted.  Either delete this card from the header or replace it.'b'
        The field-specifier of record-valued keyword cards; always `None` on
        normal cards.
        'u'
        The field-specifier of record-valued keyword cards; always `None` on
        normal cards.
        'b'The field-specifier may not be blank in record-valued keyword cards.'u'The field-specifier may not be blank in record-valued keyword cards.'b'Cannot coerce cards to be record-valued keyword cards by setting the field_specifier attribute'u'Cannot coerce cards to be record-valued keyword cards by setting the field_specifier attribute'b'The field_specifier attribute may not be deleted from record-valued keyword cards.'u'The field_specifier attribute may not be deleted from record-valued keyword cards.'b'
        The card "image", that is, the 80 byte character string that represents
        this card in an actual FITS header.
        'u'
        The card "image", that is, the 80 byte character string that represents
        this card in an actual FITS header.
        'b'fix+warn'u'fix+warn'b'
        `True` if the card is completely blank--that is, it has no keyword,
        value, or comment.  It appears in the header as 80 spaces.

        Returns `False` otherwise.
        'u'
        `True` if the card is completely blank--that is, it has no keyword,
        value, or comment.  It appears in the header as 80 spaces.

        Returns `False` otherwise.
        'b'
        Construct a `Card` object from a (raw) string. It will pad the string
        if it is not the length of a card image (80 columns).  If the card
        image is longer than 80 columns, assume it contains ``CONTINUE``
        card(s).
        'u'
        Construct a `Card` object from a (raw) string. It will pad the string
        if it is not the length of a card image (80 columns).  If the card
        image is longer than 80 columns, assume it contains ``CONTINUE``
        card(s).
        'b'latin1'u'latin1'b'
        `classmethod` to convert a keyword value that may contain a
        field-specifier to uppercase.  The effect is to raise the key to
        uppercase and leave the field specifier in its original case.

        Parameters
        ----------
        keyword : or str
            A keyword value or a ``keyword.field-specifier`` value
        'u'
        `classmethod` to convert a keyword value that may contain a
        field-specifier to uppercase.  The effect is to raise the key to
        uppercase and leave the field specifier in its original case.

        Parameters
        ----------
        keyword : or str
            A keyword value or a ``keyword.field-specifier`` value
        'b'keyword'u'keyword'b'field_specifier'u'field_specifier'b'
        Determine whether or not the card is a record-valued keyword card.

        If one argument is given, that argument is treated as a full card image
        and parsed as such.  If two arguments are given, the first is treated
        as the card keyword (including the field-specifier if the card is
        intended as a RVKC), and the second as the card value OR the first value
        can be the base keyword, and the second value the 'field-specifier:
        value' string.

        If the check passes the ._keyword, ._value, and .field_specifier
        keywords are set.

        Examples
        --------
        ::

            self._check_if_rvkc('DP1', 'AXIS.1: 2')
            self._check_if_rvkc('DP1.AXIS.1', 2)
            self._check_if_rvkc('DP1     = AXIS.1: 2')
        'u'
        Determine whether or not the card is a record-valued keyword card.

        If one argument is given, that argument is treated as a full card image
        and parsed as such.  If two arguments are given, the first is treated
        as the card keyword (including the field-specifier if the card is
        intended as a RVKC), and the second as the card value OR the first value
        can be the base keyword, and the second value the 'field-specifier:
        value' string.

        If the check passes the ._keyword, ._value, and .field_specifier
        keywords are set.

        Examples
        --------
        ::

            self._check_if_rvkc('DP1', 'AXIS.1: 2')
            self._check_if_rvkc('DP1.AXIS.1', 2)
            self._check_if_rvkc('DP1     = AXIS.1: 2')
        'b'
        Implements `Card._check_if_rvkc` for the case of an unparsed card
        image.  If given one argument this is the full intact image.  If given
        two arguments the card has already been split between keyword and
        value+comment at the standard value indicator '= '.
        'u'
        Implements `Card._check_if_rvkc` for the case of an unparsed card
        image.  If given one argument this is the full intact image.  If given
        two arguments the card has already been split between keyword and
        value+comment at the standard value indicator '= '.
        'b'rawval'u'rawval'b'
        Sort of addendum to Card.__init__ to set the appropriate internal
        attributes if the card was determined to be a RVKC.
        'u'
        Sort of addendum to Card.__init__ to set the appropriate internal
        attributes if the card was determined to be a RVKC.
        'b'HIERARCH'u'HIERARCH'b'The following header keyword is invalid or follows an unrecognized non-standard convention:
'u'The following header keyword is invalid or follows an unrecognized non-standard convention:
'b'Extract the keyword value from the card image.'u'Extract the keyword value from the card image.'b'Unparsable card ('u'Unparsable card ('b'), fix it first with .verify('fix').'u'), fix it first with .verify('fix').'b'bool'u'bool'b'T'u'T'b'strg'u'strg'b''''u''''b'numr'u'numr'b'digt'u'digt'b'cplx'u'cplx'b'real'u'real'b'imag'b'value'u'value'b'comm'u'comm'b'
        Split the card image between the keyword and the rest of the card.
        'u'
        Split the card image between the keyword and the rest of the card.
        'b'&'u'&'b'' / 'u'' / 'b'Fix the card image for fixable non-standard compliance.'u'Fix the card image for fixable non-standard compliance.'b'{:{len}}'u'{:{len}}'b'Card is too long, comment will be truncated.'u'Card is too long, comment will be truncated.'b'
        Break up long string value/comment into ``CONTINUE`` cards.
        This is a primitive implementation: it will put the value
        string in one block and the comment string in another.  Also,
        it does not break at the blank space between words.  So it may
        not look pretty.
        'u'
        Break up long string value/comment into ``CONTINUE`` cards.
        This is a primitive implementation: it will put the value
        string in one block and the comment string in another.  Also,
        it does not break at the blank space between words.  So it may
        not look pretty.
        'b'CONTINUE  'u'CONTINUE  'b''{}''u''{}''b''{}&''u''{}&''b'{}'u'{}'b'CONTINUE  '' / 'u'CONTINUE  '' / 'b'CONTINUE  '&' / 'u'CONTINUE  '&' / 'b'
        If a commentary card's value is too long to fit on a single card, this
        will render the card as multiple consecutive commentary card of the
        same type.
        'u'
        If a commentary card's value is too long to fit on a single card, this
        will render the card as multiple consecutive commentary card of the
        same type.
        'b'Fixed 'u'Fixed 'b' card to meet the FITS standard.'u' card to meet the FITS standard.'b'Card 'u'Card 'b' is not FITS standard (equal sign not at column 8).'u' is not FITS standard (equal sign not at column 8).'b'err_text'u'err_text'b'fix_text'u'fix_text'b'fix'u'fix'b'Card keyword 'u'Card keyword 'b' is not upper case.'u' is not upper case.'b'Illegal keyword name 'u'Illegal keyword name 'b'fixable'u'fixable'b'Unprintable string 'u'Unprintable string 'b'; commentary cards may only contain printable ASCII characters'u'; commentary cards may only contain printable ASCII characters'b' is not FITS standard (invalid value string: 'u' is not FITS standard (invalid value string: 'b'; header comments may only contain printable ASCII characters'u'; header comments may only contain printable ASCII characters'b'
        If the card image is greater than 80 characters, it should consist of a
        normal card followed by one or more CONTINUE card.  This method returns
        the subcards that make up this logical card.

        This can also support the case where a HISTORY or COMMENT card has a
        long value that is stored internally as multiple concatenated card
        images.
        'u'
        If the card image is greater than 80 characters, it should consist of a
        normal card followed by one or more CONTINUE card.  This method returns
        the subcards that make up this logical card.

        This can also support the case where a HISTORY or COMMENT card has a
        long value that is stored internally as multiple concatenated card
        images.
        'b'Long card images must have CONTINUE cards after the first card or have commentary keywords like HISTORY or COMMENT.'u'Long card images must have CONTINUE cards after the first card or have commentary keywords like HISTORY or COMMENT.'b'CONTINUE cards must have string values.'u'CONTINUE cards must have string values.'b'
    Converts an a string to an int if possible, or to a float.

    If the string is neither a string or a float a value error is raised.
    'u'
    Converts an a string to an int if possible, or to a float.

    If the string is neither a string or a float a value error is raised.
    'b'
    Converts a card value to its appropriate string representation as
    defined by the FITS format.
    'u'
    Converts a card value to its appropriate string representation as
    defined by the FITS format.
    'b'Format a floating number to make sure it is at most 20 characters.'u'Format a floating number to make sure it is at most 20 characters.'b'E'u'E'b'Pad blank space to the input string to be multiple of 80.'u'Pad blank space to the input string to be multiple of 80.'u'astropy.io.fits.Card'u'io.fits.Card'u'fits.Card'Cartesian representations and differentials.ufuncerfa_ufunc
    Representation of points in 3D cartesian coordinates.

    Parameters
    ----------
    x, y, z : `~astropy.units.Quantity` or array
        The x, y, and z coordinates of the point(s). If ``x``, ``y``, and ``z``
        have different shapes, they should be broadcastable. If not quantity,
        ``unit`` should be set.  If only ``x`` is given, it is assumed that it
        contains an array with the 3 coordinates stored along ``xyz_axis``.
    unit : unit-like
        If given, the coordinates will be converted to this unit (or taken to
        be in this unit if not given.
    xyz_axis : int, optional
        The axis along which the coordinates are stored when a single array is
        provided rather than distinct ``x``, ``y``, and ``z`` (default: 0).

    differentials : dict, `~astropy.coordinates.CartesianDifferential`, optional
        Any differential classes that should be associated with this
        representation. The input must either be a single
        `~astropy.coordinates.CartesianDifferential` instance, or a dictionary of
        `~astropy.coordinates.CartesianDifferential` s with keys set to a string representation of
        the SI unit with which the differential (derivative) is taken. For
        example, for a velocity differential on a positional representation, the
        key would be ``'s'`` for seconds, indicating that the derivative is a
        time derivative.

    copy : bool, optional
        If `True` (default), arrays will be copied. If `False`, arrays will
        be references, though possibly broadcast to ensure matching shapes.
    _xyzxyz_axisOV_xyz_axis_zxyz_axis should only be set if x, y, and z are in a single array passed in through x, i.e., y and z should not be not given."xyz_axis should only be set if x, y, and z are in a single array"" passed in through x, i.e., y and z should not be not given."x, y, and z are required to instantiate UnitsErrorx, y, and z should have matching physical typesoget_xyzReturn a vector array of the x, y, and z coordinates.

        Parameters
        ----------
        xyz_axis : int, optional
            The axis in the final array along which the x, y, z components
            should be stored (default: 0).

        Returns
        -------
        xyz : `~astropy.units.Quantity`
            With dimension 3 along ``xyz_axis``.  Note that, if possible,
            this will be a view.
        
        Transform the cartesian coordinates using a 3x3 matrix.

        This returns a new representation and does not modify the original one.
        Any differentials attached to this representation will also be
        transformed.

        Parameters
        ----------
        matrix : ndarray
            A 3x3 transformation matrix, such as a rotation matrix.

        Examples
        --------
        We can start off by creating a cartesian representation object:

            >>> from astropy import units as u
            >>> from astropy.coordinates import CartesianRepresentation
            >>> rep = CartesianRepresentation([1, 2] * u.pc,
            ...                               [2, 3] * u.pc,
            ...                               [3, 4] * u.pc)

        We now create a rotation matrix around the z axis:

            >>> from astropy.coordinates.matrix_utilities import rotation_matrix
            >>> rotation = rotation_matrix(30 * u.deg, axis='z')

        Finally, we can apply this transformation:

            >>> rep_new = rep.transform(rotation)
            >>> rep_new.xyz  # doctest: +FLOAT_CMP
            <Quantity [[ 1.8660254 , 3.23205081],
                       [ 1.23205081, 1.59807621],
                       [ 3.        , 4.        ]] pc>
        rxpother_cpmVector mean.

        Returns a new CartesianRepresentation instance with the means of the
        x, y, and z components.

        Refer to `~numpy.mean` for full documentation of the arguments, noting
        that ``axis`` is the entry in the ``shape`` of the representation, and
        that the ``out`` argument cannot be used.
        Vector sum.

        Returns a new CartesianRepresentation instance with the sums of the
        x, y, and z components.

        Refer to `~numpy.sum` for full documentation of the arguments, noting
        that ``axis`` is the entry in the ``shape`` of the representation, and
        that the ``out`` argument cannot be used.
        Dot product of two representations.

        Note that any associated differentials will be dropped during this
        operation.

        Parameters
        ----------
        other : `~astropy.coordinates.BaseRepresentation` subclass instance
            If not already cartesian, it is converted.

        Returns
        -------
        dot_product : `~astropy.units.Quantity`
            The sum of the product of the x, y, and z components of ``self``
            and ``other``.
        can only take dot product with another representation, not a "can only take dot product with another ""representation, not a " instance.pdpCross product of two representations.

        Parameters
        ----------
        other : `~astropy.coordinates.BaseRepresentation` subclass instance
            If not already cartesian, it is converted.

        Returns
        -------
        cross_product : `~astropy.coordinates.CartesianRepresentation`
            With vectors perpendicular to both ``self`` and ``other``.
        cannot only take cross product with another representation, not a "cannot only take cross product with another "pxpsxoDifferentials in of points in 3D cartesian coordinates.

    Parameters
    ----------
    d_x, d_y, d_z : `~astropy.units.Quantity` or array
        The x, y, and z coordinates of the differentials. If ``d_x``, ``d_y``,
        and ``d_z`` have different shapes, they should be broadcastable. If not
        quantities, ``unit`` should be set.  If only ``d_x`` is given, it is
        assumed that it contains an array with the 3 coordinates stored along
        ``xyz_axis``.
    unit : `~astropy.units.Unit` or str
        If given, the differentials will be converted to this unit (or taken to
        be in this unit if not given.
    xyz_axis : int, optional
        The axis along which the coordinates are stored when a single array is
        provided instead of distinct ``d_x``, ``d_y``, and ``d_z`` (default: 0).
    copy : bool, optional
        If `True` (default), arrays will be copied. If `False`, arrays will
        be references, though possibly broadcast to ensure matching shapes.
    _d_xyzd_xd_yd_z_d_x_d_y_d_zxyz_axis should only be set if d_x, d_y, and d_z are in a single array passed in through d_x, i.e., d_y and d_z should not be not given."xyz_axis should only be set if d_x, d_y, and d_z are in a single array"" passed in through d_x, i.e., d_y and d_z should not be not given."d_x, d_y, and d_z are required to instantiate "d_x, d_y, and d_z are required to instantiate"d_x, d_y and d_z should have equivalent units.Transform differentials using a 3x3 matrix in a Cartesian basis.

        This returns a new differential and does not modify the original one.

        Parameters
        ----------
        matrix : (3,3) array-like
            A 3x3 (or stack thereof) matrix, such as a rotation matrix.
        base, transformed_base : `~astropy.coordinates.CartesianRepresentation` or None, optional
            Not used in the Cartesian transformation.
        get_d_xyzReturn a vector array of the x, y, and z coordinates.

        Parameters
        ----------
        xyz_axis : int, optional
            The axis in the final array along which the x, y, z components
            should be stored (default: 0).

        Returns
        -------
        d_xyz : `~astropy.units.Quantity`
            With dimension 3 along ``xyz_axis``.  Note that, if possible,
            this will be a view.
        d_xyz# Short-cut for 3-D array input.# Keep a link to the array with all three coordinates# so that we can return it quickly if needed in get_xyz.# Create combined array.  TO DO: keep it in _xyz for repeated use?# But then in-place changes have to cancel it. Likely best to# also update components.# erfa rxp: Multiply a p-vector by an r-matrix.# transformed representation# Handle differentials attached to this representation# erfa pm: Modulus of p-vector.# erfa pdp: p-vector inner (=scalar=dot) product.# erfa pxp: p-vector outer (=vector=cross) product.# Create combined array.  TO DO: keep it in _d_xyz for repeated use?b'Cartesian representations and differentials.'u'Cartesian representations and differentials.'b'
    Representation of points in 3D cartesian coordinates.

    Parameters
    ----------
    x, y, z : `~astropy.units.Quantity` or array
        The x, y, and z coordinates of the point(s). If ``x``, ``y``, and ``z``
        have different shapes, they should be broadcastable. If not quantity,
        ``unit`` should be set.  If only ``x`` is given, it is assumed that it
        contains an array with the 3 coordinates stored along ``xyz_axis``.
    unit : unit-like
        If given, the coordinates will be converted to this unit (or taken to
        be in this unit if not given.
    xyz_axis : int, optional
        The axis along which the coordinates are stored when a single array is
        provided rather than distinct ``x``, ``y``, and ``z`` (default: 0).

    differentials : dict, `~astropy.coordinates.CartesianDifferential`, optional
        Any differential classes that should be associated with this
        representation. The input must either be a single
        `~astropy.coordinates.CartesianDifferential` instance, or a dictionary of
        `~astropy.coordinates.CartesianDifferential` s with keys set to a string representation of
        the SI unit with which the differential (derivative) is taken. For
        example, for a velocity differential on a positional representation, the
        key would be ``'s'`` for seconds, indicating that the derivative is a
        time derivative.

    copy : bool, optional
        If `True` (default), arrays will be copied. If `False`, arrays will
        be references, though possibly broadcast to ensure matching shapes.
    'u'
    Representation of points in 3D cartesian coordinates.

    Parameters
    ----------
    x, y, z : `~astropy.units.Quantity` or array
        The x, y, and z coordinates of the point(s). If ``x``, ``y``, and ``z``
        have different shapes, they should be broadcastable. If not quantity,
        ``unit`` should be set.  If only ``x`` is given, it is assumed that it
        contains an array with the 3 coordinates stored along ``xyz_axis``.
    unit : unit-like
        If given, the coordinates will be converted to this unit (or taken to
        be in this unit if not given.
    xyz_axis : int, optional
        The axis along which the coordinates are stored when a single array is
        provided rather than distinct ``x``, ``y``, and ``z`` (default: 0).

    differentials : dict, `~astropy.coordinates.CartesianDifferential`, optional
        Any differential classes that should be associated with this
        representation. The input must either be a single
        `~astropy.coordinates.CartesianDifferential` instance, or a dictionary of
        `~astropy.coordinates.CartesianDifferential` s with keys set to a string representation of
        the SI unit with which the differential (derivative) is taken. For
        example, for a velocity differential on a positional representation, the
        key would be ``'s'`` for seconds, indicating that the derivative is a
        time derivative.

    copy : bool, optional
        If `True` (default), arrays will be copied. If `False`, arrays will
        be references, though possibly broadcast to ensure matching shapes.
    'b'OV'u'OV'b'xyz_axis should only be set if x, y, and z are in a single array passed in through x, i.e., y and z should not be not given.'u'xyz_axis should only be set if x, y, and z are in a single array passed in through x, i.e., y and z should not be not given.'b'x, y, and z are required to instantiate 'u'x, y, and z are required to instantiate 'b'x, y, and z should have matching physical types'u'x, y, and z should have matching physical types'b'Return a vector array of the x, y, and z coordinates.

        Parameters
        ----------
        xyz_axis : int, optional
            The axis in the final array along which the x, y, z components
            should be stored (default: 0).

        Returns
        -------
        xyz : `~astropy.units.Quantity`
            With dimension 3 along ``xyz_axis``.  Note that, if possible,
            this will be a view.
        'u'Return a vector array of the x, y, and z coordinates.

        Parameters
        ----------
        xyz_axis : int, optional
            The axis in the final array along which the x, y, z components
            should be stored (default: 0).

        Returns
        -------
        xyz : `~astropy.units.Quantity`
            With dimension 3 along ``xyz_axis``.  Note that, if possible,
            this will be a view.
        'b'
        Transform the cartesian coordinates using a 3x3 matrix.

        This returns a new representation and does not modify the original one.
        Any differentials attached to this representation will also be
        transformed.

        Parameters
        ----------
        matrix : ndarray
            A 3x3 transformation matrix, such as a rotation matrix.

        Examples
        --------
        We can start off by creating a cartesian representation object:

            >>> from astropy import units as u
            >>> from astropy.coordinates import CartesianRepresentation
            >>> rep = CartesianRepresentation([1, 2] * u.pc,
            ...                               [2, 3] * u.pc,
            ...                               [3, 4] * u.pc)

        We now create a rotation matrix around the z axis:

            >>> from astropy.coordinates.matrix_utilities import rotation_matrix
            >>> rotation = rotation_matrix(30 * u.deg, axis='z')

        Finally, we can apply this transformation:

            >>> rep_new = rep.transform(rotation)
            >>> rep_new.xyz  # doctest: +FLOAT_CMP
            <Quantity [[ 1.8660254 , 3.23205081],
                       [ 1.23205081, 1.59807621],
                       [ 3.        , 4.        ]] pc>
        'u'
        Transform the cartesian coordinates using a 3x3 matrix.

        This returns a new representation and does not modify the original one.
        Any differentials attached to this representation will also be
        transformed.

        Parameters
        ----------
        matrix : ndarray
            A 3x3 transformation matrix, such as a rotation matrix.

        Examples
        --------
        We can start off by creating a cartesian representation object:

            >>> from astropy import units as u
            >>> from astropy.coordinates import CartesianRepresentation
            >>> rep = CartesianRepresentation([1, 2] * u.pc,
            ...                               [2, 3] * u.pc,
            ...                               [3, 4] * u.pc)

        We now create a rotation matrix around the z axis:

            >>> from astropy.coordinates.matrix_utilities import rotation_matrix
            >>> rotation = rotation_matrix(30 * u.deg, axis='z')

        Finally, we can apply this transformation:

            >>> rep_new = rep.transform(rotation)
            >>> rep_new.xyz  # doctest: +FLOAT_CMP
            <Quantity [[ 1.8660254 , 3.23205081],
                       [ 1.23205081, 1.59807621],
                       [ 3.        , 4.        ]] pc>
        'b'Vector mean.

        Returns a new CartesianRepresentation instance with the means of the
        x, y, and z components.

        Refer to `~numpy.mean` for full documentation of the arguments, noting
        that ``axis`` is the entry in the ``shape`` of the representation, and
        that the ``out`` argument cannot be used.
        'u'Vector mean.

        Returns a new CartesianRepresentation instance with the means of the
        x, y, and z components.

        Refer to `~numpy.mean` for full documentation of the arguments, noting
        that ``axis`` is the entry in the ``shape`` of the representation, and
        that the ``out`` argument cannot be used.
        'b'Vector sum.

        Returns a new CartesianRepresentation instance with the sums of the
        x, y, and z components.

        Refer to `~numpy.sum` for full documentation of the arguments, noting
        that ``axis`` is the entry in the ``shape`` of the representation, and
        that the ``out`` argument cannot be used.
        'u'Vector sum.

        Returns a new CartesianRepresentation instance with the sums of the
        x, y, and z components.

        Refer to `~numpy.sum` for full documentation of the arguments, noting
        that ``axis`` is the entry in the ``shape`` of the representation, and
        that the ``out`` argument cannot be used.
        'b'Dot product of two representations.

        Note that any associated differentials will be dropped during this
        operation.

        Parameters
        ----------
        other : `~astropy.coordinates.BaseRepresentation` subclass instance
            If not already cartesian, it is converted.

        Returns
        -------
        dot_product : `~astropy.units.Quantity`
            The sum of the product of the x, y, and z components of ``self``
            and ``other``.
        'u'Dot product of two representations.

        Note that any associated differentials will be dropped during this
        operation.

        Parameters
        ----------
        other : `~astropy.coordinates.BaseRepresentation` subclass instance
            If not already cartesian, it is converted.

        Returns
        -------
        dot_product : `~astropy.units.Quantity`
            The sum of the product of the x, y, and z components of ``self``
            and ``other``.
        'b'can only take dot product with another representation, not a 'u'can only take dot product with another representation, not a 'b' instance.'u' instance.'b'Cross product of two representations.

        Parameters
        ----------
        other : `~astropy.coordinates.BaseRepresentation` subclass instance
            If not already cartesian, it is converted.

        Returns
        -------
        cross_product : `~astropy.coordinates.CartesianRepresentation`
            With vectors perpendicular to both ``self`` and ``other``.
        'u'Cross product of two representations.

        Parameters
        ----------
        other : `~astropy.coordinates.BaseRepresentation` subclass instance
            If not already cartesian, it is converted.

        Returns
        -------
        cross_product : `~astropy.coordinates.CartesianRepresentation`
            With vectors perpendicular to both ``self`` and ``other``.
        'b'cannot only take cross product with another representation, not a 'u'cannot only take cross product with another representation, not a 'b'Differentials in of points in 3D cartesian coordinates.

    Parameters
    ----------
    d_x, d_y, d_z : `~astropy.units.Quantity` or array
        The x, y, and z coordinates of the differentials. If ``d_x``, ``d_y``,
        and ``d_z`` have different shapes, they should be broadcastable. If not
        quantities, ``unit`` should be set.  If only ``d_x`` is given, it is
        assumed that it contains an array with the 3 coordinates stored along
        ``xyz_axis``.
    unit : `~astropy.units.Unit` or str
        If given, the differentials will be converted to this unit (or taken to
        be in this unit if not given.
    xyz_axis : int, optional
        The axis along which the coordinates are stored when a single array is
        provided instead of distinct ``d_x``, ``d_y``, and ``d_z`` (default: 0).
    copy : bool, optional
        If `True` (default), arrays will be copied. If `False`, arrays will
        be references, though possibly broadcast to ensure matching shapes.
    'u'Differentials in of points in 3D cartesian coordinates.

    Parameters
    ----------
    d_x, d_y, d_z : `~astropy.units.Quantity` or array
        The x, y, and z coordinates of the differentials. If ``d_x``, ``d_y``,
        and ``d_z`` have different shapes, they should be broadcastable. If not
        quantities, ``unit`` should be set.  If only ``d_x`` is given, it is
        assumed that it contains an array with the 3 coordinates stored along
        ``xyz_axis``.
    unit : `~astropy.units.Unit` or str
        If given, the differentials will be converted to this unit (or taken to
        be in this unit if not given.
    xyz_axis : int, optional
        The axis along which the coordinates are stored when a single array is
        provided instead of distinct ``d_x``, ``d_y``, and ``d_z`` (default: 0).
    copy : bool, optional
        If `True` (default), arrays will be copied. If `False`, arrays will
        be references, though possibly broadcast to ensure matching shapes.
    'b'xyz_axis should only be set if d_x, d_y, and d_z are in a single array passed in through d_x, i.e., d_y and d_z should not be not given.'u'xyz_axis should only be set if d_x, d_y, and d_z are in a single array passed in through d_x, i.e., d_y and d_z should not be not given.'b'd_x, d_y, and d_z are required to instantiate 'u'd_x, d_y, and d_z are required to instantiate 'b'd_x, d_y and d_z should have equivalent units.'u'd_x, d_y and d_z should have equivalent units.'b'Transform differentials using a 3x3 matrix in a Cartesian basis.

        This returns a new differential and does not modify the original one.

        Parameters
        ----------
        matrix : (3,3) array-like
            A 3x3 (or stack thereof) matrix, such as a rotation matrix.
        base, transformed_base : `~astropy.coordinates.CartesianRepresentation` or None, optional
            Not used in the Cartesian transformation.
        'u'Transform differentials using a 3x3 matrix in a Cartesian basis.

        This returns a new differential and does not modify the original one.

        Parameters
        ----------
        matrix : (3,3) array-like
            A 3x3 (or stack thereof) matrix, such as a rotation matrix.
        base, transformed_base : `~astropy.coordinates.CartesianRepresentation` or None, optional
            Not used in the Cartesian transformation.
        'b'Return a vector array of the x, y, and z coordinates.

        Parameters
        ----------
        xyz_axis : int, optional
            The axis in the final array along which the x, y, z components
            should be stored (default: 0).

        Returns
        -------
        d_xyz : `~astropy.units.Quantity`
            With dimension 3 along ``xyz_axis``.  Note that, if possible,
            this will be a view.
        'u'Return a vector array of the x, y, and z coordinates.

        Parameters
        ----------
        xyz_axis : int, optional
            The axis in the final array along which the x, y, z components
            should be stored (default: 0).

        Returns
        -------
        d_xyz : `~astropy.units.Quantity`
            With dimension 3 along ``xyz_axis``.  Note that, if possible,
            this will be a view.
        'u'astropy.coordinates.representation.cartesian'u'coordinates.representation.cartesian'u'representation.cartesian'This module implements the base CCDData class.sharedmethodNDDataArrayInverseVarianceVarianceUncertaintyCCDDatafits_ccddata_readerfits_ccddata_writer_known_uncertainties_unc_name_to_cls_unc_cls_to_name_config_ccd_requires_unit_arithmeticDecorator factory which temporarily disables the need for a unit when
    creating a new CCDData instance. The final result must have a unit.

    Parameters
    ----------
    op : function
        The function to apply. Supported are:

        - ``np.add``
        - ``np.subtract``
        - ``np.multiply``
        - ``np.true_divide``

    Notes
    -----
    Should only be used on CCDData ``add``, ``subtract``, ``divide`` or
    ``multiply`` because only these methods from NDArithmeticMixin are
    overwritten.
    decoratoroperandoperand2_prepare_then_do_arithmeticSee `astropy.nddata.NDArithmeticMixin.`._uncertainty_unit_equivalent_to_parentuncertainty_typeparent_unitunsupported uncertainty type: A class describing basic CCD data.

    The CCDData class is based on the NDData object and includes a data array,
    uncertainty frame, mask frame, flag frame, meta data, units, and WCS
    information for a single CCD image.

    Parameters
    ----------
    data : `~astropy.nddata.CCDData`-like or array-like
        The actual data contained in this `~astropy.nddata.CCDData` object.
        Note that the data will always be saved by *reference*, so you should
        make a copy of the ``data`` before passing it in if that's the desired
        behavior.

    uncertainty : `~astropy.nddata.StdDevUncertainty`,             `~astropy.nddata.VarianceUncertainty`,             `~astropy.nddata.InverseVariance`, `numpy.ndarray` or             None, optional
        Uncertainties on the data. If the uncertainty is a `numpy.ndarray`, it
        it assumed to be, and stored as, a `~astropy.nddata.StdDevUncertainty`.
        Default is ``None``.

    mask : `numpy.ndarray` or None, optional
        Mask for the data, given as a boolean Numpy array with a shape
        matching that of the data. The values must be `False` where
        the data is *valid* and `True` when it is not (like Numpy
        masked arrays). If ``data`` is a numpy masked array, providing
        ``mask`` here will causes the mask from the masked array to be
        ignored.
        Default is ``None``.

    flags : `numpy.ndarray` or `~astropy.nddata.FlagCollection` or None,             optional
        Flags giving information about each pixel. These can be specified
        either as a Numpy array of any type with a shape matching that of the
        data, or as a `~astropy.nddata.FlagCollection` instance which has a
        shape matching that of the data.
        Default is ``None``.

    wcs : `~astropy.wcs.WCS` or None, optional
        WCS-object containing the world coordinate system for the data.
        Default is ``None``.

    meta : dict-like object or None, optional
        Metadata for this object. "Metadata" here means all information that
        is included with this object but not part of any other attribute
        of this particular object, e.g. creation date, unique identifier,
        simulation parameters, exposure time, telescope name, etc.

    unit : `~astropy.units.Unit` or str, optional
        The units of the data.
        Default is ``None``.

        .. warning::

            If the unit is ``None`` or not otherwise specified it will raise a
            ``ValueError``

    psf : `numpy.ndarray` or None, optional
        Image representation of the PSF at the center of this image. In order
        for convolution to be flux-preserving, this should generally be
        normalized to sum to unity.

    Raises
    ------
    ValueError
        If the ``uncertainty`` or ``mask`` inputs cannot be broadcast (e.g.,
        match shape) onto ``data``.

    Methods
    -------
    read(\*args, \**kwargs)
        ``Classmethod`` to create an CCDData instance based on a ``FITS`` file.
        This method uses :func:`fits_ccddata_reader` with the provided
        parameters.
    write(\*args, \**kwargs)
        Writes the contents of the CCDData instance into a new ``FITS`` file.
        This method uses :func:`fits_ccddata_writer` with the provided
        parameters.

    Attributes
    ----------
    known_invalid_fits_unit_strings
        A dictionary that maps commonly-used fits unit name strings that are
        technically invalid to the correct valid unit type (or unit string).
        This is primarily for variant names like "ELECTRONS/S" which are not
        formally valid, but are unambiguous and frequently enough encountered
        that it is convenient to map them to the correct unit.

    Notes
    -----
    `~astropy.nddata.CCDData` objects can be easily converted to a regular
     Numpy array using `numpy.asarray`.

    For example::

        >>> from astropy.nddata import CCDData
        >>> import numpy as np
        >>> x = CCDData([1,2,3], unit='adu')
        >>> np.asarray(x)
        array([1, 2, 3])

    This is useful, for example, when plotting a 2D image using
    matplotlib.

        >>> from astropy.nddata import CCDData
        >>> from matplotlib import pyplot as plt   # doctest: +SKIP
        >>> x = CCDData([[1,2,3], [4,5,6]], unit='adu')
        >>> plt.imshow(x)   # doctest: +SKIP

    kwdcan't have both header and meta.llwcsthe wcs must be a WCS instance.a unit for CCDData must be specified._slice_wcs
        Override the WCS slicing behaviour so that the wcs attribute continues
        to be an `astropy.wcs.WCS`.
        _handle_wcs_slicing_error_unitpsf_psfThe psf must be a numpy array._meta_uncertainty_parent_nddatauncertainty must have same shape as data.array provided for uncertainty; assuming it is a StdDevUncertainty."array provided for uncertainty; assuming it is a ""StdDevUncertainty."uncertainty must be an instance of a NDUncertainty object or a numpy array."uncertainty must be an instance of a ""NDUncertainty object or a numpy array."parent_nddatato_hduMASKUNCERTUTYPEPSFIMAGEhdu_maskhdu_uncertaintyhdu_flagswcs_relaxkey_uncertainty_typeas_image_hduhdu_psfCreates an HDUList object from a CCDData object.

        Parameters
        ----------
        hdu_mask, hdu_uncertainty, hdu_flags, hdu_psf : str or None, optional
            If it is a string append this attribute to the HDUList as
            `~astropy.io.fits.ImageHDU` with the string as extension name.
            Flags are not supported at this time. If ``None`` this attribute
            is not appended.
            Default is ``'MASK'`` for mask, ``'UNCERT'`` for uncertainty,
            ``'PSFIMAGE'`` for psf, and `None` for flags.

        wcs_relax : bool
            Value of the ``relax`` parameter to use in converting the WCS to a
            FITS header using `~astropy.wcs.WCS.to_header`. The common
            ``CTYPE`` ``RA---TAN-SIP`` and ``DEC--TAN-SIP`` requires
            ``relax=True`` for the ``-SIP`` part of the ``CTYPE`` to be
            preserved.

        key_uncertainty_type : str, optional
            The header key name for the class name of the uncertainty (if any)
            that is used to store the uncertainty type in the uncertainty hdu.
            Default is ``UTYPE``.

            .. versionadded:: 3.1

        as_image_hdu : bool
            If this option is `True`, the first item of the returned
            `~astropy.io.fits.HDUList` is a `~astropy.io.fits.ImageHDU`, instead
            of the default `~astropy.io.fits.PrimaryHDU`.

        Raises
        ------
        ValueError
            - If ``self.mask`` is set but not a `numpy.ndarray`.
            - If ``self.uncertainty`` is set but not a astropy uncertainty type.
            - If ``self.uncertainty`` is set but has another unit then
              ``self.data``.

        NotImplementedError
            Saving flags is not supported.

        Returns
        -------
        hdulist : `~astropy.io.fits.HDUList`
        dummy_ccd_insert_in_metadata_fits_safebunitto_headerrelaxwcs_headeruseblankshdusonly a numpy.ndarray mask can be saved.hduMaskuncertainty_clsonly uncertainties of type  can be saved.uncertainty_namehdr_uncertaintysaving uncertainties with a unit that is not equivalent to the unit from the data unit is not supported."saving uncertainties with a unit that is not ""equivalent to the unit from the data unit is not ""supported."hduUncertadding the flags to a HDU is not supported at this time.
        Return a copy of the CCDData object.
        
        Insert key/value pair into metadata in a way that FITS can serialize.

        Parameters
        ----------
        key : str
            Key to be inserted in dictionary.

        value : str or None
            Value to be inserted.

        Notes
        -----
        This addresses a shortcoming of the FITS standard. There are length
        restrictions on both the ``key`` (8 characters) and ``value`` (72
        characters) in the FITS standard. There is a convention for handling
        long keywords and a convention for handling long values, but the
        two conventions cannot be used at the same time.

        This addresses that case by checking the length of the ``key`` and
        ``value`` and, if necessary, shortening the key.
        72short_nameShortened name for ELECTRONS/SELECTRONSelectronsknown_invalid_fits_unit_stringsJD-OBSMJD-OBSDATE-OBS_KEEP_THESE_KEYWORDS_IN_HEADERPC1_1PC1_2PC2_1PC2_2_PCsCD1_1CD1_2CD2_1CD2_2_CDs_generate_wcs_and_update_headerhdr
    Generate a WCS object from a header and remove the WCS-specific
    keywords from the header.

    Parameters
    ----------
    hdr : astropy.io.fits.header or other dict-like

    Returns
    -------
    new_header, wcs
    An exception happened while extracting WCS information from the Header.
"An exception happened while extracting WCS information from ""the Header.\n"new_hdrcdsip{}_{}_{}APBPpolynomialspolyproduct
    Generate a CCDData object from a FITS file.

    Parameters
    ----------
    filename : str
        Name of fits file.

    hdu : int, str, tuple of (str, int), optional
        Index or other identifier of the Header Data Unit of the FITS
        file from which CCDData should be initialized. If zero and
        no data in the primary HDU, it will search for the first
        extension HDU with data. The header will be added to the primary HDU.
        Default is ``0``.

    unit : `~astropy.units.Unit`, optional
        Units of the image data. If this argument is provided and there is a
        unit for the image in the FITS header (the keyword ``BUNIT`` is used
        as the unit, if present), this argument is used for the unit.
        Default is ``None``.

    hdu_uncertainty : str or None, optional
        FITS extension from which the uncertainty should be initialized. If the
        extension does not exist the uncertainty of the CCDData is ``None``.
        Default is ``'UNCERT'``.

    hdu_mask : str or None, optional
        FITS extension from which the mask should be initialized. If the
        extension does not exist the mask of the CCDData is ``None``.
        Default is ``'MASK'``.

    hdu_flags : str or None, optional
        Currently not implemented.
        Default is ``None``.

    key_uncertainty_type : str, optional
        The header key name where the class name of the uncertainty  is stored
        in the hdu of the uncertainty (if any).
        Default is ``UTYPE``.

        .. versionadded:: 3.1

    hdu_psf : str or None, optional
        FITS extension from which the psf image should be initialized. If the
        extension does not exist the psf of the CCDData is `None`.

    kwd :
        Any additional keyword parameters are passed through to the FITS reader
        in :mod:`astropy.io.fits`; see Notes for additional discussion.

    Notes
    -----
    FITS files that contained scaled data (e.g. unsigned integer images) will
    be scaled and the keywords used to manage scaled data in
    :mod:`astropy.io.fits` are disabled.
    Image data must be scaled.do_not_scale_image_dataScale information is not preserved.scale_backunsupport_open_keywordsunsupported keyword: unc_hdustored_unc_nameunc_typeloading flags is currently not supported.comb_hdrfirst HDU with data is extension fits_unit_stringkifusThe Header value for the key BUNIT () cannot be interpreted as valid unit. To successfully read the file as CCDData you can pass in a valid `unit` argument explicitly or change the header of the FITS file before reading it.") ""cannot be interpreted as valid unit. To successfully read the ""file as CCDData you can pass in a valid `unit` ""argument explicitly or change the header of the FITS ""file before reading it."using the unit  passed to the FITS reader instead of the unit " passed to the FITS reader instead ""of the unit " in the FITS file.use_unitccd_data
    Write CCDData object to FITS file.

    Parameters
    ----------
    ccd_data : CCDData
        Object to write.

    filename : str
        Name of file.

    hdu_mask, hdu_uncertainty, hdu_flags, hdu_psf : str or None, optional
        If it is a string append this attribute to the HDUList as
        `~astropy.io.fits.ImageHDU` with the string as extension name.
        Flags are not supported at this time. If ``None`` this attribute
        is not appended.
        Default is ``'MASK'`` for mask, ``'UNCERT'`` for uncertainty,
        ``'PSFIMAGE'`` for psf, and `None` for flags.

    key_uncertainty_type : str, optional
        The header key name for the class name of the uncertainty (if any)
        that is used to store the uncertainty type in the uncertainty hdu.
        Default is ``UTYPE``.

        .. versionadded:: 3.1

    as_image_hdu : bool
        If this option is `True`, the first item of the returned
        `~astropy.io.fits.HDUList` is a `~astropy.io.fits.ImageHDU`, instead of
        the default `~astropy.io.fits.PrimaryHDU`.

    kwd :
        All additional keywords are passed to :py:mod:`astropy.io.fits`

    Raises
    ------
    ValueError
        - If ``self.mask`` is set but not a `numpy.ndarray`.
        - If ``self.uncertainty`` is set but not a
          `~astropy.nddata.StdDevUncertainty`.
        - If ``self.uncertainty`` is set but has another unit then
          ``self.data``.

    NotImplementedError
        Saving flags is not supported.
    register_readerregister_writeris_fits# Global value which can turn on/off the unit requirements when creating a# CCDData. Should be used with care because several functions actually break# if the unit is None!# Wrap it again as CCDData so it checks the final unit.# Check if a unit is set. This can be temporarily disabled by the# _CCDDataUnit contextmanager.# Copy here so that we can modify the HDU header by adding WCS# information without changing the header of the CCDData object.# Because _insert_in_metadata_fits_safe is written as a method# we need to create a dummy CCDData instance to hold the FITS# header we are constructing. This probably indicates that# _insert_in_metadata_fits_safe should be rewritten in a more# sensible way...# Simply extending the FITS header with the WCS can lead to# duplicates of the WCS keywords; iterating over the WCS# header should be safer.# Turns out if I had read the io.fits.Header.extend docs more# carefully, I would have realized that the keywords exist to# avoid duplicates and preserve, as much as possible, the# structure of the commentary cards.# Note that until astropy/astropy#3967 is closed, the extend# will fail if there are comment cards in the WCS header but# not header.# Always assuming that the mask is a np.ndarray (check that it has# a 'shape').# Convert boolean mask to uint since io.fits cannot handle bool.# We need to save some kind of information which uncertainty was# used so that loading the HDUList can infer the uncertainty type.# No idea how this can be done so only allow StdDevUncertainty.# Assuming uncertainty is an StdDevUncertainty save just the array# this might be problematic if the Uncertainty has a unit differing# from the data so abort for different units. This is important for# astropy > 1.2# The PSF is an image, so write it as a separate ImageHDU.# A dictionary mapping "known" invalid fits unit# These need to be importable by the tests...# Try constructing a WCS object.# Normally WCS only raises Warnings and doesn't fail but in rare# cases (malformed header) it could fail...# Test for success by checking to see if the wcs ctype has a non-empty# value, return None for wcs if ctype is empty.# If the keywords below are in the header they are also added to WCS.# It seems like they should *not* be removed from the header, though.# Check that this does not result in an inconsistent header WCS if the WCS# is converted back to a header.# The PCi_j representation is used by the astropy.wcs object,# so CDi_j keywords were not removed from new_hdr. Remove them now.# The other case -- CD in the header produced by astropy.wcs -- should# never happen based on [1], which computes the matrix in PC form.# [1]: https://github.com/astropy/astropy/blob/1cf277926d3598dd672dd528504767c37531e8c9/cextern/wcslib/C/wcshdr.c#L596# The test test_ccddata.test_wcs_keyword_removal_for_wcs_test_files() does# check for the possibility that both PC and CD are present in the result# so if the implementation of to_header changes in wcslib in the future# then the tests should catch it, and then this code will need to be# updated.# We need to check for any SIP coefficients that got left behind if the# header has SIP.# For compatibility reasons the default is standard deviation# uncertainty because files could have been created before the# uncertainty type was stored in the header.# Mask is saved as uint but we want it to be boolean.# search for the first instance with data if# the primary header is empty.# Add header values from the primary header that aren't# present in the extension header.# patch to handle FITS files using ADU for the unit instead of the# standard version of 'adu'# Convert the BUNIT header keyword to a unit and if that's not# possible raise a meaningful error message.b'This module implements the base CCDData class.'u'This module implements the base CCDData class.'b'CCDData'u'CCDData'b'fits_ccddata_reader'u'fits_ccddata_reader'b'fits_ccddata_writer'u'fits_ccddata_writer'b'Decorator factory which temporarily disables the need for a unit when
    creating a new CCDData instance. The final result must have a unit.

    Parameters
    ----------
    op : function
        The function to apply. Supported are:

        - ``np.add``
        - ``np.subtract``
        - ``np.multiply``
        - ``np.true_divide``

    Notes
    -----
    Should only be used on CCDData ``add``, ``subtract``, ``divide`` or
    ``multiply`` because only these methods from NDArithmeticMixin are
    overwritten.
    'u'Decorator factory which temporarily disables the need for a unit when
    creating a new CCDData instance. The final result must have a unit.

    Parameters
    ----------
    op : function
        The function to apply. Supported are:

        - ``np.add``
        - ``np.subtract``
        - ``np.multiply``
        - ``np.true_divide``

    Notes
    -----
    Should only be used on CCDData ``add``, ``subtract``, ``divide`` or
    ``multiply`` because only these methods from NDArithmeticMixin are
    overwritten.
    'b'See `astropy.nddata.NDArithmeticMixin.'u'See `astropy.nddata.NDArithmeticMixin.'b'`.'u'`.'b'unsupported uncertainty type: 'u'unsupported uncertainty type: 'b'A class describing basic CCD data.

    The CCDData class is based on the NDData object and includes a data array,
    uncertainty frame, mask frame, flag frame, meta data, units, and WCS
    information for a single CCD image.

    Parameters
    ----------
    data : `~astropy.nddata.CCDData`-like or array-like
        The actual data contained in this `~astropy.nddata.CCDData` object.
        Note that the data will always be saved by *reference*, so you should
        make a copy of the ``data`` before passing it in if that's the desired
        behavior.

    uncertainty : `~astropy.nddata.StdDevUncertainty`,             `~astropy.nddata.VarianceUncertainty`,             `~astropy.nddata.InverseVariance`, `numpy.ndarray` or             None, optional
        Uncertainties on the data. If the uncertainty is a `numpy.ndarray`, it
        it assumed to be, and stored as, a `~astropy.nddata.StdDevUncertainty`.
        Default is ``None``.

    mask : `numpy.ndarray` or None, optional
        Mask for the data, given as a boolean Numpy array with a shape
        matching that of the data. The values must be `False` where
        the data is *valid* and `True` when it is not (like Numpy
        masked arrays). If ``data`` is a numpy masked array, providing
        ``mask`` here will causes the mask from the masked array to be
        ignored.
        Default is ``None``.

    flags : `numpy.ndarray` or `~astropy.nddata.FlagCollection` or None,             optional
        Flags giving information about each pixel. These can be specified
        either as a Numpy array of any type with a shape matching that of the
        data, or as a `~astropy.nddata.FlagCollection` instance which has a
        shape matching that of the data.
        Default is ``None``.

    wcs : `~astropy.wcs.WCS` or None, optional
        WCS-object containing the world coordinate system for the data.
        Default is ``None``.

    meta : dict-like object or None, optional
        Metadata for this object. "Metadata" here means all information that
        is included with this object but not part of any other attribute
        of this particular object, e.g. creation date, unique identifier,
        simulation parameters, exposure time, telescope name, etc.

    unit : `~astropy.units.Unit` or str, optional
        The units of the data.
        Default is ``None``.

        .. warning::

            If the unit is ``None`` or not otherwise specified it will raise a
            ``ValueError``

    psf : `numpy.ndarray` or None, optional
        Image representation of the PSF at the center of this image. In order
        for convolution to be flux-preserving, this should generally be
        normalized to sum to unity.

    Raises
    ------
    ValueError
        If the ``uncertainty`` or ``mask`` inputs cannot be broadcast (e.g.,
        match shape) onto ``data``.

    Methods
    -------
    read(\*args, \**kwargs)
        ``Classmethod`` to create an CCDData instance based on a ``FITS`` file.
        This method uses :func:`fits_ccddata_reader` with the provided
        parameters.
    write(\*args, \**kwargs)
        Writes the contents of the CCDData instance into a new ``FITS`` file.
        This method uses :func:`fits_ccddata_writer` with the provided
        parameters.

    Attributes
    ----------
    known_invalid_fits_unit_strings
        A dictionary that maps commonly-used fits unit name strings that are
        technically invalid to the correct valid unit type (or unit string).
        This is primarily for variant names like "ELECTRONS/S" which are not
        formally valid, but are unambiguous and frequently enough encountered
        that it is convenient to map them to the correct unit.

    Notes
    -----
    `~astropy.nddata.CCDData` objects can be easily converted to a regular
     Numpy array using `numpy.asarray`.

    For example::

        >>> from astropy.nddata import CCDData
        >>> import numpy as np
        >>> x = CCDData([1,2,3], unit='adu')
        >>> np.asarray(x)
        array([1, 2, 3])

    This is useful, for example, when plotting a 2D image using
    matplotlib.

        >>> from astropy.nddata import CCDData
        >>> from matplotlib import pyplot as plt   # doctest: +SKIP
        >>> x = CCDData([[1,2,3], [4,5,6]], unit='adu')
        >>> plt.imshow(x)   # doctest: +SKIP

    'u'A class describing basic CCD data.

    The CCDData class is based on the NDData object and includes a data array,
    uncertainty frame, mask frame, flag frame, meta data, units, and WCS
    information for a single CCD image.

    Parameters
    ----------
    data : `~astropy.nddata.CCDData`-like or array-like
        The actual data contained in this `~astropy.nddata.CCDData` object.
        Note that the data will always be saved by *reference*, so you should
        make a copy of the ``data`` before passing it in if that's the desired
        behavior.

    uncertainty : `~astropy.nddata.StdDevUncertainty`,             `~astropy.nddata.VarianceUncertainty`,             `~astropy.nddata.InverseVariance`, `numpy.ndarray` or             None, optional
        Uncertainties on the data. If the uncertainty is a `numpy.ndarray`, it
        it assumed to be, and stored as, a `~astropy.nddata.StdDevUncertainty`.
        Default is ``None``.

    mask : `numpy.ndarray` or None, optional
        Mask for the data, given as a boolean Numpy array with a shape
        matching that of the data. The values must be `False` where
        the data is *valid* and `True` when it is not (like Numpy
        masked arrays). If ``data`` is a numpy masked array, providing
        ``mask`` here will causes the mask from the masked array to be
        ignored.
        Default is ``None``.

    flags : `numpy.ndarray` or `~astropy.nddata.FlagCollection` or None,             optional
        Flags giving information about each pixel. These can be specified
        either as a Numpy array of any type with a shape matching that of the
        data, or as a `~astropy.nddata.FlagCollection` instance which has a
        shape matching that of the data.
        Default is ``None``.

    wcs : `~astropy.wcs.WCS` or None, optional
        WCS-object containing the world coordinate system for the data.
        Default is ``None``.

    meta : dict-like object or None, optional
        Metadata for this object. "Metadata" here means all information that
        is included with this object but not part of any other attribute
        of this particular object, e.g. creation date, unique identifier,
        simulation parameters, exposure time, telescope name, etc.

    unit : `~astropy.units.Unit` or str, optional
        The units of the data.
        Default is ``None``.

        .. warning::

            If the unit is ``None`` or not otherwise specified it will raise a
            ``ValueError``

    psf : `numpy.ndarray` or None, optional
        Image representation of the PSF at the center of this image. In order
        for convolution to be flux-preserving, this should generally be
        normalized to sum to unity.

    Raises
    ------
    ValueError
        If the ``uncertainty`` or ``mask`` inputs cannot be broadcast (e.g.,
        match shape) onto ``data``.

    Methods
    -------
    read(\*args, \**kwargs)
        ``Classmethod`` to create an CCDData instance based on a ``FITS`` file.
        This method uses :func:`fits_ccddata_reader` with the provided
        parameters.
    write(\*args, \**kwargs)
        Writes the contents of the CCDData instance into a new ``FITS`` file.
        This method uses :func:`fits_ccddata_writer` with the provided
        parameters.

    Attributes
    ----------
    known_invalid_fits_unit_strings
        A dictionary that maps commonly-used fits unit name strings that are
        technically invalid to the correct valid unit type (or unit string).
        This is primarily for variant names like "ELECTRONS/S" which are not
        formally valid, but are unambiguous and frequently enough encountered
        that it is convenient to map them to the correct unit.

    Notes
    -----
    `~astropy.nddata.CCDData` objects can be easily converted to a regular
     Numpy array using `numpy.asarray`.

    For example::

        >>> from astropy.nddata import CCDData
        >>> import numpy as np
        >>> x = CCDData([1,2,3], unit='adu')
        >>> np.asarray(x)
        array([1, 2, 3])

    This is useful, for example, when plotting a 2D image using
    matplotlib.

        >>> from astropy.nddata import CCDData
        >>> from matplotlib import pyplot as plt   # doctest: +SKIP
        >>> x = CCDData([[1,2,3], [4,5,6]], unit='adu')
        >>> plt.imshow(x)   # doctest: +SKIP

    'b'header'u'header'b'can't have both header and meta.'u'can't have both header and meta.'b'the wcs must be a WCS instance.'u'the wcs must be a WCS instance.'b'a unit for CCDData must be specified.'u'a unit for CCDData must be specified.'b'
        Override the WCS slicing behaviour so that the wcs attribute continues
        to be an `astropy.wcs.WCS`.
        'u'
        Override the WCS slicing behaviour so that the wcs attribute continues
        to be an `astropy.wcs.WCS`.
        'b'The psf must be a numpy array.'u'The psf must be a numpy array.'b'_parent_nddata'u'_parent_nddata'b'uncertainty must have same shape as data.'u'uncertainty must have same shape as data.'b'array provided for uncertainty; assuming it is a StdDevUncertainty.'u'array provided for uncertainty; assuming it is a StdDevUncertainty.'b'uncertainty must be an instance of a NDUncertainty object or a numpy array.'u'uncertainty must be an instance of a NDUncertainty object or a numpy array.'b'MASK'u'MASK'b'UNCERT'u'UNCERT'b'UTYPE'u'UTYPE'b'PSFIMAGE'u'PSFIMAGE'b'Creates an HDUList object from a CCDData object.

        Parameters
        ----------
        hdu_mask, hdu_uncertainty, hdu_flags, hdu_psf : str or None, optional
            If it is a string append this attribute to the HDUList as
            `~astropy.io.fits.ImageHDU` with the string as extension name.
            Flags are not supported at this time. If ``None`` this attribute
            is not appended.
            Default is ``'MASK'`` for mask, ``'UNCERT'`` for uncertainty,
            ``'PSFIMAGE'`` for psf, and `None` for flags.

        wcs_relax : bool
            Value of the ``relax`` parameter to use in converting the WCS to a
            FITS header using `~astropy.wcs.WCS.to_header`. The common
            ``CTYPE`` ``RA---TAN-SIP`` and ``DEC--TAN-SIP`` requires
            ``relax=True`` for the ``-SIP`` part of the ``CTYPE`` to be
            preserved.

        key_uncertainty_type : str, optional
            The header key name for the class name of the uncertainty (if any)
            that is used to store the uncertainty type in the uncertainty hdu.
            Default is ``UTYPE``.

            .. versionadded:: 3.1

        as_image_hdu : bool
            If this option is `True`, the first item of the returned
            `~astropy.io.fits.HDUList` is a `~astropy.io.fits.ImageHDU`, instead
            of the default `~astropy.io.fits.PrimaryHDU`.

        Raises
        ------
        ValueError
            - If ``self.mask`` is set but not a `numpy.ndarray`.
            - If ``self.uncertainty`` is set but not a astropy uncertainty type.
            - If ``self.uncertainty`` is set but has another unit then
              ``self.data``.

        NotImplementedError
            Saving flags is not supported.

        Returns
        -------
        hdulist : `~astropy.io.fits.HDUList`
        'u'Creates an HDUList object from a CCDData object.

        Parameters
        ----------
        hdu_mask, hdu_uncertainty, hdu_flags, hdu_psf : str or None, optional
            If it is a string append this attribute to the HDUList as
            `~astropy.io.fits.ImageHDU` with the string as extension name.
            Flags are not supported at this time. If ``None`` this attribute
            is not appended.
            Default is ``'MASK'`` for mask, ``'UNCERT'`` for uncertainty,
            ``'PSFIMAGE'`` for psf, and `None` for flags.

        wcs_relax : bool
            Value of the ``relax`` parameter to use in converting the WCS to a
            FITS header using `~astropy.wcs.WCS.to_header`. The common
            ``CTYPE`` ``RA---TAN-SIP`` and ``DEC--TAN-SIP`` requires
            ``relax=True`` for the ``-SIP`` part of the ``CTYPE`` to be
            preserved.

        key_uncertainty_type : str, optional
            The header key name for the class name of the uncertainty (if any)
            that is used to store the uncertainty type in the uncertainty hdu.
            Default is ``UTYPE``.

            .. versionadded:: 3.1

        as_image_hdu : bool
            If this option is `True`, the first item of the returned
            `~astropy.io.fits.HDUList` is a `~astropy.io.fits.ImageHDU`, instead
            of the default `~astropy.io.fits.PrimaryHDU`.

        Raises
        ------
        ValueError
            - If ``self.mask`` is set but not a `numpy.ndarray`.
            - If ``self.uncertainty`` is set but not a astropy uncertainty type.
            - If ``self.uncertainty`` is set but has another unit then
              ``self.data``.

        NotImplementedError
            Saving flags is not supported.

        Returns
        -------
        hdulist : `~astropy.io.fits.HDUList`
        'b'bunit'u'bunit'b'only a numpy.ndarray mask can be saved.'u'only a numpy.ndarray mask can be saved.'b'only uncertainties of type 'u'only uncertainties of type 'b' can be saved.'u' can be saved.'b'saving uncertainties with a unit that is not equivalent to the unit from the data unit is not supported.'u'saving uncertainties with a unit that is not equivalent to the unit from the data unit is not supported.'b'adding the flags to a HDU is not supported at this time.'u'adding the flags to a HDU is not supported at this time.'b'
        Return a copy of the CCDData object.
        'u'
        Return a copy of the CCDData object.
        'b'
        Insert key/value pair into metadata in a way that FITS can serialize.

        Parameters
        ----------
        key : str
            Key to be inserted in dictionary.

        value : str or None
            Value to be inserted.

        Notes
        -----
        This addresses a shortcoming of the FITS standard. There are length
        restrictions on both the ``key`` (8 characters) and ``value`` (72
        characters) in the FITS standard. There is a convention for handling
        long keywords and a convention for handling long values, but the
        two conventions cannot be used at the same time.

        This addresses that case by checking the length of the ``key`` and
        ``value`` and, if necessary, shortening the key.
        'u'
        Insert key/value pair into metadata in a way that FITS can serialize.

        Parameters
        ----------
        key : str
            Key to be inserted in dictionary.

        value : str or None
            Value to be inserted.

        Notes
        -----
        This addresses a shortcoming of the FITS standard. There are length
        restrictions on both the ``key`` (8 characters) and ``value`` (72
        characters) in the FITS standard. There is a convention for handling
        long keywords and a convention for handling long values, but the
        two conventions cannot be used at the same time.

        This addresses that case by checking the length of the ``key`` and
        ``value`` and, if necessary, shortening the key.
        'b'Shortened name for 'u'Shortened name for 'b'ELECTRONS/S'u'ELECTRONS/S'b'ELECTRONS'u'ELECTRONS'b'electrons'u'electrons'b'JD-OBS'u'JD-OBS'b'MJD-OBS'u'MJD-OBS'b'DATE-OBS'u'DATE-OBS'b'PC1_1'u'PC1_1'b'PC1_2'u'PC1_2'b'PC2_1'u'PC2_1'b'PC2_2'u'PC2_2'b'CD1_1'u'CD1_1'b'CD1_2'u'CD1_2'b'CD2_1'u'CD2_1'b'CD2_2'u'CD2_2'b'
    Generate a WCS object from a header and remove the WCS-specific
    keywords from the header.

    Parameters
    ----------
    hdr : astropy.io.fits.header or other dict-like

    Returns
    -------
    new_header, wcs
    'u'
    Generate a WCS object from a header and remove the WCS-specific
    keywords from the header.

    Parameters
    ----------
    hdr : astropy.io.fits.header or other dict-like

    Returns
    -------
    new_header, wcs
    'b'An exception happened while extracting WCS information from the Header.
'u'An exception happened while extracting WCS information from the Header.
'b'{}_{}_{}'u'{}_{}_{}'b'AP'u'AP'b'BP'u'BP'b'_order'u'_order'b'
    Generate a CCDData object from a FITS file.

    Parameters
    ----------
    filename : str
        Name of fits file.

    hdu : int, str, tuple of (str, int), optional
        Index or other identifier of the Header Data Unit of the FITS
        file from which CCDData should be initialized. If zero and
        no data in the primary HDU, it will search for the first
        extension HDU with data. The header will be added to the primary HDU.
        Default is ``0``.

    unit : `~astropy.units.Unit`, optional
        Units of the image data. If this argument is provided and there is a
        unit for the image in the FITS header (the keyword ``BUNIT`` is used
        as the unit, if present), this argument is used for the unit.
        Default is ``None``.

    hdu_uncertainty : str or None, optional
        FITS extension from which the uncertainty should be initialized. If the
        extension does not exist the uncertainty of the CCDData is ``None``.
        Default is ``'UNCERT'``.

    hdu_mask : str or None, optional
        FITS extension from which the mask should be initialized. If the
        extension does not exist the mask of the CCDData is ``None``.
        Default is ``'MASK'``.

    hdu_flags : str or None, optional
        Currently not implemented.
        Default is ``None``.

    key_uncertainty_type : str, optional
        The header key name where the class name of the uncertainty  is stored
        in the hdu of the uncertainty (if any).
        Default is ``UTYPE``.

        .. versionadded:: 3.1

    hdu_psf : str or None, optional
        FITS extension from which the psf image should be initialized. If the
        extension does not exist the psf of the CCDData is `None`.

    kwd :
        Any additional keyword parameters are passed through to the FITS reader
        in :mod:`astropy.io.fits`; see Notes for additional discussion.

    Notes
    -----
    FITS files that contained scaled data (e.g. unsigned integer images) will
    be scaled and the keywords used to manage scaled data in
    :mod:`astropy.io.fits` are disabled.
    'u'
    Generate a CCDData object from a FITS file.

    Parameters
    ----------
    filename : str
        Name of fits file.

    hdu : int, str, tuple of (str, int), optional
        Index or other identifier of the Header Data Unit of the FITS
        file from which CCDData should be initialized. If zero and
        no data in the primary HDU, it will search for the first
        extension HDU with data. The header will be added to the primary HDU.
        Default is ``0``.

    unit : `~astropy.units.Unit`, optional
        Units of the image data. If this argument is provided and there is a
        unit for the image in the FITS header (the keyword ``BUNIT`` is used
        as the unit, if present), this argument is used for the unit.
        Default is ``None``.

    hdu_uncertainty : str or None, optional
        FITS extension from which the uncertainty should be initialized. If the
        extension does not exist the uncertainty of the CCDData is ``None``.
        Default is ``'UNCERT'``.

    hdu_mask : str or None, optional
        FITS extension from which the mask should be initialized. If the
        extension does not exist the mask of the CCDData is ``None``.
        Default is ``'MASK'``.

    hdu_flags : str or None, optional
        Currently not implemented.
        Default is ``None``.

    key_uncertainty_type : str, optional
        The header key name where the class name of the uncertainty  is stored
        in the hdu of the uncertainty (if any).
        Default is ``UTYPE``.

        .. versionadded:: 3.1

    hdu_psf : str or None, optional
        FITS extension from which the psf image should be initialized. If the
        extension does not exist the psf of the CCDData is `None`.

    kwd :
        Any additional keyword parameters are passed through to the FITS reader
        in :mod:`astropy.io.fits`; see Notes for additional discussion.

    Notes
    -----
    FITS files that contained scaled data (e.g. unsigned integer images) will
    be scaled and the keywords used to manage scaled data in
    :mod:`astropy.io.fits` are disabled.
    'b'Image data must be scaled.'u'Image data must be scaled.'b'do_not_scale_image_data'u'do_not_scale_image_data'b'Scale information is not preserved.'u'Scale information is not preserved.'b'scale_back'u'scale_back'b'unsupported keyword: 'u'unsupported keyword: 'b'loading flags is currently not supported.'u'loading flags is currently not supported.'b'first HDU with data is extension 'u'first HDU with data is extension 'b'The Header value for the key BUNIT ('u'The Header value for the key BUNIT ('b') cannot be interpreted as valid unit. To successfully read the file as CCDData you can pass in a valid `unit` argument explicitly or change the header of the FITS file before reading it.'u') cannot be interpreted as valid unit. To successfully read the file as CCDData you can pass in a valid `unit` argument explicitly or change the header of the FITS file before reading it.'b'using the unit 'u'using the unit 'b' passed to the FITS reader instead of the unit 'u' passed to the FITS reader instead of the unit 'b' in the FITS file.'u' in the FITS file.'b'
    Write CCDData object to FITS file.

    Parameters
    ----------
    ccd_data : CCDData
        Object to write.

    filename : str
        Name of file.

    hdu_mask, hdu_uncertainty, hdu_flags, hdu_psf : str or None, optional
        If it is a string append this attribute to the HDUList as
        `~astropy.io.fits.ImageHDU` with the string as extension name.
        Flags are not supported at this time. If ``None`` this attribute
        is not appended.
        Default is ``'MASK'`` for mask, ``'UNCERT'`` for uncertainty,
        ``'PSFIMAGE'`` for psf, and `None` for flags.

    key_uncertainty_type : str, optional
        The header key name for the class name of the uncertainty (if any)
        that is used to store the uncertainty type in the uncertainty hdu.
        Default is ``UTYPE``.

        .. versionadded:: 3.1

    as_image_hdu : bool
        If this option is `True`, the first item of the returned
        `~astropy.io.fits.HDUList` is a `~astropy.io.fits.ImageHDU`, instead of
        the default `~astropy.io.fits.PrimaryHDU`.

    kwd :
        All additional keywords are passed to :py:mod:`astropy.io.fits`

    Raises
    ------
    ValueError
        - If ``self.mask`` is set but not a `numpy.ndarray`.
        - If ``self.uncertainty`` is set but not a
          `~astropy.nddata.StdDevUncertainty`.
        - If ``self.uncertainty`` is set but has another unit then
          ``self.data``.

    NotImplementedError
        Saving flags is not supported.
    'u'
    Write CCDData object to FITS file.

    Parameters
    ----------
    ccd_data : CCDData
        Object to write.

    filename : str
        Name of file.

    hdu_mask, hdu_uncertainty, hdu_flags, hdu_psf : str or None, optional
        If it is a string append this attribute to the HDUList as
        `~astropy.io.fits.ImageHDU` with the string as extension name.
        Flags are not supported at this time. If ``None`` this attribute
        is not appended.
        Default is ``'MASK'`` for mask, ``'UNCERT'`` for uncertainty,
        ``'PSFIMAGE'`` for psf, and `None` for flags.

    key_uncertainty_type : str, optional
        The header key name for the class name of the uncertainty (if any)
        that is used to store the uncertainty type in the uncertainty hdu.
        Default is ``UTYPE``.

        .. versionadded:: 3.1

    as_image_hdu : bool
        If this option is `True`, the first item of the returned
        `~astropy.io.fits.HDUList` is a `~astropy.io.fits.ImageHDU`, instead of
        the default `~astropy.io.fits.PrimaryHDU`.

    kwd :
        All additional keywords are passed to :py:mod:`astropy.io.fits`

    Raises
    ------
    ValueError
        - If ``self.mask`` is set but not a `numpy.ndarray`.
        - If ``self.uncertainty`` is set but not a
          `~astropy.nddata.StdDevUncertainty`.
        - If ``self.uncertainty`` is set but has another unit then
          ``self.data``.

    NotImplementedError
        Saving flags is not supported.
    'u'astropy.nddata.ccddata'u'nddata.ccddata'u'ccddata'An extensible ASCII table reader and writer.

cds.py:
  Classes to read CDS / Vizier table format

:Copyright: Smithsonian Astrophysical Observatory (2011)
:Author: Tom Aldcroft (aldcroft@head.cfa.harvard.edu)
fnmatchUnrecognizedUnit__doctest_skip___is_section_delimiterCheck if line is a section delimiter.

    CDS/MRT tables use dashes or equal signs ("------" or "======") to
    separate sections. This function checks if a line contains only either
    of these characters.

    Parameters
    ----------
    line : str
        String containing an entire line from the table text file.

    Returns
    -------
    status : bool
        True if the line is a section delimiter, False otherwise.

    ------=======CdsHeader_subfmtThe ReadMe file to construct header from.readme\d*(\S)Unrecognized  format "" for column"'" for column'
        Initialize the header Column objects from the table ``lines`` for a CDS/MRT
        header.

        Parameters
        ----------
        lines : list
            List of table lines

        table_namein_headerreadme_inputterget_linescomment_linesByte-by-byte Description of file: (?P<name>.+)$[, ]+Can't find table  in found_linei_col_defByte-by-byte Descriptionno line with "Byte-by-byte Description" found\s*
                (?P<start> \d+ \s* -)? \s*
                (?P<end>   \d+)        \s+
                (?P<format> [\w.]+)     \s+
                (?P<units> \S+)        \s+
                (?P<name>  \S+)
                (\s+ (?P<descr> \S.*))?VERBOSEre_col_defislice[-\s]---parse_strictdescr(?P<limits>[\[\]] \S* [\[\]])?\?((?P<equal>=)(?P<nullval> \S*))?(?P<order>[-+]?[=]?)(\s* (?P<descriptiontext> \S.*))?r"(?P<limits>[\[\]] \S* [\[\]])?"r"\?"r"((?P<equal>=)(?P<nullval> \S*))?"r"(?P<order>[-+]?[=]?)"r"(\s* (?P<descriptiontext> \S.*))?"descriptiontextfillvalnullvalnullLine "" not parsable as CDS headerCdsDataCDS table data reader.Skip over CDS/MRT header by finding the last section delimiter.i_sectionsNo  section delimiter foundCDS format table.

    See: https://vizier.unistra.fr/doc/catstd.htx

    Example::

      Table: Table name here
      = ==============================================================================
      Catalog reference paper
          Bibliography info here
      ================================================================================
      ADC_Keywords: Keyword ; Another keyword ; etc

      Description:
          Catalog description here.
      ================================================================================
      Byte-by-byte Description of file: datafile3.txt
      --------------------------------------------------------------------------------
         Bytes Format Units  Label  Explanations
      --------------------------------------------------------------------------------
         1-  3 I3     ---    Index  Running identification number
         5-  6 I2     h      RAh    Hour of Right Ascension (J2000)
         8-  9 I2     min    RAm    Minute of Right Ascension (J2000)
        11- 15 F5.2   s      RAs    Second of Right Ascension (J2000)
      --------------------------------------------------------------------------------
      Note (1): A CDS file can contain sections with various metadata.
                Notes can be multiple lines.
      Note (2): Another note.
      --------------------------------------------------------------------------------
        1 03 28 39.09
        2 04 18 24.11

    **About parsing the CDS format**

    The CDS format consists of a table description and the table data.  These
    can be in separate files as a ``ReadMe`` file plus data file(s), or
    combined in a single file.  Different subsections within the description
    are separated by lines of dashes or equal signs ("------" or "======").
    The table which specifies the column information must be preceded by a line
    starting with "Byte-by-byte Description of file:".

    In the case where the table description is combined with the data values,
    the data must be in the last section and must be preceded by a section
    delimiter line (dashes or equal signs only).

    **Basic usage**

    Use the ``ascii.read()`` function as normal, with an optional ``readme``
    parameter indicating the CDS ReadMe file.  If not supplied it is assumed that
    the header information is at the top of the given table.  Examples::

      >>> from astropy.io import ascii
      >>> table = ascii.read("data/cds.dat")
      >>> table = ascii.read("data/vizier/table1.dat", readme="data/vizier/ReadMe")
      >>> table = ascii.read("data/cds/multi/lhs2065.dat", readme="data/cds/multi/ReadMe")
      >>> table = ascii.read("data/cds/glob/lmxbrefs.dat", readme="data/cds/glob/ReadMe")

    The table name and the CDS ReadMe file can be entered as URLs.  This can be used
    to directly load tables from the Internet.  For example, Vizier tables from the
    CDS::

      >>> table = ascii.read("ftp://cdsarc.unistra.fr/pub/cats/VII/253/snrs.dat",
      ...             readme="ftp://cdsarc.unistra.fr/pub/cats/VII/253/ReadMe")

    If the header (ReadMe) and data are stored in a single file and there
    is content between the header and the data (for instance Notes), then the
    parsing process may fail.  In this case you can instruct the reader to
    guess the actual start of the data by supplying ``data_start='guess'`` in the
    call to the ``ascii.read()`` function.  You should verify that the output
    data table matches expectation based on the input CDS file.

    **Using a reader object**

    When ``Cds`` reader object is created with a ``readme`` parameter
    passed to it at initialization, then when the ``read`` method is
    executed with a table filename, the header information for the
    specified table is taken from the ``readme`` file.  An
    ``InconsistentTableError`` is raised if the ``readme`` file does not
    have header information for the given table.

      >>> readme = "data/vizier/ReadMe"
      >>> r = ascii.get_reader(ascii.Cds, readme=readme)
      >>> table = r.read("data/vizier/table1.dat")
      >>> # table5.dat has the same ReadMe file
      >>> table = r.read("data/vizier/table5.dat")

    If no ``readme`` parameter is specified, then the header
    information is assumed to be at the top of the given table.

      >>> r = ascii.get_reader(ascii.Cds)
      >>> table = r.read("data/cds.dat")
      >>> #The following gives InconsistentTableError, since no
      >>> #readme file was given and table1.dat does not have a header.
      >>> table = r.read("data/vizier/table1.dat")
      Traceback (most recent call last):
        ...
      InconsistentTableError: No CDS section delimiter found

    Caveats:

    * The Units and Explanations are available in the column ``unit`` and
      ``description`` attributes, respectively.
    * The other metadata defined by this format is not available in the output table.
    CDS format tableNot available for the CDS class (raises NotImplementedError).guesslinesepinputterdata_start# Check that line starts with either 6 "-" or "="# and that it contains only a single repeated character.# Latter condition fixes cases where a regular row starts with 6 "-".# Read header block for the table ``self.data.table_name`` from the read# me file ``self.readme``.# Header info is not in data lines but in a separate file.# Split 'name' in case in contains multiple files# Iterate on names to find if one matches the tablename# including wildcards.# First line after list of file descriptions# Set i_col_def to last description line# "---" is the marker for no unit in CDS/MRT table# catch when warnings are turned into errors so we can check# whether this line is likely a multi-line description (see below)# If parsing the format fails and the unit is unrecognized,# then this line is likely a continuation of the previous col's# description that happens to start with a number# Because we may have ignored a UnitsWarning turned into an error# we do this again so it can be raised again if it is a real error# Matches limits specifier (eg []) that may or may not be# present# Matches '?' directly# Matches to nullval if and only if '=' is present# Matches to order specifier: ('+', '-', '+=', '-=')# Matches description text even even if no whitespace is# present after '?'# CDS/MRT tables can use -, --, ---, or ---- to mark missing values# see https://github.com/astropy/astropy/issues/1335# could be a continuation of the previous col's description# If the header has a ReadMe and data has a filename# then no need to skip, as the data lines do not have header# info. The ``read`` method adds the table_name to the ``data``# attribute.# If the read kwarg `data_start` is 'guess' then the table may have extraneous# lines between the end of the header and the beginning of data.# Replicate the first part of BaseReader.read up to the point where# the table lines are initially read in.# For strings only# Get a list of the lines (rows) in the table# Now try increasing data.start_line by one until the table reads successfully.# For efficiency use the in-memory list of lines instead of `table`, which# could be a file.b'An extensible ASCII table reader and writer.

cds.py:
  Classes to read CDS / Vizier table format

:Copyright: Smithsonian Astrophysical Observatory (2011)
:Author: Tom Aldcroft (aldcroft@head.cfa.harvard.edu)
'u'An extensible ASCII table reader and writer.

cds.py:
  Classes to read CDS / Vizier table format

:Copyright: Smithsonian Astrophysical Observatory (2011)
:Author: Tom Aldcroft (aldcroft@head.cfa.harvard.edu)
'b'Check if line is a section delimiter.

    CDS/MRT tables use dashes or equal signs ("------" or "======") to
    separate sections. This function checks if a line contains only either
    of these characters.

    Parameters
    ----------
    line : str
        String containing an entire line from the table text file.

    Returns
    -------
    status : bool
        True if the line is a section delimiter, False otherwise.

    'u'Check if line is a section delimiter.

    CDS/MRT tables use dashes or equal signs ("------" or "======") to
    separate sections. This function checks if a line contains only either
    of these characters.

    Parameters
    ----------
    line : str
        String containing an entire line from the table text file.

    Returns
    -------
    status : bool
        True if the line is a section delimiter, False otherwise.

    'b'------'u'------'b'======='u'======='b'The ReadMe file to construct header from.'u'The ReadMe file to construct header from.'b'\d*(\S)'u'\d*(\S)'b'Unrecognized 'u'Unrecognized 'b' format "'u' format "'b'" for column"'u'" for column"'b'
        Initialize the header Column objects from the table ``lines`` for a CDS/MRT
        header.

        Parameters
        ----------
        lines : list
            List of table lines

        'u'
        Initialize the header Column objects from the table ``lines`` for a CDS/MRT
        header.

        Parameters
        ----------
        lines : list
            List of table lines

        'b'Byte-by-byte Description of file: (?P<name>.+)$'u'Byte-by-byte Description of file: (?P<name>.+)$'b'[, ]+'u'[, ]+'b'Can't find table 'u'Can't find table 'b' in 'u' in 'b'Byte-by-byte Description'u'Byte-by-byte Description'b'no line with "Byte-by-byte Description" found'u'no line with "Byte-by-byte Description" found'b'\s*
                (?P<start> \d+ \s* -)? \s*
                (?P<end>   \d+)        \s+
                (?P<format> [\w.]+)     \s+
                (?P<units> \S+)        \s+
                (?P<name>  \S+)
                (\s+ (?P<descr> \S.*))?'u'\s*
                (?P<start> \d+ \s* -)? \s*
                (?P<end>   \d+)        \s+
                (?P<format> [\w.]+)     \s+
                (?P<units> \S+)        \s+
                (?P<name>  \S+)
                (\s+ (?P<descr> \S.*))?'b'[-\s]'u'[-\s]'b'start'u'start'b'end'u'end'b'---'u'---'b'cds'u'cds'b'descr'u'descr'b'(?P<limits>[\[\]] \S* [\[\]])?\?((?P<equal>=)(?P<nullval> \S*))?(?P<order>[-+]?[=]?)(\s* (?P<descriptiontext> \S.*))?'u'(?P<limits>[\[\]] \S* [\[\]])?\?((?P<equal>=)(?P<nullval> \S*))?(?P<order>[-+]?[=]?)(\s* (?P<descriptiontext> \S.*))?'b'descriptiontext'u'descriptiontext'b'nan'b'nullval'u'nullval'b'Line "'u'Line "'b'" not parsable as CDS header'u'" not parsable as CDS header'b'CDS table data reader.'u'CDS table data reader.'b'Skip over CDS/MRT header by finding the last section delimiter.'u'Skip over CDS/MRT header by finding the last section delimiter.'b'No 'u'No 'b' section delimiter found'u' section delimiter found'b'CDS format table.

    See: https://vizier.unistra.fr/doc/catstd.htx

    Example::

      Table: Table name here
      = ==============================================================================
      Catalog reference paper
          Bibliography info here
      ================================================================================
      ADC_Keywords: Keyword ; Another keyword ; etc

      Description:
          Catalog description here.
      ================================================================================
      Byte-by-byte Description of file: datafile3.txt
      --------------------------------------------------------------------------------
         Bytes Format Units  Label  Explanations
      --------------------------------------------------------------------------------
         1-  3 I3     ---    Index  Running identification number
         5-  6 I2     h      RAh    Hour of Right Ascension (J2000)
         8-  9 I2     min    RAm    Minute of Right Ascension (J2000)
        11- 15 F5.2   s      RAs    Second of Right Ascension (J2000)
      --------------------------------------------------------------------------------
      Note (1): A CDS file can contain sections with various metadata.
                Notes can be multiple lines.
      Note (2): Another note.
      --------------------------------------------------------------------------------
        1 03 28 39.09
        2 04 18 24.11

    **About parsing the CDS format**

    The CDS format consists of a table description and the table data.  These
    can be in separate files as a ``ReadMe`` file plus data file(s), or
    combined in a single file.  Different subsections within the description
    are separated by lines of dashes or equal signs ("------" or "======").
    The table which specifies the column information must be preceded by a line
    starting with "Byte-by-byte Description of file:".

    In the case where the table description is combined with the data values,
    the data must be in the last section and must be preceded by a section
    delimiter line (dashes or equal signs only).

    **Basic usage**

    Use the ``ascii.read()`` function as normal, with an optional ``readme``
    parameter indicating the CDS ReadMe file.  If not supplied it is assumed that
    the header information is at the top of the given table.  Examples::

      >>> from astropy.io import ascii
      >>> table = ascii.read("data/cds.dat")
      >>> table = ascii.read("data/vizier/table1.dat", readme="data/vizier/ReadMe")
      >>> table = ascii.read("data/cds/multi/lhs2065.dat", readme="data/cds/multi/ReadMe")
      >>> table = ascii.read("data/cds/glob/lmxbrefs.dat", readme="data/cds/glob/ReadMe")

    The table name and the CDS ReadMe file can be entered as URLs.  This can be used
    to directly load tables from the Internet.  For example, Vizier tables from the
    CDS::

      >>> table = ascii.read("ftp://cdsarc.unistra.fr/pub/cats/VII/253/snrs.dat",
      ...             readme="ftp://cdsarc.unistra.fr/pub/cats/VII/253/ReadMe")

    If the header (ReadMe) and data are stored in a single file and there
    is content between the header and the data (for instance Notes), then the
    parsing process may fail.  In this case you can instruct the reader to
    guess the actual start of the data by supplying ``data_start='guess'`` in the
    call to the ``ascii.read()`` function.  You should verify that the output
    data table matches expectation based on the input CDS file.

    **Using a reader object**

    When ``Cds`` reader object is created with a ``readme`` parameter
    passed to it at initialization, then when the ``read`` method is
    executed with a table filename, the header information for the
    specified table is taken from the ``readme`` file.  An
    ``InconsistentTableError`` is raised if the ``readme`` file does not
    have header information for the given table.

      >>> readme = "data/vizier/ReadMe"
      >>> r = ascii.get_reader(ascii.Cds, readme=readme)
      >>> table = r.read("data/vizier/table1.dat")
      >>> # table5.dat has the same ReadMe file
      >>> table = r.read("data/vizier/table5.dat")

    If no ``readme`` parameter is specified, then the header
    information is assumed to be at the top of the given table.

      >>> r = ascii.get_reader(ascii.Cds)
      >>> table = r.read("data/cds.dat")
      >>> #The following gives InconsistentTableError, since no
      >>> #readme file was given and table1.dat does not have a header.
      >>> table = r.read("data/vizier/table1.dat")
      Traceback (most recent call last):
        ...
      InconsistentTableError: No CDS section delimiter found

    Caveats:

    * The Units and Explanations are available in the column ``unit`` and
      ``description`` attributes, respectively.
    * The other metadata defined by this format is not available in the output table.
    'u'CDS format table.

    See: https://vizier.unistra.fr/doc/catstd.htx

    Example::

      Table: Table name here
      = ==============================================================================
      Catalog reference paper
          Bibliography info here
      ================================================================================
      ADC_Keywords: Keyword ; Another keyword ; etc

      Description:
          Catalog description here.
      ================================================================================
      Byte-by-byte Description of file: datafile3.txt
      --------------------------------------------------------------------------------
         Bytes Format Units  Label  Explanations
      --------------------------------------------------------------------------------
         1-  3 I3     ---    Index  Running identification number
         5-  6 I2     h      RAh    Hour of Right Ascension (J2000)
         8-  9 I2     min    RAm    Minute of Right Ascension (J2000)
        11- 15 F5.2   s      RAs    Second of Right Ascension (J2000)
      --------------------------------------------------------------------------------
      Note (1): A CDS file can contain sections with various metadata.
                Notes can be multiple lines.
      Note (2): Another note.
      --------------------------------------------------------------------------------
        1 03 28 39.09
        2 04 18 24.11

    **About parsing the CDS format**

    The CDS format consists of a table description and the table data.  These
    can be in separate files as a ``ReadMe`` file plus data file(s), or
    combined in a single file.  Different subsections within the description
    are separated by lines of dashes or equal signs ("------" or "======").
    The table which specifies the column information must be preceded by a line
    starting with "Byte-by-byte Description of file:".

    In the case where the table description is combined with the data values,
    the data must be in the last section and must be preceded by a section
    delimiter line (dashes or equal signs only).

    **Basic usage**

    Use the ``ascii.read()`` function as normal, with an optional ``readme``
    parameter indicating the CDS ReadMe file.  If not supplied it is assumed that
    the header information is at the top of the given table.  Examples::

      >>> from astropy.io import ascii
      >>> table = ascii.read("data/cds.dat")
      >>> table = ascii.read("data/vizier/table1.dat", readme="data/vizier/ReadMe")
      >>> table = ascii.read("data/cds/multi/lhs2065.dat", readme="data/cds/multi/ReadMe")
      >>> table = ascii.read("data/cds/glob/lmxbrefs.dat", readme="data/cds/glob/ReadMe")

    The table name and the CDS ReadMe file can be entered as URLs.  This can be used
    to directly load tables from the Internet.  For example, Vizier tables from the
    CDS::

      >>> table = ascii.read("ftp://cdsarc.unistra.fr/pub/cats/VII/253/snrs.dat",
      ...             readme="ftp://cdsarc.unistra.fr/pub/cats/VII/253/ReadMe")

    If the header (ReadMe) and data are stored in a single file and there
    is content between the header and the data (for instance Notes), then the
    parsing process may fail.  In this case you can instruct the reader to
    guess the actual start of the data by supplying ``data_start='guess'`` in the
    call to the ``ascii.read()`` function.  You should verify that the output
    data table matches expectation based on the input CDS file.

    **Using a reader object**

    When ``Cds`` reader object is created with a ``readme`` parameter
    passed to it at initialization, then when the ``read`` method is
    executed with a table filename, the header information for the
    specified table is taken from the ``readme`` file.  An
    ``InconsistentTableError`` is raised if the ``readme`` file does not
    have header information for the given table.

      >>> readme = "data/vizier/ReadMe"
      >>> r = ascii.get_reader(ascii.Cds, readme=readme)
      >>> table = r.read("data/vizier/table1.dat")
      >>> # table5.dat has the same ReadMe file
      >>> table = r.read("data/vizier/table5.dat")

    If no ``readme`` parameter is specified, then the header
    information is assumed to be at the top of the given table.

      >>> r = ascii.get_reader(ascii.Cds)
      >>> table = r.read("data/cds.dat")
      >>> #The following gives InconsistentTableError, since no
      >>> #readme file was given and table1.dat does not have a header.
      >>> table = r.read("data/vizier/table1.dat")
      Traceback (most recent call last):
        ...
      InconsistentTableError: No CDS section delimiter found

    Caveats:

    * The Units and Explanations are available in the column ``unit`` and
      ``description`` attributes, respectively.
    * The other metadata defined by this format is not available in the output table.
    'b'CDS format table'u'CDS format table'b'Not available for the CDS class (raises NotImplementedError).'u'Not available for the CDS class (raises NotImplementedError).'b'guess'u'guess'u'astropy.io.ascii.cds'u'io.ascii.cds'u'ascii.cds'
This package defines units used in the CDS format, both the units
defined in `Centre de Donnes astronomiques de Strasbourg
<https://cds.unistra.fr/>`_ `Standards for Astronomical Catalogues 2.0
<https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_ format and the `complete
set of supported units <https://vizier.unistra.fr/viz-bin/Unit>`_.
This format is used by VOTable up to version 1.2.

These units are not available in the top-level `astropy.units`
namespace.  To use these units, you must import the `astropy.units.cds`
module::

    >>> from astropy.units import cds
    >>> q = 10. * cds.lyr  # doctest: +SKIP

To include them in `~astropy.units.UnitBase.compose` and the results of
`~astropy.units.UnitBase.find_equivalent_units`, do::

    >>> from astropy.units import cds
    >>> cds.enable()  # doctest: +SKIP

Note, however, that this can introduce conflicts between CDS and other
units in the top-level namespace. A safer way to use CDS units is to enable
them inside a context manager. For instance, you could do the following if
you have a string that uses CDS units:

>>> import astropy.units as u
>>> unit_string = "mmHg"
>>> with cds.enable():
...     pressure_unit = u.Unit(unit_string)
>>> (720*pressure_unit).to(u.bar)
<Quantity 0.95992119 bar>
enable_initialize_moduleInitialize CDS units module.shortfactorsi_prefixesbinary_prefixesAmperePa0Bohr radiusalalphaFine structure constantAngstromAngstroemAAarcmarcminuteminute of arcarcsarcsecondsecond of arcatmatmosphereastronomical unitbarbarnbitCoulombspeed of lightcal4.1854caloriecandelaDDebye (dipole)Julian daydyndyneelectron chargeeps0electric constantergelectron voltFaradGravitation constantgramgaussGaussgeoMassMgeoHenryhr\hPlanck constantHertzinch0.0254JouleJDjovMassBoltzmannlitrelumensolar luminositylxluxmetermagnitudemem_eelectron massMJDmmHg133.322387415Pamillimeter of mercurymolmolempm_pproton masssolar massmu00magnetic constantmuBBohr magnetonNewtonOhmPascalpixppm1e-061e-6parts per milliongas constantradianRgeoEarth equatorial radiusJupiter equatorial radiussolar radiusRyRydbergSiemenssolar unitTesla1000.01e3metric tonneatomic massVVoltWattWbWeberexcludesasmicroarcsecondmicrosecond of arcmilliarcsecondmillisecond of arcdimensionless and unscaledpercentCrabCrab (X-ray) flux
    Enable CDS units so they appear in results of
    `~astropy.units.UnitBase.find_equivalent_units` and
    `~astropy.units.UnitBase.compose`.  This will disable
    all of the "default" `astropy.units` units, since there
    are some namespace clashes between the two.

    This may be used with the ``with`` statement to enable CDS
    units only temporarily.
    getmodule# Local imports to avoid polluting top-level namespace# The CDS format also supports power-of-2 prefixes as defined here:# http://physics.nist.gov/cuu/Units/binary.html# CDS only uses the short prefixes# The following units are defined in alphabetical order, directly from# here: https://vizier.unistra.fr/viz-bin/Unit# The Vizier "standard" defines this in units of "kg s-3", but# that may not make a whole lot of sense, so here we just define# it as its own new disconnected unit.# Local imports to avoid cyclical import and polluting namespaceb'
This package defines units used in the CDS format, both the units
defined in `Centre de Donnes astronomiques de Strasbourg
<https://cds.unistra.fr/>`_ `Standards for Astronomical Catalogues 2.0
<https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_ format and the `complete
set of supported units <https://vizier.unistra.fr/viz-bin/Unit>`_.
This format is used by VOTable up to version 1.2.

These units are not available in the top-level `astropy.units`
namespace.  To use these units, you must import the `astropy.units.cds`
module::

    >>> from astropy.units import cds
    >>> q = 10. * cds.lyr  # doctest: +SKIP

To include them in `~astropy.units.UnitBase.compose` and the results of
`~astropy.units.UnitBase.find_equivalent_units`, do::

    >>> from astropy.units import cds
    >>> cds.enable()  # doctest: +SKIP

Note, however, that this can introduce conflicts between CDS and other
units in the top-level namespace. A safer way to use CDS units is to enable
them inside a context manager. For instance, you could do the following if
you have a string that uses CDS units:

>>> import astropy.units as u
>>> unit_string = "mmHg"
>>> with cds.enable():
...     pressure_unit = u.Unit(unit_string)
>>> (720*pressure_unit).to(u.bar)
<Quantity 0.95992119 bar>
'u'
This package defines units used in the CDS format, both the units
defined in `Centre de Donnes astronomiques de Strasbourg
<https://cds.unistra.fr/>`_ `Standards for Astronomical Catalogues 2.0
<https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_ format and the `complete
set of supported units <https://vizier.unistra.fr/viz-bin/Unit>`_.
This format is used by VOTable up to version 1.2.

These units are not available in the top-level `astropy.units`
namespace.  To use these units, you must import the `astropy.units.cds`
module::

    >>> from astropy.units import cds
    >>> q = 10. * cds.lyr  # doctest: +SKIP

To include them in `~astropy.units.UnitBase.compose` and the results of
`~astropy.units.UnitBase.find_equivalent_units`, do::

    >>> from astropy.units import cds
    >>> cds.enable()  # doctest: +SKIP

Note, however, that this can introduce conflicts between CDS and other
units in the top-level namespace. A safer way to use CDS units is to enable
them inside a context manager. For instance, you could do the following if
you have a string that uses CDS units:

>>> import astropy.units as u
>>> unit_string = "mmHg"
>>> with cds.enable():
...     pressure_unit = u.Unit(unit_string)
>>> (720*pressure_unit).to(u.bar)
<Quantity 0.95992119 bar>
'b'enable'u'enable'b'Initialize CDS units module.'u'Initialize CDS units module.'b'Ampere'u'Ampere'b'year'u'year'b'P'u'P'b'a0'u'a0'b'Bohr radius'u'Bohr radius'b'al'u'al'b'alpha'u'alpha'b'Fine structure constant'u'Fine structure constant'b'Angstrom'u'Angstrom'b''u''b'Angstroem'u'Angstroem'b'AA'u'AA'b'arcmin'u'arcmin'b'arcm'u'arcm'b'minute of arc'u'minute of arc'b'arcsec'u'arcsec'b'arcs'u'arcs'b'second of arc'u'second of arc'b'atm'u'atm'b'atmosphere'u'atmosphere'b'astronomical unit'u'astronomical unit'b'bar'u'bar'b'barn'u'barn'b'bit'u'bit'b'Coulomb'u'Coulomb'b'speed of light'u'speed of light'b'cal'u'cal'b'calorie'u'calorie'b'cd'u'cd'b'candela'u'candela'b'D'u'D'b'Debye (dipole)'u'Debye (dipole)'b'Julian day'u'Julian day'b''u''b'degree'u'degree'b'dyn'u'dyn'b'dyne'u'dyne'b'electron charge'u'electron charge'b'eps0'u'eps0'b'electric constant'u'electric constant'b'erg'u'erg'b'electron volt'u'electron volt'b'Farad'u'Farad'b'G'u'G'b'Gravitation constant'u'Gravitation constant'b'g'u'g'b'gram'u'gram'b'gauss'u'gauss'b'Gauss'u'Gauss'b'geoMass'u'geoMass'b'Mgeo'u'Mgeo'b'Henry'u'Henry'b'h'u'h'b'hour'u'hour'b'hr'u'hr'b'\h'u'\h'b'Planck constant'u'Planck constant'b'Hz'u'Hz'b'Hertz'u'Hertz'b'inch'u'inch'b'Joule'u'Joule'b'JD'u'JD'b'jovMass'u'jovMass'b'K'u'K'b'k'u'k'b'Boltzmann'u'Boltzmann'b'litre'u'litre'b'lumen'u'lumen'b'solar luminosity'u'solar luminosity'b'lx'u'lx'b'lux'u'lux'b'meter'u'meter'b'mag'u'mag'b'magnitude'u'magnitude'b'me'u'me'b'electron mass'u'electron mass'b'min'b'minute'u'minute'b'MJD'u'MJD'b'mmHg'u'mmHg'b'millimeter of mercury'u'millimeter of mercury'b'mol'u'mol'b'mole'u'mole'b'mp'u'mp'b'proton mass'u'proton mass'b'solar mass'u'solar mass'b'mu0'u'mu0'b'0'u'0'b'magnetic constant'u'magnetic constant'b'muB'u'muB'b'Bohr magneton'u'Bohr magneton'b'Newton'u'Newton'b'Ohm'u'Ohm'b'Pa'u'Pa'b'Pascal'u'Pascal'b'pi'u'pi'u''b'pix'u'pix'b'pixel'u'pixel'b'ppm'u'ppm'b'parts per million'u'parts per million'b'gas constant'u'gas constant'b'rad'u'rad'b'radian'u'radian'b'Rgeo'u'Rgeo'b'Earth equatorial radius'u'Earth equatorial radius'b'Jupiter equatorial radius'u'Jupiter equatorial radius'b'solar radius'u'solar radius'b'Ry'u'Ry'b'Rydberg'u'Rydberg'b'Siemens'u'Siemens'b'sec'u'sec'b'second'u'second'b'sr'u'sr'b'steradian'u'steradian'b'solar unit'u'solar unit'b'Tesla'u'Tesla'b'metric tonne'u'metric tonne'b'atomic mass'u'atomic mass'b'da'u'da'b'V'u'V'b'Volt'u'Volt'b'Watt'u'Watt'b'Wb'u'Wb'b'Weber'u'Weber'b'yr'u'yr'b'as'u'as'b'microsecond of arc'u'microsecond of arc'b'mas'u'mas'b'millisecond of arc'u'millisecond of arc'b'dimensionless and unscaled'u'dimensionless and unscaled'b'percent'u'percent'b'Crab'u'Crab'b'Crab (X-ray) flux'u'Crab (X-ray) flux'b'
    Enable CDS units so they appear in results of
    `~astropy.units.UnitBase.find_equivalent_units` and
    `~astropy.units.UnitBase.compose`.  This will disable
    all of the "default" `astropy.units` units, since there
    are some namespace clashes between the two.

    This may be used with the ``with`` statement to enable CDS
    units only temporarily.
    'u'
    Enable CDS units so they appear in results of
    `~astropy.units.UnitBase.find_equivalent_units` and
    `~astropy.units.UnitBase.compose`.  This will disable
    all of the "default" `astropy.units` units, since there
    are some namespace clashes between the two.

    This may be used with the ``with`` statement to enable CDS
    units only temporarily.
    'u'astropy.units.cds'u'units.cds'Handles the CDS string format for units.is_effectively_unityparsingLexerastropy.utils.parsingThreadSafeParser
    Support the `Centre de Donnes astronomiques de Strasbourg
    <https://cds.unistra.fr/>`_ `Standards for Astronomical
    Catalogues 2.0 <https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_
    format, and the `complete set of supported units
    <https://vizier.unistra.fr/viz-bin/Unit>`_.  This format is used
    by VOTable up to version 1.2.
    PRODUCTDIVISIONOPEN_PARENCLOSE_PARENOPEN_BRACKETCLOSE_BRACKETUNITDIMENSIONLESS_tokenslazytokens\.t_PRODUCTt_DIVISION\(t_OPEN_PAREN\)t_CLOSE_PAREN\[t_OPEN_BRACKET\]t_CLOSE_BRACKET((\d+\.?\d+)|(\.\d+))([eE][+-]?\d+)?[eE\.]\d+[+-](?=\d)t_X[x]t_UNIT%||\\h|(a|eps|mu)0|((?!\d)\w)+t_DIMENSIONLESS---|-t_ignoreInvalid character at col cds_lextablextabastropy/unitspackageUNICODEreflags
        The grammar here is based on the description in the `Standards
        for Astronomical Catalogues 2.0
        <https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_, which is not
        terribly precise.  The exact grammar is here is based on the
        YACC grammar in the `unity library <https://purl.org/nxg/dist/unity/>`_.
        p_main
            main : factor combined_units
                 | combined_units
                 | DIMENSIONLESS
                 | OPEN_BRACKET combined_units CLOSE_BRACKET
                 | OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET
                 | factor
            dexp_combined_units
            combined_units : product_of_units
                           | division_of_units
            p_product_of_units
            product_of_units : unit_expression PRODUCT combined_units
                             | unit_expression
            p_division_of_units
            division_of_units : DIVISION unit_expression
                              | combined_units DIVISION unit_expression
            p_unit_expression
            unit_expression : unit_with_power
                            | OPEN_PAREN combined_units CLOSE_PAREN
            p_factor
            factor : signed_float X UINT signed_int
                   | UINT X UINT signed_int
                   | UINT signed_int
                   | UINT
                   | signed_float
            Only base ten exponents are allowed in CDS10.0p_unit_with_power
            unit_with_power : UNIT numeric_power
                            | UNIT
            p_numeric_power
            numeric_power : sign UINT
            
            sign : SIGN
                 |
            p_signed_int
            signed_int : SIGN UINT
            p_signed_float
            signed_float : sign UINT
                         | sign UFLOAT
            p_errorcds_parsetabtabmoduleCDS unit must not contain whitespace# Licensed under a 3-clause BSD style license - see LICNSE.rst# This module includes files automatically generated from ply (these end in# _lextab.py and _parsetab.py). To generate these files, remove them from this# folder, then build astropy and run the tests in-place:#   pytest astropy/units# You can then commit the changes to the re-generated _lextab.py and# _parsetab.py files.# NOTE THE ORDERING OF THESE RULES IS IMPORTANT!!# Regular expression rules for simple tokens# multiplication for factor in front of unit# Most units are just combinations of letters with no numbers, but there# are a few special ones (\h is Planch constant) and three that end in 0.# These are separate from t_UNIT since they cannot have a prefactor.# Error handling rule# Remove units that aren't known to the formatb'Handles the CDS string format for units.'u'Handles the CDS string format for units.'b'
    Support the `Centre de Donnes astronomiques de Strasbourg
    <https://cds.unistra.fr/>`_ `Standards for Astronomical
    Catalogues 2.0 <https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_
    format, and the `complete set of supported units
    <https://vizier.unistra.fr/viz-bin/Unit>`_.  This format is used
    by VOTable up to version 1.2.
    'u'
    Support the `Centre de Donnes astronomiques de Strasbourg
    <https://cds.unistra.fr/>`_ `Standards for Astronomical
    Catalogues 2.0 <https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_
    format, and the `complete set of supported units
    <https://vizier.unistra.fr/viz-bin/Unit>`_.  This format is used
    by VOTable up to version 1.2.
    'b'PRODUCT'u'PRODUCT'b'DIVISION'u'DIVISION'b'OPEN_PAREN'u'OPEN_PAREN'b'CLOSE_PAREN'u'CLOSE_PAREN'b'OPEN_BRACKET'u'OPEN_BRACKET'b'CLOSE_BRACKET'u'CLOSE_BRACKET'b'UNIT'u'UNIT'b'DIMENSIONLESS'u'DIMENSIONLESS'b'\.'u'\.'b'\('u'\('b'\)'u'\)'b'\['u'\['b'\]'u'\]'b'((\d+\.?\d+)|(\.\d+))([eE][+-]?\d+)?'u'((\d+\.?\d+)|(\.\d+))([eE][+-]?\d+)?'b'[eE\.]'u'[eE\.]'b'\d+'u'\d+'b'[+-](?=\d)'u'[+-](?=\d)'b'[x]'u'[x]'b'%||\\h|(a|eps|mu)0|((?!\d)\w)+'u'%||\\h|(a|eps|mu)0|((?!\d)\w)+'b'---|-'u'---|-'b'Invalid character at col 'u'Invalid character at col 'b'cds_lextab'u'cds_lextab'b'astropy/units'u'astropy/units'b'
        The grammar here is based on the description in the `Standards
        for Astronomical Catalogues 2.0
        <https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_, which is not
        terribly precise.  The exact grammar is here is based on the
        YACC grammar in the `unity library <https://purl.org/nxg/dist/unity/>`_.
        'u'
        The grammar here is based on the description in the `Standards
        for Astronomical Catalogues 2.0
        <https://vizier.unistra.fr/vizier/doc/catstd-3.2.htx>`_, which is not
        terribly precise.  The exact grammar is here is based on the
        YACC grammar in the `unity library <https://purl.org/nxg/dist/unity/>`_.
        'b'
            main : factor combined_units
                 | combined_units
                 | DIMENSIONLESS
                 | OPEN_BRACKET combined_units CLOSE_BRACKET
                 | OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET
                 | factor
            'u'
            main : factor combined_units
                 | combined_units
                 | DIMENSIONLESS
                 | OPEN_BRACKET combined_units CLOSE_BRACKET
                 | OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET
                 | factor
            'b'
            combined_units : product_of_units
                           | division_of_units
            'u'
            combined_units : product_of_units
                           | division_of_units
            'b'
            product_of_units : unit_expression PRODUCT combined_units
                             | unit_expression
            'u'
            product_of_units : unit_expression PRODUCT combined_units
                             | unit_expression
            'b'
            division_of_units : DIVISION unit_expression
                              | combined_units DIVISION unit_expression
            'u'
            division_of_units : DIVISION unit_expression
                              | combined_units DIVISION unit_expression
            'b'
            unit_expression : unit_with_power
                            | OPEN_PAREN combined_units CLOSE_PAREN
            'u'
            unit_expression : unit_with_power
                            | OPEN_PAREN combined_units CLOSE_PAREN
            'b'
            factor : signed_float X UINT signed_int
                   | UINT X UINT signed_int
                   | UINT signed_int
                   | UINT
                   | signed_float
            'u'
            factor : signed_float X UINT signed_int
                   | UINT X UINT signed_int
                   | UINT signed_int
                   | UINT
                   | signed_float
            'b'Only base ten exponents are allowed in CDS'u'Only base ten exponents are allowed in CDS'b'
            unit_with_power : UNIT numeric_power
                            | UNIT
            'u'
            unit_with_power : UNIT numeric_power
                            | UNIT
            'b'
            numeric_power : sign UINT
            'u'
            numeric_power : sign UINT
            'b'
            sign : SIGN
                 |
            'u'
            sign : SIGN
                 |
            'b'
            signed_int : SIGN UINT
            'u'
            signed_int : SIGN UINT
            'b'
            signed_float : sign UINT
                         | sign UFLOAT
            'u'
            signed_float : sign UINT
                         | sign UFLOAT
            'b'cds_parsetab'u'cds_parsetab'b'CDS unit must not contain whitespace'u'CDS unit must not contain whitespace'u'astropy.units.format.cds'u'units.format.cds'u'format.cds'(?P<t_UFLOAT>((\d+\.?\d+)|(\.\d+))([eE][+-]?\d+)?)|(?P<t_UINT>\d+)|(?P<t_SIGN>[+-](?=\d))|(?P<t_X>[x])|(?P<t_UNIT>%||\\h|(a|eps|mu)0|((?!\d)\w)+)|(?P<t_DIMENSIONLESS>---|-)|(?P<t_PRODUCT>\.)|(?P<t_OPEN_PAREN>\()|(?P<t_CLOSE_PAREN>\))|(?P<t_OPEN_BRACKET>\[)|(?P<t_CLOSE_BRACKET>\])|(?P<t_DIVISION>/)# cds_lextab.py. This file automatically created by PLY (version 3.11). Don't edit!b'(?P<t_UFLOAT>((\d+\.?\d+)|(\.\d+))([eE][+-]?\d+)?)|(?P<t_UINT>\d+)|(?P<t_SIGN>[+-](?=\d))|(?P<t_X>[x])|(?P<t_UNIT>%||\\h|(a|eps|mu)0|((?!\d)\w)+)|(?P<t_DIMENSIONLESS>---|-)|(?P<t_PRODUCT>\.)|(?P<t_OPEN_PAREN>\()|(?P<t_CLOSE_PAREN>\))|(?P<t_OPEN_BRACKET>\[)|(?P<t_CLOSE_BRACKET>\])|(?P<t_DIVISION>/)'u'(?P<t_UFLOAT>((\d+\.?\d+)|(\.\d+))([eE][+-]?\d+)?)|(?P<t_UINT>\d+)|(?P<t_SIGN>[+-](?=\d))|(?P<t_X>[x])|(?P<t_UNIT>%||\\h|(a|eps|mu)0|((?!\d)\w)+)|(?P<t_DIMENSIONLESS>---|-)|(?P<t_PRODUCT>\.)|(?P<t_OPEN_PAREN>\()|(?P<t_CLOSE_PAREN>\))|(?P<t_OPEN_BRACKET>\[)|(?P<t_CLOSE_BRACKET>\])|(?P<t_DIVISION>/)'b't_X'u't_X'b't_UNIT'u't_UNIT'b't_DIMENSIONLESS'u't_DIMENSIONLESS'u'astropy.units.format.cds_lextab'u'units.format.cds_lextab'u'format.cds_lextab'CLOSE_BRACKET CLOSE_PAREN DIMENSIONLESS DIVISION OPEN_BRACKET OPEN_PAREN PRODUCT SIGN UFLOAT UINT UNIT X
            main : factor combined_units
                 | combined_units
                 | DIMENSIONLESS
                 | OPEN_BRACKET combined_units CLOSE_BRACKET
                 | OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET
                 | factor
            
            combined_units : product_of_units
                           | division_of_units
            
            product_of_units : unit_expression PRODUCT combined_units
                             | unit_expression
            
            division_of_units : DIVISION unit_expression
                              | combined_units DIVISION unit_expression
            
            unit_expression : unit_with_power
                            | OPEN_PAREN combined_units CLOSE_PAREN
            
            factor : signed_float X UINT signed_int
                   | UINT X UINT signed_int
                   | UINT signed_int
                   | UINT
                   | signed_float
            
            unit_with_power : UNIT numeric_power
                            | UNIT
            
            numeric_power : sign UINT
            
            sign : SIGN
                 |
            
            signed_int : SIGN UINT
            
            signed_float : sign UINT
                         | sign UFLOAT
            combined_unitssigned_floatproduct_of_unitsdivision_of_unitsunit_expressionunit_with_powersigned_intnumeric_powerS' -> mainmain -> factor combined_unitscds.py143main -> combined_units144main -> DIMENSIONLESS145main -> OPEN_BRACKET combined_units CLOSE_BRACKET146main -> OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET147main -> factor148combined_units -> product_of_units162combined_units -> division_of_units163product_of_units -> unit_expression PRODUCT combined_units169product_of_units -> unit_expressiondivision_of_units -> DIVISION unit_expression179division_of_units -> combined_units DIVISION unit_expressionunit_expression -> unit_with_power189unit_expression -> OPEN_PAREN combined_units CLOSE_PARENfactor -> signed_float X UINT signed_intfactor -> UINT X UINT signed_intfactor -> UINT signed_int201factor -> UINT202factor -> signed_float203unit_with_power -> UNIT numeric_power218unit_with_power -> UNIT219numeric_power -> sign UINT235signed_int -> SIGN UINT244signed_float -> sign UINTsigned_float -> sign UFLOAT# cds_parsetab.pyb'CLOSE_BRACKET CLOSE_PAREN DIMENSIONLESS DIVISION OPEN_BRACKET OPEN_PAREN PRODUCT SIGN UFLOAT UINT UNIT X
            main : factor combined_units
                 | combined_units
                 | DIMENSIONLESS
                 | OPEN_BRACKET combined_units CLOSE_BRACKET
                 | OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET
                 | factor
            
            combined_units : product_of_units
                           | division_of_units
            
            product_of_units : unit_expression PRODUCT combined_units
                             | unit_expression
            
            division_of_units : DIVISION unit_expression
                              | combined_units DIVISION unit_expression
            
            unit_expression : unit_with_power
                            | OPEN_PAREN combined_units CLOSE_PAREN
            
            factor : signed_float X UINT signed_int
                   | UINT X UINT signed_int
                   | UINT signed_int
                   | UINT
                   | signed_float
            
            unit_with_power : UNIT numeric_power
                            | UNIT
            
            numeric_power : sign UINT
            
            sign : SIGN
                 |
            
            signed_int : SIGN UINT
            
            signed_float : sign UINT
                         | sign UFLOAT
            'u'CLOSE_BRACKET CLOSE_PAREN DIMENSIONLESS DIVISION OPEN_BRACKET OPEN_PAREN PRODUCT SIGN UFLOAT UINT UNIT X
            main : factor combined_units
                 | combined_units
                 | DIMENSIONLESS
                 | OPEN_BRACKET combined_units CLOSE_BRACKET
                 | OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET
                 | factor
            
            combined_units : product_of_units
                           | division_of_units
            
            product_of_units : unit_expression PRODUCT combined_units
                             | unit_expression
            
            division_of_units : DIVISION unit_expression
                              | combined_units DIVISION unit_expression
            
            unit_expression : unit_with_power
                            | OPEN_PAREN combined_units CLOSE_PAREN
            
            factor : signed_float X UINT signed_int
                   | UINT X UINT signed_int
                   | UINT signed_int
                   | UINT
                   | signed_float
            
            unit_with_power : UNIT numeric_power
                            | UNIT
            
            numeric_power : sign UINT
            
            sign : SIGN
                 |
            
            signed_int : SIGN UINT
            
            signed_float : sign UINT
                         | sign UFLOAT
            'b'main'u'main'b'factor'u'factor'b'combined_units'u'combined_units'b'signed_float'u'signed_float'b'product_of_units'u'product_of_units'b'division_of_units'u'division_of_units'b'unit_expression'u'unit_expression'b'unit_with_power'u'unit_with_power'b'signed_int'u'signed_int'b'numeric_power'u'numeric_power'b'S' -> main'u'S' -> main'b'main -> factor combined_units'u'main -> factor combined_units'b'p_main'u'p_main'b'cds.py'u'cds.py'b'main -> combined_units'u'main -> combined_units'b'main -> DIMENSIONLESS'u'main -> DIMENSIONLESS'b'main -> OPEN_BRACKET combined_units CLOSE_BRACKET'u'main -> OPEN_BRACKET combined_units CLOSE_BRACKET'b'main -> OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET'u'main -> OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET'b'main -> factor'u'main -> factor'b'combined_units -> product_of_units'u'combined_units -> product_of_units'b'p_combined_units'u'p_combined_units'b'combined_units -> division_of_units'u'combined_units -> division_of_units'b'product_of_units -> unit_expression PRODUCT combined_units'u'product_of_units -> unit_expression PRODUCT combined_units'b'p_product_of_units'u'p_product_of_units'b'product_of_units -> unit_expression'u'product_of_units -> unit_expression'b'division_of_units -> DIVISION unit_expression'u'division_of_units -> DIVISION unit_expression'b'p_division_of_units'u'p_division_of_units'b'division_of_units -> combined_units DIVISION unit_expression'u'division_of_units -> combined_units DIVISION unit_expression'b'unit_expression -> unit_with_power'u'unit_expression -> unit_with_power'b'p_unit_expression'u'p_unit_expression'b'unit_expression -> OPEN_PAREN combined_units CLOSE_PAREN'u'unit_expression -> OPEN_PAREN combined_units CLOSE_PAREN'b'factor -> signed_float X UINT signed_int'u'factor -> signed_float X UINT signed_int'b'p_factor'u'p_factor'b'factor -> UINT X UINT signed_int'u'factor -> UINT X UINT signed_int'b'factor -> UINT signed_int'u'factor -> UINT signed_int'b'factor -> UINT'u'factor -> UINT'b'factor -> signed_float'u'factor -> signed_float'b'unit_with_power -> UNIT numeric_power'u'unit_with_power -> UNIT numeric_power'b'p_unit_with_power'u'p_unit_with_power'b'unit_with_power -> UNIT'u'unit_with_power -> UNIT'b'numeric_power -> sign UINT'u'numeric_power -> sign UINT'b'p_numeric_power'u'p_numeric_power'b'signed_int -> SIGN UINT'u'signed_int -> SIGN UINT'b'p_signed_int'u'p_signed_int'b'signed_float -> sign UINT'u'signed_float -> sign UINT'b'p_signed_float'u'p_signed_float'b'signed_float -> sign UFLOAT'u'signed_float -> sign UFLOAT'u'astropy.units.format.cds_parsetab'u'units.format.cds_parsetab'u'format.cds_parsetab'
Astronomical and physics constants in cgs units.  See :mod:`astropy.constants`
for a complete listing of constants defined in Astropy.
_nm_cabbrevesuemub'
Astronomical and physics constants in cgs units.  See :mod:`astropy.constants`
for a complete listing of constants defined in Astropy.
'u'
Astronomical and physics constants in cgs units.  See :mod:`astropy.constants`
for a complete listing of constants defined in Astropy.
'b'esu'u'esu'b'emu'u'emu'u'astropy.constants.cgs'u'constants.cgs'u'cgs'
This package defines the CGS units.  They are also available in
(and should be used through) the `astropy.units` namespace.
fractionsFractionGalgalGal: CGS unit of accelerationerg: CGS unit of energydyne: CGS unit of forceBaBaryebaryeBarye: CGS unit of pressurepoisepoise: CGS unit of dynamic viscosityStstokesstokes: CGS unit of kinematic viscosityKayserkayserkayser: CGS unit of wavenumberDebyedebye1e-29Debye: CGS unit of electric dipole momentFrFranklinstatcoulombstatCFranklin: CGS (ESU) unit of chargestatAstatamperestatampere: CGS (ESU) unit of currentBiBiotabAabampereBiot: CGS (EMU) unit of currentabCabcoulombabcoulomb: CGS (EMU) of charge0.00011e-4Gauss: CGS unit for magnetic fieldMxMaxwellmaxwellMaxwell: CGS unit for magnetic fluxOeOerstedoerstedOersted: CGS unit for magnetic field strength# ACCELERATION# Use CGS definition of erg# FORCE# PRESSURE# DYNAMIC VISCOSITY# KINEMATIC VISCOSITY# WAVENUMBER# ELECTRICAL# MAGNETIC# BASESb'
This package defines the CGS units.  They are also available in
(and should be used through) the `astropy.units` namespace.
'u'
This package defines the CGS units.  They are also available in
(and should be used through) the `astropy.units` namespace.
'b'Gal'u'Gal'b'gal'u'gal'b'Gal: CGS unit of acceleration'u'Gal: CGS unit of acceleration'b'erg: CGS unit of energy'u'erg: CGS unit of energy'b'dyne: CGS unit of force'u'dyne: CGS unit of force'b'Ba'u'Ba'b'Barye'u'Barye'b'barye'u'barye'b'Barye: CGS unit of pressure'u'Barye: CGS unit of pressure'b'poise'u'poise'b'poise: CGS unit of dynamic viscosity'u'poise: CGS unit of dynamic viscosity'b'St'u'St'b'stokes'u'stokes'b'stokes: CGS unit of kinematic viscosity'u'stokes: CGS unit of kinematic viscosity'b'Kayser'u'Kayser'b'kayser'u'kayser'b'kayser: CGS unit of wavenumber'u'kayser: CGS unit of wavenumber'b'Debye'u'Debye'b'debye'u'debye'b'Debye: CGS unit of electric dipole moment'u'Debye: CGS unit of electric dipole moment'b'Fr'u'Fr'b'Franklin'u'Franklin'b'statcoulomb'u'statcoulomb'b'statC'u'statC'b'Franklin: CGS (ESU) unit of charge'u'Franklin: CGS (ESU) unit of charge'b'statA'u'statA'b'statampere'u'statampere'b'statampere: CGS (ESU) unit of current'u'statampere: CGS (ESU) unit of current'b'Bi'u'Bi'b'Biot'u'Biot'b'abA'u'abA'b'abampere'u'abampere'b'Biot: CGS (EMU) unit of current'u'Biot: CGS (EMU) unit of current'b'abC'u'abC'b'abcoulomb'u'abcoulomb'b'abcoulomb: CGS (EMU) of charge'u'abcoulomb: CGS (EMU) of charge'b'Gauss: CGS unit for magnetic field'u'Gauss: CGS unit for magnetic field'b'Mx'u'Mx'b'Maxwell'u'Maxwell'b'maxwell'u'maxwell'b'Maxwell: CGS unit for magnetic flux'u'Maxwell: CGS unit for magnetic flux'b'Oe'u'Oe'b'Oersted'u'Oersted'b'oersted'u'oersted'b'Oersted: CGS unit for magnetic field strength'u'Oersted: CGS unit for magnetic field strength'u'astropy.units.cgs'u'units.cgs'
A collection of functions for checking various XML-related strings for
standards compliance.
urllibcheck_idID
    Returns `True` if *ID* is a valid XML ID.
    ^[A-Za-z_][A-Za-z0-9_\.\-]*$fix_id
    Given an arbitrary string, create one that can be used as an xml
    id.  This is rather simplistic at the moment, since it just
    replaces non-valid characters with underscores.
    ^[^A-Za-z_]$[^A-Za-z_][^A-Za-z0-9_\.\-](?![\r\l\t ])[^\r\l\t]*(?![\r\l\t ])_token_regexcheck_tokentoken
    Returns `True` if *token* is a valid XML token, as defined by XML
    Schema Part 2.
    [^\r\n\t ]?([^\r\n\t ]| [^\r\n\t ])*[^\r\n\t ]?$check_mime_content_typecontent_type
    Returns `True` if *content_type* is a valid MIME content type
    (syntactically at least), as defined by RFC 2045.
    0x20ctrls[^()<>@,;:\"/[\]?= ]+token_regex(?P<type>)/(?P<subtype>check_anyuriuri
    Returns `True` if *uri* is a valid URI as defined in RFC 2396.
    (([a-zA-Z][0-9a-zA-Z+\-\.]*:)?/{0,2}[0-9a-zA-Z;/?:@&=+$\.\-_!~*'()%]+)?(#[0-9a-zA-Z;/?:@&=+$\.\-_!~*'()%]+)?r"(([a-zA-Z][0-9a-zA-Z+\-\.]*:)?/{0,2}[0-9a-zA-Z;"r"/?:@&=+$\.\-_!~*'()%]+)?(#[0-9a-zA-Z;/?:@&=+$\.\-_!~*'()%]+)?"urlparseb'
A collection of functions for checking various XML-related strings for
standards compliance.
'u'
A collection of functions for checking various XML-related strings for
standards compliance.
'b'
    Returns `True` if *ID* is a valid XML ID.
    'u'
    Returns `True` if *ID* is a valid XML ID.
    'b'^[A-Za-z_][A-Za-z0-9_\.\-]*$'u'^[A-Za-z_][A-Za-z0-9_\.\-]*$'b'
    Given an arbitrary string, create one that can be used as an xml
    id.  This is rather simplistic at the moment, since it just
    replaces non-valid characters with underscores.
    'u'
    Given an arbitrary string, create one that can be used as an xml
    id.  This is rather simplistic at the moment, since it just
    replaces non-valid characters with underscores.
    'b'^[^A-Za-z_]$'u'^[^A-Za-z_]$'b'[^A-Za-z_]'u'[^A-Za-z_]'b'[^A-Za-z0-9_\.\-]'u'[^A-Za-z0-9_\.\-]'b'(?![\r\l\t ])[^\r\l\t]*(?![\r\l\t ])'u'(?![\r\l\t ])[^\r\l\t]*(?![\r\l\t ])'b'
    Returns `True` if *token* is a valid XML token, as defined by XML
    Schema Part 2.
    'u'
    Returns `True` if *token* is a valid XML token, as defined by XML
    Schema Part 2.
    'b'[^\r\n\t ]?([^\r\n\t ]| [^\r\n\t ])*[^\r\n\t ]?$'u'[^\r\n\t ]?([^\r\n\t ]| [^\r\n\t ])*[^\r\n\t ]?$'b'
    Returns `True` if *content_type* is a valid MIME content type
    (syntactically at least), as defined by RFC 2045.
    'u'
    Returns `True` if *content_type* is a valid MIME content type
    (syntactically at least), as defined by RFC 2045.
    'b'[^()<>@,;:\"/[\]?= 'u'[^()<>@,;:\"/[\]?= 'b']+'u']+'b'(?P<type>'u'(?P<type>'b')/(?P<subtype>'u')/(?P<subtype>'b'
    Returns `True` if *uri* is a valid URI as defined in RFC 2396.
    'u'
    Returns `True` if *uri* is a valid URI as defined in RFC 2396.
    'b'(([a-zA-Z][0-9a-zA-Z+\-\.]*:)?/{0,2}[0-9a-zA-Z;/?:@&=+$\.\-_!~*'()%]+)?(#[0-9a-zA-Z;/?:@&=+$\.\-_!~*'()%]+)?'u'(([a-zA-Z][0-9a-zA-Z+\-\.]*:)?/{0,2}[0-9a-zA-Z;/?:@&=+$\.\-_!~*'()%]+)?(#[0-9a-zA-Z;/?:@&=+$\.\-_!~*'()%]+)?'u'astropy.utils.xml.check'u'utils.xml.check'u'xml.check'u'check'mledesign_matrixfrequencyfit_meancenter_datantermsLomb-Scargle Periodogram.

    This implements a chi-squared-based periodogram, which is relatively slow
    but useful for validating the faster algorithms in the package.

    Parameters
    ----------
    t, y, dy : array-like
        times, values, and errors of the data points. These should be
        broadcastable to the same shape. None should be `~astropy.units.Quantity``.
    frequency : array-like
        frequencies (not angular frequencies) at which to calculate periodogram
    normalization : str, optional
        Normalization to use for the periodogram.
        Options are 'standard', 'model', 'log', or 'psd'.
    fit_mean : bool, optional
        if True, include a constant offset as part of the model at each
        frequency. This can lead to more accurate results, especially in the
        case of incomplete phase coverage.
    center_data : bool, optional
        if True, pre-center the data by subtracting the weighted mean
        of the input data. This is especially important if ``fit_mean = False``
    nterms : int, optional
        Number of Fourier terms in the fit

    Returns
    -------
    power : array-like
        Lomb-Scargle power associated with each frequency.
        Units of the result depend on the normalization.

    References
    ----------
    .. [1] M. Zechmeister and M. Kurster, A&A 496, 577-584 (2009)
    .. [2] W. Press et al, Numerical Recipes in C (2002)
    .. [3] Scargle, J.D. 1982, ApJ 263:835-853
    t, y, dy should be one dimensionalfrequency should be one-dimensionalywchi2_refcompute_powerbiasXTXXTylinalgsolve' not recognized# if fit_mean is true, centering the data now simplifies the math below.# compute the unnormalized model chi2 at each frequencyb'Lomb-Scargle Periodogram.

    This implements a chi-squared-based periodogram, which is relatively slow
    but useful for validating the faster algorithms in the package.

    Parameters
    ----------
    t, y, dy : array-like
        times, values, and errors of the data points. These should be
        broadcastable to the same shape. None should be `~astropy.units.Quantity``.
    frequency : array-like
        frequencies (not angular frequencies) at which to calculate periodogram
    normalization : str, optional
        Normalization to use for the periodogram.
        Options are 'standard', 'model', 'log', or 'psd'.
    fit_mean : bool, optional
        if True, include a constant offset as part of the model at each
        frequency. This can lead to more accurate results, especially in the
        case of incomplete phase coverage.
    center_data : bool, optional
        if True, pre-center the data by subtracting the weighted mean
        of the input data. This is especially important if ``fit_mean = False``
    nterms : int, optional
        Number of Fourier terms in the fit

    Returns
    -------
    power : array-like
        Lomb-Scargle power associated with each frequency.
        Units of the result depend on the normalization.

    References
    ----------
    .. [1] M. Zechmeister and M. Kurster, A&A 496, 577-584 (2009)
    .. [2] W. Press et al, Numerical Recipes in C (2002)
    .. [3] Scargle, J.D. 1982, ApJ 263:835-853
    'u'Lomb-Scargle Periodogram.

    This implements a chi-squared-based periodogram, which is relatively slow
    but useful for validating the faster algorithms in the package.

    Parameters
    ----------
    t, y, dy : array-like
        times, values, and errors of the data points. These should be
        broadcastable to the same shape. None should be `~astropy.units.Quantity``.
    frequency : array-like
        frequencies (not angular frequencies) at which to calculate periodogram
    normalization : str, optional
        Normalization to use for the periodogram.
        Options are 'standard', 'model', 'log', or 'psd'.
    fit_mean : bool, optional
        if True, include a constant offset as part of the model at each
        frequency. This can lead to more accurate results, especially in the
        case of incomplete phase coverage.
    center_data : bool, optional
        if True, pre-center the data by subtracting the weighted mean
        of the input data. This is especially important if ``fit_mean = False``
    nterms : int, optional
        Number of Fourier terms in the fit

    Returns
    -------
    power : array-like
        Lomb-Scargle power associated with each frequency.
        Units of the result depend on the normalization.

    References
    ----------
    .. [1] M. Zechmeister and M. Kurster, A&A 496, 577-584 (2009)
    .. [2] W. Press et al, Numerical Recipes in C (2002)
    .. [3] Scargle, J.D. 1982, ApJ 263:835-853
    'b't, y, dy should be one dimensional'u't, y, dy should be one dimensional'b'frequency should be one-dimensional'u'frequency should be one-dimensional'b'' not recognized'u'' not recognized'u'periodograms.lombscargle.implementations.chi2_impl'u'lombscargle.implementations.chi2_impl'u'implementations.chi2_impl'u'chi2_impl'
This module contains simple functions for dealing with circular statistics, for
instance, mean, variance, standard deviation, correlation coefficient, and so
on. This module also cover tests of uniformity, e.g., the Rayleigh and V tests.
The Maximum Likelihood Estimator for the Von Mises distribution along with the
Cramer-Rao Lower Bounds are also implemented. Almost all of the implementations
are based on reference [1]_, which is also the basis for the R package
'CircStats' [2]_.
circcorrcoefcircmeancircmomentcircstdcircvarrayleightestvonmisesmlevtestphiWeights and data have inconsistent shape._anglearctan2theta_lengthhypotComputes the circular mean angle of an array of circular data.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which circular means are computed. The default is to compute
        the mean of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22, for
        detailed explanation.

    Returns
    -------
    circmean : ndarray or `~astropy.units.Quantity`
        Circular mean.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circmean
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circmean(data) # doctest: +FLOAT_CMP
    <Quantity 48.62718088722989 deg>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    Computes the circular variance of an array of circular data.

    There are some concepts for defining measures of dispersion for circular
    data. The variance implemented here is based on the definition given by
    [1]_, which is also the same used by the R package 'CircStats' [2]_.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
        Dimensionless, if Quantity.
    axis : int, optional
        Axis along which circular variances are computed. The default is to
        compute the variance of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    circvar : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Circular variance.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circvar
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circvar(data) # doctest: +FLOAT_CMP
    <Quantity 0.16356352748437508>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>

    Notes
    -----
    For Scipy < 1.9.0, ``scipy.stats.circvar`` uses a different
    definition based on an approximation using the limit of small
    angles that approaches the linear variance. For Scipy >= 1.9.0,
    ``scipy.stats.cirvar`` uses a definition consistent with this
    implementation.
    angularComputes the circular standard deviation of an array of circular data.

    The standard deviation implemented here is based on the definitions given
    by [1]_, which is also the same used by the R package 'CirStat' [2]_.

    Two methods are implemented: 'angular' and 'circular'. The former is
    defined as sqrt(2 * (1 - R)) and it is bounded in [0, 2*Pi]. The
    latter is defined as sqrt(-2 * ln(R)) and it is bounded in [0, inf].

    Following 'CircStat' the default method used to obtain the standard
    deviation is 'angular'.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
        If quantity, must be dimensionless.
    axis : int, optional
        Axis along which circular variances are computed. The default is to
        compute the variance of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [3]_, remark 1.4, page 22,
        for detailed explanation.
    method : str, optional
        The method used to estimate the standard deviation:

        - 'angular' : obtains the angular deviation

        - 'circular' : obtains the circular deviation


    Returns
    -------
    circstd : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Angular or circular standard deviation.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circstd
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circstd(data) # doctest: +FLOAT_CMP
    <Quantity 0.57195022>

    Alternatively, using the 'circular' method:

    >>> import numpy as np
    >>> from astropy.stats import circstd
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circstd(data, method='circular') # doctest: +FLOAT_CMP
    <Quantity 0.59766999>

    References
    ----------
    .. [1] P. Berens. "CircStat: A MATLAB Toolbox for Circular Statistics".
       Journal of Statistical Software, vol 31, issue 10, 2009.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.

    circularmethod should be either 'angular' or 'circular'centeredComputes the ``p``-th trigonometric circular moment for an array
    of circular data.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    p : float, optional
        Order of the circular moment.
    centered : bool, optional
        If ``True``, central circular moments are computed. Default value is
        ``False``.
    axis : int, optional
        Axis along which circular moments are computed. The default is to
        compute the circular moment of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    circmoment : ndarray or `~astropy.units.Quantity`
        The first and second elements correspond to the direction and length of
        the ``p``-th circular moment, respectively.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circmoment
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circmoment(data, p=2) # doctest: +FLOAT_CMP
    (<Quantity 90.99263082432564 deg>, <Quantity 0.48004283892950717>)

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    betaweights_alphaweights_betaComputes the circular correlation coefficient between two array of
    circular data.

    Parameters
    ----------
    alpha : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    beta : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which circular correlation coefficients are computed.
        The default is the compute the circular correlation coefficient of the
        flattened array.
    weights_alpha : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights_alpha``
        represents a weighting factor for each group such that
        ``sum(weights_alpha, axis)`` equals the number of observations.
        See [1]_, remark 1.4, page 22, for detailed explanation.
    weights_beta : numpy.ndarray, optional
        See description of ``weights_alpha``.

    Returns
    -------
    rho : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Circular correlation coefficient.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circcorrcoef
    >>> from astropy import units as u
    >>> alpha = np.array([356, 97, 211, 232, 343, 292, 157, 302, 335, 302,
    ...                   324, 85, 324, 340, 157, 238, 254, 146, 232, 122,
    ...                   329])*u.deg
    >>> beta = np.array([119, 162, 221, 259, 270, 29, 97, 292, 40, 313, 94,
    ...                  45, 47, 108, 221, 270, 119, 248, 270, 45, 23])*u.deg
    >>> circcorrcoef(alpha, beta) # doctest: +FLOAT_CMP
    <Quantity 0.2704648826748831>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    alpha and beta must be arrays of the same sizemu_amu_bsin_asin_brhoPerforms the Rayleigh test of uniformity.

    This test is  used to identify a non-uniform distribution, i.e. it is
    designed for detecting an unimodal deviation from uniformity. More
    precisely, it assumes the following hypotheses:
    - H0 (null hypothesis): The population is distributed uniformly around the
    circle.
    - H1 (alternative hypothesis): The population is not distributed uniformly
    around the circle.
    Small p-values suggest to reject the null hypothesis.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which the Rayleigh test will be performed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``np.sum(weights, axis)``
        equals the number of observations.
        See [1]_, remark 1.4, page 22, for detailed explanation.

    Returns
    -------
    p-value : float or `~astropy.units.Quantity` ['dimensionless']

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import rayleightest
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> rayleightest(data) # doctest: +FLOAT_CMP
    <Quantity 0.2563487733797317>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] M. Chirstman., C. Miller. "Testing a Sample of Directions for
       Uniformity." Lecture Notes, STA 6934/5805. University of Florida, 2007.
    .. [4] D. Wilkie. "Rayleigh Test for Randomness of Circular Data". Applied
       Statistics. 1983.
       <http://wexler.free.fr/library/files/wilkie%20(1983)%20rayleigh%20test%20for%20randomness%20of%20circular%20data.pdf>
    Rbartmp24.0132.076.0288.0p_valuemuPerforms the Rayleigh test of uniformity where the alternative
    hypothesis H1 is assumed to have a known mean angle ``mu``.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    mu : float or `~astropy.units.Quantity` ['angle'], optional
        Mean angle. Assumed to be known.
    axis : int, optional
        Axis along which the V test will be performed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    p-value : float or `~astropy.units.Quantity` ['dimensionless']

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import vtest
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> vtest(data) # doctest: +FLOAT_CMP
    <Quantity 0.6223678199713766>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] M. Chirstman., C. Miller. "Testing a Sample of Directions for
       Uniformity." Lecture Notes, STA 6934/5805. University of Florida, 2007.
    scipy.statsR0barcdfpzpdffz16.03051254608.0_A1invlogical_and0.53kappa10.850.41.390.43kappa2kappa3Computes the Maximum Likelihood Estimator (MLE) for the parameters of
    the von Mises distribution.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which the mle will be computed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    mu : float or `~astropy.units.Quantity`
        The mean (aka location parameter).
    kappa : float or `~astropy.units.Quantity` ['dimensionless']
        The concentration parameter.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import vonmisesmle
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> vonmisesmle(data) # doctest: +FLOAT_CMP
    (<Quantity 101.16894320013179 deg>, <Quantity 1.49358958737054>)

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    kappa# Utility function for computing the generalized rectangular components# of the circular data.# Utility function for computing the generalized sample mean angle# theta will be an angle in the interval [-np.pi, np.pi)# [-180, 180)*u.deg in case data is a Quantity# Utility function for computing the generalized sample length# see [3] and [4] for the formulae below# see reference [3]# Approximation for _A1inv(x) according R Package 'CircStats'# See http://www.scienceasia.org/2012.38.n1/scias38_118.pdf, equation (4)b'
This module contains simple functions for dealing with circular statistics, for
instance, mean, variance, standard deviation, correlation coefficient, and so
on. This module also cover tests of uniformity, e.g., the Rayleigh and V tests.
The Maximum Likelihood Estimator for the Von Mises distribution along with the
Cramer-Rao Lower Bounds are also implemented. Almost all of the implementations
are based on reference [1]_, which is also the basis for the R package
'CircStats' [2]_.
'u'
This module contains simple functions for dealing with circular statistics, for
instance, mean, variance, standard deviation, correlation coefficient, and so
on. This module also cover tests of uniformity, e.g., the Rayleigh and V tests.
The Maximum Likelihood Estimator for the Von Mises distribution along with the
Cramer-Rao Lower Bounds are also implemented. Almost all of the implementations
are based on reference [1]_, which is also the basis for the R package
'CircStats' [2]_.
'b'circcorrcoef'u'circcorrcoef'b'circmean'u'circmean'b'circmoment'u'circmoment'b'circstd'u'circstd'b'circvar'u'circvar'b'rayleightest'u'rayleightest'b'vonmisesmle'u'vonmisesmle'b'vtest'u'vtest'b'Weights and data have inconsistent shape.'u'Weights and data have inconsistent shape.'b'Computes the circular mean angle of an array of circular data.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which circular means are computed. The default is to compute
        the mean of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22, for
        detailed explanation.

    Returns
    -------
    circmean : ndarray or `~astropy.units.Quantity`
        Circular mean.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circmean
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circmean(data) # doctest: +FLOAT_CMP
    <Quantity 48.62718088722989 deg>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    'u'Computes the circular mean angle of an array of circular data.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which circular means are computed. The default is to compute
        the mean of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22, for
        detailed explanation.

    Returns
    -------
    circmean : ndarray or `~astropy.units.Quantity`
        Circular mean.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circmean
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circmean(data) # doctest: +FLOAT_CMP
    <Quantity 48.62718088722989 deg>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    'b'Computes the circular variance of an array of circular data.

    There are some concepts for defining measures of dispersion for circular
    data. The variance implemented here is based on the definition given by
    [1]_, which is also the same used by the R package 'CircStats' [2]_.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
        Dimensionless, if Quantity.
    axis : int, optional
        Axis along which circular variances are computed. The default is to
        compute the variance of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    circvar : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Circular variance.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circvar
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circvar(data) # doctest: +FLOAT_CMP
    <Quantity 0.16356352748437508>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>

    Notes
    -----
    For Scipy < 1.9.0, ``scipy.stats.circvar`` uses a different
    definition based on an approximation using the limit of small
    angles that approaches the linear variance. For Scipy >= 1.9.0,
    ``scipy.stats.cirvar`` uses a definition consistent with this
    implementation.
    'u'Computes the circular variance of an array of circular data.

    There are some concepts for defining measures of dispersion for circular
    data. The variance implemented here is based on the definition given by
    [1]_, which is also the same used by the R package 'CircStats' [2]_.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
        Dimensionless, if Quantity.
    axis : int, optional
        Axis along which circular variances are computed. The default is to
        compute the variance of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    circvar : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Circular variance.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circvar
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circvar(data) # doctest: +FLOAT_CMP
    <Quantity 0.16356352748437508>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>

    Notes
    -----
    For Scipy < 1.9.0, ``scipy.stats.circvar`` uses a different
    definition based on an approximation using the limit of small
    angles that approaches the linear variance. For Scipy >= 1.9.0,
    ``scipy.stats.cirvar`` uses a definition consistent with this
    implementation.
    'b'angular'u'angular'b'Computes the circular standard deviation of an array of circular data.

    The standard deviation implemented here is based on the definitions given
    by [1]_, which is also the same used by the R package 'CirStat' [2]_.

    Two methods are implemented: 'angular' and 'circular'. The former is
    defined as sqrt(2 * (1 - R)) and it is bounded in [0, 2*Pi]. The
    latter is defined as sqrt(-2 * ln(R)) and it is bounded in [0, inf].

    Following 'CircStat' the default method used to obtain the standard
    deviation is 'angular'.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
        If quantity, must be dimensionless.
    axis : int, optional
        Axis along which circular variances are computed. The default is to
        compute the variance of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [3]_, remark 1.4, page 22,
        for detailed explanation.
    method : str, optional
        The method used to estimate the standard deviation:

        - 'angular' : obtains the angular deviation

        - 'circular' : obtains the circular deviation


    Returns
    -------
    circstd : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Angular or circular standard deviation.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circstd
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circstd(data) # doctest: +FLOAT_CMP
    <Quantity 0.57195022>

    Alternatively, using the 'circular' method:

    >>> import numpy as np
    >>> from astropy.stats import circstd
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circstd(data, method='circular') # doctest: +FLOAT_CMP
    <Quantity 0.59766999>

    References
    ----------
    .. [1] P. Berens. "CircStat: A MATLAB Toolbox for Circular Statistics".
       Journal of Statistical Software, vol 31, issue 10, 2009.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.

    'u'Computes the circular standard deviation of an array of circular data.

    The standard deviation implemented here is based on the definitions given
    by [1]_, which is also the same used by the R package 'CirStat' [2]_.

    Two methods are implemented: 'angular' and 'circular'. The former is
    defined as sqrt(2 * (1 - R)) and it is bounded in [0, 2*Pi]. The
    latter is defined as sqrt(-2 * ln(R)) and it is bounded in [0, inf].

    Following 'CircStat' the default method used to obtain the standard
    deviation is 'angular'.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
        If quantity, must be dimensionless.
    axis : int, optional
        Axis along which circular variances are computed. The default is to
        compute the variance of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [3]_, remark 1.4, page 22,
        for detailed explanation.
    method : str, optional
        The method used to estimate the standard deviation:

        - 'angular' : obtains the angular deviation

        - 'circular' : obtains the circular deviation


    Returns
    -------
    circstd : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Angular or circular standard deviation.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circstd
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circstd(data) # doctest: +FLOAT_CMP
    <Quantity 0.57195022>

    Alternatively, using the 'circular' method:

    >>> import numpy as np
    >>> from astropy.stats import circstd
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circstd(data, method='circular') # doctest: +FLOAT_CMP
    <Quantity 0.59766999>

    References
    ----------
    .. [1] P. Berens. "CircStat: A MATLAB Toolbox for Circular Statistics".
       Journal of Statistical Software, vol 31, issue 10, 2009.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.

    'b'circular'u'circular'b'method should be either 'angular' or 'circular''u'method should be either 'angular' or 'circular''b'Computes the ``p``-th trigonometric circular moment for an array
    of circular data.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    p : float, optional
        Order of the circular moment.
    centered : bool, optional
        If ``True``, central circular moments are computed. Default value is
        ``False``.
    axis : int, optional
        Axis along which circular moments are computed. The default is to
        compute the circular moment of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    circmoment : ndarray or `~astropy.units.Quantity`
        The first and second elements correspond to the direction and length of
        the ``p``-th circular moment, respectively.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circmoment
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circmoment(data, p=2) # doctest: +FLOAT_CMP
    (<Quantity 90.99263082432564 deg>, <Quantity 0.48004283892950717>)

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    'u'Computes the ``p``-th trigonometric circular moment for an array
    of circular data.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    p : float, optional
        Order of the circular moment.
    centered : bool, optional
        If ``True``, central circular moments are computed. Default value is
        ``False``.
    axis : int, optional
        Axis along which circular moments are computed. The default is to
        compute the circular moment of the flattened array.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    circmoment : ndarray or `~astropy.units.Quantity`
        The first and second elements correspond to the direction and length of
        the ``p``-th circular moment, respectively.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circmoment
    >>> from astropy import units as u
    >>> data = np.array([51, 67, 40, 109, 31, 358])*u.deg
    >>> circmoment(data, p=2) # doctest: +FLOAT_CMP
    (<Quantity 90.99263082432564 deg>, <Quantity 0.48004283892950717>)

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    'b'Computes the circular correlation coefficient between two array of
    circular data.

    Parameters
    ----------
    alpha : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    beta : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which circular correlation coefficients are computed.
        The default is the compute the circular correlation coefficient of the
        flattened array.
    weights_alpha : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights_alpha``
        represents a weighting factor for each group such that
        ``sum(weights_alpha, axis)`` equals the number of observations.
        See [1]_, remark 1.4, page 22, for detailed explanation.
    weights_beta : numpy.ndarray, optional
        See description of ``weights_alpha``.

    Returns
    -------
    rho : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Circular correlation coefficient.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circcorrcoef
    >>> from astropy import units as u
    >>> alpha = np.array([356, 97, 211, 232, 343, 292, 157, 302, 335, 302,
    ...                   324, 85, 324, 340, 157, 238, 254, 146, 232, 122,
    ...                   329])*u.deg
    >>> beta = np.array([119, 162, 221, 259, 270, 29, 97, 292, 40, 313, 94,
    ...                  45, 47, 108, 221, 270, 119, 248, 270, 45, 23])*u.deg
    >>> circcorrcoef(alpha, beta) # doctest: +FLOAT_CMP
    <Quantity 0.2704648826748831>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    'u'Computes the circular correlation coefficient between two array of
    circular data.

    Parameters
    ----------
    alpha : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    beta : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which circular correlation coefficients are computed.
        The default is the compute the circular correlation coefficient of the
        flattened array.
    weights_alpha : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights_alpha``
        represents a weighting factor for each group such that
        ``sum(weights_alpha, axis)`` equals the number of observations.
        See [1]_, remark 1.4, page 22, for detailed explanation.
    weights_beta : numpy.ndarray, optional
        See description of ``weights_alpha``.

    Returns
    -------
    rho : ndarray or `~astropy.units.Quantity` ['dimensionless']
        Circular correlation coefficient.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import circcorrcoef
    >>> from astropy import units as u
    >>> alpha = np.array([356, 97, 211, 232, 343, 292, 157, 302, 335, 302,
    ...                   324, 85, 324, 340, 157, 238, 254, 146, 232, 122,
    ...                   329])*u.deg
    >>> beta = np.array([119, 162, 221, 259, 270, 29, 97, 292, 40, 313, 94,
    ...                  45, 47, 108, 221, 270, 119, 248, 270, 45, 23])*u.deg
    >>> circcorrcoef(alpha, beta) # doctest: +FLOAT_CMP
    <Quantity 0.2704648826748831>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    'b'alpha and beta must be arrays of the same size'u'alpha and beta must be arrays of the same size'b'Performs the Rayleigh test of uniformity.

    This test is  used to identify a non-uniform distribution, i.e. it is
    designed for detecting an unimodal deviation from uniformity. More
    precisely, it assumes the following hypotheses:
    - H0 (null hypothesis): The population is distributed uniformly around the
    circle.
    - H1 (alternative hypothesis): The population is not distributed uniformly
    around the circle.
    Small p-values suggest to reject the null hypothesis.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which the Rayleigh test will be performed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``np.sum(weights, axis)``
        equals the number of observations.
        See [1]_, remark 1.4, page 22, for detailed explanation.

    Returns
    -------
    p-value : float or `~astropy.units.Quantity` ['dimensionless']

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import rayleightest
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> rayleightest(data) # doctest: +FLOAT_CMP
    <Quantity 0.2563487733797317>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] M. Chirstman., C. Miller. "Testing a Sample of Directions for
       Uniformity." Lecture Notes, STA 6934/5805. University of Florida, 2007.
    .. [4] D. Wilkie. "Rayleigh Test for Randomness of Circular Data". Applied
       Statistics. 1983.
       <http://wexler.free.fr/library/files/wilkie%20(1983)%20rayleigh%20test%20for%20randomness%20of%20circular%20data.pdf>
    'u'Performs the Rayleigh test of uniformity.

    This test is  used to identify a non-uniform distribution, i.e. it is
    designed for detecting an unimodal deviation from uniformity. More
    precisely, it assumes the following hypotheses:
    - H0 (null hypothesis): The population is distributed uniformly around the
    circle.
    - H1 (alternative hypothesis): The population is not distributed uniformly
    around the circle.
    Small p-values suggest to reject the null hypothesis.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which the Rayleigh test will be performed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``np.sum(weights, axis)``
        equals the number of observations.
        See [1]_, remark 1.4, page 22, for detailed explanation.

    Returns
    -------
    p-value : float or `~astropy.units.Quantity` ['dimensionless']

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import rayleightest
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> rayleightest(data) # doctest: +FLOAT_CMP
    <Quantity 0.2563487733797317>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] M. Chirstman., C. Miller. "Testing a Sample of Directions for
       Uniformity." Lecture Notes, STA 6934/5805. University of Florida, 2007.
    .. [4] D. Wilkie. "Rayleigh Test for Randomness of Circular Data". Applied
       Statistics. 1983.
       <http://wexler.free.fr/library/files/wilkie%20(1983)%20rayleigh%20test%20for%20randomness%20of%20circular%20data.pdf>
    'b'Performs the Rayleigh test of uniformity where the alternative
    hypothesis H1 is assumed to have a known mean angle ``mu``.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    mu : float or `~astropy.units.Quantity` ['angle'], optional
        Mean angle. Assumed to be known.
    axis : int, optional
        Axis along which the V test will be performed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    p-value : float or `~astropy.units.Quantity` ['dimensionless']

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import vtest
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> vtest(data) # doctest: +FLOAT_CMP
    <Quantity 0.6223678199713766>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] M. Chirstman., C. Miller. "Testing a Sample of Directions for
       Uniformity." Lecture Notes, STA 6934/5805. University of Florida, 2007.
    'u'Performs the Rayleigh test of uniformity where the alternative
    hypothesis H1 is assumed to have a known mean angle ``mu``.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    mu : float or `~astropy.units.Quantity` ['angle'], optional
        Mean angle. Assumed to be known.
    axis : int, optional
        Axis along which the V test will be performed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    p-value : float or `~astropy.units.Quantity` ['dimensionless']

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import vtest
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> vtest(data) # doctest: +FLOAT_CMP
    <Quantity 0.6223678199713766>

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    .. [3] M. Chirstman., C. Miller. "Testing a Sample of Directions for
       Uniformity." Lecture Notes, STA 6934/5805. University of Florida, 2007.
    'b'Computes the Maximum Likelihood Estimator (MLE) for the parameters of
    the von Mises distribution.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which the mle will be computed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    mu : float or `~astropy.units.Quantity`
        The mean (aka location parameter).
    kappa : float or `~astropy.units.Quantity` ['dimensionless']
        The concentration parameter.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import vonmisesmle
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> vonmisesmle(data) # doctest: +FLOAT_CMP
    (<Quantity 101.16894320013179 deg>, <Quantity 1.49358958737054>)

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    'u'Computes the Maximum Likelihood Estimator (MLE) for the parameters of
    the von Mises distribution.

    Parameters
    ----------
    data : ndarray or `~astropy.units.Quantity`
        Array of circular (directional) data, which is assumed to be in
        radians whenever ``data`` is ``numpy.ndarray``.
    axis : int, optional
        Axis along which the mle will be computed.
    weights : numpy.ndarray, optional
        In case of grouped data, the i-th element of ``weights`` represents a
        weighting factor for each group such that ``sum(weights, axis)``
        equals the number of observations. See [1]_, remark 1.4, page 22,
        for detailed explanation.

    Returns
    -------
    mu : float or `~astropy.units.Quantity`
        The mean (aka location parameter).
    kappa : float or `~astropy.units.Quantity` ['dimensionless']
        The concentration parameter.

    Examples
    --------
    >>> import numpy as np
    >>> from astropy.stats import vonmisesmle
    >>> from astropy import units as u
    >>> data = np.array([130, 90, 0, 145])*u.deg
    >>> vonmisesmle(data) # doctest: +FLOAT_CMP
    (<Quantity 101.16894320013179 deg>, <Quantity 1.49358958737054>)

    References
    ----------
    .. [1] S. R. Jammalamadaka, A. SenGupta. "Topics in Circular Statistics".
       Series on Multivariate Analysis, Vol. 5, 2001.
    .. [2] C. Agostinelli, U. Lund. "Circular Statistics from 'Topics in
       Circular Statistics (2001)'". 2015.
       <https://cran.r-project.org/web/packages/CircStats/CircStats.pdf>
    'u'astropy.stats.circstats'u'stats.circstats'u'circstats'DEFAULT_OBSTIMEEARTH_CENTER
    Other parameters
    ----------------
    obstime : `~astropy.time.Time`
        The time at which the observation is taken.  Used for determining the
        position of the Earth and its precession.
    location : `~astropy.coordinates.EarthLocation`
        The location on the Earth.  This can be specified either as an
        `~astropy.coordinates.EarthLocation` object or as anything that can be
        transformed to an `~astropy.coordinates.ITRS` frame. The default is the
        centre of the Earth.

    A coordinate or frame in the Celestial Intermediate Reference System (CIRS).

    The frame attributes are listed under **Other Parameters**.
    The reference time (e.g., time of observation# The "self-transform" is defined in icrs_cirs_transformations.py, because in# the current implementation it goes through ICRS (like GCRS)b'
    Other parameters
    ----------------
    obstime : `~astropy.time.Time`
        The time at which the observation is taken.  Used for determining the
        position of the Earth and its precession.
    location : `~astropy.coordinates.EarthLocation`
        The location on the Earth.  This can be specified either as an
        `~astropy.coordinates.EarthLocation` object or as anything that can be
        transformed to an `~astropy.coordinates.ITRS` frame. The default is the
        centre of the Earth.
'u'
    Other parameters
    ----------------
    obstime : `~astropy.time.Time`
        The time at which the observation is taken.  Used for determining the
        position of the Earth and its precession.
    location : `~astropy.coordinates.EarthLocation`
        The location on the Earth.  This can be specified either as an
        `~astropy.coordinates.EarthLocation` object or as anything that can be
        transformed to an `~astropy.coordinates.ITRS` frame. The default is the
        centre of the Earth.
'b'
    A coordinate or frame in the Celestial Intermediate Reference System (CIRS).

    The frame attributes are listed under **Other Parameters**.
    'u'
    A coordinate or frame in the Celestial Intermediate Reference System (CIRS).

    The frame attributes are listed under **Other Parameters**.
    'b'The reference time (e.g., time of observation'u'The reference time (e.g., time of observation'u'astropy.coordinates.builtin_frames.cirs'u'coordinates.builtin_frames.cirs'u'builtin_frames.cirs'u'cirs'
Contains the transformation functions for getting to "observed" systems from CIRS.
astropy.coordinates.erfa_astromerfa_astromastropy.coordinates.transformationsFunctionTransformWithFiniteDifferencePIOVER2cirs_to_observedcirs_cooobserved_frameis_unitsphericalusreprcirs_racirs_decapioastromatioqobserved_to_cirsobserved_coocirs_framecoord_typeatoiqcirs_at_aa_time# if the data are UnitSphericalRepresentation, we can skip the distance calculations# We used to do "astrometric" corrections here, but these are no longer necessary# CIRS has proper topocentric behaviour# first set up the astrometry context for CIRS<->observed# since we've transformed to CIRS at the observatory location, just use CIRS distance# the 'A' indicates zen/az inputs# first set up the astrometry context for ICRS<->CIRS at the observed_coo time# this final transform may be a no-op if the obstimes and locations are the sameb'
Contains the transformation functions for getting to "observed" systems from CIRS.
'u'
Contains the transformation functions for getting to "observed" systems from CIRS.
'u'astropy.coordinates.builtin_frames.cirs_observed_transforms'u'coordinates.builtin_frames.cirs_observed_transforms'u'builtin_frames.cirs_observed_transforms'u'cirs_observed_transforms'selectsocketthreadingurlunparseSAMP_STATUS_OKSAMP_STATUS_WARNINGSAMPClientErrorSAMPWarningSAMPHubServerstandard_profileThreadingXMLRPCServerget_num_argsinternet_onSAMPClient
    Utility class which provides facilities to create and manage a SAMP
    compliant XML-RPC server that acts as SAMP callable client application.

    Parameters
    ----------
    hub : :class:`~astropy.samp.SAMPHubProxy`
        An instance of :class:`~astropy.samp.SAMPHubProxy` to be
        used for messaging with the SAMP Hub.

    name : str, optional
        Client name (corresponding to ``samp.name`` metadata keyword).

    description : str, optional
        Client description (corresponding to ``samp.description.text`` metadata
        keyword).

    metadata : dict, optional
        Client application metadata in the standard SAMP format.

    addr : str, optional
        Listening address (or IP). This defaults to 127.0.0.1 if the internet
        is not reachable, otherwise it defaults to the host name.

    port : int, optional
        Listening XML-RPC server socket port. If left set to 0 (the default),
        the operating system will select a free port.

    callable : bool, optional
        Whether the client can receive calls and notifications. If set to
        `False`, then the client can send notifications and calls, but can not
        receive any.
    addrport_is_running_is_registeredsamp.namesamp.description.text_metadata_addr_port_xmlrpcAddr_callable_public_id_private_key_hub_id_notification_bindings_pingsamp.app.ping_client_env_getclient.env.get_call_bindings_response_bindings127.0.0.1_host_namegetfqdngetaddrinfoThread_serve_foreverdaemonlogRequestsallow_noneregister_introspection_functionsregister_functionreceive_notificationsamp.client.receiveNotificationreceive_callsamp.client.receiveCallreceive_responsesamp.client.receiveResponsegetsocknamehttpprotocol
        Start the client in a separate thread (non-blocking).

        This only has an effect if ``callable`` was set to `True` when
        initializing the client.
        _run_clienttimeout
        Stop the client.

        Parameters
        ----------
        timeout : float
            Timeout after which to give up if the client cannot be cleanly
            shut down.
        is_aliveClient was not shut down successfully (timeout=s)is_running
        Whether the client is currently running.
        is_registered
        Whether the client is currently registered.
        0.1read_readyhandle_requestCall to select in SAMPClient failed: server_closeprivate_keysender_idmsg_idmsg_mtypemsg_paramsmessagesamp.statussamp.resultreplyenvironEnvironment variable not defined.samp.errortxtsamp.error_handle_notificationget_private_keysamp.mtypesamp.paramsget_mtype_subtypesmsubsmtypebound_func
        Standard callable client ``receive_notification`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_notification`
        method is used to bind distinct operations to MTypes. In case of a
        customized callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        sender_id : str
            Sender public ID.

        message : dict
            Received message.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        _handle_call
        Standard callable client ``receive_call`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_call` method is
        used to bind distinct operations to MTypes. In case of a customized
        callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        sender_id : str
            Sender public ID.

        msg_id : str
            Message ID received.

        message : dict
            Received message.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        _handle_responseresponder_idmsg_tagresponse
        Standard callable client ``receive_response`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_response` method
        is used to bind distinct operations to MTypes. In case of a customized
        callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        responder_id : str
            Responder public ID.

        msg_tag : str
            Response message tag.

        response : dict
            Received response.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        bind_receive_messagedeclare
        Bind a specific MType to a function or class method, being intended for
        a call or a notification.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, msg_id,
                                      mtype, params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``msg_id`` is the Hub message-id (calls only,
        otherwise is `None`), ``mtype`` is the message MType, ``params`` is the
        message parameter set (content of ``"samp.params"``) and ``extra`` is a
        dictionary containing any extra message map entry. The client is
        automatically declared subscribed to the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        bind_receive_callbind_receive_notification
        Bind a specific MType notification to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, mtype,
                                      params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``mtype`` is the message MType, ``params`` is
        the notified message parameter set (content of ``"samp.params"``) and
        ``extra`` is a dictionary containing any extra message map entry. The
        client is automatically declared subscribed to the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        _declare_subscriptionsClient not callable.
        Bind a specific MType call to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, msg_id,
                                      mtype, params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``msg_id`` is the Hub message-id, ``mtype`` is
        the message MType, ``params`` is the message parameter set (content of
        ``"samp.params"``) and ``extra`` is a dictionary containing any extra
        message map entry. The client is automatically declared subscribed to
        the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        bind_receive_response
        Bind a specific msg-tag response to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, responder_id,
                                      msg_tag, response)

        where ``private_key`` is the client private-key, ``responder_id`` is
        the message responder ID, ``msg_tag`` is the message-tag provided at
        call time and ``response`` is the response received.

        Parameters
        ----------
        msg_tag : str
            Message-tag to be caught.

        function : callable
            Application function to be used when ``msg_tag`` is received.
        unbind_receive_notification
        Remove from the notifications binding table the specified MType and
        unsubscribe the client from it (if required).

        Parameters
        ----------
        mtype : str
            MType to be removed.

        declare : bool
            Specify whether the client must be automatically declared as
            unsubscribed from the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        unbind_receive_call
        Remove from the calls binding table the specified MType and unsubscribe
        the client from it (if required).

        Parameters
        ----------
        mtype : str
            MType to be removed.

        declare : bool
            Specify whether the client must be automatically declared as
            unsubscribed from the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        unbind_receive_response
        Remove from the responses binding table the specified message-tag.

        Parameters
        ----------
        msg_tag : str
            Message-tag to be removed.
        declare_subscriptionssubscriptions
        Declares the MTypes the client wishes to subscribe to, implicitly
        defined with the MType binding methods
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_notification`
        and :meth:`~astropy.samp.client.SAMPClient.bind_receive_call`.

        An optional ``subscriptions`` map can be added to the final map passed
        to the :meth:`~astropy.samp.hub_proxy.SAMPHubProxy.declare_subscriptions`
        method.

        Parameters
        ----------
        subscriptions : dict, optional
            Dictionary containing the list of MTypes to subscribe to, with the
            same format of the ``subscriptions`` map passed to the
            :meth:`~astropy.samp.hub_proxy.SAMPHubProxy.declare_subscriptions`
            method.
        
        Register the client to the SAMP Hub.
        is_connectedClient already registeredlockfilesamp.secretsamp.self-idRegistration failed - samp.self-id was not set by the hub.samp.private-keyRegistration failed - samp.private-key was not set by the hub.samp.hub-id_set_xmlrpc_callbackdeclare_metadataUnable to register to the SAMP Hub. Hub proxy not connected.
        Unregister the client from the SAMP Hub.
        Unable to unregister from the SAMP Hub. Hub proxy not connected.set_xmlrpc_callbackmtypes_dictUnable to declare subscriptions. Hub unreachable or not connected or client not registered."Unable to declare subscriptions. Hub ""unreachable or not connected or client ""not registered."
        Declare the client application metadata supported.

        Parameters
        ----------
        metadata : dict, optional
            Dictionary containing the client application metadata as defined in
            the SAMP definition document. If omitted, then no metadata are
            declared.
        Unable to declare metadata. Hub unreachable or not connected or client not registered."Unable to declare metadata. Hub "
        Return the client private key used for the Standard Profile
        communications obtained at registration time (``samp.private-key``).

        Returns
        -------
        key : str
            Client private key.
        get_public_id
        Return public client ID obtained at registration time
        (``samp.self-id``).

        Returns
        -------
        id : str
            Client public ID.
        # TODO: define what is meant by callable# GENERAL# HUB INTERACTION# If the port was set to zero, then the operating system has# selected a free port. We now check what this port number is.# Setting _is_running to False causes the loop in _serve_forever to# exit. The thread should then stop running. We wait for the thread to# terminate until the timeout, then we continue anyway.# Collect notification mtypes and metadata# Add optional subscription mapb'SAMPClient'u'SAMPClient'b'
    Utility class which provides facilities to create and manage a SAMP
    compliant XML-RPC server that acts as SAMP callable client application.

    Parameters
    ----------
    hub : :class:`~astropy.samp.SAMPHubProxy`
        An instance of :class:`~astropy.samp.SAMPHubProxy` to be
        used for messaging with the SAMP Hub.

    name : str, optional
        Client name (corresponding to ``samp.name`` metadata keyword).

    description : str, optional
        Client description (corresponding to ``samp.description.text`` metadata
        keyword).

    metadata : dict, optional
        Client application metadata in the standard SAMP format.

    addr : str, optional
        Listening address (or IP). This defaults to 127.0.0.1 if the internet
        is not reachable, otherwise it defaults to the host name.

    port : int, optional
        Listening XML-RPC server socket port. If left set to 0 (the default),
        the operating system will select a free port.

    callable : bool, optional
        Whether the client can receive calls and notifications. If set to
        `False`, then the client can send notifications and calls, but can not
        receive any.
    'u'
    Utility class which provides facilities to create and manage a SAMP
    compliant XML-RPC server that acts as SAMP callable client application.

    Parameters
    ----------
    hub : :class:`~astropy.samp.SAMPHubProxy`
        An instance of :class:`~astropy.samp.SAMPHubProxy` to be
        used for messaging with the SAMP Hub.

    name : str, optional
        Client name (corresponding to ``samp.name`` metadata keyword).

    description : str, optional
        Client description (corresponding to ``samp.description.text`` metadata
        keyword).

    metadata : dict, optional
        Client application metadata in the standard SAMP format.

    addr : str, optional
        Listening address (or IP). This defaults to 127.0.0.1 if the internet
        is not reachable, otherwise it defaults to the host name.

    port : int, optional
        Listening XML-RPC server socket port. If left set to 0 (the default),
        the operating system will select a free port.

    callable : bool, optional
        Whether the client can receive calls and notifications. If set to
        `False`, then the client can send notifications and calls, but can not
        receive any.
    'b'samp.name'u'samp.name'b'samp.description.text'u'samp.description.text'b'samp.app.ping'u'samp.app.ping'b'client.env.get'u'client.env.get'b'127.0.0.1'u'127.0.0.1'b'samp.client.receiveNotification'u'samp.client.receiveNotification'b'samp.client.receiveCall'u'samp.client.receiveCall'b'samp.client.receiveResponse'u'samp.client.receiveResponse'b'http'u'http'b'
        Start the client in a separate thread (non-blocking).

        This only has an effect if ``callable`` was set to `True` when
        initializing the client.
        'u'
        Start the client in a separate thread (non-blocking).

        This only has an effect if ``callable`` was set to `True` when
        initializing the client.
        'b'
        Stop the client.

        Parameters
        ----------
        timeout : float
            Timeout after which to give up if the client cannot be cleanly
            shut down.
        'u'
        Stop the client.

        Parameters
        ----------
        timeout : float
            Timeout after which to give up if the client cannot be cleanly
            shut down.
        'b'Client was not shut down successfully (timeout='u'Client was not shut down successfully (timeout='b's)'u's)'b'
        Whether the client is currently running.
        'u'
        Whether the client is currently running.
        'b'
        Whether the client is currently registered.
        'u'
        Whether the client is currently registered.
        'b'Call to select in SAMPClient failed: 'u'Call to select in SAMPClient failed: 'b'samp.status'u'samp.status'b'samp.result'u'samp.result'b'Environment variable not defined.'u'Environment variable not defined.'b'samp.errortxt'u'samp.errortxt'b'samp.error'u'samp.error'b'samp.mtype'u'samp.mtype'b'samp.params'u'samp.params'b'
        Standard callable client ``receive_notification`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_notification`
        method is used to bind distinct operations to MTypes. In case of a
        customized callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        sender_id : str
            Sender public ID.

        message : dict
            Received message.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        'u'
        Standard callable client ``receive_notification`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_notification`
        method is used to bind distinct operations to MTypes. In case of a
        customized callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        sender_id : str
            Sender public ID.

        message : dict
            Received message.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        'b'
        Standard callable client ``receive_call`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_call` method is
        used to bind distinct operations to MTypes. In case of a customized
        callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        sender_id : str
            Sender public ID.

        msg_id : str
            Message ID received.

        message : dict
            Received message.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        'u'
        Standard callable client ``receive_call`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_call` method is
        used to bind distinct operations to MTypes. In case of a customized
        callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        sender_id : str
            Sender public ID.

        msg_id : str
            Message ID received.

        message : dict
            Received message.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        'b'
        Standard callable client ``receive_response`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_response` method
        is used to bind distinct operations to MTypes. In case of a customized
        callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        responder_id : str
            Responder public ID.

        msg_tag : str
            Response message tag.

        response : dict
            Received response.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        'u'
        Standard callable client ``receive_response`` method.

        This method is automatically handled when the
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_response` method
        is used to bind distinct operations to MTypes. In case of a customized
        callable client implementation that inherits from the
        :class:`~astropy.samp.SAMPClient` class this method should be
        overwritten.

        .. note:: When overwritten, this method must always return
                  a string result (even empty).

        Parameters
        ----------
        private_key : str
            Client private key.

        responder_id : str
            Responder public ID.

        msg_tag : str
            Response message tag.

        response : dict
            Received response.

        Returns
        -------
        confirmation : str
            Any confirmation string.
        'b'
        Bind a specific MType to a function or class method, being intended for
        a call or a notification.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, msg_id,
                                      mtype, params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``msg_id`` is the Hub message-id (calls only,
        otherwise is `None`), ``mtype`` is the message MType, ``params`` is the
        message parameter set (content of ``"samp.params"``) and ``extra`` is a
        dictionary containing any extra message map entry. The client is
        automatically declared subscribed to the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'u'
        Bind a specific MType to a function or class method, being intended for
        a call or a notification.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, msg_id,
                                      mtype, params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``msg_id`` is the Hub message-id (calls only,
        otherwise is `None`), ``mtype`` is the message MType, ``params`` is the
        message parameter set (content of ``"samp.params"``) and ``extra`` is a
        dictionary containing any extra message map entry. The client is
        automatically declared subscribed to the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'b'
        Bind a specific MType notification to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, mtype,
                                      params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``mtype`` is the message MType, ``params`` is
        the notified message parameter set (content of ``"samp.params"``) and
        ``extra`` is a dictionary containing any extra message map entry. The
        client is automatically declared subscribed to the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'u'
        Bind a specific MType notification to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, mtype,
                                      params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``mtype`` is the message MType, ``params`` is
        the notified message parameter set (content of ``"samp.params"``) and
        ``extra`` is a dictionary containing any extra message map entry. The
        client is automatically declared subscribed to the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'b'Client not callable.'u'Client not callable.'b'
        Bind a specific MType call to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, msg_id,
                                      mtype, params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``msg_id`` is the Hub message-id, ``mtype`` is
        the message MType, ``params`` is the message parameter set (content of
        ``"samp.params"``) and ``extra`` is a dictionary containing any extra
        message map entry. The client is automatically declared subscribed to
        the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'u'
        Bind a specific MType call to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, sender_id, msg_id,
                                      mtype, params, extra)

        where ``private_key`` is the client private-key, ``sender_id`` is the
        notification sender ID, ``msg_id`` is the Hub message-id, ``mtype`` is
        the message MType, ``params`` is the message parameter set (content of
        ``"samp.params"``) and ``extra`` is a dictionary containing any extra
        message map entry. The client is automatically declared subscribed to
        the MType by default.

        Parameters
        ----------
        mtype : str
            MType to be caught.

        function : callable
            Application function to be used when ``mtype`` is received.

        declare : bool, optional
            Specify whether the client must be automatically declared as
            subscribed to the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).

        metadata : dict, optional
            Dictionary containing additional metadata to declare associated
            with the MType subscribed to (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'b'
        Bind a specific msg-tag response to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, responder_id,
                                      msg_tag, response)

        where ``private_key`` is the client private-key, ``responder_id`` is
        the message responder ID, ``msg_tag`` is the message-tag provided at
        call time and ``response`` is the response received.

        Parameters
        ----------
        msg_tag : str
            Message-tag to be caught.

        function : callable
            Application function to be used when ``msg_tag`` is received.
        'u'
        Bind a specific msg-tag response to a function or class method.

        The function must be of the form::

            def my_function_or_method(<self,> private_key, responder_id,
                                      msg_tag, response)

        where ``private_key`` is the client private-key, ``responder_id`` is
        the message responder ID, ``msg_tag`` is the message-tag provided at
        call time and ``response`` is the response received.

        Parameters
        ----------
        msg_tag : str
            Message-tag to be caught.

        function : callable
            Application function to be used when ``msg_tag`` is received.
        'b'
        Remove from the notifications binding table the specified MType and
        unsubscribe the client from it (if required).

        Parameters
        ----------
        mtype : str
            MType to be removed.

        declare : bool
            Specify whether the client must be automatically declared as
            unsubscribed from the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'u'
        Remove from the notifications binding table the specified MType and
        unsubscribe the client from it (if required).

        Parameters
        ----------
        mtype : str
            MType to be removed.

        declare : bool
            Specify whether the client must be automatically declared as
            unsubscribed from the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'b'
        Remove from the calls binding table the specified MType and unsubscribe
        the client from it (if required).

        Parameters
        ----------
        mtype : str
            MType to be removed.

        declare : bool
            Specify whether the client must be automatically declared as
            unsubscribed from the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'u'
        Remove from the calls binding table the specified MType and unsubscribe
        the client from it (if required).

        Parameters
        ----------
        mtype : str
            MType to be removed.

        declare : bool
            Specify whether the client must be automatically declared as
            unsubscribed from the MType (see also
            :meth:`~astropy.samp.client.SAMPClient.declare_subscriptions`).
        'b'
        Remove from the responses binding table the specified message-tag.

        Parameters
        ----------
        msg_tag : str
            Message-tag to be removed.
        'u'
        Remove from the responses binding table the specified message-tag.

        Parameters
        ----------
        msg_tag : str
            Message-tag to be removed.
        'b'
        Declares the MTypes the client wishes to subscribe to, implicitly
        defined with the MType binding methods
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_notification`
        and :meth:`~astropy.samp.client.SAMPClient.bind_receive_call`.

        An optional ``subscriptions`` map can be added to the final map passed
        to the :meth:`~astropy.samp.hub_proxy.SAMPHubProxy.declare_subscriptions`
        method.

        Parameters
        ----------
        subscriptions : dict, optional
            Dictionary containing the list of MTypes to subscribe to, with the
            same format of the ``subscriptions`` map passed to the
            :meth:`~astropy.samp.hub_proxy.SAMPHubProxy.declare_subscriptions`
            method.
        'u'
        Declares the MTypes the client wishes to subscribe to, implicitly
        defined with the MType binding methods
        :meth:`~astropy.samp.client.SAMPClient.bind_receive_notification`
        and :meth:`~astropy.samp.client.SAMPClient.bind_receive_call`.

        An optional ``subscriptions`` map can be added to the final map passed
        to the :meth:`~astropy.samp.hub_proxy.SAMPHubProxy.declare_subscriptions`
        method.

        Parameters
        ----------
        subscriptions : dict, optional
            Dictionary containing the list of MTypes to subscribe to, with the
            same format of the ``subscriptions`` map passed to the
            :meth:`~astropy.samp.hub_proxy.SAMPHubProxy.declare_subscriptions`
            method.
        'b'
        Register the client to the SAMP Hub.
        'u'
        Register the client to the SAMP Hub.
        'b'Client already registered'u'Client already registered'b'samp.secret'u'samp.secret'b'samp.self-id'u'samp.self-id'b'Registration failed - samp.self-id was not set by the hub.'u'Registration failed - samp.self-id was not set by the hub.'b'samp.private-key'u'samp.private-key'b'Registration failed - samp.private-key was not set by the hub.'u'Registration failed - samp.private-key was not set by the hub.'b'samp.hub-id'u'samp.hub-id'b'Unable to register to the SAMP Hub. Hub proxy not connected.'u'Unable to register to the SAMP Hub. Hub proxy not connected.'b'
        Unregister the client from the SAMP Hub.
        'u'
        Unregister the client from the SAMP Hub.
        'b'Unable to unregister from the SAMP Hub. Hub proxy not connected.'u'Unable to unregister from the SAMP Hub. Hub proxy not connected.'b'Unable to declare subscriptions. Hub unreachable or not connected or client not registered.'u'Unable to declare subscriptions. Hub unreachable or not connected or client not registered.'b'
        Declare the client application metadata supported.

        Parameters
        ----------
        metadata : dict, optional
            Dictionary containing the client application metadata as defined in
            the SAMP definition document. If omitted, then no metadata are
            declared.
        'u'
        Declare the client application metadata supported.

        Parameters
        ----------
        metadata : dict, optional
            Dictionary containing the client application metadata as defined in
            the SAMP definition document. If omitted, then no metadata are
            declared.
        'b'Unable to declare metadata. Hub unreachable or not connected or client not registered.'u'Unable to declare metadata. Hub unreachable or not connected or client not registered.'b'
        Return the client private key used for the Standard Profile
        communications obtained at registration time (``samp.private-key``).

        Returns
        -------
        key : str
            Client private key.
        'u'
        Return the client private key used for the Standard Profile
        communications obtained at registration time (``samp.private-key``).

        Returns
        -------
        key : str
            Client private key.
        'b'
        Return public client ID obtained at registration time
        (``samp.self-id``).

        Returns
        -------
        id : str
            Client public ID.
        'u'
        Return public client ID obtained at registration time
        (``samp.self-id``).

        Returns
        -------
        id : str
            Client public ID.
        'u'astropy.samp.client'u'samp.client'u'client'
Astronomical and physics constants in SI units.  See :mod:`astropy.constants`
for a complete listing of constants defined in Astropy.
CODATA2010CODATA 2010default_reference_registry_has_incompatible_unitsEMCODATA20106.62606957e-34J s2.9e-410.00000029e-34hbarReduced Planck constantBoltzmann constant1.3806488e-23J / (K)1.3e-290.0000013e-23Speed of light in vacuum299792458.02.99792458e8m / (s)Gravitational constant6.67384e-11m3 / (kg s2)8e-150.00080e-11g0Standard acceleration of gravity9.80665m / s2Proton mass1.672621777e-277.4e-350.000000074e-27m_nNeutron mass1.674927351e-27Electron mass9.10938291e-314e-380.00000040e-31Atomic mass1.660538921e-277.3e-350.000000073e-27Stefan-Boltzmann constant5.670373e-085.670373e-8W / (K4 m2)2.1e-130.000021e-8Electron charge1.602176565e-193.5e-270.000000035e-19Electric constant8.854187817e-12F/mN_AAvogadro's number6.02214129e+236.02214129e231 / (mol)2.7e+160.00000027e23Gas constant8.3144621J / (K mol)7.5e-060.0000075RydRydberg constant10973731.5685391 / (m)5.5e-050.0000555.2917721092e-110.52917721092e-101.7e-200.00000000017e-109.27400968e-24927.400968e-26J/T2e-310.00002e-26Fine-structure constant0.00729735256987.2973525698e-32.4e-120.0000000024e-3Standard atmosphere101325Magnetic constant4e-074.0e-7N/A2sigma_TThomson scattering cross-section6.652458734e-290.6652458734e-28m21.3e-370.0000000013e-28b_wienWien wavelength displacement law constant0.00289777212.8977721e-3m K2.6e-090.0000026e-3e_esue_emue_gauss# PHYSICAL CONSTANTS# cgs constants# Only constants that cannot be converted directly from S.I. are defined here.b'
Astronomical and physics constants in SI units.  See :mod:`astropy.constants`
for a complete listing of constants defined in Astropy.
'u'
Astronomical and physics constants in SI units.  See :mod:`astropy.constants`
for a complete listing of constants defined in Astropy.
'b'CODATA 2010'u'CODATA 2010'b'J s'u'J s'b'hbar'u'hbar'b'Reduced Planck constant'u'Reduced Planck constant'b'k_B'u'k_B'b'Boltzmann constant'u'Boltzmann constant'b'J / (K)'u'J / (K)'b'Speed of light in vacuum'u'Speed of light in vacuum'b'm / (s)'u'm / (s)'b'Gravitational constant'u'Gravitational constant'b'm3 / (kg s2)'u'm3 / (kg s2)'b'g0'u'g0'b'Standard acceleration of gravity'u'Standard acceleration of gravity'b'm / s2'u'm / s2'b'm_p'u'm_p'b'Proton mass'u'Proton mass'b'm_n'u'm_n'b'Neutron mass'u'Neutron mass'b'm_e'u'm_e'b'Electron mass'u'Electron mass'b'Atomic mass'u'Atomic mass'b'sigma_sb'u'sigma_sb'b'Stefan-Boltzmann constant'u'Stefan-Boltzmann constant'b'W / (K4 m2)'u'W / (K4 m2)'b'Electron charge'u'Electron charge'b'Electric constant'u'Electric constant'b'F/m'u'F/m'b'N_A'u'N_A'b'Avogadro's number'u'Avogadro's number'b'1 / (mol)'u'1 / (mol)'b'Gas constant'u'Gas constant'b'J / (K mol)'u'J / (K mol)'b'Ryd'u'Ryd'b'Rydberg constant'u'Rydberg constant'b'1 / (m)'u'1 / (m)'b'J/T'u'J/T'b'Fine-structure constant'u'Fine-structure constant'b'Standard atmosphere'u'Standard atmosphere'b'Magnetic constant'u'Magnetic constant'b'N/A2'u'N/A2'b'sigma_T'u'sigma_T'b'Thomson scattering cross-section'u'Thomson scattering cross-section'b'm2'u'm2'b'b_wien'u'b_wien'b'Wien wavelength displacement law constant'u'Wien wavelength displacement law constant'b'm K'u'm K'u'astropy.constants.codata2010'u'constants.codata2010'CODATA2014CODATA 2014EMCODATA20146.62607004e-346.626070040e-348.1e-420.000000081e-341.0545718e-341.054571800e-341.3e-420.000000013e-341.38064852e-237.9e-300.00000079e-236.67408e-113.1e-150.00031e-111.672621898e-272.1e-350.000000021e-271.674927471e-279.10938356e-311.1e-380.00000011e-311.66053904e-271.660539040e-272e-350.000000020e-275.670367e-085.670367e-81.3e-130.000013e-81.6021766208e-199.8e-280.0000000098e-196.022140857e+236.022140857e237400000000000000.00.000000074e238.31445984.8e-060.000004810973731.5685086.5e-050.0000655.2917721067e-110.52917721067e-101.2e-200.00000000012e-109.274009994e-24927.4009994e-260.00729735256647.2973525664e-31.7e-120.0000000017e-36.6524587158e-290.66524587158e-289.1e-380.00000000091e-280.00289777292.8977729e-31.7e-090.0000017e-3b'CODATA 2014'u'CODATA 2014'u'astropy.constants.codata2014'u'constants.codata2014'CODATA2018CODATA 2018EMCODATA20186.62607015e-341.380649e-236.6743e-116.67430e-111.5e-150.00015e-111.67262192369e-275.1e-370.00000000051e-271.67492749804e-279.5e-370.00000000095e-279.1093837015e-312.8e-400.0000000028e-311.6605390666e-271.66053906660e-275e-370.00000000050e-271.602176634e-19Vacuum electric permittivity8.8541878128e-121.3e-210.0000000013e-126.02214076e+236.02214076e2310973731.5681610973731.5681602.1e-050.0000215.29177210903e-118e-210.00000000080e-119.2740100783e-242.8e-330.0000000028e-240.00729735256937.2973525693e-31.1e-120.0000000011e-3Vacuum magnetic permeability1.25663706212e-061.25663706212e-61.9e-160.00000000019e-66.6524587321e-296e-380.0000000060e-294.965114231744276# https://en.wikipedia.org/wiki/2019_redefinition_of_SI_base_units# Formula taken from NIST wall chart.# The numerical factor is from a numerical solution to the equation for the# maximum. See https://en.wikipedia.org/wiki/Wien%27s_displacement_law# CGS constants.# Because both e and c are exact, these are also exact by definition.b'CODATA 2018'u'CODATA 2018'b'Vacuum electric permittivity'u'Vacuum electric permittivity'b'Vacuum magnetic permeability'u'Vacuum magnetic permeability'u'astropy.constants.codata2018'u'constants.codata2018'Utilities for generating new Python code at runtime.make_function_with_signature^[A-Za-z][A-Za-z_]*_ARGNAME_RE
Regular expression used my make_func which limits the allowed argument
names for the created function.  Only valid Python variable names in
the ASCII range and not beginning with '_' are allowed, currently.
varargsvarkwargs
    Make a new function from an existing function but with the desired
    signature.

    The desired signature must of course be compatible with the arguments
    actually accepted by the input function.

    The ``args`` are strings that should be the names of the positional
    arguments.  ``kwargs`` can map names of keyword arguments to their
    default values.  It may be either a ``dict`` or a list of ``(keyword,
    default)`` tuples.

    If ``varargs`` is a string it is added to the positional arguments as
    ``*<varargs>``.  Likewise ``varkwargs`` can be the name for a variable
    keyword argument placeholder like ``**<varkwargs>``.

    If not specified the name of the new function is taken from the original
    function.  Otherwise, the ``name`` argument can be used to specify a new
    name.

    Note, the names may only be valid Python variable names.
    pos_argskey_argsiter_kwargsargnameiskeywordinvalid argument name: def_signature, *call_signature__funcglobal_varslocal_vars_kwargsdefault_var, **currentframef_backfrmmodname.pycsplitext.py<string>__main__co_firstlinenonum_blank_linesblank_lines    def ):
        return ____func()
    # Check that all the argument names are valid# Make local variables to handle setting the default args# The lstrip is in case there were *no* positional arguments (a rare case)# in any context this will actually be used...b'Utilities for generating new Python code at runtime.'u'Utilities for generating new Python code at runtime.'b'make_function_with_signature'u'make_function_with_signature'b'^[A-Za-z][A-Za-z_]*'u'^[A-Za-z][A-Za-z_]*'b'
Regular expression used my make_func which limits the allowed argument
names for the created function.  Only valid Python variable names in
the ASCII range and not beginning with '_' are allowed, currently.
'u'
Regular expression used my make_func which limits the allowed argument
names for the created function.  Only valid Python variable names in
the ASCII range and not beginning with '_' are allowed, currently.
'b'
    Make a new function from an existing function but with the desired
    signature.

    The desired signature must of course be compatible with the arguments
    actually accepted by the input function.

    The ``args`` are strings that should be the names of the positional
    arguments.  ``kwargs`` can map names of keyword arguments to their
    default values.  It may be either a ``dict`` or a list of ``(keyword,
    default)`` tuples.

    If ``varargs`` is a string it is added to the positional arguments as
    ``*<varargs>``.  Likewise ``varkwargs`` can be the name for a variable
    keyword argument placeholder like ``**<varkwargs>``.

    If not specified the name of the new function is taken from the original
    function.  Otherwise, the ``name`` argument can be used to specify a new
    name.

    Note, the names may only be valid Python variable names.
    'u'
    Make a new function from an existing function but with the desired
    signature.

    The desired signature must of course be compatible with the arguments
    actually accepted by the input function.

    The ``args`` are strings that should be the names of the positional
    arguments.  ``kwargs`` can map names of keyword arguments to their
    default values.  It may be either a ``dict`` or a list of ``(keyword,
    default)`` tuples.

    If ``varargs`` is a string it is added to the positional arguments as
    ``*<varargs>``.  Likewise ``varkwargs`` can be the name for a variable
    keyword argument placeholder like ``**<varkwargs>``.

    If not specified the name of the new function is taken from the original
    function.  Otherwise, the ``name`` argument can be used to specify a new
    name.

    Note, the names may only be valid Python variable names.
    'b'invalid argument name: 'u'invalid argument name: 'b', *'u', *'b'__func'u'__func'b'_kwargs'u'_kwargs'b', **'u', **'b'.pyc'u'.pyc'b'.py'u'.py'b'<string>'u'<string>'b'__main__'u'__main__'b'    def 'u'    def 'b'):
        return __'u'):
        return __'b'__func('u'__func('b')
    'u')
    'u'astropy.utils.codegen'u'utils.codegen'u'codegen'C:/Users/Asus/AppData/Local/Programs/Python/Python310/Lib/collectionsC:/Users/Asus/AppData/Local/Programs/Python/Python310/LibC:/Users/Asus/AppData/Local/Programs/Python/Python310C:/Users/Asus/AppData/Local/Programs/PythonC:/Users/Asus/AppData/Local/ProgramsC:/Users/Asus/AppData/LocalC:/Users/Asus/AppData
A module containing specialized collection classes.
HomogeneousList
    A subclass of list that contains only elements of a given type or
    types.  If an item that is not of the specified type is added to
    the list, a `TypeError` is raised.
    
        Parameters
        ----------
        types : sequence of types
            The types to accept.

        values : sequence, optional
            An initial set of values.
        _types_asserthomogeneous list must contain only objects of type 'b'
A module containing specialized collection classes.
'u'
A module containing specialized collection classes.
'b'
    A subclass of list that contains only elements of a given type or
    types.  If an item that is not of the specified type is added to
    the list, a `TypeError` is raised.
    'u'
    A subclass of list that contains only elements of a given type or
    types.  If an item that is not of the specified type is added to
    the list, a `TypeError` is raised.
    'b'
        Parameters
        ----------
        types : sequence of types
            The types to accept.

        values : sequence, optional
            An initial set of values.
        'u'
        Parameters
        ----------
        types : sequence of types
            The types to accept.

        values : sequence, optional
            An initial set of values.
        'b'homogeneous list must contain only objects of type ''u'homogeneous list must contain only objects of type ''u'astropy.utils.collections'u'utils.collections'u'collections'weakrefStructuredUnitNUMPY_LT_2_0BaseColumnInfodtype_info_nameastropy.utils.metadataMetaDatadtype_bytes_or_charspprint_column_mixins_ColumnGetitemShim_MaskedColumnGetitemShimFORMATTER
    Warning class for when a string column is assigned a value
    that gets truncated because the base (numpy) string length
    is too short.

    This does not inherit from AstropyWarning because we want to use
    stacklevel=2 to show the user where the issue occurred in their code.
    _auto_namesn_colsgreatergreater_equallessless_equalnot_equalequalisfinitesignbit_comparison_functionscol_copy
    Mixin-safe version of Column.copy() (with copy_data=True).

    Parameters
    ----------
    col : Column or mixin column
        Input column
    copy_indices : bool
        Copy the column ``indices`` attribute

    Returns
    -------
    col : Copy of input column
    BaseColumnnewcolreplace_colFalseArray
    Boolean mask array that is always False.

    This is used to create a stub ``mask`` property which is a boolean array of
    ``False`` used by default for mixin columns and corresponding to the mixin
    column data shape.  The ``mask`` looks like a normal numpy array but an
    exception will be raised if ``True`` is assigned to any element.  The
    consequences of the limitation are most obvious in the high-level table
    operations.

    Parameters
    ----------
    shape : tuple
        Data shape
    Cannot set any element of  class to True_expand_string_array_for_valuesarr
    For string-dtype return a version of ``arr`` that is wide enough for ``values``.
    If ``arr`` is not string-dtype or does not need expansion then return ``arr``.

    Parameters
    ----------
    arr : np.ndarray
        Input array
    values : scalar or array-like
        Values for width comparison for string arrays

    Returns
    -------
    arr_expanded : np.ndarray

    charvalues_str_lenarr_str_lenarr_dtype_convert_sequence_data_to_arrayConvert N-d sequence-like data to ndarray or MaskedArray.

    This is the core function for converting Python lists or list of lists to a
    numpy array. This handles embedded np.ma.masked constants in ``data`` along
    with the special case of an homogeneous list of MaskedArray elements.

    Considerations:

    - np.ma.array is about 50 times slower than np.array for list input. This
      function avoids using np.ma.array on list input.
    - np.array emits a UserWarning for embedded np.ma.masked, but only for int
      or float inputs. For those it converts to np.nan and forces float dtype.
      For other types np.array is inconsistent, for instance converting
      np.ma.masked to "0.0" for str types.
    - Searching in pure Python for np.ma.masked in ``data`` is comparable in
      speed to calling ``np.array(data)``.
    - This function may end up making two additional copies of input ``data``.

    Parameters
    ----------
    data : N-d sequence
        Input data, typically list or list of lists
    dtype : None or dtype-like
        Output datatype (None lets np.array choose)

    Returns
    -------
    np_data : np.ndarray or np.ma.MaskedArray

    np_ma_maskedhas_len_gt0np_datawarns.*converting a masked element.*.*Promotion of numbers and bools to strings.*has_unitMaskErrord0 is ma_maskedany_statementany( for d0 in data)any(d is ma_masked for d in d for dma_maskedcontexthas_maskeddata_filledfilldimrangesidxs_make_compareoper
    Make Column comparison methods which encode the ``other`` object to utf-8
    in the case of a bytestring dtype for Py3+.

    Parameters
    ----------
    oper : str
        Operator name
    _compare_encode_str
    Container for meta information like name, description, format.

    This is required when the object is used as a mixin column within a table,
    but can be used as a general way to store meta information.
    attr_names_attrs_no_copy_represent_as_dict_primary_datapart_unit
        Return a new Column instance which is consistent with the
        input ``cols`` and has ``length`` rows.

        This is intended for creating an empty column object whose elements can
        be set in-place for table operations like join or vstack.

        Parameters
        ----------
        cols : list
            List of input columns
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Column (or subclass)
            New instance of this class consistent with ``cols``

        _parent_clsget_sortable_arrays
        Return a list of arrays which can be lexically sorted to represent
        the order of the parent column.

        For Column this is just the column itself.

        Returns
        -------
        arrays : list of ndarray
        default_factoryself_data_name_parent_table_format
        An alias for the existing ``data`` attribute.
        parent_tablerefcopy_data
        Return a copy of the current instance.

        If ``data`` is supplied then a view (reference) of ``data`` is used,
        and ``copy_data`` is ignored.

        Parameters
        ----------
        order : {'C', 'F', 'A', 'K'}, optional
            Controls the memory layout of the copy. 'C' means C-order,
            'F' means F-order, 'A' means 'F' if ``a`` is Fortran contiguous,
            'C' otherwise. 'K' means match the layout of ``a`` as closely
            as possible. (Note that this function and :func:numpy.copy are very
            similar, but have different default values for their order=
            arguments.)  Default is 'C'.
        data : array, optional
            If supplied then use a view of ``data`` instead of the instance
            data.  This allows copying the instance attributes and meta.
        copy_data : bool, optional
            Make a copy of the internal numpy array instead of using a
            reference.  Default is True.

        Returns
        -------
        col : Column or MaskedColumn
            Copy of the current column (same type as original)
        __array_finalize___mask_copy_groupsstate
        Restore the internal state of the Column/MaskedColumn for pickling
        purposes.  This requires that the last element of ``state`` is a
        5-tuple that has Column-specific state values.
        super_class
        Return a 3-tuple for pickling a Column.  Use the super-class
        functionality but then add in a 5-tuple of Column-specific values
        that get used in __setstate__.
        reconstruct_funcreconstruct_func_argscolumn_state_copy_attrs__array_wrap__out_arrreturn_scalar
        __array_wrap__ is called at the end of every ufunc.

        Normally, we want a Column object back and do not have to do anything
        special. But there are two exceptions:

        1) If the output shape is different (e.g. for reduction ufuncs
           like sum() or mean()), a Column still linking to a parent_table
           makes little sense, so we return the output viewed as the
           column content (ndarray or MaskedArray).
           For this case, if numpy tells us to ``return_scalar`` (for numpy
           >= 2.0, otherwise assume to be true), we use "[()]" to ensure we
           convert a zero rank array to a scalar. (For some reason np.sum()
           returns a zero rank scalar array while np.mean() returns a scalar;
           So the [()] is needed for this case.)

        2) When the output is created by any function that returns a boolean
           we also want to consistently return an array rather than a column
           (see #1446 and #1685)
        
        The name of this column.
        Expected a str value, got  with type _rename_column
        Format string for displaying values in this column.
        format_stringprev_formatInvalid format for column '': could not display values in this column using this format"': could not display ""values in this column using this format"Array-interface compliant full description of the column.

        This returns a 3-tuple (name, type, shape) that can always be
        used in a structured array dtype definition.
        iter_str_vals
        Return an iterator that yields the string-formatted values of this
        column.

        Returns
        -------
        str_vals : iterator
            Column values formatted as strings
        _formatter_pformat_col_itershow_nameshow_unitshow_dtypeoutsattrs_equalCompare the column attributes of ``col`` to this object.

        The comparison attributes are: ``name``, ``unit``, ``dtype``,
        ``format``, ``description``, and ``meta``.

        Parameters
        ----------
        col : Column
            Comparison column

        Returns
        -------
        equal : bool
            True if all attributes are equal
        Comparison `col` must be a Column or MaskedColumn objectReturn a list of formatted string representation of column values.

        If ``max_lines=None`` is supplied then the height of the
        screen terminal is used to set ``max_lines``.  If the terminal
        height cannot be determined then the default will be
        determined using the ``astropy.conf.max_lines`` configuration
        item. If a negative value of ``max_lines`` is supplied then
        there is no line limit applied (default).

        Parameters
        ----------
        max_lines : int or None
            Maximum lines of output (header + data rows).
            -1 (default) implies no limit, ``None`` implies using the
            height of the current terminal.

        show_name : bool
            Include column name. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        show_dtype : bool
            Include column dtype. Default is False.

        html : bool
            Format the output as an HTML table. Default is False.

        Returns
        -------
        lines : list
            List of lines with header and formatted column values

        _pformat_colPrint a formatted string representation of column values.

        If ``max_lines=None`` (default) then the height of the
        screen terminal is used to set ``max_lines``.  If the terminal
        height cannot be determined then the default will be
        determined using the ``astropy.conf.max_lines`` configuration
        item. If a negative value of ``max_lines`` is supplied then
        there is no line limit applied.

        Parameters
        ----------
        max_lines : int
            Maximum number of values in output

        show_name : bool
            Include column name. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        show_dtype : bool
            Include column dtype. Default is True.
        n_headermoreInteractively browse column with a paging interface.

        Supported keys::

          f, <space> : forward one page
          b : back one page
          r : refresh same page
          n : next row
          p : previous row
          < : go to beginning
          > : go to end
          q : quit browsing
          h : print this help

        Parameters
        ----------
        max_lines : int
            Maximum number of lines in table output.

        show_name : bool
            Include a header row for column names. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        _more_tabcol
        The unit associated with this column.  May be a string or a
        `astropy.units.UnitBase` instance.

        Setting the ``unit`` property does not change the values of the
        data.  To perform a unit conversion, use ``convert_unit_to``.
        silentsidesorterutf-8convert_unit_tonew_unit
        Converts the values of the column in-place from the current
        unit to the given unit.

        To change the unit associated with this column without
        actually changing the data values, simply set the ``unit``
        property.

        Parameters
        ----------
        new_unit : str or `astropy.units.UnitBase` instance
            The unit to convert to.

        equivalencies : list of tuple
           A list of equivalence pairs to try if the unit are not
           directly convertible.  See :ref:`astropy:unit_equivalencies`.

        Raises
        ------
        astropy.units.UnitsError
            If units are inconsistent
        No unit set on columngroup_by
        Group this column by the specified ``keys``.

        This effectively splits the column into groups which correspond to
        unique values of the ``keys`` grouping object.  The output is a new
        `Column` or `MaskedColumn` which contains a copy of this column but
        sorted by row according to ``keys``.

        The ``keys`` input to ``group_by`` must be a numpy array with the
        same length as this column.

        Parameters
        ----------
        keys : numpy array
            Key grouping object

        Returns
        -------
        out : Column
            New column with groups attribute set accordingly
        column_group_by
        Copy current groups into a copy of self ``out``.
        
        A view of this table column as a `~astropy.units.Quantity` object with
        units given by the Column's `unit` parameter.
        
        Converts this table column to a `~astropy.units.Quantity` object with
        the requested units.

        Parameters
        ----------
        unit : unit-like
            The unit to convert to (i.e., a valid argument to the
            :meth:`astropy.units.Quantity.to` method).
        equivalencies : list of tuple
            Equivalencies to use for this conversion.  See
            :meth:`astropy.units.Quantity.to` for more details.

        Returns
        -------
        quantity : `~astropy.units.Quantity`
            A quantity object with the contents of this column in the units
            ``unit``.
        
        Copy key column attributes from ``obj`` to self.
        obj_meta
        Encode anything that is unicode-ish as utf-8.  This method is only
        called for Py3+.
        chararrayDefine a data column for use in a Table object.

    Parameters
    ----------
    data : list, ndarray, or None
        Column data values
    name : str
        Column name and key for reference within Table
    dtype : `~numpy.dtype`-like
        Data type for column
    shape : tuple or ()
        Dimensions of a single row element in the column data
    length : int or 0
        Number of row elements in column data
    description : str or None
        Full description of column
    unit : str or None
        Physical unit
    format : str, None, or callable
        Format string for outputting column values.  This can be an
        "old-style" (``format % value``) or "new-style" (`str.format`)
        format specification string or a function or any callable object that
        accepts a single value and returns a string.
    meta : dict-like or None
        Meta-data associated with the column

    Examples
    --------
    A Column can be created in two different ways:

    - Provide a ``data`` value but not ``shape`` or ``length`` (which are
      inferred from the data).

      Examples::

        col = Column(data=[1, 2], name='name')  # shape=(2,)
        col = Column(data=[[1, 2], [3, 4]], name='name')  # shape=(2, 2)
        col = Column(data=[1, 2], name='name', dtype=float)
        col = Column(data=np.array([1, 2]), name='name')
        col = Column(data=['hello', 'world'], name='name')

      The ``dtype`` argument can be any value which is an acceptable
      fixed-size data-type initializer for the numpy.dtype() method.  See
      `<https://numpy.org/doc/stable/reference/arrays.dtypes.html>`_.
      Examples include:

      - Python non-string type (float, int, bool)
      - Numpy non-string type (e.g. np.float32, np.int64, np.bool\_)
      - Numpy.dtype array-protocol type strings (e.g. 'i4', 'f8', 'S15')

      If no ``dtype`` value is provide then the type is inferred using
      ``np.array(data)``.

    - Provide ``length`` and optionally ``shape``, but not ``data``

      Examples::

        col = Column(name='name', length=5)
        col = Column(name='name', dtype=int, length=10, shape=(3,4))

      The default ``dtype`` is ``np.float64``.  The ``shape`` argument is the
      array shape of a single cell in the column.

    To access the ``Column`` data as a raw `numpy.ndarray` object, you can use
    one of the ``data`` or ``value`` attributes (which are equivalent)::

        col.data
        col.value
    Cannot convert a MaskedColumn with masked value to a Columncannot set mask value to a column in non-masked Table_convert_col_for_tablereplace_column_base_repr_descr_vals>
astropy.utils.xml.writerxml_escapeshow_lengthdata_lines_repr_html___bytes___check_string_truncate
        Emit a warning if any elements of ``value`` will be truncated when
        ``value`` is assigned to self.
        value_str_lenself_str_lentruncated right side string(s) longer than  character(s) during assignment"character(s) during assignment"characteradjust_indices
        Insert values before the given indices in the column and return
        a new `~astropy.table.Column` object.

        Parameters
        ----------
        obj : int, slice or sequence of int
            Object that defines the index or indices before which ``values`` is
            inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different from
            that of the column, ``values`` is converted to the matching type.
            ``values`` should be shaped so that it can be broadcast appropriately.
        axis : int, optional
            Axis along which to insert ``values``.  If ``axis`` is None then
            the column array is flattened before insertion.  Default is 0,
            which will insert a row.

        Returns
        -------
        out : `~astropy.table.Column`
            A copy of column with ``values`` and ``mask`` inserted.  Note that the
            insertion does not occur in-place: a new column is returned.
        Oself_for_insertMaskedColumnInfo
    Container for meta information like name, description, format.

    This is required when the object is used as a mixin column within a table,
    but can be used as a general way to store meta information.  In this case
    it just adds the ``mask_val`` attribute.
    serialize_methodnull_valuedata_maskhdf5parquet_serialize_contextserialize method must be either "data_mask" or "null_value"Define a masked data column for use in a Table object.

    Parameters
    ----------
    data : list, ndarray, or None
        Column data values
    name : str
        Column name and key for reference within Table
    mask : list, ndarray or None
        Boolean mask for which True indicates missing or invalid data
    fill_value : float, int, str, or None
        Value used when filling masked column elements
    dtype : `~numpy.dtype`-like
        Data type for column
    shape : tuple or ()
        Dimensions of a single row element in the column data
    length : int or 0
        Number of row elements in column data
    description : str or None
        Full description of column
    unit : str or None
        Physical unit
    format : str, None, or callable
        Format string for outputting column values.  This can be an
        "old-style" (``format % value``) or "new-style" (`str.format`)
        format specification string or a function or any callable object that
        accepts a single value and returns a string.
    meta : dict-like or None
        Meta-data associated with the column

    Examples
    --------
    A MaskedColumn is similar to a Column except that it includes ``mask`` and
    ``fill_value`` attributes.  It can be created in two different ways:

    - Provide a ``data`` value but not ``shape`` or ``length`` (which are
      inferred from the data).

      Examples::

        col = MaskedColumn(data=[1, 2], name='name')
        col = MaskedColumn(data=[1, 2], name='name', mask=[True, False])
        col = MaskedColumn(data=[1, 2], name='name', dtype=float, fill_value=99)

      The ``mask`` argument will be cast as a boolean array and specifies
      which elements are considered to be missing or invalid.

      The ``dtype`` argument can be any value which is an acceptable
      fixed-size data-type initializer for the numpy.dtype() method.  See
      `<https://numpy.org/doc/stable/reference/arrays.dtypes.html>`_.
      Examples include:

      - Python non-string type (float, int, bool)
      - Numpy non-string type (e.g. np.float32, np.int64, np.bool\_)
      - Numpy.dtype array-protocol type strings (e.g. 'i4', 'f8', 'S15')

      If no ``dtype`` value is provide then the type is inferred using
      ``np.array(data)``.  When ``data`` is provided then the ``shape``
      and ``length`` arguments are ignored.

    - Provide ``length`` and optionally ``shape``, but not ``data``

      Examples::

        col = MaskedColumn(name='name', length=5)
        col = MaskedColumn(name='name', dtype=int, length=10, shape=(3,4))

      The default ``dtype`` is ``np.float64``.  The ``shape`` argument is the
      array shape of a single cell in the column.

    To access the ``Column`` data as a raw `numpy.ma.MaskedArray` object, you can
    use one of the ``data`` or ``value`` attributes (which are equivalent)::

        col.data
        col.value
    data_fill_valuedefault_fill_valueget_fill_valueSet fill value both in the masked column view and in the parent table
        if it exists.  Setting one or the other alone doesn't work.
        _fill_valueset_fill_valueThe plain MaskedArray data held by this column._baseclassReturn a copy of self, with masked values filled with a given value.

        Parameters
        ----------
        fill_value : scalar; optional
            The value to use for invalid entries (`None` by default).  If
            `None`, the ``fill_value`` attribute of the array is used
            instead.

        Returns
        -------
        filled_column : Column
            A copy of ``self`` with masked entries replaced by `fill_value`
            (be it the function argument or the attribute of ``self``).
        column_cls
        Insert values along the given axis before the given indices and return
        a new `~astropy.table.MaskedColumn` object.

        Parameters
        ----------
        obj : int, slice or sequence of int
            Object that defines the index or indices before which ``values`` is
            inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different from
            that of the column, ``values`` is converted to the matching type.
            ``values`` should be shaped so that it can be broadcast appropriately.
        mask : bool or array-like
            Mask value(s) to insert.  If not supplied, and values does not have
            a mask either, then False is used.
        axis : int, optional
            Axis along which to insert ``values``.  If ``axis`` is None then
            the column array is flattened before insertion.  Default is 0,
            which will insert a row.

        Returns
        -------
        out : `~astropy.table.MaskedColumn`
            A copy of column with ``values`` and ``mask`` inserted.  Note that the
            insertion does not occur in-place: a new masked column is returned.
        self_manew_datanew_masknew_ma_basedict_optinfo_copy_attrs_slice# These "shims" provide __getitem__ implementations for Column and MaskedColumn# Create a generic TableFormatter object for use by bare columns with no# parent table.# Always emit this warning, not just the first instance# list of one and two-dimensional comparison functions, which sometimes return# a Column class and sometimes a plain array. Used in __array_wrap__ to ensure# they only return plain (masked) arrays (see #1446 and #1685)# If the column has info defined, we copy it and adjust any indices# to point to the copied column.  By guarding with the if statement,# we avoid side effects (of creating the default info instance).# Starting with numpy 2.0, np.char.str_len() propagates the mask for# masked data. We want masked values to be preserved so unmask# `values` prior to counting string lengths.# Find the length of the longest string in the new values.# Determine character repeat count of arr.dtype.  Returns a positive# int or None (something like 'U0' is not possible in numpy).  If new values# are longer than current then make a new (wider) version of arr.# Avoid repeated lookups of this object# Special case of an homogeneous list of MaskedArray elements (see #8977).# np.ma.masked is an instance of MaskedArray, so exclude those values.# First convert data to a plain ndarray. If there are instances of np.ma.masked# in the data this will issue a warning for int and float.# Ensure this warning from numpy is always enabled and that it is not# converted to an error (which can happen during pytest).# FutureWarning in numpy 1.21. See https://github.com/astropy/astropy/issues/11291# and https://github.com/numpy/numpy/issues/18425.# Catches case of dtype=int with masked values, instead let it# convert to float# Implies input was a scalar or an empty list (e.g. initializing an# empty table with pre-declared names and dtypes but no data).  Here we# need to fall through to initializing with the original data=[].# If there were no warnings and the data are int or float, then we are done.# Other dtypes like string or complex can have masked values and the# np.array() conversion gives the wrong answer (e.g. converting np.ma.masked# to the string "0.0").# Now we need to determine if there is an np.ma.masked anywhere in input data.# Make a statement like below to look for np.ma.masked in a nested sequence.# Because np.array(data) succeeded we know that `data` has a regular N-d# structure. Find ma_masked:#   any(any(any(d2 is ma_masked for d2 in d1) for d1 in d0) for d0 in data)# Using this eval avoids creating a copy of `data` in the more-usual case of# no masked elements.# If there are any masks then explicitly change each one to a fill value and# set a mask boolean array. If not has_masked then we're done.# Make type-appropriate fill value based on initial conversion.# Zero works for every numeric type.# If we see a bool and dtype not specified then assume bool for# the entire array. Not perfect but in most practical cases OK.# Unfortunately numpy types [False, 0] as int, not bool (and# [False, np.ma.masked] => array([0.0, np.nan])).# If no dtype is provided then need to convert back to list so np.array# does type autodetection.# Use np.array first to convert `data` to ndarray (fast) and then make# masked array from an ndarray with mask (fast) instead of from `data`.# copy enclosed ref to allow swap below# If other is a Quantity, we should let it do the work, since# it can deal with our possible unit (which, for MaskedColumn,# would get dropped below, as '.data' is accessed in super()).# If we are unicode and other is a column with bytes, defer to it for# doing the unicode sandwich.  This avoids problems like those# discussed in #6838 and #6899.# If we are bytes, encode other as needed.# Now just let the regular ndarray.__eq__, etc., take over.# But we should not return Column instances for this case.# For structured columns, data is used to store a dict of columns.# Store entries in that dict as name.key instead of name.data.key.# For a regular column, we are done, but for a structured# column, we use a SerializedColumns to store the pieces.# If this column has a StructuredUnit, we split it and store# it on the corresponding part. Otherwise, we just store it# as an attribute below.  All other attributes we remove from# the parts, so that we do not store them multiple times.# (Note that attributes are not linked to the parent, so it# is safe to reset them.)# TODO: deal with (some of) this in Column.__getitem__?# Alternatively: should we store info on the first part?# TODO: special-case format somehow? Can we have good formats# for structured columns?# No need to store as an attribute as well.# Create the attributes required to reconstruct the column.# Store the shape if needed. Just like scalar data, a structured data# column (e.g. with dtype `f8,i8`) can be multidimensional within each# row and have a shape, and that needs to be distinguished from the# case that each entry in the structure has the same shape (e.g.,# distinguist a column with dtype='f8,i8' and 2 elements per row from# one with dtype '2f8,2i8' and just one element per row).# Also store the standard info attributes since these are# stored on the parent and can thus just be passed on as# arguments.  TODO: factor out with essentially the same# code in serialize._represent_mixin_as_column.# Reconstruct a structured Column, by first making an empty column# and then filling it with the structured data.# There are three elements in the shape of `part`:# (table length, shape of structured column, shape of part like '3f8')# The column `shape` only includes the second, so by adding one to its# length to include the table length, we pick off a possible last bit.# Construct the empty column from `map` (note: 'data' removed above).# Fill it with the structured data.# When unpickling a MaskedColumn, ``data`` will be a bare# BaseColumn with none of the expected attributes.  In this case# do NOT execute this block which initializes from ``data``# If 'info' has been defined, copy basic properties (if needed).# Note: It seems there are some cases where _parent_table is not set,# such after restoring from a pickled Column.  Perhaps that should be# fixed, but this is also okay for now.# If there is meta on the original column then deepcopy (since "copy" of column# implies complete independence from original).  __array_finalize__ will have already# made a light copy.  I'm not sure how to avoid that initial light copy.# MetaData descriptor does a deepcopy here# for MaskedColumn, MaskedArray.__array_finalize__ also copies mask# from self, which is not the idea here, so undo# Get the Column attributes# Using super().__setstate__(state) gives# "TypeError 'int' object is not iterable", raised in# astropy.table._column_mixins._ColumnGetitemShim.__setstate_cython__()# Previously, it seems to have given an infinite recursion.# Hence, manually call the right super class to actually set up# the array object.# Set the Column attributes# Define Column-specific attrs and meta that gets added to state.# Obj will be none for direct call to Column() creator# Self was created from template (e.g. obj[slice] or (obj * 2))# or viewcast e.g. obj.view(Column).  In either case we want to# init Column attributes for self from obj if possible.# may have been copied in __new__# set new format string# test whether it formats without error exemplarily# revert to restore previous format if there was one# Iterate over formatted values with no max number of lines, no column# name, no unit, and ignoring the returned header info in outs.# For bytes type data, encode the `v` value as UTF-8 (if necessary) before# calling searchsorted. This prevents a factor of 1000 slowdown in# searchsorted in this case.# Strip off the BaseColumn-ness for repr and str so that# MaskedColumn.data __repr__ does not include masked_BaseColumn(data =# [1 2], ...).# the Quantity initializer is used here because it correctly fails# if the column's values are non-numeric (like strings), while .view# will happily return a quantity with gibberish for numerical values# Light copy of meta if it is not empty# Either no parent table or parent table is None# If scalar then just convert to correct numpy type and use numpy repr# Convert input ``value`` to the string dtype of this column and# find the length of the longest string in the array.# Parse the array-protocol typestring (e.g. '|U15') of self.dtype which# has the character repeat count on the right side.# Issue warning for string assignment that truncates ``value``# update indices# Set items using a view of the underlying data, as it gives an# order-of-magnitude speed-up. [#2994]# Even if values is array-like (e.g. [1,2,3]), insert as a single# object.  Numpy.insert instead inserts each element in an array-like# input individually.# We do this to make the methods show up in the API docs# Add `serialize_method` attribute to the attrs that MaskedColumnInfo knows# about.  This allows customization of the way that MaskedColumn objects# get written to file depending on format.  The default is to use whatever# the writer would normally do, which in the case of FITS or ECSV is to use# a NULL value within the data itself.  If serialize_method is 'data_mask'# then the mask is explicitly written out as a separate column if there# are any masked values.  See also code below.# When `serialize_method` is 'data_mask', and data and mask are being written# as separate columns, use column names <name> and <name>.mask (instead# of default encoding as <name>.data and <name>.mask).# If bound to a data object instance then create the dict of attributes# which stores the info attribute values.# Specify how to serialize this object depending on context.# If we are a structured masked column, then our parent class,# ColumnInfo, will already have set up a dict with masked parts,# which will be serialized later, so no further work needed here.# If the serialize method for this context (e.g. 'fits' or 'ecsv') is# 'data_mask', that means to serialize using an explicit mask column.# Note: a driver here is a performance issue in #8443 where repr() of a# np.ma.MaskedArray value is up to 10 times slower than repr of a normal array# value.  So regardless of whether there are masked elements it is useful to# explicitly define this as a serialized column and use col.data.data (ndarray)# instead of letting it fall through to the "standard" serialization machinery.# Only if there are actually masked elements do we add the ``mask`` column# If mask is None then we need to determine the mask (if any) from the data.# The naive method is looking for a mask attribute on data, but this can fail,# see #8816.  Instead use ``MaskedArray`` to do the work.# Handle odd-ball issue with np.ma.nomask (numpy #13758), and see below.# Force the creation of a full mask array as nomask is tricky to# use and will fail in an unexpected manner when setting a value# to the mask.# Create self using MaskedArray as a wrapper class, following the example of# class MSubArray in# https://github.com/numpy/numpy/blob/maintenance/1.8.x/numpy/ma/tests/test_subclassing.py# This pattern makes it so that __array_finalize__ is called as expected (e.g. #1471 and# https://github.com/astropy/astropy/commit/ff6039e8)# First just pass through all args and kwargs to BaseColumn, then wrap that object# with MaskedArray.# The above process preserves info relevant for Column, but this does# not include serialize_method (and possibly other future attributes)# relevant for MaskedColumn, so we set info explicitly.# Note: do not set fill_value in the MaskedArray constructor because this does not# go through the fill_value workarounds.# needs to be done here since self doesn't come from BaseColumn.__new__# defer to native ma.MaskedArray method# another ma bug workaround: If the value of fill_value for a string array is# requested but not yet set then it gets created as 'N/A'.  From this point onward# any new fill_values are truncated to 3 characters.  Note that this does not# occur if the masked array is a structured array (as in the previous block that# deals with the parent table).# >>> x = ma.array(['xxxx'])# >>> x.fill_value  # fill_value now gets represented as an 'S3' array# 'N/A'# >>> x.fill_value='yyyy'# >>> x.fill_value# 'yyy'# To handle this we are forced to reset a private variable first:# By default, a MaskedArray view will set the _baseclass to be the# same as that of our own class, i.e., BaseColumn.  Since we want# to return a plain MaskedArray, we reset the baseclass accordingly.# Use parent table definition of Column if available# self viewed as MaskedArray# This is a workaround to fix gh-9521# Fixes issue #3023: when calling getitem with a MaskedArray subclass# the original object attributes are not copied.# TODO: this part is essentially the same as what is done in# __array_finalize__ and could probably be called directly in our# override of __getitem__ in _columns_mixins.pyx). Refactor?# we need this because __getitem__ does a shallow copy of indices# Account for a bug in np.ma.MaskedArray setitem.# https://github.com/numpy/numpy/issues/8624# Check for string truncation after filling masked items with# empty (zero-length) string.  Note that filled() does not make# a copy if there are no masked items.b'
    Warning class for when a string column is assigned a value
    that gets truncated because the base (numpy) string length
    is too short.

    This does not inherit from AstropyWarning because we want to use
    stacklevel=2 to show the user where the issue occurred in their code.
    'u'
    Warning class for when a string column is assigned a value
    that gets truncated because the base (numpy) string length
    is too short.

    This does not inherit from AstropyWarning because we want to use
    stacklevel=2 to show the user where the issue occurred in their code.
    'b'
    Mixin-safe version of Column.copy() (with copy_data=True).

    Parameters
    ----------
    col : Column or mixin column
        Input column
    copy_indices : bool
        Copy the column ``indices`` attribute

    Returns
    -------
    col : Copy of input column
    'u'
    Mixin-safe version of Column.copy() (with copy_data=True).

    Parameters
    ----------
    col : Column or mixin column
        Input column
    copy_indices : bool
        Copy the column ``indices`` attribute

    Returns
    -------
    col : Copy of input column
    'b'
    Boolean mask array that is always False.

    This is used to create a stub ``mask`` property which is a boolean array of
    ``False`` used by default for mixin columns and corresponding to the mixin
    column data shape.  The ``mask`` looks like a normal numpy array but an
    exception will be raised if ``True`` is assigned to any element.  The
    consequences of the limitation are most obvious in the high-level table
    operations.

    Parameters
    ----------
    shape : tuple
        Data shape
    'u'
    Boolean mask array that is always False.

    This is used to create a stub ``mask`` property which is a boolean array of
    ``False`` used by default for mixin columns and corresponding to the mixin
    column data shape.  The ``mask`` looks like a normal numpy array but an
    exception will be raised if ``True`` is assigned to any element.  The
    consequences of the limitation are most obvious in the high-level table
    operations.

    Parameters
    ----------
    shape : tuple
        Data shape
    'b'Cannot set any element of 'u'Cannot set any element of 'b' class to True'u' class to True'b'
    For string-dtype return a version of ``arr`` that is wide enough for ``values``.
    If ``arr`` is not string-dtype or does not need expansion then return ``arr``.

    Parameters
    ----------
    arr : np.ndarray
        Input array
    values : scalar or array-like
        Values for width comparison for string arrays

    Returns
    -------
    arr_expanded : np.ndarray

    'u'
    For string-dtype return a version of ``arr`` that is wide enough for ``values``.
    If ``arr`` is not string-dtype or does not need expansion then return ``arr``.

    Parameters
    ----------
    arr : np.ndarray
        Input array
    values : scalar or array-like
        Values for width comparison for string arrays

    Returns
    -------
    arr_expanded : np.ndarray

    'b'Convert N-d sequence-like data to ndarray or MaskedArray.

    This is the core function for converting Python lists or list of lists to a
    numpy array. This handles embedded np.ma.masked constants in ``data`` along
    with the special case of an homogeneous list of MaskedArray elements.

    Considerations:

    - np.ma.array is about 50 times slower than np.array for list input. This
      function avoids using np.ma.array on list input.
    - np.array emits a UserWarning for embedded np.ma.masked, but only for int
      or float inputs. For those it converts to np.nan and forces float dtype.
      For other types np.array is inconsistent, for instance converting
      np.ma.masked to "0.0" for str types.
    - Searching in pure Python for np.ma.masked in ``data`` is comparable in
      speed to calling ``np.array(data)``.
    - This function may end up making two additional copies of input ``data``.

    Parameters
    ----------
    data : N-d sequence
        Input data, typically list or list of lists
    dtype : None or dtype-like
        Output datatype (None lets np.array choose)

    Returns
    -------
    np_data : np.ndarray or np.ma.MaskedArray

    'u'Convert N-d sequence-like data to ndarray or MaskedArray.

    This is the core function for converting Python lists or list of lists to a
    numpy array. This handles embedded np.ma.masked constants in ``data`` along
    with the special case of an homogeneous list of MaskedArray elements.

    Considerations:

    - np.ma.array is about 50 times slower than np.array for list input. This
      function avoids using np.ma.array on list input.
    - np.array emits a UserWarning for embedded np.ma.masked, but only for int
      or float inputs. For those it converts to np.nan and forces float dtype.
      For other types np.array is inconsistent, for instance converting
      np.ma.masked to "0.0" for str types.
    - Searching in pure Python for np.ma.masked in ``data`` is comparable in
      speed to calling ``np.array(data)``.
    - This function may end up making two additional copies of input ``data``.

    Parameters
    ----------
    data : N-d sequence
        Input data, typically list or list of lists
    dtype : None or dtype-like
        Output datatype (None lets np.array choose)

    Returns
    -------
    np_data : np.ndarray or np.ma.MaskedArray

    'b'__len__'u'__len__'b'.*converting a masked element.*'u'.*converting a masked element.*'b'.*Promotion of numbers and bools to strings.*'u'.*Promotion of numbers and bools to strings.*'b'd0 is ma_masked'u'd0 is ma_masked'b'any('u'any('b' for d0 in data)'u' for d0 in data)'b'any(d'u'any(d'b' is ma_masked for d'u' is ma_masked for d'b' in d'u' in d'b' for d'u' for d'b'ma_masked'u'ma_masked'b'
    Make Column comparison methods which encode the ``other`` object to utf-8
    in the case of a bytestring dtype for Py3+.

    Parameters
    ----------
    oper : str
        Operator name
    'u'
    Make Column comparison methods which encode the ``other`` object to utf-8
    in the case of a bytestring dtype for Py3+.

    Parameters
    ----------
    oper : str
        Operator name
    'b'
    Container for meta information like name, description, format.

    This is required when the object is used as a mixin column within a table,
    but can be used as a general way to store meta information.
    'u'
    Container for meta information like name, description, format.

    This is required when the object is used as a mixin column within a table,
    but can be used as a general way to store meta information.
    'b'groups'u'groups'b'
        Return a new Column instance which is consistent with the
        input ``cols`` and has ``length`` rows.

        This is intended for creating an empty column object whose elements can
        be set in-place for table operations like join or vstack.

        Parameters
        ----------
        cols : list
            List of input columns
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Column (or subclass)
            New instance of this class consistent with ``cols``

        'u'
        Return a new Column instance which is consistent with the
        input ``cols`` and has ``length`` rows.

        This is intended for creating an empty column object whose elements can
        be set in-place for table operations like join or vstack.

        Parameters
        ----------
        cols : list
            List of input columns
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Column (or subclass)
            New instance of this class consistent with ``cols``

        'b'
        Return a list of arrays which can be lexically sorted to represent
        the order of the parent column.

        For Column this is just the column itself.

        Returns
        -------
        arrays : list of ndarray
        'u'
        Return a list of arrays which can be lexically sorted to represent
        the order of the parent column.

        For Column this is just the column itself.

        Returns
        -------
        arrays : list of ndarray
        'b'_name'u'_name'b'indices'u'indices'b'
        An alias for the existing ``data`` attribute.
        'u'
        An alias for the existing ``data`` attribute.
        'b'_parent_table'u'_parent_table'b'
        Return a copy of the current instance.

        If ``data`` is supplied then a view (reference) of ``data`` is used,
        and ``copy_data`` is ignored.

        Parameters
        ----------
        order : {'C', 'F', 'A', 'K'}, optional
            Controls the memory layout of the copy. 'C' means C-order,
            'F' means F-order, 'A' means 'F' if ``a`` is Fortran contiguous,
            'C' otherwise. 'K' means match the layout of ``a`` as closely
            as possible. (Note that this function and :func:numpy.copy are very
            similar, but have different default values for their order=
            arguments.)  Default is 'C'.
        data : array, optional
            If supplied then use a view of ``data`` instead of the instance
            data.  This allows copying the instance attributes and meta.
        copy_data : bool, optional
            Make a copy of the internal numpy array instead of using a
            reference.  Default is True.

        Returns
        -------
        col : Column or MaskedColumn
            Copy of the current column (same type as original)
        'u'
        Return a copy of the current instance.

        If ``data`` is supplied then a view (reference) of ``data`` is used,
        and ``copy_data`` is ignored.

        Parameters
        ----------
        order : {'C', 'F', 'A', 'K'}, optional
            Controls the memory layout of the copy. 'C' means C-order,
            'F' means F-order, 'A' means 'F' if ``a`` is Fortran contiguous,
            'C' otherwise. 'K' means match the layout of ``a`` as closely
            as possible. (Note that this function and :func:numpy.copy are very
            similar, but have different default values for their order=
            arguments.)  Default is 'C'.
        data : array, optional
            If supplied then use a view of ``data`` instead of the instance
            data.  This allows copying the instance attributes and meta.
        copy_data : bool, optional
            Make a copy of the internal numpy array instead of using a
            reference.  Default is True.

        Returns
        -------
        col : Column or MaskedColumn
            Copy of the current column (same type as original)
        'b'
        Restore the internal state of the Column/MaskedColumn for pickling
        purposes.  This requires that the last element of ``state`` is a
        5-tuple that has Column-specific state values.
        'u'
        Restore the internal state of the Column/MaskedColumn for pickling
        purposes.  This requires that the last element of ``state`` is a
        5-tuple that has Column-specific state values.
        'b'_unit'u'_unit'b'_format'u'_format'b'
        Return a 3-tuple for pickling a Column.  Use the super-class
        functionality but then add in a 5-tuple of Column-specific values
        that get used in __setstate__.
        'u'
        Return a 3-tuple for pickling a Column.  Use the super-class
        functionality but then add in a 5-tuple of Column-specific values
        that get used in __setstate__.
        'b'__dict__'u'__dict__'b'
        __array_wrap__ is called at the end of every ufunc.

        Normally, we want a Column object back and do not have to do anything
        special. But there are two exceptions:

        1) If the output shape is different (e.g. for reduction ufuncs
           like sum() or mean()), a Column still linking to a parent_table
           makes little sense, so we return the output viewed as the
           column content (ndarray or MaskedArray).
           For this case, if numpy tells us to ``return_scalar`` (for numpy
           >= 2.0, otherwise assume to be true), we use "[()]" to ensure we
           convert a zero rank array to a scalar. (For some reason np.sum()
           returns a zero rank scalar array while np.mean() returns a scalar;
           So the [()] is needed for this case.)

        2) When the output is created by any function that returns a boolean
           we also want to consistently return an array rather than a column
           (see #1446 and #1685)
        'u'
        __array_wrap__ is called at the end of every ufunc.

        Normally, we want a Column object back and do not have to do anything
        special. But there are two exceptions:

        1) If the output shape is different (e.g. for reduction ufuncs
           like sum() or mean()), a Column still linking to a parent_table
           makes little sense, so we return the output viewed as the
           column content (ndarray or MaskedArray).
           For this case, if numpy tells us to ``return_scalar`` (for numpy
           >= 2.0, otherwise assume to be true), we use "[()]" to ensure we
           convert a zero rank array to a scalar. (For some reason np.sum()
           returns a zero rank scalar array while np.mean() returns a scalar;
           So the [()] is needed for this case.)

        2) When the output is created by any function that returns a boolean
           we also want to consistently return an array rather than a column
           (see #1446 and #1685)
        'b'
        The name of this column.
        'u'
        The name of this column.
        'b'Expected a str value, got 'u'Expected a str value, got 'b' with type 'u' with type 'b'
        Format string for displaying values in this column.
        'u'
        Format string for displaying values in this column.
        'b'Invalid format for column ''u'Invalid format for column ''b'': could not display values in this column using this format'u'': could not display values in this column using this format'b'Array-interface compliant full description of the column.

        This returns a 3-tuple (name, type, shape) that can always be
        used in a structured array dtype definition.
        'u'Array-interface compliant full description of the column.

        This returns a 3-tuple (name, type, shape) that can always be
        used in a structured array dtype definition.
        'b'
        Return an iterator that yields the string-formatted values of this
        column.

        Returns
        -------
        str_vals : iterator
            Column values formatted as strings
        'u'
        Return an iterator that yields the string-formatted values of this
        column.

        Returns
        -------
        str_vals : iterator
            Column values formatted as strings
        'b'Compare the column attributes of ``col`` to this object.

        The comparison attributes are: ``name``, ``unit``, ``dtype``,
        ``format``, ``description``, and ``meta``.

        Parameters
        ----------
        col : Column
            Comparison column

        Returns
        -------
        equal : bool
            True if all attributes are equal
        'u'Compare the column attributes of ``col`` to this object.

        The comparison attributes are: ``name``, ``unit``, ``dtype``,
        ``format``, ``description``, and ``meta``.

        Parameters
        ----------
        col : Column
            Comparison column

        Returns
        -------
        equal : bool
            True if all attributes are equal
        'b'Comparison `col` must be a Column or MaskedColumn object'u'Comparison `col` must be a Column or MaskedColumn object'b'dtype'u'dtype'b'Return a list of formatted string representation of column values.

        If ``max_lines=None`` is supplied then the height of the
        screen terminal is used to set ``max_lines``.  If the terminal
        height cannot be determined then the default will be
        determined using the ``astropy.conf.max_lines`` configuration
        item. If a negative value of ``max_lines`` is supplied then
        there is no line limit applied (default).

        Parameters
        ----------
        max_lines : int or None
            Maximum lines of output (header + data rows).
            -1 (default) implies no limit, ``None`` implies using the
            height of the current terminal.

        show_name : bool
            Include column name. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        show_dtype : bool
            Include column dtype. Default is False.

        html : bool
            Format the output as an HTML table. Default is False.

        Returns
        -------
        lines : list
            List of lines with header and formatted column values

        'u'Return a list of formatted string representation of column values.

        If ``max_lines=None`` is supplied then the height of the
        screen terminal is used to set ``max_lines``.  If the terminal
        height cannot be determined then the default will be
        determined using the ``astropy.conf.max_lines`` configuration
        item. If a negative value of ``max_lines`` is supplied then
        there is no line limit applied (default).

        Parameters
        ----------
        max_lines : int or None
            Maximum lines of output (header + data rows).
            -1 (default) implies no limit, ``None`` implies using the
            height of the current terminal.

        show_name : bool
            Include column name. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        show_dtype : bool
            Include column dtype. Default is False.

        html : bool
            Format the output as an HTML table. Default is False.

        Returns
        -------
        lines : list
            List of lines with header and formatted column values

        'b'Print a formatted string representation of column values.

        If ``max_lines=None`` (default) then the height of the
        screen terminal is used to set ``max_lines``.  If the terminal
        height cannot be determined then the default will be
        determined using the ``astropy.conf.max_lines`` configuration
        item. If a negative value of ``max_lines`` is supplied then
        there is no line limit applied.

        Parameters
        ----------
        max_lines : int
            Maximum number of values in output

        show_name : bool
            Include column name. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        show_dtype : bool
            Include column dtype. Default is True.
        'u'Print a formatted string representation of column values.

        If ``max_lines=None`` (default) then the height of the
        screen terminal is used to set ``max_lines``.  If the terminal
        height cannot be determined then the default will be
        determined using the ``astropy.conf.max_lines`` configuration
        item. If a negative value of ``max_lines`` is supplied then
        there is no line limit applied.

        Parameters
        ----------
        max_lines : int
            Maximum number of values in output

        show_name : bool
            Include column name. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        show_dtype : bool
            Include column dtype. Default is True.
        'b'n_header'u'n_header'b'Interactively browse column with a paging interface.

        Supported keys::

          f, <space> : forward one page
          b : back one page
          r : refresh same page
          n : next row
          p : previous row
          < : go to beginning
          > : go to end
          q : quit browsing
          h : print this help

        Parameters
        ----------
        max_lines : int
            Maximum number of lines in table output.

        show_name : bool
            Include a header row for column names. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        'u'Interactively browse column with a paging interface.

        Supported keys::

          f, <space> : forward one page
          b : back one page
          r : refresh same page
          n : next row
          p : previous row
          < : go to beginning
          > : go to end
          q : quit browsing
          h : print this help

        Parameters
        ----------
        max_lines : int
            Maximum number of lines in table output.

        show_name : bool
            Include a header row for column names. Default is True.

        show_unit : bool
            Include a header row for unit. Default is False.

        'b'
        The unit associated with this column.  May be a string or a
        `astropy.units.UnitBase` instance.

        Setting the ``unit`` property does not change the values of the
        data.  To perform a unit conversion, use ``convert_unit_to``.
        'u'
        The unit associated with this column.  May be a string or a
        `astropy.units.UnitBase` instance.

        Setting the ``unit`` property does not change the values of the
        data.  To perform a unit conversion, use ``convert_unit_to``.
        'b'silent'u'silent'b'utf-8'u'utf-8'b'
        Converts the values of the column in-place from the current
        unit to the given unit.

        To change the unit associated with this column without
        actually changing the data values, simply set the ``unit``
        property.

        Parameters
        ----------
        new_unit : str or `astropy.units.UnitBase` instance
            The unit to convert to.

        equivalencies : list of tuple
           A list of equivalence pairs to try if the unit are not
           directly convertible.  See :ref:`astropy:unit_equivalencies`.

        Raises
        ------
        astropy.units.UnitsError
            If units are inconsistent
        'u'
        Converts the values of the column in-place from the current
        unit to the given unit.

        To change the unit associated with this column without
        actually changing the data values, simply set the ``unit``
        property.

        Parameters
        ----------
        new_unit : str or `astropy.units.UnitBase` instance
            The unit to convert to.

        equivalencies : list of tuple
           A list of equivalence pairs to try if the unit are not
           directly convertible.  See :ref:`astropy:unit_equivalencies`.

        Raises
        ------
        astropy.units.UnitsError
            If units are inconsistent
        'b'No unit set on column'u'No unit set on column'b'_groups'u'_groups'b'
        Group this column by the specified ``keys``.

        This effectively splits the column into groups which correspond to
        unique values of the ``keys`` grouping object.  The output is a new
        `Column` or `MaskedColumn` which contains a copy of this column but
        sorted by row according to ``keys``.

        The ``keys`` input to ``group_by`` must be a numpy array with the
        same length as this column.

        Parameters
        ----------
        keys : numpy array
            Key grouping object

        Returns
        -------
        out : Column
            New column with groups attribute set accordingly
        'u'
        Group this column by the specified ``keys``.

        This effectively splits the column into groups which correspond to
        unique values of the ``keys`` grouping object.  The output is a new
        `Column` or `MaskedColumn` which contains a copy of this column but
        sorted by row according to ``keys``.

        The ``keys`` input to ``group_by`` must be a numpy array with the
        same length as this column.

        Parameters
        ----------
        keys : numpy array
            Key grouping object

        Returns
        -------
        out : Column
            New column with groups attribute set accordingly
        'b'
        Copy current groups into a copy of self ``out``.
        'u'
        Copy current groups into a copy of self ``out``.
        'b'
        A view of this table column as a `~astropy.units.Quantity` object with
        units given by the Column's `unit` parameter.
        'u'
        A view of this table column as a `~astropy.units.Quantity` object with
        units given by the Column's `unit` parameter.
        'b'
        Converts this table column to a `~astropy.units.Quantity` object with
        the requested units.

        Parameters
        ----------
        unit : unit-like
            The unit to convert to (i.e., a valid argument to the
            :meth:`astropy.units.Quantity.to` method).
        equivalencies : list of tuple
            Equivalencies to use for this conversion.  See
            :meth:`astropy.units.Quantity.to` for more details.

        Returns
        -------
        quantity : `~astropy.units.Quantity`
            A quantity object with the contents of this column in the units
            ``unit``.
        'u'
        Converts this table column to a `~astropy.units.Quantity` object with
        the requested units.

        Parameters
        ----------
        unit : unit-like
            The unit to convert to (i.e., a valid argument to the
            :meth:`astropy.units.Quantity.to` method).
        equivalencies : list of tuple
            Equivalencies to use for this conversion.  See
            :meth:`astropy.units.Quantity.to` for more details.

        Returns
        -------
        quantity : `~astropy.units.Quantity`
            A quantity object with the contents of this column in the units
            ``unit``.
        'b'
        Copy key column attributes from ``obj`` to self.
        'u'
        Copy key column attributes from ``obj`` to self.
        'b'
        Encode anything that is unicode-ish as utf-8.  This method is only
        called for Py3+.
        'u'
        Encode anything that is unicode-ish as utf-8.  This method is only
        called for Py3+.
        'b'Define a data column for use in a Table object.

    Parameters
    ----------
    data : list, ndarray, or None
        Column data values
    name : str
        Column name and key for reference within Table
    dtype : `~numpy.dtype`-like
        Data type for column
    shape : tuple or ()
        Dimensions of a single row element in the column data
    length : int or 0
        Number of row elements in column data
    description : str or None
        Full description of column
    unit : str or None
        Physical unit
    format : str, None, or callable
        Format string for outputting column values.  This can be an
        "old-style" (``format % value``) or "new-style" (`str.format`)
        format specification string or a function or any callable object that
        accepts a single value and returns a string.
    meta : dict-like or None
        Meta-data associated with the column

    Examples
    --------
    A Column can be created in two different ways:

    - Provide a ``data`` value but not ``shape`` or ``length`` (which are
      inferred from the data).

      Examples::

        col = Column(data=[1, 2], name='name')  # shape=(2,)
        col = Column(data=[[1, 2], [3, 4]], name='name')  # shape=(2, 2)
        col = Column(data=[1, 2], name='name', dtype=float)
        col = Column(data=np.array([1, 2]), name='name')
        col = Column(data=['hello', 'world'], name='name')

      The ``dtype`` argument can be any value which is an acceptable
      fixed-size data-type initializer for the numpy.dtype() method.  See
      `<https://numpy.org/doc/stable/reference/arrays.dtypes.html>`_.
      Examples include:

      - Python non-string type (float, int, bool)
      - Numpy non-string type (e.g. np.float32, np.int64, np.bool\_)
      - Numpy.dtype array-protocol type strings (e.g. 'i4', 'f8', 'S15')

      If no ``dtype`` value is provide then the type is inferred using
      ``np.array(data)``.

    - Provide ``length`` and optionally ``shape``, but not ``data``

      Examples::

        col = Column(name='name', length=5)
        col = Column(name='name', dtype=int, length=10, shape=(3,4))

      The default ``dtype`` is ``np.float64``.  The ``shape`` argument is the
      array shape of a single cell in the column.

    To access the ``Column`` data as a raw `numpy.ndarray` object, you can use
    one of the ``data`` or ``value`` attributes (which are equivalent)::

        col.data
        col.value
    'u'Define a data column for use in a Table object.

    Parameters
    ----------
    data : list, ndarray, or None
        Column data values
    name : str
        Column name and key for reference within Table
    dtype : `~numpy.dtype`-like
        Data type for column
    shape : tuple or ()
        Dimensions of a single row element in the column data
    length : int or 0
        Number of row elements in column data
    description : str or None
        Full description of column
    unit : str or None
        Physical unit
    format : str, None, or callable
        Format string for outputting column values.  This can be an
        "old-style" (``format % value``) or "new-style" (`str.format`)
        format specification string or a function or any callable object that
        accepts a single value and returns a string.
    meta : dict-like or None
        Meta-data associated with the column

    Examples
    --------
    A Column can be created in two different ways:

    - Provide a ``data`` value but not ``shape`` or ``length`` (which are
      inferred from the data).

      Examples::

        col = Column(data=[1, 2], name='name')  # shape=(2,)
        col = Column(data=[[1, 2], [3, 4]], name='name')  # shape=(2, 2)
        col = Column(data=[1, 2], name='name', dtype=float)
        col = Column(data=np.array([1, 2]), name='name')
        col = Column(data=['hello', 'world'], name='name')

      The ``dtype`` argument can be any value which is an acceptable
      fixed-size data-type initializer for the numpy.dtype() method.  See
      `<https://numpy.org/doc/stable/reference/arrays.dtypes.html>`_.
      Examples include:

      - Python non-string type (float, int, bool)
      - Numpy non-string type (e.g. np.float32, np.int64, np.bool\_)
      - Numpy.dtype array-protocol type strings (e.g. 'i4', 'f8', 'S15')

      If no ``dtype`` value is provide then the type is inferred using
      ``np.array(data)``.

    - Provide ``length`` and optionally ``shape``, but not ``data``

      Examples::

        col = Column(name='name', length=5)
        col = Column(name='name', dtype=int, length=10, shape=(3,4))

      The default ``dtype`` is ``np.float64``.  The ``shape`` argument is the
      array shape of a single cell in the column.

    To access the ``Column`` data as a raw `numpy.ndarray` object, you can use
    one of the ``data`` or ``value`` attributes (which are equivalent)::

        col.data
        col.value
    'b'Cannot convert a MaskedColumn with masked value to a Column'u'Cannot convert a MaskedColumn with masked value to a Column'b'cannot set mask value to a column in non-masked Table'u'cannot set mask value to a column in non-masked Table'b'length'u'length'b'>
'u'>
'b'
        Emit a warning if any elements of ``value`` will be truncated when
        ``value`` is assigned to self.
        'u'
        Emit a warning if any elements of ``value`` will be truncated when
        ``value`` is assigned to self.
        'b'truncated right side string(s) longer than 'u'truncated right side string(s) longer than 'b' character(s) during assignment'u' character(s) during assignment'b'__eq__'u'__eq__'b'__ne__'u'__ne__'b'__gt__'u'__gt__'b'__lt__'u'__lt__'b'__ge__'u'__ge__'b'__le__'u'__le__'b'
        Insert values before the given indices in the column and return
        a new `~astropy.table.Column` object.

        Parameters
        ----------
        obj : int, slice or sequence of int
            Object that defines the index or indices before which ``values`` is
            inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different from
            that of the column, ``values`` is converted to the matching type.
            ``values`` should be shaped so that it can be broadcast appropriately.
        axis : int, optional
            Axis along which to insert ``values``.  If ``axis`` is None then
            the column array is flattened before insertion.  Default is 0,
            which will insert a row.

        Returns
        -------
        out : `~astropy.table.Column`
            A copy of column with ``values`` and ``mask`` inserted.  Note that the
            insertion does not occur in-place: a new column is returned.
        'u'
        Insert values before the given indices in the column and return
        a new `~astropy.table.Column` object.

        Parameters
        ----------
        obj : int, slice or sequence of int
            Object that defines the index or indices before which ``values`` is
            inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different from
            that of the column, ``values`` is converted to the matching type.
            ``values`` should be shaped so that it can be broadcast appropriately.
        axis : int, optional
            Axis along which to insert ``values``.  If ``axis`` is None then
            the column array is flattened before insertion.  Default is 0,
            which will insert a row.

        Returns
        -------
        out : `~astropy.table.Column`
            A copy of column with ``values`` and ``mask`` inserted.  Note that the
            insertion does not occur in-place: a new column is returned.
        'b'O'u'O'b'
    Container for meta information like name, description, format.

    This is required when the object is used as a mixin column within a table,
    but can be used as a general way to store meta information.  In this case
    it just adds the ``mask_val`` attribute.
    'u'
    Container for meta information like name, description, format.

    This is required when the object is used as a mixin column within a table,
    but can be used as a general way to store meta information.  In this case
    it just adds the ``mask_val`` attribute.
    'b'serialize_method'u'serialize_method'b'null_value'u'null_value'b'ecsv'u'ecsv'b'data_mask'u'data_mask'b'hdf5'u'hdf5'b'parquet'u'parquet'b'serialize method must be either "data_mask" or "null_value"'u'serialize method must be either "data_mask" or "null_value"'b'Define a masked data column for use in a Table object.

    Parameters
    ----------
    data : list, ndarray, or None
        Column data values
    name : str
        Column name and key for reference within Table
    mask : list, ndarray or None
        Boolean mask for which True indicates missing or invalid data
    fill_value : float, int, str, or None
        Value used when filling masked column elements
    dtype : `~numpy.dtype`-like
        Data type for column
    shape : tuple or ()
        Dimensions of a single row element in the column data
    length : int or 0
        Number of row elements in column data
    description : str or None
        Full description of column
    unit : str or None
        Physical unit
    format : str, None, or callable
        Format string for outputting column values.  This can be an
        "old-style" (``format % value``) or "new-style" (`str.format`)
        format specification string or a function or any callable object that
        accepts a single value and returns a string.
    meta : dict-like or None
        Meta-data associated with the column

    Examples
    --------
    A MaskedColumn is similar to a Column except that it includes ``mask`` and
    ``fill_value`` attributes.  It can be created in two different ways:

    - Provide a ``data`` value but not ``shape`` or ``length`` (which are
      inferred from the data).

      Examples::

        col = MaskedColumn(data=[1, 2], name='name')
        col = MaskedColumn(data=[1, 2], name='name', mask=[True, False])
        col = MaskedColumn(data=[1, 2], name='name', dtype=float, fill_value=99)

      The ``mask`` argument will be cast as a boolean array and specifies
      which elements are considered to be missing or invalid.

      The ``dtype`` argument can be any value which is an acceptable
      fixed-size data-type initializer for the numpy.dtype() method.  See
      `<https://numpy.org/doc/stable/reference/arrays.dtypes.html>`_.
      Examples include:

      - Python non-string type (float, int, bool)
      - Numpy non-string type (e.g. np.float32, np.int64, np.bool\_)
      - Numpy.dtype array-protocol type strings (e.g. 'i4', 'f8', 'S15')

      If no ``dtype`` value is provide then the type is inferred using
      ``np.array(data)``.  When ``data`` is provided then the ``shape``
      and ``length`` arguments are ignored.

    - Provide ``length`` and optionally ``shape``, but not ``data``

      Examples::

        col = MaskedColumn(name='name', length=5)
        col = MaskedColumn(name='name', dtype=int, length=10, shape=(3,4))

      The default ``dtype`` is ``np.float64``.  The ``shape`` argument is the
      array shape of a single cell in the column.

    To access the ``Column`` data as a raw `numpy.ma.MaskedArray` object, you can
    use one of the ``data`` or ``value`` attributes (which are equivalent)::

        col.data
        col.value
    'u'Define a masked data column for use in a Table object.

    Parameters
    ----------
    data : list, ndarray, or None
        Column data values
    name : str
        Column name and key for reference within Table
    mask : list, ndarray or None
        Boolean mask for which True indicates missing or invalid data
    fill_value : float, int, str, or None
        Value used when filling masked column elements
    dtype : `~numpy.dtype`-like
        Data type for column
    shape : tuple or ()
        Dimensions of a single row element in the column data
    length : int or 0
        Number of row elements in column data
    description : str or None
        Full description of column
    unit : str or None
        Physical unit
    format : str, None, or callable
        Format string for outputting column values.  This can be an
        "old-style" (``format % value``) or "new-style" (`str.format`)
        format specification string or a function or any callable object that
        accepts a single value and returns a string.
    meta : dict-like or None
        Meta-data associated with the column

    Examples
    --------
    A MaskedColumn is similar to a Column except that it includes ``mask`` and
    ``fill_value`` attributes.  It can be created in two different ways:

    - Provide a ``data`` value but not ``shape`` or ``length`` (which are
      inferred from the data).

      Examples::

        col = MaskedColumn(data=[1, 2], name='name')
        col = MaskedColumn(data=[1, 2], name='name', mask=[True, False])
        col = MaskedColumn(data=[1, 2], name='name', dtype=float, fill_value=99)

      The ``mask`` argument will be cast as a boolean array and specifies
      which elements are considered to be missing or invalid.

      The ``dtype`` argument can be any value which is an acceptable
      fixed-size data-type initializer for the numpy.dtype() method.  See
      `<https://numpy.org/doc/stable/reference/arrays.dtypes.html>`_.
      Examples include:

      - Python non-string type (float, int, bool)
      - Numpy non-string type (e.g. np.float32, np.int64, np.bool\_)
      - Numpy.dtype array-protocol type strings (e.g. 'i4', 'f8', 'S15')

      If no ``dtype`` value is provide then the type is inferred using
      ``np.array(data)``.  When ``data`` is provided then the ``shape``
      and ``length`` arguments are ignored.

    - Provide ``length`` and optionally ``shape``, but not ``data``

      Examples::

        col = MaskedColumn(name='name', length=5)
        col = MaskedColumn(name='name', dtype=int, length=10, shape=(3,4))

      The default ``dtype`` is ``np.float64``.  The ``shape`` argument is the
      array shape of a single cell in the column.

    To access the ``Column`` data as a raw `numpy.ma.MaskedArray` object, you can
    use one of the ``data`` or ``value`` attributes (which are equivalent)::

        col.data
        col.value
    'b'fill_value'u'fill_value'b'Set fill value both in the masked column view and in the parent table
        if it exists.  Setting one or the other alone doesn't work.
        'u'Set fill value both in the masked column view and in the parent table
        if it exists.  Setting one or the other alone doesn't work.
        'b'The plain MaskedArray data held by this column.'u'The plain MaskedArray data held by this column.'b'Return a copy of self, with masked values filled with a given value.

        Parameters
        ----------
        fill_value : scalar; optional
            The value to use for invalid entries (`None` by default).  If
            `None`, the ``fill_value`` attribute of the array is used
            instead.

        Returns
        -------
        filled_column : Column
            A copy of ``self`` with masked entries replaced by `fill_value`
            (be it the function argument or the attribute of ``self``).
        'u'Return a copy of self, with masked values filled with a given value.

        Parameters
        ----------
        fill_value : scalar; optional
            The value to use for invalid entries (`None` by default).  If
            `None`, the ``fill_value`` attribute of the array is used
            instead.

        Returns
        -------
        filled_column : Column
            A copy of ``self`` with masked entries replaced by `fill_value`
            (be it the function argument or the attribute of ``self``).
        'b'
        Insert values along the given axis before the given indices and return
        a new `~astropy.table.MaskedColumn` object.

        Parameters
        ----------
        obj : int, slice or sequence of int
            Object that defines the index or indices before which ``values`` is
            inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different from
            that of the column, ``values`` is converted to the matching type.
            ``values`` should be shaped so that it can be broadcast appropriately.
        mask : bool or array-like
            Mask value(s) to insert.  If not supplied, and values does not have
            a mask either, then False is used.
        axis : int, optional
            Axis along which to insert ``values``.  If ``axis`` is None then
            the column array is flattened before insertion.  Default is 0,
            which will insert a row.

        Returns
        -------
        out : `~astropy.table.MaskedColumn`
            A copy of column with ``values`` and ``mask`` inserted.  Note that the
            insertion does not occur in-place: a new masked column is returned.
        'u'
        Insert values along the given axis before the given indices and return
        a new `~astropy.table.MaskedColumn` object.

        Parameters
        ----------
        obj : int, slice or sequence of int
            Object that defines the index or indices before which ``values`` is
            inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different from
            that of the column, ``values`` is converted to the matching type.
            ``values`` should be shaped so that it can be broadcast appropriately.
        mask : bool or array-like
            Mask value(s) to insert.  If not supplied, and values does not have
            a mask either, then False is used.
        axis : int, optional
            Axis along which to insert ``values``.  If ``axis`` is None then
            the column array is flattened before insertion.  Default is 0,
            which will insert a row.

        Returns
        -------
        out : `~astropy.table.MaskedColumn`
            A copy of column with ``values`` and ``mask`` inserted.  Note that the
            insertion does not occur in-place: a new masked column is returned.
        'u'astropy.table.column'u'table.column'OrderedDictpairwiseindentNotifierMixin_convert_arraycmpencode_asciiColDefsDelayedi1Lu1i8f4f8c8c16FITS2NUMPYNUMPY2FITSb1u4FORMATORDERFITSUPCONVERTERSASCII2NUMPYASCII2STRASCII_DEFAULT_WIDTHSTDISP_RE_DICT(?:(?P<formatc>[F])(?:(?P<width>[0-9]+)\.{1}(?P<precision>[0-9]+))+)|(?:(?P<formatc>[AL])(?P<width>[0-9]+)+)|(?:(?P<formatc>[IBOZ])(?:(?P<width>[0-9]+)(?:\.{0,1}(?P<precision>[0-9]+))?))|r"(?:(?P<formatc>[IBOZ])(?:(?P<width>[0-9]+)"r"(?:\.{0,1}(?P<precision>[0-9]+))?))|"(?:(?P<formatc>[EGD])(?:(?P<width>[0-9]+)\.(?P<precision>[0-9]+))+)(?:E{0,1}(?P<exponential>[0-9]+)?)|r"(?:(?P<formatc>[EGD])(?:(?P<width>[0-9]+)\."r"(?P<precision>[0-9]+))+)"r"(?:E{0,1}(?P<exponential>[0-9]+)?)|"(?:(?P<formatc>E[NS])(?:(?P<width>[0-9]+)\.{1}(?P<precision>[0-9]+))+)ENES{{:{width}d}}{{:{width}b}}{{:{width}o}}{{:{width}x}}{{:{width}.{precision}f}}{{:{width}.{precision}g}}TDISP_FMT_DICT{{:>{width}}}{{:{width}.{precision}e}}TUNITTNULLTSCALTZEROTDISPTBCOLTDIMTCTYPTCUNITCRPXTCRVLTCDLTTRPOSKEYWORD_NAMESbscalebzerodispcoord_unitcoord_ref_pointcoord_ref_valuecoord_inctime_ref_posKEYWORD_ATTRIBUTESThis is a list of the attributes that can be set on `Column` objects.KEYWORD_TO_ATTRIBUTEATTRIBUTE_TO_KEYWORD(?P<repeat>^[0-9]*)(?P<format>[LXBIJKAEDCMPQ])(?P<option>[!-~]*)TFORMAT_RE(?:(?P<format>[AIJ])(?P<width>[0-9]+)?)|(?:(?P<formatf>[FED])(?:(?P<widthf>[0-9]+)(?:\.(?P<precision>[0-9]+))?)?)r"(?:(?P<format>[AIJ])(?P<width>[0-9]+)?)|"r"(?:(?P<formatf>[FED])"r"(?:(?P<widthf>[0-9]+)(?:\."r"(?P<precision>[0-9]+))?)?)"TFORMAT_ASCII_RE[0-9a-zA-Z_]+TTYPE_RE
Regular expression for valid table column names.  See FITS Standard v3.0 section 7.2.2.
(?P<label>^T[A-Z]*)(?P<num>[1-9][0-9 ]*$)TDEF_RE\(\s*(?P<dims>(?:\d+\s*)(?:,\s*\d+\s*)*\s*)\)\s*TDIM_REASCIITNULLDEFAULT_ASCII_TNULLDelayed file-reading data.proxy_BaseColumnFormat
    Base class for binary table column formats (just called _ColumnFormat)
    and ASCII table column formats (_AsciiColumnFormat).
    canonical
        The Numpy dtype object created from the format's associated recformat.
        recformatfrom_column_formatCreates a column format object from another column format object
        regardless of their type.

        That is, this can convert a _ColumnFormat to an _AsciiColumnFormat
        or vice versa at least in cases where a direct translation is possible.
        from_recformat_ColumnFormat
    Represents a FITS binary table column format.

    This is an enhancement over using a normal string for the format, since the
    repeat count, format code, and option are available as separate attributes,
    and smart comparison is used.  For example 1J == J.
    _parse_tformatQ_FormatPfrom_tform_FormatQp_formatCreates a column format from a Numpy record dtype format._convert_formatReturns the equivalent Numpy record format string.
        Returns a 'canonical' string representation of this format.

        This is in the proper form of rTa where T is the single character data
        type code, a is the optional part, and r is the repeat.  If repeat == 1
        (the default) it is left out of this representation.
        _AsciiColumnFormatSimilar to _ColumnFormat but specifically for columns in ASCII tables.

    The formats of ASCII table columns and binary table columns are inherently
    incompatible in FITS.  They don't support the same ranges and types of
    values, and even reuse format codes in subtly different ways.  For example
    the format code 'Iw' in ASCII columns refers to any integer whose string
    representation is at most w characters wide, so 'I' can represent
    effectively any integer that will fit in a FITS columns.  Whereas for
    binary tables 'I' very explicitly refers to a 16-bit signed integer.

    Conversions between the two column formats can be performed using the
    ``to/from_binary`` methods on this class, or the ``to/from_ascii``
    methods on the `_ColumnFormat` class.  But again, not all conversions are
    possible and may result in a `ValueError`.
    _parse_ascii_tformatprecision_pseudo_logical_convert_ascii_format
        Returns a 'canonical' string representation of this format.

        This is in the proper form of Tw.d where T is the single character data
        type code, w is the width in characters for this field, and d is the
        number of digits after the decimal place (for format codes 'E', 'F',
        and 'D' only).
        _FormatXFor X format in binary tables.For P format in variable length table.(?P<repeat>\d+)?{}(?P<dtype>[LXBIJKAEDCM])(?:\((?P<max>\d*)\))?_format_re_template_format_code_format_re2i4_descriptor_formatInvalid column format: array_dtypeCarries type description of the Q format for variable length arrays.

    The Q format is like the P format but uses 64-bit integers in the array
    descriptors, allowing for heaps stored beyond 2GB into a file.
    2i8ColumnAttribute
    Descriptor for attributes of `Column` that are associated with keywords
    in the FITS header and describe properties of the column as specified in
    the FITS standard.

    Each `ColumnAttribute` may have a ``validator`` method defined on it.
    This validates values set on this attribute to ensure that they meet the
    FITS standard.  Invalid values will raise a warning and will not be used in
    formatting the column.  The validator should take two arguments--the
    `Column` it is being assigned to, and the new value for the attribute, and
    it must raise an `AssertionError` if the value is invalid.

    The `ColumnAttribute` itself is a decorator that can be used to define the
    ``validator`` for each column attribute.  For example::

        @ColumnAttribute('TTYPE')
        def name(col, name):
            if not isinstance(name, str):
                raise AssertionError

    The actual object returned by this decorator is the `ColumnAttribute`
    instance though, not the ``name`` function.  As such ``name`` is not a
    method of the class it is defined in.

    The setter for `ColumnAttribute` also updates the header of any table
    HDU this column is attached to in order to reflect the change.  The
    ``validator`` should ensure that the value is valid for inclusion in a FITS
    header.
    _validatorobjtypeold_value_notifycolumn_attribute_changed
        Set the validator for this column attribute.

        Returns ``self`` so that this can be used as a decorator, as described
        in the docs for this class.
        ('')
    Class which contains the definition of one column, e.g.  ``ttype``,
    ``tform``, etc. and the array containing values for the column.
    
        Construct a `Column` by specifying attributes.  All attributes
        except ``format`` can be optional; see :ref:`astropy:column_creation`
        and :ref:`astropy:creating_ascii_table` for more information regarding
        ``TFORM`` keyword.

        Parameters
        ----------
        name : str, optional
            column name, corresponding to ``TTYPE`` keyword

        format : str
            column format, corresponding to ``TFORM`` keyword

        unit : str, optional
            column unit, corresponding to ``TUNIT`` keyword

        null : str, optional
            null value, corresponding to ``TNULL`` keyword

        bscale : int-like, optional
            bscale value, corresponding to ``TSCAL`` keyword

        bzero : int-like, optional
            bzero value, corresponding to ``TZERO`` keyword

        disp : str, optional
            display format, corresponding to ``TDISP`` keyword

        start : int, optional
            column starting position (ASCII table only), corresponding
            to ``TBCOL`` keyword

        dim : str, optional
            column dimension corresponding to ``TDIM`` keyword

        array : iterable, optional
            a `list`, `numpy.ndarray` (or other iterable that can be used to
            initialize an ndarray) providing initial data for this column.
            The array will be automatically converted, if possible, to the data
            format of the column.  In the case were non-trivial ``bscale``
            and/or ``bzero`` arguments are given, the values in the array must
            be the *physical* values--that is, the values of column as if the
            scaling has already been applied (the array stored on the column
            object will then be converted back to its storage values).

        ascii : bool, optional
            set `True` if this describes a column for an ASCII table; this
            may be required to disambiguate the column format

        coord_type : str, optional
            coordinate/axis type corresponding to ``TCTYP`` keyword

        coord_unit : str, optional
            coordinate/axis unit corresponding to ``TCUNI`` keyword

        coord_ref_point : int-like, optional
            pixel coordinate of the reference point corresponding to ``TCRPX``
            keyword

        coord_ref_value : int-like, optional
            coordinate value at reference point corresponding to ``TCRVL``
            keyword

        coord_inc : int-like, optional
            coordinate increment at reference point corresponding to ``TCDLT``
            keyword

        time_ref_pos : str, optional
            reference position for a time coordinate column corresponding to
            ``TRPOS`` keyword
        Must specify format to construct Column._verify_keywordsvalid_kwargsinvalid_kwargsThe following keyword arguments to Column were invalid:_dims_pseudo_unsigned_ints_VLFData is inconsistent with the format `_convert_to_valid_data_type_physical_values_parent_fits_rec; 
        Two columns are equal if their name and format are the same.  Other
        attributes aren't taken into account at this time.
        
        Like __eq__, the hash of a column should be based on the unique column
        name and format, and be case-insensitive with respect to the column
        name.
        
        The Numpy `~numpy.ndarray` associated with this `Column`.

        If the column was instantiated with an array passed to the ``array``
        argument, this will return that array.  However, if the column is
        later added to a table, such as via `BinTableHDU.from_columns` as
        is typically the case, this attribute will be updated to reference
        the associated field in the table, which may no longer be the same
        array.
        It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got "It is strongly recommended that column names contain only ""upper and lower-case ASCII letters, digits, or underscores ""for maximum compatibility with other software ""(got "Column name must be a string able to fit in a single FITS card--typically this means a maximum of 68 characters, though it may be fewer if the string contains special characters like quotes."Column name must be a string able to fit in a single ""FITS card--typically this means a maximum of 68 ""characters, though it may be fewer if the string ""contains special characters like quotes."Coordinate/axis type must be a string of at most 8 characters.Coordinate/axis unit must be a string.RealPixel coordinate of the reference point must be real floating type.Coordinate value at reference point must be real floating type.Coordinate increment must be real floating type.Time reference position must be a string.Whether this `Column` represents a column in an ASCII table.
        Return a copy of this `Column`.
        The format argument to this class's initializer may come in many
        forms.  This uses the given column format class ``cls`` to convert
        to a format of that type.

        TODO: There should be an abc base class for column format classes
        Illegal format `
        Given the keyword arguments used to initialize a Column, specifically
        those that typically read from a FITS header (so excluding array),
        verify that each keyword has a valid value.

        Returns a 2-tuple of dicts.  The first maps valid keywords to their
        values.  The second maps invalid keywords to a 2-tuple of their value,
        and a message explaining why they were found invalid.
        _determine_formatsColumn format option (TFORMn) failed verification:  The invalid value will be ignored for the purpose of formatting the data in this column."The invalid value will be ignored for the purpose of ""formatting the data in this column."Column format option (TFORMn) must be a string with a valid FITS table format (got "Column format option (TFORMn) must be a string with a valid ""FITS table format (got "). The invalid value will be ignored for the purpose of formatting the data in this column."). "ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got "ASCII table null option (TNULLn) is longer than ""the column's character width and will be truncated "tnull_formatsColumn null option (TNULLn) must be an integer for binary table columns (got "Column null option (TNULLn) must be an integer for ""binary table columns (got ").  The invalid value will be ignored for the purpose of formatting the data in this column.").  The invalid value ""will be ignored for the purpose of formatting ""the data in this column."Column null option (TNULLn) is invalid for binary table columns of type "Column null option (TNULLn) is invalid for binary ""table columns of type " (got ").  "Column disp option (TDISPn) must be a string (got "Column disp option (TDISPn) must be a string (got ""). The invalid value will be ignored for the ""purpose of formatting the data in this column."Column disp option (TDISPn) may not use the 'L' format with ASCII table columns.  The invalid value will be ignored for the purpose of formatting the data in this column."Column disp option (TDISPn) may not use the 'L' format ""with ASCII table columns.  The invalid value will be ""ignored for the purpose of formatting the data in this ""column."_parse_tdisp_formatColumn disp option (TDISPn) failed verification: "Column disp option (TDISPn) failed verification: "" The invalid value will be ignored for the "Column start option (TBCOLn) is not allowed for binary table columns (got "Column start option (TBCOLn) is not allowed for binary ""table columns (got ").  The invalid keyword will be ignored for the purpose of formatting the data in this column.").  The invalid keyword will be "Column start option (TBCOLn) must be a positive integer (got "Column start option (TBCOLn) must be a positive integer "").  The invalid value will be ignored for the "dims_tupleColumn dim option (TDIMn) is not allowed for ASCII table columns (got "Column dim option (TDIMn) is not allowed for ASCII table ""columns (got ").  The invalid keyword will be ignored for the purpose of formatting this column.").  The invalid keyword will be ignored ""for the purpose of formatting this column."_parse_tdim`dim` argument must be a string containing a valid value for the TDIMn header keyword associated with this column, or a tuple containing the C-order dimensions for the column.  The invalid value will be ignored for the purpose of formatting this column."`dim` argument must be a string containing a valid value ""for the TDIMn header keyword associated with this column, ""or a tuple containing the C-order dimensions for the ""column.  The invalid value will be ignored for the purpose ""of formatting this column."The repeat count of the column format  for column " for column " is fewer than the number of elements per the TDIM argument " is fewer than the number of elements per the TDIM ""argument ".  The invalid TDIMn value will be ignored for the purpose of formatting this column.".  The invalid TDIMn value will be ignored "Coordinate/axis type option (TCTYPn) must be a string (got "Coordinate/axis type option (TCTYPn) must be a string "). The invalid keyword will be ignored for the purpose of formatting this column."). The invalid keyword will be ignored "Coordinate/axis type option (TCTYPn) must be a string of at most 8 characters (got "of at most 8 characters (got ""). The invalid ""keyword will be ignored for the purpose of formatting this column."Coordinate/axis unit option (TCUNIn) must be a string (got "Coordinate/axis unit option (TCUNIn) must be a string "Column  option (n) must be a real floating type (got "n) must be a ""real floating type (got ""). The invalid value will be ""ignored for the purpose of formatting the data in this column."Time coordinate reference position option (TRPOSn) must be a string (got "Time coordinate reference position option (TRPOSn) must be ""a string (got ""). The invalid keyword will be ""ignored for the purpose of formatting this column."
        Given a format string and whether or not the Column is for an
        ASCII table (ascii=None means unspecified, but lean toward binary table
        where ambiguous) create an appropriate _BaseColumnFormat instance for
        the column's format, and determine the appropriate recarray format.

        The values of the start and dim keyword arguments are also useful, as
        the former is only valid for ASCII tables and the latter only for
        BINARY tables.
        _dtype_to_recformat_guess_formatColumns cannot have both a start (TCOLn) and dim (TDIMn) option, since the former is only applies to ASCII tables, and the latter is only valid for binary tables."Columns cannot have both a start (TCOLn) and dim ""(TDIMn) option, since the former is only applies to ""ASCII tables, and the latter is only valid for binary tables."guess_formatdimsPQSUfsizeFalse_numpy_formatbzeros
    Column definitions class.

    It has attributes corresponding to the `Column` attributes
    (e.g. `ColDefs` has the attribute ``names`` while `Column`
    has ``name``). Each attribute in `ColDefs` is a list of
    corresponding attribute values from all `Column` objects.
    _col_format_cls_columns_type_AsciiColDefs_arrays
        Parameters
        ----------
        input : sequence of `Column` or `ColDefs` or ndarray or `~numpy.recarray`
            An existing table HDU, an existing `ColDefs`, or any multi-field
            Numpy array or `numpy.recarray`.

        ascii : bool
            Use True to ensure that ASCII table columns are used.

        hdu.table_TableBaseHDU_init_from_coldefsfields_init_from_array_init_from_sequence_init_from_tableInput to ColDefs must be a table HDU, a list of Columns, or a record/field array."Input to ColDefs must be a table HDU, a list ""of Columns, or a record/field array."_add_listenercoldefsInitialize from an existing ColDefs object (just copy the
        columns and convert their formats if necessary).
        _copy_columnElement  in the ColDefs input is not a Column.Input data with shape  is not a valid representation of a row-oriented table. Expected a 1D array with rows as elements." is not a valid representation ""of a row-oriented table. Expected a 1D array with rows as elements."cnameftypedtypesColumn '' contains unsupported object types or mixed types: "' contains unsupported object types or ""mixed types: "findall[0-9]+subdtypedimelnfieldscol_keywordsnumInvalid keyword for column __copy____deepcopy__memoUtility function used currently only by _init_from_coldefs
        to help convert columns from binary format to ASCII format or vice
        versa if necessary (otherwise performs a straight copy).
        new_column
        Automatically returns the values for the given keyword attribute for
        all `Column`s in this list.

        Implements for example self.units, self.formats, etc.
        offsetsformat__recformatsReturns the values of the TDIMn keywords parsed into tuples.ColDefs(
    Wrong type of input._other_update_column_attribute_changednew_value
        Handle column attribute changed notifications from columns that are
        members of this `ColDefs`.

        `ColDefs` itself does not currently do anything with this, and just
        bubbles the notification up to any listening table HDUs that may need
        to update their headers, etc.  However, this also informs the table of
        the numerical index of the column that changed.
        add_col
        Append one `Column` to the column definition.
        load_datacolumn_addeddel_colcol_name
        Delete (the definition of) one `Column`.

        col_name : str or int
            The column's name or index
        _remove_listenercolumn_removedchange_attribattrib
        Change an attribute (in the ``KEYWORD_ATTRIBUTES`` list) of a `Column`.

        Parameters
        ----------
        col_name : str or int
            The column name or index to change

        attrib : str
            The attribute name

        new_value : object
            The new value for the attribute
        change_namenew_name
        Change a `Column`'s name.

        Parameters
        ----------
        col_name : str
            The current name of the column

        new_name : str
            The new name of the column
        New name  already exists.change_unit
        Change a `Column`'s unit.

        Parameters
        ----------
        col_name : str or int
            The column name or index

        new_unit : str
            The new unit for the column
        
        Get attribute(s) information of the column definition.

        Parameters
        ----------
        attrib : str
            Can be one or more of the attributes listed in
            ``astropy.io.fits.column.KEYWORD_ATTRIBUTES``.  The default is
            ``"all"`` which will print out all attributes.  It forgives plurals
            and blanks.  If there are two or more attribute names, they must be
            separated by comma(s).

        output : file-like, optional
            File-like object to output to.  Outputs to stdout by default.
            If `False`, returns the attributes as a `dict` instead.

        Notes
        -----
        This function doesn't return anything by default; it just prints to
        stdout.
        ret' is not an attribute of the column definitions.
:
ColDefs implementation for ASCII tables._update_field_metricsstartsspans_spans_widthdata_typeA list of the widths of each field in the table.widths
        Updates the list of the start columns, the list of the widths of each
        field, and the total width of each record in the table.
        end_colVariable length field object.
        Parameters
        ----------
        input
            a sequence of variable-sized elements.
        Inconsistent input data array: element_dtype
        To make sure the new item has consistent data type to avoid
        misalignment.
        nelemlen_value
    Get the index of the ``key`` in the ``names`` list.

    The ``key`` can be an integer or string.  If integer, it is the index
    in the list.  If string,

        a. Field (column) names are case sensitive: you can have two
           different columns called 'abc' and 'ABC' respectively.

        b. When you *refer* to a field (presumably with the field
           method), it will try to match the exact name first, so in
           the example in (a), field('abc') will get the first field,
           and field('ABC') will get the second field.

        If there is no exact name matched, it will try to match the
        name with case insensitivity.  So, in the last example,
        field('Abc') will cause an exception since there is no unique
        mapping.  If there is a field named "XYZ" and no other field
        name is a case variant of "XYZ", then field('xyz'),
        field('Xyz'), etc. will get this field.
    Illegal key '_keyKey '' does not exist.Ambiguous key name '_unwrapx
    Unwrap the X format column into a Boolean array.

    Parameters
    ----------
    input
        input ``Uint8`` array of shape (`s`, `nbytes`)

    output
        output Boolean array of shape (`s`, `repeat`)

    repeat
        number of bits
    pow2_min_max_wrapx
    Wrap the X format column Boolean array into an ``UInt8`` array.

    Parameters
    ----------
    input
        input Boolean array of shape (`s`, `repeat`)

    output
        output ``Uint8`` array of shape (`s`, `nbytes`)

    repeat
        number of bits
    unusedleft_shift_makepdescr_outputnrows
    Construct the P (or Q) format column array, both the data descriptors and
    the data.  It returns the output "data" array of data type `dtype`.

    The descriptor location will have a zero offset for all columns
    after this call.  The final offset will be calculated when the file
    is written.

    Parameters
    ----------
    array
        input object array

    descr_output
        output "descriptor" array of data type int32 (for P format arrays) or
        int64 (for Q format arrays)--must be nrows long in its first dimension

    format
        the _FormatP object representing the format of the variable array

    nrows : int, optional
        number of rows to create in the column; defaults to the number of rows
        in the input array
    _offsetdata_output_nbytesrowvalThe heapsize limit for 'P' format has been reached. Please consider using the 'Q' format for your file."The heapsize limit for 'P' format has been reached. ""Please consider using the 'Q' format for your file."Parse ``TFORMn`` keyword for a binary table into a
    ``(repeat, format, option)`` tuple.
    Format  is not recognized.
    Parse the ``TFORMn`` keywords for ASCII tables into a ``(format, width,
    precision)`` tuple (the latter is always zero unless format is one of 'E',
    'F', or 'D').
    formatfwidthfFormat {!r} is not unambiguously an ASCII table format.convert_intFormat {!r} is not valid--field width and decimal precision must be integers."Format {!r} is not valid--field width and decimal precision ""must be integers." not valid--field width must be a positive integeter. not valid--the number of decimal digits must be less than the format's total width " not valid--the number of decimal digits ""must be less than the format's total width "tdimParse the ``TDIM`` value into a tuple (may return an empty tuple if
    the value ``TDIM`` value is empty or invalid).
    _scalar_to_format
    Given a scalar value or string, returns the minimum FITS column format
    that can represent that value.  'minimum' is defined by the order given in
    FORMATORDER.
    type_min_scalar_typenumpy_dtype_strfits_format_cmp_recformats
    Compares two numpy recformats using the ordering given by FORMATORDER.
    _convert_fits2record
    Convert FITS format spec to record format spec.
    output_formatrepeat_str_convert_record2fits
    Convert record format spec to FITS format spec.
    ndimsnelntot
    Utility function for converting a dtype object or string that instantiates
    a dtype (e.g. 'float32') into one of the two character Numpy format codes
    that have been traditionally used by Astropy.
    
    Convert FITS format spec to record format spec.  Do the opposite if
    reverse=True.
    Convert ASCII table format spec to record format spec.A1tdisp
    Parse the ``TDISPn`` keywords for ASCII and binary tables into a
    ``(format, width, precision, exponential)`` tuple (the TDISP values
    for ASCII and binary are identical except for 'Lw',
    which is only present in BINTABLE extensions.

    Parameters
    ----------
    tdisp : str
        TDISPn FITS Header keyword.  Used to specify display formatting.

    Returns
    -------
    formatc: str
        The format characters from TDISPn
    width: str
        The width int value from TDISPn
    precision: str
        The precision int value from TDISPn
    exponential: str
        The exponential int value from TDISPn

    NSfmt_keytdisp_reformatcexponential_fortran_to_python_format
    Turn the TDISPn fortran format pieces into a final Python format string.
    See the format_type definitions above the TDISP_FMT_DICT. If codes is
    changed to take advantage of the exponential specification, will need to
    add it as another input parameter.

    Parameters
    ----------
    tdisp : str
        TDISPn FITS Header keyword.  Used to specify display formatting.

    Returns
    -------
    format_string: str
        The TDISPn keyword string translated into a Python format string.
    format_typepython_to_tdisplogical_dtype
    Turn the Python format string to a TDISP FITS compliant format string. Not
    all formats convert. these will cause a Warning and return None.

    Parameters
    ----------
    format_string : str
        TDISPn FITS Header keyword.  Used to specify display formatting.
    logical_dtype : bool
        True is this format type should be a logical type, 'L'. Needs special
        handling.

    Returns
    -------
    tdsip_string: str
        The TDISPn keyword string translated into a Python format string.
    fmt_to_tdisp{{:}fmt_strsep cannot be mapped to the accepted TDISPn keyword values.  Format will not be moved into TDISPn keyword." cannot be mapped to the accepted TDISPn ""keyword values.  Format will not be moved into TDISPn keyword."# mapping from TFORM data type to numpy data type (code)# L: Logical (Boolean)# B: Unsigned Byte# I: 16-bit Integer# J: 32-bit Integer# K: 64-bit Integer# E: Single-precision Floating Point# D: Double-precision Floating Point# C: Single-precision Complex# M: Double-precision Complex# A: Character# the inverse dictionary of the above# Normally booleans are represented as ints in Astropy, but if passed in a numpy# boolean array, that should be supported# Add unsigned types, which will be stored as signed ints with a TZERO card.# Add half precision floating point numbers which will be up-converted to# single precision.# This is the order in which values are converted to FITS types# Note that only double precision floating point/complex are supported# Convert single precision floating point/complex to double precision.# mapping from ASCII table TFORM data type to numpy data type# I: Integer (32-bit)# J: Integer (64-bit; non-standard)# F: Float (64-bit; fixed decimal notation)# E: Float (64-bit; exponential notation)# D: Float (64-bit; exponential notation, always 64-bit by convention)# Maps FITS ASCII column format codes to the appropriate Python string# formatting codes for that type.# For each ASCII table format code, provides a default width (and decimal# precision) for when one isn't given explicitly in the column format# TDISPn for both ASCII and Binary tables# mapping from TDISP format to python format#    Can't predefine zero padding and space padding before hand without#    knowing the value being formatted, so grabbing precision and using that#    to zero pad, ignoring width. Same with B, O, and Z# B: Binary Integer# O: Octal Integer# Z: Hexadecimal Integer# EN: Float (engineering fortran format, exponential multiple of thee# ES: Float (scientific, same as EN but non-zero leading digit# E: Float, exponential notation#    Can't get exponential restriction to work without knowing value#    before hand, so just using width and precision, same with D, G, EN, and#    ES formats# D: Double-precision Floating Point with exponential#    (E but for double precision)# G: Double-precision Floating Point, may or may not show exponent# tuple of column/field definition common names and keyword names, make# sure to preserve the one-to-one correspondence when updating the list(s).# Use lists, instead of dictionaries so the names can be displayed in a# preferred order.# TODO: Define a list of default comments to associate with each table keyword# TFORMn regular expression# TFORMn for ASCII tables; two different versions depending on whether# the format is floating-point or not; allows empty values for width# in which case defaults are used# table definition keyword regular expression# table dimension keyword regular expression (fairly flexible with whitespace)# value for ASCII table cell with value = TNULL# this can be reset by user.# The default placeholder to use for NULL values in ASCII tables when# converting from binary to ASCII tables# This forces the data for the HDU to be read, which will replace# the corresponding Delayed objects in the Tables Columns to be# transformed into ndarrays.  It will also return the value of the# requested data element.# TODO: There should be a generic factory that returns either# _FormatP or _FormatQ as appropriate for a given TFORMn# Format of variable length arrays# If no width has been specified, set the dtype here to default as well# This is to support handling logical (boolean) data from binary tables# in an ASCII table# Hack# use an array, even if it is only ONE u1 (i.e. use tuple always)# TODO: Table column formats need to be verified upon first reading the file;# as it is, an invalid P format will raise a VerifyError from some deep,# unexpected place# As far as I can tell from my reading of the FITS standard, a type code is# *required* for P and Q formats; there is no default# The name of the attribute associated with this keyword is currently# determined from the KEYWORD_NAMES/ATTRIBUTES lists.  This could be# make more flexible in the future, for example, to support custom# column attributes.# any of the input argument (except array) can be a Card or just# a number/string# get the argument's value# TODO: Try to eliminate the following two special cases# for recformat and dim:# This is not actually stored as an attribute on columns for some# reason# The 'dim' keyword's original value is stored in self.dim, while# *only* the tuple form is stored in self._dims.# Awful hack to use for now to keep track of whether the column holds# pseudo-unsigned int data# if the column data is not ndarray, make it to be one, i.e.# input arrays can be just list or tuple, not required to be ndarray# does not include Object array because there is no guarantee# the elements in the object array are consistent.# try to convert to a ndarray first# then try to convert it to a strings array# then try variable length array# Note: This includes _FormatQ by inheritance# We have required (through documentation) that arrays passed in to# this constructor are already in their physical values, so we make# note of that here# According to the FITS standard column names must be case-insensitive# Ideally the .array attribute never would have existed in the first# place, or would have been internal-only.  This is a legacy of the# older design from Astropy that needs to have continued support, for# now.# One of the main problems with this design was that it created a# reference cycle.  When the .array attribute was updated after# creating a FITS_rec from the column (as explained in the docstring) a# reference cycle was created.  This is because the code in BinTableHDU# (and a few other places) does essentially the following:# data._coldefs = columns  # The ColDefs object holding this Column# for col in columns:#     col.array = data.field(col.name)# This way each columns .array attribute now points to the field in the# table data.  It's actually a pretty confusing interface (since it# replaces the array originally pointed to by .array), but it's the way# things have been for a long, long time.# However, this results, in *many* cases, in a reference cycle.# Because the array returned by data.field(col.name), while sometimes# an array that owns its own data, is usually like a slice of the# original data.  It has the original FITS_rec as the array .base.# This results in the following reference cycle (for the n-th column):#    data -> data._coldefs -> data._coldefs[n] ->#     data._coldefs[n].array -> data._coldefs[n].array.base -> data# Because ndarray objects do not handled by Python's garbage collector# the reference cycle cannot be broken.  Therefore the FITS_rec's# refcount never goes to zero, its __del__ is never called, and its# memory is never freed.  This didn't occur in *all* cases, but it did# occur in many cases.# To get around this, Column.array is no longer a simple attribute# like it was previously.  Now each Column has a ._parent_fits_rec# attribute which is a weakref to a FITS_rec object.  Code that# previously assigned each col.array to field in a FITS_rec (as in# the example a few paragraphs above) is still used, however now# array.setter checks if a reference cycle will be created.  And if# so, instead of saving directly to the Column's __dict__, it creates# the ._prent_fits_rec weakref, and all lookups of the column's .array# go through that instead.# This alone does not fully solve the problem.  Because# _parent_fits_rec is a weakref, if the user ever holds a reference to# the Column, but deletes all references to the underlying FITS_rec,# the .array attribute would suddenly start returning None instead of# the array data.  This problem is resolved on FITS_rec's end.  See the# note in the FITS_rec._coldefs property for the rest of the story.# If the Columns's array is not a reference to an existing FITS_rec,# then it is just stored in self.__dict__; otherwise check the# _parent_fits_rec reference if it 's still available.# The following looks over the bases of the given array to check if it# has a ._coldefs attribute (i.e. is a FITS_rec) and that that _coldefs# contains this Column itself, and would create a reference cycle if we# stored the array directly in self.__dict__.# In this case it instead sets up the _parent_fits_rec weakref to the# underlying FITS_rec, so that array.getter can return arrays through# self._parent_fits_rec().field(self.name), rather than storing a# hard reference to the field like it used to.# Just in case the user already set .array to their own# array.# Allow None to indicate deleting the name, or to just indicate an# unspecified name (when creating a new Column).# Check that the name meets the recommended standard--other column# names are *allowed*, but will be discouraged# This ensures that the new name can fit into a single FITS card# without any special extension like CONTINUE cards or the like.# just use a throw-away format# Short circuit in case we're already a _BaseColumnFormat--there is at# least one case in which this can happen# legit recarray format?# legit FITS format?# Currently we don't have any validation for name, unit, bscale, or# bzero so include those by default# TODO: Add validation for these keywords, obviously# Validate null option# Note: Enough code exists that thinks empty strings are sensible# inputs for these options that we need to treat '' as None# Make this an exception instead of a warning, since any# non-int value is meaningless# TODO: We should also check that TNULLn's integer value# is in the range allowed by the column's format# Validate the disp option# TODO: Add full parsing and validation of TDISPn keywords# disp is at least one character long and has the 'L' format# which is not recognized for ASCII tables# Validate the start option# The 'start' option only applies to ASCII columns# Process TDIMn options# ASCII table columns can't have a TDIMn keyword associated with it;# for now we just issue a warning and ignore it.# TODO: This should be checked by the FITS verification code# NOTE: If valid, the dim keyword's value in the valid dict is# a tuple, not the original string; if invalid just the original# string is returned# TDIMs have different meaning for VLA format,# no warning should be thrown# If the given format string is unambiguously a Numpy dtype or one of# the Numpy record format type specifiers supported by Astropy then that# should take priority--otherwise assume it is a FITS format# check format# We're just give a string which could be either a Numpy format# code, or a format for a binary column array *or* a format for an# ASCII column array--there may be many ambiguities here.  Try our# best to guess what the user intended.# The format is already acceptable and unambiguous# This is impossible; this can't be a valid FITS column# Only ASCII table columns can have a 'start' option# Only binary tables can have a dim option# If the format is *technically* a valid binary column format# (i.e. it has a valid format code followed by arbitrary# "optional" codes), but it is also strictly a valid ASCII# table format, then assume an ASCII table column was being# requested (the more likely case, after all).# A safe guess which reflects the existing behavior of previous# Astropy versions# For whatever reason our guess was wrong (for example if we got# just 'F' that's not a valid binary format, but it an ASCII format# code albeit with the width/precision omitted# If this fails too we're out of options--it is truly an invalid# format, or at least not supported# Convert the format to a type we understand# The 'last' dimension (first in the order given# in the TDIMn keyword itself) is the number of# characters in each string# boolean needs to be scaled back to storage values ('T', 'F')# Preserve byte order of the original array for now; see #77# Handle arrays passed in as unsigned ints as pseudo-unsigned# int arrays; blatantly tacked in here for now--we need columns# to have explicit knowledge of whether they treated as# pseudo-unsigned# Basically the array is uint, has scale == 1.0, and the# bzero is the appropriate value for a pseudo-unsigned# integer of the input dtype, then go ahead and assume that# uint is assumed# The .base here means we're dropping the shape information,# which is only used to format recarray fields, and is not# useful for converting input arrays to the correct data type# force ASCII if this has been explicitly requested# If given a FITS_rec object we can directly copy its columns, but# only if its columns have already been defined, otherwise this# will loop back in on itself and blow up# Construct columns from the fields of a record array# if the input is a list of Columns# Construct columns from fields in an HDU header# Listen for changes on all columns# Determine the appropriate dimensions for items in the column# should take into account multidimensional items in the column# n x m string arrays must include the max string# length in their dimensions (e.g. l x n x m)# Check for unsigned ints.# go through header keywords to pick out column definition keywords# definition dictionaries for each field# skip if there is no match# Go ahead and convert the format value to the# appropriate ColumnFormat container now# Verify the column keywords and display any warnings if necessary;# we only want to pass on the valid keywords# Special cases for recformat and dim# TODO: Try to eliminate the need for these special cases# data reading will be delayed# now build the columns# Add the table HDU is a listener to changes to the columns# (either changes to individual columns, or changes to the set of# columns (add/remove/etc.))# This column has a FITS format compatible with this column# definitions class (that is ascii or binary)# Try to use the Numpy recformat as the equivalency between the# two formats; if that conversion can't be made then these# columns can't be transferred# TODO: Catch exceptions here and raise an explicit error about# column format conversion# Handle a few special cases of column format options that are not# compatible between ASCII an binary tables# TODO: This is sort of hacked in right now; we really need# separate classes for ASCII and Binary table Columns, and they# should handle formatting issues like these# the column is a binary table column...# We can't just "guess" a value to represent null# values in the new column, so just disable this for# now; users may modify it later# the column is an ASCII table column...# ASCII columns may not use the logical data display format;# for now just drop the TDISPn option for this column as we# don't have a systematic conversion of boolean data to ASCII# tables yet# Note: This previously returned a dtype that just used the raw field# widths based on the format's repeat count, and did not incorporate# field *shapes* as provided by TDIMn keywords.# Now this incorporates TDIMn from the start, which makes *this* method# a little more complicated, but simplifies code elsewhere (for example# fields will have the correct shapes even in the raw recarray).# Note: the size of the *original* format_ may be greater than# one would expect from the number of elements determined by# dim.  The FITS format allows this--the rest of the field is# filled with undefined values.# Note: VLA array descriptors should not be reshaped# as they are always of shape (2,)# The hasattr check is mostly just useful in debugging sessions# where self.columns may not be defined yet# Ask the HDU object to load the data before we modify our columns# Obliterate caches of certain things# Listen for changes on the new column# If this ColDefs is being tracked by a Table, inform the# table that its data is now invalid.# If this ColDefs is being tracked by a table HDU, inform the HDU (or# any other listeners) that the column has been removed# Just send a reference to self, and the index of the column that was# removed# if the format of an ASCII column has no width, add one# Widths is the width of each field *including* any space between# fields; this is so that we can map the fields to string records in a# Numpy recarray# Refers to the ASCII text column, not the table col# Update the start columns and column span widths taking into# account the case that the starting column of a field may not# be the column immediately after the previous field# Utilities# this handles ['abc'] and [['a','b','c']]# equally, beautiful!# try to find exact match first# try to match case-insentively,# occurrence of _key in names# multiple match# reset the output# shift the unused bits# TODO: A great deal of this is redundant with FITS_rec._convert_p; see if# we can merge the two somehow.# detect overflow when using P format# TODO: Maybe catch this error use a default type (bytes, maybe?) for# unrecognized column types.  As long as we can determine the correct# byte width somehow..# Be flexible on case# Floating point format# Just use a default width of 0 if unspecified# This should only be the case for floating-point formats# Just for integer/string formats; ignore precision# For any format, if width was unspecified use the set defaults# Ignore any dim values that don't specify a multidimensional column# First, if value is a string, try to convert to the appropriate scalar# Strip endianness# to accommodate both the ASCII table and binary table column# format spec, i.e. A7 in ASCII table is the same as 7A in# binary table, so both will produce 'S7'.# Technically the FITS standard does not allow this but it's a very# common mistake# make sure option is integer# Unicode dtype--itemsize is 4 times actual ASCII character length,# which what matters for FITS column formats# Use dtype.base and dtype.subdtype --dtype for multi-dimensional items# This is a kludge that will place string arrays into a# single field, so at least we won't lose data.  Need to# use a TDIM keyword to fix this, declaring as (slength,# dim1, dim2, ...)  as mwrfits does# record format# Special case for logical/boolean types--for ASCII tables we# represent these as single character columns containing 'T' or 'F'# (a la the storage format for Logical columns in binary tables)# Use for the width the maximum required to represent integers# of that byte size plus 1 for signs, but use a minimum of the# default width (to keep with existing behavior)# This is tricky, but go ahead and use D if float-64, and E# if float-32 with their default widths# TODO: There may be reasonable ways to represent other Numpy types so# let's see what other possibilities there are besides just 'S', 'i',# and 'f'.  If it doesn't have a reasonable ASCII representation then# raise an exception# This gives a sensible "default" dtype for a given ASCII# format code# The following logic is taken from CFITSIO:# For integers, if the width <= 4 we can safely use 16-bit ints for all# values, if width >= 10 we may need to accommodate 64-bit ints.# values [for the non-standard J format code just always force 64-bit]# Use appropriate regex for format type# Some formats have precision and exponential# Once parsed, check format dict to do conversion to a formatting string# Strip out extra format characters that aren't a type or a width/precision# Character format, only translate right aligned, and don't take zero fills# Number formats, don't take zero fills# If format has a "." split out the width and precision# Otherwise we just have a width# Catch logical data type, set the format type back to L in this caseb'ColDefs'u'ColDefs'b'Delayed'u'Delayed'b'i1'u'i1'b'L'u'L'b'u1'u'u1'b'i8'u'i8'b'f4'u'f4'b'f8'u'f8'b'c8'u'c8'b'c16'u'c16'b'b1'u'b1'b'u2'u'u2'b'u4'u'u4'b'f2'u'f2'b'(?:(?P<formatc>[F])(?:(?P<width>[0-9]+)\.{1}(?P<precision>[0-9]+))+)|'u'(?:(?P<formatc>[F])(?:(?P<width>[0-9]+)\.{1}(?P<precision>[0-9]+))+)|'b'(?:(?P<formatc>[AL])(?P<width>[0-9]+)+)|'u'(?:(?P<formatc>[AL])(?P<width>[0-9]+)+)|'b'(?:(?P<formatc>[IBOZ])(?:(?P<width>[0-9]+)(?:\.{0,1}(?P<precision>[0-9]+))?))|'u'(?:(?P<formatc>[IBOZ])(?:(?P<width>[0-9]+)(?:\.{0,1}(?P<precision>[0-9]+))?))|'b'(?:(?P<formatc>[EGD])(?:(?P<width>[0-9]+)\.(?P<precision>[0-9]+))+)(?:E{0,1}(?P<exponential>[0-9]+)?)|'u'(?:(?P<formatc>[EGD])(?:(?P<width>[0-9]+)\.(?P<precision>[0-9]+))+)(?:E{0,1}(?P<exponential>[0-9]+)?)|'b'(?:(?P<formatc>E[NS])(?:(?P<width>[0-9]+)\.{1}(?P<precision>[0-9]+))+)'u'(?:(?P<formatc>E[NS])(?:(?P<width>[0-9]+)\.{1}(?P<precision>[0-9]+))+)'b'EN'u'EN'b'ES'u'ES'b'{{:{width}d}}'u'{{:{width}d}}'b'{{:{width}b}}'u'{{:{width}b}}'b'{{:{width}o}}'u'{{:{width}o}}'b'{{:{width}x}}'u'{{:{width}x}}'b'{{:{width}.{precision}f}}'u'{{:{width}.{precision}f}}'b'{{:{width}.{precision}g}}'u'{{:{width}.{precision}g}}'b'{{:>{width}}}'u'{{:>{width}}}'b'{{:{width}.{precision}e}}'u'{{:{width}.{precision}e}}'b'TUNIT'u'TUNIT'b'TNULL'u'TNULL'b'TSCAL'u'TSCAL'b'TZERO'u'TZERO'b'TDISP'u'TDISP'b'TBCOL'u'TBCOL'b'TDIM'u'TDIM'b'TCTYP'u'TCTYP'b'TCUNI'u'TCUNI'b'TCRPX'u'TCRPX'b'TCRVL'u'TCRVL'b'TCDLT'u'TCDLT'b'TRPOS'u'TRPOS'b'null'u'null'b'bscale'u'bscale'b'bzero'u'bzero'b'disp'u'disp'b'dim'u'dim'b'coord_type'u'coord_type'b'coord_unit'u'coord_unit'b'coord_ref_point'u'coord_ref_point'b'coord_ref_value'u'coord_ref_value'b'coord_inc'u'coord_inc'b'time_ref_pos'u'time_ref_pos'b'This is a list of the attributes that can be set on `Column` objects.'u'This is a list of the attributes that can be set on `Column` objects.'b'(?P<repeat>^[0-9]*)(?P<format>[LXBIJKAEDCMPQ])(?P<option>[!-~]*)'u'(?P<repeat>^[0-9]*)(?P<format>[LXBIJKAEDCMPQ])(?P<option>[!-~]*)'b'(?:(?P<format>[AIJ])(?P<width>[0-9]+)?)|(?:(?P<formatf>[FED])(?:(?P<widthf>[0-9]+)(?:\.(?P<precision>[0-9]+))?)?)'u'(?:(?P<format>[AIJ])(?P<width>[0-9]+)?)|(?:(?P<formatf>[FED])(?:(?P<widthf>[0-9]+)(?:\.(?P<precision>[0-9]+))?)?)'b'[0-9a-zA-Z_]+'u'[0-9a-zA-Z_]+'b'
Regular expression for valid table column names.  See FITS Standard v3.0 section 7.2.2.
'u'
Regular expression for valid table column names.  See FITS Standard v3.0 section 7.2.2.
'b'(?P<label>^T[A-Z]*)(?P<num>[1-9][0-9 ]*$)'u'(?P<label>^T[A-Z]*)(?P<num>[1-9][0-9 ]*$)'b'\(\s*(?P<dims>(?:\d+\s*)(?:,\s*\d+\s*)*\s*)\)\s*'u'\(\s*(?P<dims>(?:\d+\s*)(?:,\s*\d+\s*)*\s*)\)\s*'b'Delayed file-reading data.'u'Delayed file-reading data.'b'
    Base class for binary table column formats (just called _ColumnFormat)
    and ASCII table column formats (_AsciiColumnFormat).
    'u'
    Base class for binary table column formats (just called _ColumnFormat)
    and ASCII table column formats (_AsciiColumnFormat).
    'b'
        The Numpy dtype object created from the format's associated recformat.
        'u'
        The Numpy dtype object created from the format's associated recformat.
        'b'Creates a column format object from another column format object
        regardless of their type.

        That is, this can convert a _ColumnFormat to an _AsciiColumnFormat
        or vice versa at least in cases where a direct translation is possible.
        'u'Creates a column format object from another column format object
        regardless of their type.

        That is, this can convert a _ColumnFormat to an _AsciiColumnFormat
        or vice versa at least in cases where a direct translation is possible.
        'b'
    Represents a FITS binary table column format.

    This is an enhancement over using a normal string for the format, since the
    repeat count, format code, and option are available as separate attributes,
    and smart comparison is used.  For example 1J == J.
    'u'
    Represents a FITS binary table column format.

    This is an enhancement over using a normal string for the format, since the
    repeat count, format code, and option are available as separate attributes,
    and smart comparison is used.  For example 1J == J.
    'b'Q'u'Q'b'Creates a column format from a Numpy record dtype format.'u'Creates a column format from a Numpy record dtype format.'b'Returns the equivalent Numpy record format string.'u'Returns the equivalent Numpy record format string.'b'
        Returns a 'canonical' string representation of this format.

        This is in the proper form of rTa where T is the single character data
        type code, a is the optional part, and r is the repeat.  If repeat == 1
        (the default) it is left out of this representation.
        'u'
        Returns a 'canonical' string representation of this format.

        This is in the proper form of rTa where T is the single character data
        type code, a is the optional part, and r is the repeat.  If repeat == 1
        (the default) it is left out of this representation.
        'b'Similar to _ColumnFormat but specifically for columns in ASCII tables.

    The formats of ASCII table columns and binary table columns are inherently
    incompatible in FITS.  They don't support the same ranges and types of
    values, and even reuse format codes in subtly different ways.  For example
    the format code 'Iw' in ASCII columns refers to any integer whose string
    representation is at most w characters wide, so 'I' can represent
    effectively any integer that will fit in a FITS columns.  Whereas for
    binary tables 'I' very explicitly refers to a 16-bit signed integer.

    Conversions between the two column formats can be performed using the
    ``to/from_binary`` methods on this class, or the ``to/from_ascii``
    methods on the `_ColumnFormat` class.  But again, not all conversions are
    possible and may result in a `ValueError`.
    'u'Similar to _ColumnFormat but specifically for columns in ASCII tables.

    The formats of ASCII table columns and binary table columns are inherently
    incompatible in FITS.  They don't support the same ranges and types of
    values, and even reuse format codes in subtly different ways.  For example
    the format code 'Iw' in ASCII columns refers to any integer whose string
    representation is at most w characters wide, so 'I' can represent
    effectively any integer that will fit in a FITS columns.  Whereas for
    binary tables 'I' very explicitly refers to a 16-bit signed integer.

    Conversions between the two column formats can be performed using the
    ``to/from_binary`` methods on this class, or the ``to/from_ascii``
    methods on the `_ColumnFormat` class.  But again, not all conversions are
    possible and may result in a `ValueError`.
    'b'
        Returns a 'canonical' string representation of this format.

        This is in the proper form of Tw.d where T is the single character data
        type code, w is the width in characters for this field, and d is the
        number of digits after the decimal place (for format codes 'E', 'F',
        and 'D' only).
        'u'
        Returns a 'canonical' string representation of this format.

        This is in the proper form of Tw.d where T is the single character data
        type code, w is the width in characters for this field, and d is the
        number of digits after the decimal place (for format codes 'E', 'F',
        and 'D' only).
        'b'For X format in binary tables.'u'For X format in binary tables.'b'For P format in variable length table.'u'For P format in variable length table.'b'(?P<repeat>\d+)?{}(?P<dtype>[LXBIJKAEDCM])(?:\((?P<max>\d*)\))?'u'(?P<repeat>\d+)?{}(?P<dtype>[LXBIJKAEDCM])(?:\((?P<max>\d*)\))?'b'2i4'u'2i4'b'Invalid column format: 'u'Invalid column format: 'b'repeat'u'repeat'b'max'b'Carries type description of the Q format for variable length arrays.

    The Q format is like the P format but uses 64-bit integers in the array
    descriptors, allowing for heaps stored beyond 2GB into a file.
    'u'Carries type description of the Q format for variable length arrays.

    The Q format is like the P format but uses 64-bit integers in the array
    descriptors, allowing for heaps stored beyond 2GB into a file.
    'b'2i8'u'2i8'b'
    Descriptor for attributes of `Column` that are associated with keywords
    in the FITS header and describe properties of the column as specified in
    the FITS standard.

    Each `ColumnAttribute` may have a ``validator`` method defined on it.
    This validates values set on this attribute to ensure that they meet the
    FITS standard.  Invalid values will raise a warning and will not be used in
    formatting the column.  The validator should take two arguments--the
    `Column` it is being assigned to, and the new value for the attribute, and
    it must raise an `AssertionError` if the value is invalid.

    The `ColumnAttribute` itself is a decorator that can be used to define the
    ``validator`` for each column attribute.  For example::

        @ColumnAttribute('TTYPE')
        def name(col, name):
            if not isinstance(name, str):
                raise AssertionError

    The actual object returned by this decorator is the `ColumnAttribute`
    instance though, not the ``name`` function.  As such ``name`` is not a
    method of the class it is defined in.

    The setter for `ColumnAttribute` also updates the header of any table
    HDU this column is attached to in order to reflect the change.  The
    ``validator`` should ensure that the value is valid for inclusion in a FITS
    header.
    'u'
    Descriptor for attributes of `Column` that are associated with keywords
    in the FITS header and describe properties of the column as specified in
    the FITS standard.

    Each `ColumnAttribute` may have a ``validator`` method defined on it.
    This validates values set on this attribute to ensure that they meet the
    FITS standard.  Invalid values will raise a warning and will not be used in
    formatting the column.  The validator should take two arguments--the
    `Column` it is being assigned to, and the new value for the attribute, and
    it must raise an `AssertionError` if the value is invalid.

    The `ColumnAttribute` itself is a decorator that can be used to define the
    ``validator`` for each column attribute.  For example::

        @ColumnAttribute('TTYPE')
        def name(col, name):
            if not isinstance(name, str):
                raise AssertionError

    The actual object returned by this decorator is the `ColumnAttribute`
    instance though, not the ``name`` function.  As such ``name`` is not a
    method of the class it is defined in.

    The setter for `ColumnAttribute` also updates the header of any table
    HDU this column is attached to in order to reflect the change.  The
    ``validator`` should ensure that the value is valid for inclusion in a FITS
    header.
    'b'column_attribute_changed'u'column_attribute_changed'b'
        Set the validator for this column attribute.

        Returns ``self`` so that this can be used as a decorator, as described
        in the docs for this class.
        'u'
        Set the validator for this column attribute.

        Returns ``self`` so that this can be used as a decorator, as described
        in the docs for this class.
        'b'(''u'(''b'')'u'')'b'
    Class which contains the definition of one column, e.g.  ``ttype``,
    ``tform``, etc. and the array containing values for the column.
    'u'
    Class which contains the definition of one column, e.g.  ``ttype``,
    ``tform``, etc. and the array containing values for the column.
    'b'
        Construct a `Column` by specifying attributes.  All attributes
        except ``format`` can be optional; see :ref:`astropy:column_creation`
        and :ref:`astropy:creating_ascii_table` for more information regarding
        ``TFORM`` keyword.

        Parameters
        ----------
        name : str, optional
            column name, corresponding to ``TTYPE`` keyword

        format : str
            column format, corresponding to ``TFORM`` keyword

        unit : str, optional
            column unit, corresponding to ``TUNIT`` keyword

        null : str, optional
            null value, corresponding to ``TNULL`` keyword

        bscale : int-like, optional
            bscale value, corresponding to ``TSCAL`` keyword

        bzero : int-like, optional
            bzero value, corresponding to ``TZERO`` keyword

        disp : str, optional
            display format, corresponding to ``TDISP`` keyword

        start : int, optional
            column starting position (ASCII table only), corresponding
            to ``TBCOL`` keyword

        dim : str, optional
            column dimension corresponding to ``TDIM`` keyword

        array : iterable, optional
            a `list`, `numpy.ndarray` (or other iterable that can be used to
            initialize an ndarray) providing initial data for this column.
            The array will be automatically converted, if possible, to the data
            format of the column.  In the case were non-trivial ``bscale``
            and/or ``bzero`` arguments are given, the values in the array must
            be the *physical* values--that is, the values of column as if the
            scaling has already been applied (the array stored on the column
            object will then be converted back to its storage values).

        ascii : bool, optional
            set `True` if this describes a column for an ASCII table; this
            may be required to disambiguate the column format

        coord_type : str, optional
            coordinate/axis type corresponding to ``TCTYP`` keyword

        coord_unit : str, optional
            coordinate/axis unit corresponding to ``TCUNI`` keyword

        coord_ref_point : int-like, optional
            pixel coordinate of the reference point corresponding to ``TCRPX``
            keyword

        coord_ref_value : int-like, optional
            coordinate value at reference point corresponding to ``TCRVL``
            keyword

        coord_inc : int-like, optional
            coordinate increment at reference point corresponding to ``TCDLT``
            keyword

        time_ref_pos : str, optional
            reference position for a time coordinate column corresponding to
            ``TRPOS`` keyword
        'u'
        Construct a `Column` by specifying attributes.  All attributes
        except ``format`` can be optional; see :ref:`astropy:column_creation`
        and :ref:`astropy:creating_ascii_table` for more information regarding
        ``TFORM`` keyword.

        Parameters
        ----------
        name : str, optional
            column name, corresponding to ``TTYPE`` keyword

        format : str
            column format, corresponding to ``TFORM`` keyword

        unit : str, optional
            column unit, corresponding to ``TUNIT`` keyword

        null : str, optional
            null value, corresponding to ``TNULL`` keyword

        bscale : int-like, optional
            bscale value, corresponding to ``TSCAL`` keyword

        bzero : int-like, optional
            bzero value, corresponding to ``TZERO`` keyword

        disp : str, optional
            display format, corresponding to ``TDISP`` keyword

        start : int, optional
            column starting position (ASCII table only), corresponding
            to ``TBCOL`` keyword

        dim : str, optional
            column dimension corresponding to ``TDIM`` keyword

        array : iterable, optional
            a `list`, `numpy.ndarray` (or other iterable that can be used to
            initialize an ndarray) providing initial data for this column.
            The array will be automatically converted, if possible, to the data
            format of the column.  In the case were non-trivial ``bscale``
            and/or ``bzero`` arguments are given, the values in the array must
            be the *physical* values--that is, the values of column as if the
            scaling has already been applied (the array stored on the column
            object will then be converted back to its storage values).

        ascii : bool, optional
            set `True` if this describes a column for an ASCII table; this
            may be required to disambiguate the column format

        coord_type : str, optional
            coordinate/axis type corresponding to ``TCTYP`` keyword

        coord_unit : str, optional
            coordinate/axis unit corresponding to ``TCUNI`` keyword

        coord_ref_point : int-like, optional
            pixel coordinate of the reference point corresponding to ``TCRPX``
            keyword

        coord_ref_value : int-like, optional
            coordinate value at reference point corresponding to ``TCRVL``
            keyword

        coord_inc : int-like, optional
            coordinate increment at reference point corresponding to ``TCDLT``
            keyword

        time_ref_pos : str, optional
            reference position for a time coordinate column corresponding to
            ``TRPOS`` keyword
        'b'Must specify format to construct Column.'u'Must specify format to construct Column.'b'The following keyword arguments to Column were invalid:'u'The following keyword arguments to Column were invalid:'b'recformat'u'recformat'b'Data is inconsistent with the format `'u'Data is inconsistent with the format `'b'; 'u'; 'b'
        Two columns are equal if their name and format are the same.  Other
        attributes aren't taken into account at this time.
        'u'
        Two columns are equal if their name and format are the same.  Other
        attributes aren't taken into account at this time.
        'b'
        Like __eq__, the hash of a column should be based on the unique column
        name and format, and be case-insensitive with respect to the column
        name.
        'u'
        Like __eq__, the hash of a column should be based on the unique column
        name and format, and be case-insensitive with respect to the column
        name.
        'b'
        The Numpy `~numpy.ndarray` associated with this `Column`.

        If the column was instantiated with an array passed to the ``array``
        argument, this will return that array.  However, if the column is
        later added to a table, such as via `BinTableHDU.from_columns` as
        is typically the case, this attribute will be updated to reference
        the associated field in the table, which may no longer be the same
        array.
        'u'
        The Numpy `~numpy.ndarray` associated with this `Column`.

        If the column was instantiated with an array passed to the ``array``
        argument, this will return that array.  However, if the column is
        later added to a table, such as via `BinTableHDU.from_columns` as
        is typically the case, this attribute will be updated to reference
        the associated field in the table, which may no longer be the same
        array.
        'b'array'b'_coldefs'u'_coldefs'b'It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got 'u'It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got 'b'Column name must be a string able to fit in a single FITS card--typically this means a maximum of 68 characters, though it may be fewer if the string contains special characters like quotes.'u'Column name must be a string able to fit in a single FITS card--typically this means a maximum of 68 characters, though it may be fewer if the string contains special characters like quotes.'b'Coordinate/axis type must be a string of at most 8 characters.'u'Coordinate/axis type must be a string of at most 8 characters.'b'Coordinate/axis unit must be a string.'u'Coordinate/axis unit must be a string.'b'Pixel coordinate of the reference point must be real floating type.'u'Pixel coordinate of the reference point must be real floating type.'b'Coordinate value at reference point must be real floating type.'u'Coordinate value at reference point must be real floating type.'b'Coordinate increment must be real floating type.'u'Coordinate increment must be real floating type.'b'Time reference position must be a string.'u'Time reference position must be a string.'b'Whether this `Column` represents a column in an ASCII table.'u'Whether this `Column` represents a column in an ASCII table.'b'
        Return a copy of this `Column`.
        'u'
        Return a copy of this `Column`.
        'b'The format argument to this class's initializer may come in many
        forms.  This uses the given column format class ``cls`` to convert
        to a format of that type.

        TODO: There should be an abc base class for column format classes
        'u'The format argument to this class's initializer may come in many
        forms.  This uses the given column format class ``cls`` to convert
        to a format of that type.

        TODO: There should be an abc base class for column format classes
        'b'Illegal format `'u'Illegal format `'b'
        Given the keyword arguments used to initialize a Column, specifically
        those that typically read from a FITS header (so excluding array),
        verify that each keyword has a valid value.

        Returns a 2-tuple of dicts.  The first maps valid keywords to their
        values.  The second maps invalid keywords to a 2-tuple of their value,
        and a message explaining why they were found invalid.
        'u'
        Given the keyword arguments used to initialize a Column, specifically
        those that typically read from a FITS header (so excluding array),
        verify that each keyword has a valid value.

        Returns a 2-tuple of dicts.  The first maps valid keywords to their
        values.  The second maps invalid keywords to a 2-tuple of their value,
        and a message explaining why they were found invalid.
        'b'Column format option (TFORMn) failed verification: 'u'Column format option (TFORMn) failed verification: 'b' The invalid value will be ignored for the purpose of formatting the data in this column.'u' The invalid value will be ignored for the purpose of formatting the data in this column.'b'Column format option (TFORMn) must be a string with a valid FITS table format (got 'u'Column format option (TFORMn) must be a string with a valid FITS table format (got 'b'). The invalid value will be ignored for the purpose of formatting the data in this column.'u'). The invalid value will be ignored for the purpose of formatting the data in this column.'b'ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got 'u'ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got 'b'Column null option (TNULLn) must be an integer for binary table columns (got 'u'Column null option (TNULLn) must be an integer for binary table columns (got 'b').  The invalid value will be ignored for the purpose of formatting the data in this column.'u').  The invalid value will be ignored for the purpose of formatting the data in this column.'b'Column null option (TNULLn) is invalid for binary table columns of type 'u'Column null option (TNULLn) is invalid for binary table columns of type 'b' (got 'u' (got 'b'Column disp option (TDISPn) must be a string (got 'u'Column disp option (TDISPn) must be a string (got 'b'Column disp option (TDISPn) may not use the 'L' format with ASCII table columns.  The invalid value will be ignored for the purpose of formatting the data in this column.'u'Column disp option (TDISPn) may not use the 'L' format with ASCII table columns.  The invalid value will be ignored for the purpose of formatting the data in this column.'b'Column disp option (TDISPn) failed verification: 'u'Column disp option (TDISPn) failed verification: 'b'Column start option (TBCOLn) is not allowed for binary table columns (got 'u'Column start option (TBCOLn) is not allowed for binary table columns (got 'b').  The invalid keyword will be ignored for the purpose of formatting the data in this column.'u').  The invalid keyword will be ignored for the purpose of formatting the data in this column.'b'Column start option (TBCOLn) must be a positive integer (got 'u'Column start option (TBCOLn) must be a positive integer (got 'b'Column dim option (TDIMn) is not allowed for ASCII table columns (got 'u'Column dim option (TDIMn) is not allowed for ASCII table columns (got 'b').  The invalid keyword will be ignored for the purpose of formatting this column.'u').  The invalid keyword will be ignored for the purpose of formatting this column.'b'`dim` argument must be a string containing a valid value for the TDIMn header keyword associated with this column, or a tuple containing the C-order dimensions for the column.  The invalid value will be ignored for the purpose of formatting this column.'u'`dim` argument must be a string containing a valid value for the TDIMn header keyword associated with this column, or a tuple containing the C-order dimensions for the column.  The invalid value will be ignored for the purpose of formatting this column.'b'The repeat count of the column format 'u'The repeat count of the column format 'b' for column 'u' for column 'b' is fewer than the number of elements per the TDIM argument 'u' is fewer than the number of elements per the TDIM argument 'b'.  The invalid TDIMn value will be ignored for the purpose of formatting this column.'u'.  The invalid TDIMn value will be ignored for the purpose of formatting this column.'b'Coordinate/axis type option (TCTYPn) must be a string (got 'u'Coordinate/axis type option (TCTYPn) must be a string (got 'b'). The invalid keyword will be ignored for the purpose of formatting this column.'u'). The invalid keyword will be ignored for the purpose of formatting this column.'b'Coordinate/axis type option (TCTYPn) must be a string of at most 8 characters (got 'u'Coordinate/axis type option (TCTYPn) must be a string of at most 8 characters (got 'b'Coordinate/axis unit option (TCUNIn) must be a string (got 'u'Coordinate/axis unit option (TCUNIn) must be a string (got 'b'Column 'u'Column 'b' option ('u' option ('b'n) must be a real floating type (got 'u'n) must be a real floating type (got 'b'Time coordinate reference position option (TRPOSn) must be a string (got 'u'Time coordinate reference position option (TRPOSn) must be a string (got 'b'
        Given a format string and whether or not the Column is for an
        ASCII table (ascii=None means unspecified, but lean toward binary table
        where ambiguous) create an appropriate _BaseColumnFormat instance for
        the column's format, and determine the appropriate recarray format.

        The values of the start and dim keyword arguments are also useful, as
        the former is only valid for ASCII tables and the latter only for
        BINARY tables.
        'u'
        Given a format string and whether or not the Column is for an
        ASCII table (ascii=None means unspecified, but lean toward binary table
        where ambiguous) create an appropriate _BaseColumnFormat instance for
        the column's format, and determine the appropriate recarray format.

        The values of the start and dim keyword arguments are also useful, as
        the former is only valid for ASCII tables and the latter only for
        BINARY tables.
        'b'Columns cannot have both a start (TCOLn) and dim (TDIMn) option, since the former is only applies to ASCII tables, and the latter is only valid for binary tables.'u'Columns cannot have both a start (TCOLn) and dim (TDIMn) option, since the former is only applies to ASCII tables, and the latter is only valid for binary tables.'b'PQ'u'PQ'b'SU'u'SU'b'
    Column definitions class.

    It has attributes corresponding to the `Column` attributes
    (e.g. `ColDefs` has the attribute ``names`` while `Column`
    has ``name``). Each attribute in `ColDefs` is a list of
    corresponding attribute values from all `Column` objects.
    'u'
    Column definitions class.

    It has attributes corresponding to the `Column` attributes
    (e.g. `ColDefs` has the attribute ``names`` while `Column`
    has ``name``). Each attribute in `ColDefs` is a list of
    corresponding attribute values from all `Column` objects.
    'b'_columns_type'u'_columns_type'b'_col_format_cls'u'_col_format_cls'b'
        Parameters
        ----------
        input : sequence of `Column` or `ColDefs` or ndarray or `~numpy.recarray`
            An existing table HDU, an existing `ColDefs`, or any multi-field
            Numpy array or `numpy.recarray`.

        ascii : bool
            Use True to ensure that ASCII table columns are used.

        'u'
        Parameters
        ----------
        input : sequence of `Column` or `ColDefs` or ndarray or `~numpy.recarray`
            An existing table HDU, an existing `ColDefs`, or any multi-field
            Numpy array or `numpy.recarray`.

        ascii : bool
            Use True to ensure that ASCII table columns are used.

        'b'Input to ColDefs must be a table HDU, a list of Columns, or a record/field array.'u'Input to ColDefs must be a table HDU, a list of Columns, or a record/field array.'b'Initialize from an existing ColDefs object (just copy the
        columns and convert their formats if necessary).
        'u'Initialize from an existing ColDefs object (just copy the
        columns and convert their formats if necessary).
        'b'Element 'u'Element 'b' in the ColDefs input is not a Column.'u' in the ColDefs input is not a Column.'b'Input data with shape 'u'Input data with shape 'b' is not a valid representation of a row-oriented table. Expected a 1D array with rows as elements.'u' is not a valid representation of a row-oriented table. Expected a 1D array with rows as elements.'b'Column ''u'Column ''b'' contains unsupported object types or mixed types: 'u'' contains unsupported object types or mixed types: 'b'[0-9]+'u'[0-9]+'b'label'u'label'b'num'u'num'b'Invalid keyword for column 'u'Invalid keyword for column 'b'Utility function used currently only by _init_from_coldefs
        to help convert columns from binary format to ASCII format or vice
        versa if necessary (otherwise performs a straight copy).
        'u'Utility function used currently only by _init_from_coldefs
        to help convert columns from binary format to ASCII format or vice
        versa if necessary (otherwise performs a straight copy).
        'b'
        Automatically returns the values for the given keyword attribute for
        all `Column`s in this list.

        Implements for example self.units, self.formats, etc.
        'u'
        Automatically returns the values for the given keyword attribute for
        all `Column`s in this list.

        Implements for example self.units, self.formats, etc.
        'b'formats'u'formats'b'offsets'u'offsets'b'Returns the values of the TDIMn keywords parsed into tuples.'u'Returns the values of the TDIMn keywords parsed into tuples.'b'ColDefs('u'ColDefs('b'columns'u'columns'b'
    'u'
    'b'Wrong type of input.'u'Wrong type of input.'b'
        Handle column attribute changed notifications from columns that are
        members of this `ColDefs`.

        `ColDefs` itself does not currently do anything with this, and just
        bubbles the notification up to any listening table HDUs that may need
        to update their headers, etc.  However, this also informs the table of
        the numerical index of the column that changed.
        'u'
        Handle column attribute changed notifications from columns that are
        members of this `ColDefs`.

        `ColDefs` itself does not currently do anything with this, and just
        bubbles the notification up to any listening table HDUs that may need
        to update their headers, etc.  However, this also informs the table of
        the numerical index of the column that changed.
        'b'
        Append one `Column` to the column definition.
        'u'
        Append one `Column` to the column definition.
        'b'load_data'u'load_data'b'column_added'u'column_added'b'
        Delete (the definition of) one `Column`.

        col_name : str or int
            The column's name or index
        'u'
        Delete (the definition of) one `Column`.

        col_name : str or int
            The column's name or index
        'b'column_removed'u'column_removed'b'
        Change an attribute (in the ``KEYWORD_ATTRIBUTES`` list) of a `Column`.

        Parameters
        ----------
        col_name : str or int
            The column name or index to change

        attrib : str
            The attribute name

        new_value : object
            The new value for the attribute
        'u'
        Change an attribute (in the ``KEYWORD_ATTRIBUTES`` list) of a `Column`.

        Parameters
        ----------
        col_name : str or int
            The column name or index to change

        attrib : str
            The attribute name

        new_value : object
            The new value for the attribute
        'b'
        Change a `Column`'s name.

        Parameters
        ----------
        col_name : str
            The current name of the column

        new_name : str
            The new name of the column
        'u'
        Change a `Column`'s name.

        Parameters
        ----------
        col_name : str
            The current name of the column

        new_name : str
            The new name of the column
        'b'New name 'u'New name 'b' already exists.'u' already exists.'b'
        Change a `Column`'s unit.

        Parameters
        ----------
        col_name : str or int
            The column name or index

        new_unit : str
            The new unit for the column
        'u'
        Change a `Column`'s unit.

        Parameters
        ----------
        col_name : str or int
            The column name or index

        new_unit : str
            The new unit for the column
        'b'
        Get attribute(s) information of the column definition.

        Parameters
        ----------
        attrib : str
            Can be one or more of the attributes listed in
            ``astropy.io.fits.column.KEYWORD_ATTRIBUTES``.  The default is
            ``"all"`` which will print out all attributes.  It forgives plurals
            and blanks.  If there are two or more attribute names, they must be
            separated by comma(s).

        output : file-like, optional
            File-like object to output to.  Outputs to stdout by default.
            If `False`, returns the attributes as a `dict` instead.

        Notes
        -----
        This function doesn't return anything by default; it just prints to
        stdout.
        'u'
        Get attribute(s) information of the column definition.

        Parameters
        ----------
        attrib : str
            Can be one or more of the attributes listed in
            ``astropy.io.fits.column.KEYWORD_ATTRIBUTES``.  The default is
            ``"all"`` which will print out all attributes.  It forgives plurals
            and blanks.  If there are two or more attribute names, they must be
            separated by comma(s).

        output : file-like, optional
            File-like object to output to.  Outputs to stdout by default.
            If `False`, returns the attributes as a `dict` instead.

        Notes
        -----
        This function doesn't return anything by default; it just prints to
        stdout.
        'b'' is not an attribute of the column definitions.
'u'' is not an attribute of the column definitions.
'b':
'u':
'b'ColDefs implementation for ASCII tables.'u'ColDefs implementation for ASCII tables.'b'A list of the widths of each field in the table.'u'A list of the widths of each field in the table.'b'
        Updates the list of the start columns, the list of the widths of each
        field, and the total width of each record in the table.
        'u'
        Updates the list of the start columns, the list of the widths of each
        field, and the total width of each record in the table.
        'b'Variable length field object.'u'Variable length field object.'b'
        Parameters
        ----------
        input
            a sequence of variable-sized elements.
        'u'
        Parameters
        ----------
        input
            a sequence of variable-sized elements.
        'b'Inconsistent input data array: 'u'Inconsistent input data array: 'b'
        To make sure the new item has consistent data type to avoid
        misalignment.
        'u'
        To make sure the new item has consistent data type to avoid
        misalignment.
        'b'
    Get the index of the ``key`` in the ``names`` list.

    The ``key`` can be an integer or string.  If integer, it is the index
    in the list.  If string,

        a. Field (column) names are case sensitive: you can have two
           different columns called 'abc' and 'ABC' respectively.

        b. When you *refer* to a field (presumably with the field
           method), it will try to match the exact name first, so in
           the example in (a), field('abc') will get the first field,
           and field('ABC') will get the second field.

        If there is no exact name matched, it will try to match the
        name with case insensitivity.  So, in the last example,
        field('Abc') will cause an exception since there is no unique
        mapping.  If there is a field named "XYZ" and no other field
        name is a case variant of "XYZ", then field('xyz'),
        field('Xyz'), etc. will get this field.
    'u'
    Get the index of the ``key`` in the ``names`` list.

    The ``key`` can be an integer or string.  If integer, it is the index
    in the list.  If string,

        a. Field (column) names are case sensitive: you can have two
           different columns called 'abc' and 'ABC' respectively.

        b. When you *refer* to a field (presumably with the field
           method), it will try to match the exact name first, so in
           the example in (a), field('abc') will get the first field,
           and field('ABC') will get the second field.

        If there is no exact name matched, it will try to match the
        name with case insensitivity.  So, in the last example,
        field('Abc') will cause an exception since there is no unique
        mapping.  If there is a field named "XYZ" and no other field
        name is a case variant of "XYZ", then field('xyz'),
        field('Xyz'), etc. will get this field.
    'b'Illegal key ''u'Illegal key ''b'Key ''u'Key ''b'' does not exist.'u'' does not exist.'b'Ambiguous key name ''u'Ambiguous key name ''b'
    Unwrap the X format column into a Boolean array.

    Parameters
    ----------
    input
        input ``Uint8`` array of shape (`s`, `nbytes`)

    output
        output Boolean array of shape (`s`, `repeat`)

    repeat
        number of bits
    'u'
    Unwrap the X format column into a Boolean array.

    Parameters
    ----------
    input
        input ``Uint8`` array of shape (`s`, `nbytes`)

    output
        output Boolean array of shape (`s`, `repeat`)

    repeat
        number of bits
    'b'
    Wrap the X format column Boolean array into an ``UInt8`` array.

    Parameters
    ----------
    input
        input Boolean array of shape (`s`, `repeat`)

    output
        output ``Uint8`` array of shape (`s`, `nbytes`)

    repeat
        number of bits
    'u'
    Wrap the X format column Boolean array into an ``UInt8`` array.

    Parameters
    ----------
    input
        input Boolean array of shape (`s`, `repeat`)

    output
        output ``Uint8`` array of shape (`s`, `nbytes`)

    repeat
        number of bits
    'b'
    Construct the P (or Q) format column array, both the data descriptors and
    the data.  It returns the output "data" array of data type `dtype`.

    The descriptor location will have a zero offset for all columns
    after this call.  The final offset will be calculated when the file
    is written.

    Parameters
    ----------
    array
        input object array

    descr_output
        output "descriptor" array of data type int32 (for P format arrays) or
        int64 (for Q format arrays)--must be nrows long in its first dimension

    format
        the _FormatP object representing the format of the variable array

    nrows : int, optional
        number of rows to create in the column; defaults to the number of rows
        in the input array
    'u'
    Construct the P (or Q) format column array, both the data descriptors and
    the data.  It returns the output "data" array of data type `dtype`.

    The descriptor location will have a zero offset for all columns
    after this call.  The final offset will be calculated when the file
    is written.

    Parameters
    ----------
    array
        input object array

    descr_output
        output "descriptor" array of data type int32 (for P format arrays) or
        int64 (for Q format arrays)--must be nrows long in its first dimension

    format
        the _FormatP object representing the format of the variable array

    nrows : int, optional
        number of rows to create in the column; defaults to the number of rows
        in the input array
    'b'The heapsize limit for 'P' format has been reached. Please consider using the 'Q' format for your file.'u'The heapsize limit for 'P' format has been reached. Please consider using the 'Q' format for your file.'b'Parse ``TFORMn`` keyword for a binary table into a
    ``(repeat, format, option)`` tuple.
    'u'Parse ``TFORMn`` keyword for a binary table into a
    ``(repeat, format, option)`` tuple.
    'b'Format 'u'Format 'b' is not recognized.'u' is not recognized.'b'
    Parse the ``TFORMn`` keywords for ASCII tables into a ``(format, width,
    precision)`` tuple (the latter is always zero unless format is one of 'E',
    'F', or 'D').
    'u'
    Parse the ``TFORMn`` keywords for ASCII tables into a ``(format, width,
    precision)`` tuple (the latter is always zero unless format is one of 'E',
    'F', or 'D').
    'b'formatf'u'formatf'b'widthf'u'widthf'b'precision'u'precision'b'Format {!r} is not unambiguously an ASCII table format.'u'Format {!r} is not unambiguously an ASCII table format.'b'width'b'Format {!r} is not valid--field width and decimal precision must be integers.'u'Format {!r} is not valid--field width and decimal precision must be integers.'b' not valid--field width must be a positive integeter.'u' not valid--field width must be a positive integeter.'b' not valid--the number of decimal digits must be less than the format's total width 'u' not valid--the number of decimal digits must be less than the format's total width 'b'Parse the ``TDIM`` value into a tuple (may return an empty tuple if
    the value ``TDIM`` value is empty or invalid).
    'u'Parse the ``TDIM`` value into a tuple (may return an empty tuple if
    the value ``TDIM`` value is empty or invalid).
    'b'dims'u'dims'b'
    Given a scalar value or string, returns the minimum FITS column format
    that can represent that value.  'minimum' is defined by the order given in
    FORMATORDER.
    'u'
    Given a scalar value or string, returns the minimum FITS column format
    that can represent that value.  'minimum' is defined by the order given in
    FORMATORDER.
    'b'
    Compares two numpy recformats using the ordering given by FORMATORDER.
    'u'
    Compares two numpy recformats using the ordering given by FORMATORDER.
    'b'
    Convert FITS format spec to record format spec.
    'u'
    Convert FITS format spec to record format spec.
    'b'
    Convert record format spec to FITS format spec.
    'u'
    Convert record format spec to FITS format spec.
    'b'
    Utility function for converting a dtype object or string that instantiates
    a dtype (e.g. 'float32') into one of the two character Numpy format codes
    that have been traditionally used by Astropy.
    'u'
    Utility function for converting a dtype object or string that instantiates
    a dtype (e.g. 'float32') into one of the two character Numpy format codes
    that have been traditionally used by Astropy.
    'b'
    Convert FITS format spec to record format spec.  Do the opposite if
    reverse=True.
    'u'
    Convert FITS format spec to record format spec.  Do the opposite if
    reverse=True.
    'b'Convert ASCII table format spec to record format spec.'u'Convert ASCII table format spec to record format spec.'b'A1'u'A1'b'
    Parse the ``TDISPn`` keywords for ASCII and binary tables into a
    ``(format, width, precision, exponential)`` tuple (the TDISP values
    for ASCII and binary are identical except for 'Lw',
    which is only present in BINTABLE extensions.

    Parameters
    ----------
    tdisp : str
        TDISPn FITS Header keyword.  Used to specify display formatting.

    Returns
    -------
    formatc: str
        The format characters from TDISPn
    width: str
        The width int value from TDISPn
    precision: str
        The precision int value from TDISPn
    exponential: str
        The exponential int value from TDISPn

    'u'
    Parse the ``TDISPn`` keywords for ASCII and binary tables into a
    ``(format, width, precision, exponential)`` tuple (the TDISP values
    for ASCII and binary are identical except for 'Lw',
    which is only present in BINTABLE extensions.

    Parameters
    ----------
    tdisp : str
        TDISPn FITS Header keyword.  Used to specify display formatting.

    Returns
    -------
    formatc: str
        The format characters from TDISPn
    width: str
        The width int value from TDISPn
    precision: str
        The precision int value from TDISPn
    exponential: str
        The exponential int value from TDISPn

    'b'NS'u'NS'b'formatc'u'formatc'b'exponential'u'exponential'b'
    Turn the TDISPn fortran format pieces into a final Python format string.
    See the format_type definitions above the TDISP_FMT_DICT. If codes is
    changed to take advantage of the exponential specification, will need to
    add it as another input parameter.

    Parameters
    ----------
    tdisp : str
        TDISPn FITS Header keyword.  Used to specify display formatting.

    Returns
    -------
    format_string: str
        The TDISPn keyword string translated into a Python format string.
    'u'
    Turn the TDISPn fortran format pieces into a final Python format string.
    See the format_type definitions above the TDISP_FMT_DICT. If codes is
    changed to take advantage of the exponential specification, will need to
    add it as another input parameter.

    Parameters
    ----------
    tdisp : str
        TDISPn FITS Header keyword.  Used to specify display formatting.

    Returns
    -------
    format_string: str
        The TDISPn keyword string translated into a Python format string.
    'b'
    Turn the Python format string to a TDISP FITS compliant format string. Not
    all formats convert. these will cause a Warning and return None.

    Parameters
    ----------
    format_string : str
        TDISPn FITS Header keyword.  Used to specify display formatting.
    logical_dtype : bool
        True is this format type should be a logical type, 'L'. Needs special
        handling.

    Returns
    -------
    tdsip_string: str
        The TDISPn keyword string translated into a Python format string.
    'u'
    Turn the Python format string to a TDISP FITS compliant format string. Not
    all formats convert. these will cause a Warning and return None.

    Parameters
    ----------
    format_string : str
        TDISPn FITS Header keyword.  Used to specify display formatting.
    logical_dtype : bool
        True is this format type should be a logical type, 'L'. Needs special
        handling.

    Returns
    -------
    tdsip_string: str
        The TDISPn keyword string translated into a Python format string.
    'b'o'u'o'b'{'u'{'b'{:'u'{:'b'}'u'}'b' cannot be mapped to the accepted TDISPn keyword values.  Format will not be moved into TDISPn keyword.'u' cannot be mapped to the accepted TDISPn keyword values.  Format will not be moved into TDISPn keyword.'u'astropy.io.fits.column'u'io.fits.column'u'fits.column'Implements the wrapper for the Astropy test runner.

This is for backward-compatibility for other downstream packages and can be removed
once astropy-helpers has reached end-of-life.

shutilstatsubprocesstempfilesetuptoolsCommandastropy.logger_suppress_stdout
    A context manager to temporarily disable stdout.

    Used later when installing a temporary copy of astropy to avoid a
    very verbose output.
    devnullold_stdoutFixRemoteDataOption
    This metaclass is used to catch cases where the user is running the tests
    with --remote-data. We've now changed the --remote-data option so that it
    takes arguments, but we still want --remote-data to work as before and to
    enable all remote tests. With this metaclass, we can modify sys.argv
    before setuptools try to parse the command-line options.
    dct--remote-data-R-R=anyAstropyTestRun the tests for this packagepackage=The name of a specific package to test, e.g. 'io.fits' or 'utils'. Accepts comma separated string to specify multiple packages. If nothing is specified, all default tests are run."The name of a specific package to test, e.g. 'io.fits' or 'utils'. ""Accepts comma separated string to specify multiple packages. ""If nothing is specified, all default tests are run."test-path=Specify a test location by path.  If a relative path to a  .py file, it is relative to the built package, so e.g., a  leading "astropy/" is necessary.  If a relative  path to a .rst file, it is relative to the directory *below* the --docs-path directory, so a leading "docs/" is usually necessary.  May also be an absolute path."Specify a test location by path.  If a relative path to a  .py file, "'it is relative to the built package, so e.g., a  leading "astropy/" '"is necessary.  If a relative  path to a .rst file, it is relative to ""the directory *below* the --docs-path directory, so a leading "'"docs/" is usually necessary.  May also be an absolute path.'verbose-resultsTurn on verbose output from pytest.plugins=Plugins to enable when running pytest.pastebin=Enable pytest pastebin output. Either 'all' or 'failed'.args=Additional arguments to be passed to pytest.remote-data=Run tests that download remote data. Should be one of none/astropy/any (defaults to none)."Run tests that download remote data. Should be ""one of none/astropy/any (defaults to none)."pdbStart the interactive Python debugger on errors.Create a coverage report. Requires the coverage package.parallel=Run the tests in parallel on the specified number of CPUs.  If "auto", all the cores on the machine will be used.  Requires the pytest-xdist plugin."Run the tests in parallel on the specified number of "'CPUs.  If "auto", all the cores on the machine will be '"used.  Requires the pytest-xdist plugin."docs-path=The path to the documentation .rst files.  If not provided, and the current directory contains a directory called "docs", that will be used."The path to the documentation .rst files.  If not provided, and "'the current directory contains a directory called "docs", that '"will be used."skip-docsDon't test the documentation .rst files.repeat=How many times to repeat each test (can be used to check for sporadic failures)."How many times to repeat each test (can be used to check for ""sporadic failures)."temp-root=The root directory in which to create the temporary testing files. If unspecified the system default is used (e.g. /tmp) as explained in the documentation for tempfile.mkstemp."The root directory in which to create the temporary testing files. ""If unspecified the system default is used (e.g. /tmp) as explained ""in the documentation for tempfile.mkstemp."verbose-installTurn on terminal output from the installation of astropy in a temporary folder."Turn on terminal output from the installation of astropy in a ""temporary folder."Make the temporary installation being tested read-only.user_optionspackage_nameinitialize_optionstest_pathverbose_resultspluginspastebinremote_dataparalleldocs_pathskip_docstemp_rootverbose_installfinalize_optionsgenerate_testing_command
        Build a Python script to run the tests.
        cmd_precmd_post_generate_coverage_commandsprepostimport builtins; builtins._ASTROPY_TEST_ = Trueset_flag{cmd_pre}{0}; import {1.package_name}, sys; result = ({1.package_name}.test(package={1.package!r}, test_path={1.test_path!r}, args={1.args!r}, plugins={1.plugins!r}, verbose={1.verbose_results!r}, pastebin={1.pastebin!r}, remote_data={1.remote_data!r}, pdb={1.pdb!r}, parallel={1.parallel!r}, docs_path={1.docs_path!r}, skip_docs={1.skip_docs!r}, add_local_eggs_to_path=True, repeat={1.repeat!r})); {cmd_post}sys.exit(result)"{cmd_pre}{0}; import {1.package_name}, sys; result = (""{1.package_name}.test(""package={1.package!r}, ""test_path={1.test_path!r}, ""args={1.args!r}, ""plugins={1.plugins!r}, ""verbose={1.verbose_results!r}, ""pastebin={1.pastebin!r}, ""remote_data={1.remote_data!r}, ""pdb={1.pdb!r}, ""parallel={1.parallel!r}, ""docs_path={1.docs_path!r}, ""skip_docs={1.skip_docs!r}, ""add_local_eggs_to_path=True, ""repeat={1.repeat!r})); ""{cmd_post}""sys.exit(result)"cmdRun the tests!distributioninstall_requiresfetch_build_eggsget_option_dictbuild_docssource_dircfg_docs_dirabspath_build_temp_installtests_require.eggscopytreetesting_pathchanging permissions of temporary installation to read-only_change_permissions_testing_pathPopen-ccwdclose_fdstestprocwaitretcodesignalsend_signalSIGINTrmtreetmp_dir
        Install the package and to a temporary directory for the purposes of
        testing. This allows us to test the install command, include the
        entry points, and also avoids creating pyc and __pycache__ directories
        inside the build directory.
        mkdtemp-test-realpathinstalling to temporary directory: reinitialize_commandget_command_objinstall_cmdrun_commandget_finalized_commandinstall_libbasenamenew_docs_pathS_IRUSRS_IWUSRbasic_flagsdirswalkchmodS_IXUSR
        This method creates the post and pre commands if coverage is to be
        generated.
        --coverage can not be used with --parallel--coverage requires that the coverage package is installed.coveragercfdcoveragerc_content{packagename}tmp_coveragercwbimport coverage; cov = coverage.coverage(data_file=r""import coverage; cov ="' coverage.coverage(data_file=r"'.coverage", config_file=r"'",'' config_file=r"'"); cov.start();cov.stop(); from astropy.tests.helper import _save_coverage; _save_coverage(cov, result, r""cov.stop(); from astropy.tests.helper import _save_coverage;"' _save_coverage(cov, result, r"'", r"' r"'");# Normally we would validate the options here, but that's handled in# run_tests# Commands to run before the test function# Commands to run after the test function# see _build_temp_install below# Install the runtime dependencies.# Ensure there is a doc path# Some affiliated packages use this.# See astropy/package-template#157# fall back on a default path of "docs"# Build a testing install of the package# Install the test dependencies# NOTE: we do this here after _build_temp_install because there is# a weird but which occurs if psutil is installed in this way before# astropy is built, Cython can have segmentation fault. Strange, eh?# Copy any additional dependencies that may have been installed via# tests_requires or install_requires. We then pass the# add_local_eggs_to_path=True option to package.test() to make sure the# eggs get included in the path.# This option exists so that we can make sure that the tests don't# write to an installed location.# Run everything in a try: finally: so that the tmp dir gets deleted.# Construct this modules testing command# Run the tests in a subprocess--this is necessary since# new extension modules may have appeared, and this is the# easiest way to set up a new environment# If a keyboard interrupt is handled, pass it to the test# subprocess to prompt pytest to initiate its teardown# Remove temporary directory# On OSX the default path for temp files is under /var, but in most# cases on OSX /var is actually a symlink to /private/var; ensure we# dereference that link, because pytest is very sensitive to relative# paths...# We now install the package to the temporary directory. We do this# rather than build and copy because this will ensure that e.g. entry# points work.# We now get the path to the site-packages directory that was created# inside self.tmp_dir# Ideally, docs_path is set properly in run(), but if it is still# not set here, do not pretend it is, otherwise bad things happen.# noqa: F401# Don't use get_pkg_data_filename here, because it# requires importing astropy.config and thus screwing# up coverage results for those packages.b'Implements the wrapper for the Astropy test runner.

This is for backward-compatibility for other downstream packages and can be removed
once astropy-helpers has reached end-of-life.

'u'Implements the wrapper for the Astropy test runner.

This is for backward-compatibility for other downstream packages and can be removed
once astropy-helpers has reached end-of-life.

'b'
    A context manager to temporarily disable stdout.

    Used later when installing a temporary copy of astropy to avoid a
    very verbose output.
    'u'
    A context manager to temporarily disable stdout.

    Used later when installing a temporary copy of astropy to avoid a
    very verbose output.
    'b'6.0'u'6.0'b'
    This metaclass is used to catch cases where the user is running the tests
    with --remote-data. We've now changed the --remote-data option so that it
    takes arguments, but we still want --remote-data to work as before and to
    enable all remote tests. With this metaclass, we can modify sys.argv
    before setuptools try to parse the command-line options.
    'u'
    This metaclass is used to catch cases where the user is running the tests
    with --remote-data. We've now changed the --remote-data option so that it
    takes arguments, but we still want --remote-data to work as before and to
    enable all remote tests. With this metaclass, we can modify sys.argv
    before setuptools try to parse the command-line options.
    'b'--remote-data'u'--remote-data'b'--remote-data=any'u'--remote-data=any'b'-R'b'-R=any'u'-R=any'b'Run the tests for this package'u'Run the tests for this package'b'package='u'package='b'The name of a specific package to test, e.g. 'io.fits' or 'utils'. Accepts comma separated string to specify multiple packages. If nothing is specified, all default tests are run.'u'The name of a specific package to test, e.g. 'io.fits' or 'utils'. Accepts comma separated string to specify multiple packages. If nothing is specified, all default tests are run.'b'test-path='u'test-path='b'Specify a test location by path.  If a relative path to a  .py file, it is relative to the built package, so e.g., a  leading "astropy/" is necessary.  If a relative  path to a .rst file, it is relative to the directory *below* the --docs-path directory, so a leading "docs/" is usually necessary.  May also be an absolute path.'u'Specify a test location by path.  If a relative path to a  .py file, it is relative to the built package, so e.g., a  leading "astropy/" is necessary.  If a relative  path to a .rst file, it is relative to the directory *below* the --docs-path directory, so a leading "docs/" is usually necessary.  May also be an absolute path.'b'verbose-results'u'verbose-results'b'Turn on verbose output from pytest.'u'Turn on verbose output from pytest.'b'plugins='u'plugins='b'Plugins to enable when running pytest.'u'Plugins to enable when running pytest.'b'pastebin='u'pastebin='b'Enable pytest pastebin output. Either 'all' or 'failed'.'u'Enable pytest pastebin output. Either 'all' or 'failed'.'b'args='u'args='b'Additional arguments to be passed to pytest.'u'Additional arguments to be passed to pytest.'b'remote-data='u'remote-data='b'Run tests that download remote data. Should be one of none/astropy/any (defaults to none).'u'Run tests that download remote data. Should be one of none/astropy/any (defaults to none).'b'pdb'u'pdb'b'Start the interactive Python debugger on errors.'u'Start the interactive Python debugger on errors.'b'coverage'u'coverage'b'Create a coverage report. Requires the coverage package.'u'Create a coverage report. Requires the coverage package.'b'parallel='u'parallel='b'Run the tests in parallel on the specified number of CPUs.  If "auto", all the cores on the machine will be used.  Requires the pytest-xdist plugin.'u'Run the tests in parallel on the specified number of CPUs.  If "auto", all the cores on the machine will be used.  Requires the pytest-xdist plugin.'b'docs-path='u'docs-path='b'The path to the documentation .rst files.  If not provided, and the current directory contains a directory called "docs", that will be used.'u'The path to the documentation .rst files.  If not provided, and the current directory contains a directory called "docs", that will be used.'b'skip-docs'u'skip-docs'b'Don't test the documentation .rst files.'u'Don't test the documentation .rst files.'b'repeat='u'repeat='b'How many times to repeat each test (can be used to check for sporadic failures).'u'How many times to repeat each test (can be used to check for sporadic failures).'b'temp-root='u'temp-root='b'The root directory in which to create the temporary testing files. If unspecified the system default is used (e.g. /tmp) as explained in the documentation for tempfile.mkstemp.'u'The root directory in which to create the temporary testing files. If unspecified the system default is used (e.g. /tmp) as explained in the documentation for tempfile.mkstemp.'b'verbose-install'u'verbose-install'b'Turn on terminal output from the installation of astropy in a temporary folder.'u'Turn on terminal output from the installation of astropy in a temporary folder.'b'readonly'u'readonly'b'Make the temporary installation being tested read-only.'u'Make the temporary installation being tested read-only.'b'none'u'none'b'
        Build a Python script to run the tests.
        'u'
        Build a Python script to run the tests.
        'b'import builtins; builtins._ASTROPY_TEST_ = True'u'import builtins; builtins._ASTROPY_TEST_ = True'b'{cmd_pre}{0}; import {1.package_name}, sys; result = ({1.package_name}.test(package={1.package!r}, test_path={1.test_path!r}, args={1.args!r}, plugins={1.plugins!r}, verbose={1.verbose_results!r}, pastebin={1.pastebin!r}, remote_data={1.remote_data!r}, pdb={1.pdb!r}, parallel={1.parallel!r}, docs_path={1.docs_path!r}, skip_docs={1.skip_docs!r}, add_local_eggs_to_path=True, repeat={1.repeat!r})); {cmd_post}sys.exit(result)'u'{cmd_pre}{0}; import {1.package_name}, sys; result = ({1.package_name}.test(package={1.package!r}, test_path={1.test_path!r}, args={1.args!r}, plugins={1.plugins!r}, verbose={1.verbose_results!r}, pastebin={1.pastebin!r}, remote_data={1.remote_data!r}, pdb={1.pdb!r}, parallel={1.parallel!r}, docs_path={1.docs_path!r}, skip_docs={1.skip_docs!r}, add_local_eggs_to_path=True, repeat={1.repeat!r})); {cmd_post}sys.exit(result)'b'Run the tests!'u'Run the tests!'b'build_docs'u'build_docs'b'source_dir'u'source_dir'b'docs'u'docs'b'.eggs'u'.eggs'b'changing permissions of temporary installation to read-only'u'changing permissions of temporary installation to read-only'b'-c'b'
        Install the package and to a temporary directory for the purposes of
        testing. This allows us to test the install command, include the
        entry points, and also avoids creating pyc and __pycache__ directories
        inside the build directory.
        'u'
        Install the package and to a temporary directory for the purposes of
        testing. This allows us to test the install command, include the
        entry points, and also avoids creating pyc and __pycache__ directories
        inside the build directory.
        'b'-test-'u'-test-'b'installing to temporary directory: 'u'installing to temporary directory: 'b'install'u'install'b'pyproject.toml'u'pyproject.toml'b'
        This method creates the post and pre commands if coverage is to be
        generated.
        'u'
        This method creates the post and pre commands if coverage is to be
        generated.
        'b'--coverage can not be used with --parallel'u'--coverage can not be used with --parallel'b'--coverage requires that the coverage package is installed.'u'--coverage requires that the coverage package is installed.'b'coveragerc'u'coveragerc'b'{packagename}'u'{packagename}'b'wb'u'wb'b'import coverage; cov = coverage.coverage(data_file=r"'u'import coverage; cov = coverage.coverage(data_file=r"'b'.coverage'u'.coverage'b'", config_file=r"'u'", config_file=r"'b'"); cov.start();'u'"); cov.start();'b'cov.stop(); from astropy.tests.helper import _save_coverage; _save_coverage(cov, result, r"'u'cov.stop(); from astropy.tests.helper import _save_coverage; _save_coverage(cov, result, r"'b'", r"'u'", r"'b'");'u'");'u'astropy.tests.command'u'tests.command'u'command'setup_functionteardown_functionCWDTEST_DIRchdirassert_equal_splitlinesarg1arg2b'setup_function'u'setup_function'b'teardown_function'u'teardown_function'u'io.ascii.tests.common'u'ascii.tests.common'u'tests.common'u'common'Comparison functions for `astropy.cosmology.Cosmology`.

This module is **NOT** public API. To use these functions, import them from
the top-level namespace -- :mod:`astropy.cosmology`. This module will be
moved.
dataclassTrue_TypeAlias_FormatType_FormatsType_COSMO_AOK_CANT_BROADCASTThings that cannot broadcast.

Have to deal with things that do not broadcast well. e.g.
`~astropy.table.Row` cannot be used in an array, even if ``dtype=object``
and will raise a segfault when used in a `numpy.ufunc`.
frozen_CosmologyWrapperA private wrapper class to hide things from :mod:`numpy`.

    This should never be exposed to the user.
    wrappedpartialfrompyfuncnout_parse_formatParse Cosmology-like input into Cosmologies, given a format hint.

    Parameters
    ----------
    cosmo : |Cosmology|-like, positional-only
        |Cosmology| to parse.
    format : bool or None or str, positional-only
        Whether to allow, before equivalence is checked, the object to be
        converted to a |Cosmology|. This allows, e.g. a |Table| to be equivalent
        to a |Cosmology|. `False` (default) will not allow conversion. `True` or
        `None` will, and will use the auto-identification to try to infer the
        correct format. A `str` is assumed to be the correct format to use when
        converting.

    Returns
    -------
    |Cosmology| or generator thereof

    Raises
    ------
    TypeError
        If ``cosmo`` is not a |Cosmology| and ``format`` equals `False`.
    TypeError
        If ``cosmo`` is a |Cosmology| and ``format`` is not `None` or equal to
        `True`.
    for parsing a Cosmology, 'format' must be , not if 'format' is False, arguments must be a Cosmology, not _parse_formatscosmosParse Cosmology-like to |Cosmology|, using provided formats.

    ``format`` is broadcast to match the shape of the cosmology arguments. Note
    that the cosmology arguments are not broadcast against ``format``, so it
    cannot determine the output shape.

    Parameters
    ----------
    *cosmos : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by the corresponding ``format``.

    format : bool or None or str or array-like thereof, positional-only
        Whether to allow, before equivalence is checked, the object to be
        converted to a |Cosmology|. This allows, e.g. a |Table| to be equivalent
        to a |Cosmology|. `False` (default) will not allow conversion. `True` or
        `None` will, and will use the auto-identification to try to infer the
        correct format. A `str` is assumed to be the correct format to use when
        converting. Note ``format`` is broadcast as an object array to match the
        shape of ``cosmos`` so ``format`` cannot determine the output shape.

    Raises
    ------
    TypeError
        If any in ``cosmos`` is not a |Cosmology| and the corresponding
        ``format`` equals `False`.
    wcosmos_comparison_decoratorpyfuncDecorator to make wrapper function that parses |Cosmology|-like inputs.

    Parameters
    ----------
    pyfunc : Python function object
        An arbitrary Python function.

    Returns
    -------
    callable[..., Any]
        Wrapped `pyfunc`, as described above.

    Notes
    -----
    All decorated functions should add the following to 'Parameters'.

    format : bool or None or str or array-like thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a |Cosmology|. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. Note ``format``
        is broadcast as an object array to match the shape of ``cosmos`` so
        ``format`` cannot determine the output shape.
    wrapper takes  positional arguments but " positional"" arguments but " were givencosmo1cosmo2allow_equivalentReturn element-wise equality check on the cosmologies.

    .. note::

        Cosmologies are currently scalar in their parameters.

    Parameters
    ----------
    cosmo1, cosmo2 : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by ``format``.

    format : bool or None or str or tuple thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a |Cosmology|. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. Note ``format``
        is broadcast as an object array to match the shape of ``cosmos`` so
        ``format`` cannot determine the output shape.

    allow_equivalent : bool, optional keyword-only
        Whether to allow cosmologies to be equal even if not of the same class.
        For example, an instance of |LambdaCDM| might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like |FlatLambdaCDM|.

    Examples
    --------
    Assuming the following imports

        >>> import astropy.units as u
        >>> from astropy.cosmology import FlatLambdaCDM

    Two identical cosmologies are equal.

        >>> cosmo1 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
        >>> cosmo2 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
        >>> cosmology_equal(cosmo1, cosmo2)
        True

    And cosmologies with different parameters are not.

        >>> cosmo3 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.4)
        >>> cosmology_equal(cosmo1, cosmo3)
        False

    Two cosmologies may be equivalent even if not of the same class. In these
    examples the |LambdaCDM| has :attr:`~astropy.cosmology.LambdaCDM.Ode0` set
    to the same value calculated in |FlatLambdaCDM|.

        >>> from astropy.cosmology import LambdaCDM
        >>> cosmo3 = LambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, 0.7)
        >>> cosmology_equal(cosmo1, cosmo3)
        False
        >>> cosmology_equal(cosmo1, cosmo3, allow_equivalent=True)
        True

    While in this example, the cosmologies are not equivalent.

        >>> cosmo4 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, Tcmb0=3 * u.K)
        >>> cosmology_equal(cosmo3, cosmo4, allow_equivalent=True)
        False

    Also, using the keyword argument, the notion of equality is extended to any
    Python object that can be converted to a |Cosmology|.

        >>> mapping = cosmo2.to_format("mapping")
        >>> cosmology_equal(cosmo1, mapping, format=True)
        True

    Either (or both) arguments can be |Cosmology|-like.

        >>> cosmology_equal(mapping, cosmo2, format=True)
        True

    The list of valid formats, e.g. the |Table| in this example, may be checked
    with ``Cosmology.from_format.list_formats()``.

    As can be seen in the list of formats, not all formats can be
    auto-identified by ``Cosmology.from_format.registry``. Objects of these
    kinds can still be checked for equality, but the correct format string must
    be used.

        >>> yml = cosmo2.to_format("yaml")
        >>> cosmology_equal(cosmo1, yml, format=(None, "yaml"))
        True

    This also works with an array of ``format`` matching the number of
    cosmologies.

        >>> cosmology_equal(mapping, yml, format=[True, "yaml"])
        True
    eq__equiv___cosmology_not_equalReturn element-wise cosmology non-equality check.

    .. note::

        Cosmologies are currently scalar in their parameters.

    Parameters
    ----------
    cosmo1, cosmo2 : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by ``format``.

    out : ndarray, None, optional
        A location into which the result is stored. If provided, it must have a
        shape that the inputs broadcast to. If not provided or None, a
        freshly-allocated array is returned.

    format : bool or None or str or tuple thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a Cosmology. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. ``format`` is
        broadcast to match the shape of the cosmology arguments. Note that the
        cosmology arguments are not broadcast against ``format``, so it cannot
        determine the output shape.

    allow_equivalent : bool, optional keyword-only
        Whether to allow cosmologies to be equal even if not of the same class.
        For example, an instance of |LambdaCDM| might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like |FlatLambdaCDM|.

    See Also
    --------
    astropy.cosmology.cosmology_equal
        Element-wise equality check, with argument conversion to Cosmology.
    neq# Nothing is scoped here# PARAMETERS# The numpy bool also catches real bool for ops "==" and "in"# UTILITIES# Deal with private wrapper# Shortcut if already a cosmology# Convert, if allowed.# catches False and False_# str->str, None/True/True_->None# this can error!# parse each cosmo & format# Have to deal with things that do not broadcast well.# astropy.row cannot be used in an array, even if dtype=object# and will raise a segfault when used in a ufunc.# Make wrapper function that parses cosmology-like inputs# Parse cosmologies to format. Only do specified number.# Evaluate pyfunc, erroring if didn't match specified number.# Return, casting to correct type casting is possible.# COMPARISON FUNCTIONS# Check parameter equality# Check parameter equivalence# The options are: 1) same class & parameters; 2) same class, different# parameters; 3) different classes, equivalent parameters; 4) different# classes, different parameters. (1) & (3) => True, (2) & (4) => False.# that failed, try from 'other'# TODO! include equality check of metadata# TODO! it might eventually be worth the speed boost to implement some of#       the internals of cosmology_equal here, but for now it's a hassle.b'Comparison functions for `astropy.cosmology.Cosmology`.

This module is **NOT** public API. To use these functions, import them from
the top-level namespace -- :mod:`astropy.cosmology`. This module will be
moved.
'u'Comparison functions for `astropy.cosmology.Cosmology`.

This module is **NOT** public API. To use these functions, import them from
the top-level namespace -- :mod:`astropy.cosmology`. This module will be
moved.
'b'astropy.cosmology'b'Things that cannot broadcast.

Have to deal with things that do not broadcast well. e.g.
`~astropy.table.Row` cannot be used in an array, even if ``dtype=object``
and will raise a segfault when used in a `numpy.ufunc`.
'u'Things that cannot broadcast.

Have to deal with things that do not broadcast well. e.g.
`~astropy.table.Row` cannot be used in an array, even if ``dtype=object``
and will raise a segfault when used in a `numpy.ufunc`.
'b'A private wrapper class to hide things from :mod:`numpy`.

    This should never be exposed to the user.
    'u'A private wrapper class to hide things from :mod:`numpy`.

    This should never be exposed to the user.
    'b'wrapped'u'wrapped'b'Parse Cosmology-like input into Cosmologies, given a format hint.

    Parameters
    ----------
    cosmo : |Cosmology|-like, positional-only
        |Cosmology| to parse.
    format : bool or None or str, positional-only
        Whether to allow, before equivalence is checked, the object to be
        converted to a |Cosmology|. This allows, e.g. a |Table| to be equivalent
        to a |Cosmology|. `False` (default) will not allow conversion. `True` or
        `None` will, and will use the auto-identification to try to infer the
        correct format. A `str` is assumed to be the correct format to use when
        converting.

    Returns
    -------
    |Cosmology| or generator thereof

    Raises
    ------
    TypeError
        If ``cosmo`` is not a |Cosmology| and ``format`` equals `False`.
    TypeError
        If ``cosmo`` is a |Cosmology| and ``format`` is not `None` or equal to
        `True`.
    'u'Parse Cosmology-like input into Cosmologies, given a format hint.

    Parameters
    ----------
    cosmo : |Cosmology|-like, positional-only
        |Cosmology| to parse.
    format : bool or None or str, positional-only
        Whether to allow, before equivalence is checked, the object to be
        converted to a |Cosmology|. This allows, e.g. a |Table| to be equivalent
        to a |Cosmology|. `False` (default) will not allow conversion. `True` or
        `None` will, and will use the auto-identification to try to infer the
        correct format. A `str` is assumed to be the correct format to use when
        converting.

    Returns
    -------
    |Cosmology| or generator thereof

    Raises
    ------
    TypeError
        If ``cosmo`` is not a |Cosmology| and ``format`` equals `False`.
    TypeError
        If ``cosmo`` is a |Cosmology| and ``format`` is not `None` or equal to
        `True`.
    'b'for parsing a Cosmology, 'format' must be 'u'for parsing a Cosmology, 'format' must be 'b', not 'u', not 'b'if 'format' is False, arguments must be a Cosmology, not 'u'if 'format' is False, arguments must be a Cosmology, not 'b'Parse Cosmology-like to |Cosmology|, using provided formats.

    ``format`` is broadcast to match the shape of the cosmology arguments. Note
    that the cosmology arguments are not broadcast against ``format``, so it
    cannot determine the output shape.

    Parameters
    ----------
    *cosmos : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by the corresponding ``format``.

    format : bool or None or str or array-like thereof, positional-only
        Whether to allow, before equivalence is checked, the object to be
        converted to a |Cosmology|. This allows, e.g. a |Table| to be equivalent
        to a |Cosmology|. `False` (default) will not allow conversion. `True` or
        `None` will, and will use the auto-identification to try to infer the
        correct format. A `str` is assumed to be the correct format to use when
        converting. Note ``format`` is broadcast as an object array to match the
        shape of ``cosmos`` so ``format`` cannot determine the output shape.

    Raises
    ------
    TypeError
        If any in ``cosmos`` is not a |Cosmology| and the corresponding
        ``format`` equals `False`.
    'u'Parse Cosmology-like to |Cosmology|, using provided formats.

    ``format`` is broadcast to match the shape of the cosmology arguments. Note
    that the cosmology arguments are not broadcast against ``format``, so it
    cannot determine the output shape.

    Parameters
    ----------
    *cosmos : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by the corresponding ``format``.

    format : bool or None or str or array-like thereof, positional-only
        Whether to allow, before equivalence is checked, the object to be
        converted to a |Cosmology|. This allows, e.g. a |Table| to be equivalent
        to a |Cosmology|. `False` (default) will not allow conversion. `True` or
        `None` will, and will use the auto-identification to try to infer the
        correct format. A `str` is assumed to be the correct format to use when
        converting. Note ``format`` is broadcast as an object array to match the
        shape of ``cosmos`` so ``format`` cannot determine the output shape.

    Raises
    ------
    TypeError
        If any in ``cosmos`` is not a |Cosmology| and the corresponding
        ``format`` equals `False`.
    'b'Decorator to make wrapper function that parses |Cosmology|-like inputs.

    Parameters
    ----------
    pyfunc : Python function object
        An arbitrary Python function.

    Returns
    -------
    callable[..., Any]
        Wrapped `pyfunc`, as described above.

    Notes
    -----
    All decorated functions should add the following to 'Parameters'.

    format : bool or None or str or array-like thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a |Cosmology|. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. Note ``format``
        is broadcast as an object array to match the shape of ``cosmos`` so
        ``format`` cannot determine the output shape.
    'u'Decorator to make wrapper function that parses |Cosmology|-like inputs.

    Parameters
    ----------
    pyfunc : Python function object
        An arbitrary Python function.

    Returns
    -------
    callable[..., Any]
        Wrapped `pyfunc`, as described above.

    Notes
    -----
    All decorated functions should add the following to 'Parameters'.

    format : bool or None or str or array-like thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a |Cosmology|. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. Note ``format``
        is broadcast as an object array to match the shape of ``cosmos`` so
        ``format`` cannot determine the output shape.
    'b' takes 'u' takes 'b' positional arguments but 'u' positional arguments but 'b' were given'u' were given'b'Return element-wise equality check on the cosmologies.

    .. note::

        Cosmologies are currently scalar in their parameters.

    Parameters
    ----------
    cosmo1, cosmo2 : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by ``format``.

    format : bool or None or str or tuple thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a |Cosmology|. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. Note ``format``
        is broadcast as an object array to match the shape of ``cosmos`` so
        ``format`` cannot determine the output shape.

    allow_equivalent : bool, optional keyword-only
        Whether to allow cosmologies to be equal even if not of the same class.
        For example, an instance of |LambdaCDM| might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like |FlatLambdaCDM|.

    Examples
    --------
    Assuming the following imports

        >>> import astropy.units as u
        >>> from astropy.cosmology import FlatLambdaCDM

    Two identical cosmologies are equal.

        >>> cosmo1 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
        >>> cosmo2 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
        >>> cosmology_equal(cosmo1, cosmo2)
        True

    And cosmologies with different parameters are not.

        >>> cosmo3 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.4)
        >>> cosmology_equal(cosmo1, cosmo3)
        False

    Two cosmologies may be equivalent even if not of the same class. In these
    examples the |LambdaCDM| has :attr:`~astropy.cosmology.LambdaCDM.Ode0` set
    to the same value calculated in |FlatLambdaCDM|.

        >>> from astropy.cosmology import LambdaCDM
        >>> cosmo3 = LambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, 0.7)
        >>> cosmology_equal(cosmo1, cosmo3)
        False
        >>> cosmology_equal(cosmo1, cosmo3, allow_equivalent=True)
        True

    While in this example, the cosmologies are not equivalent.

        >>> cosmo4 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, Tcmb0=3 * u.K)
        >>> cosmology_equal(cosmo3, cosmo4, allow_equivalent=True)
        False

    Also, using the keyword argument, the notion of equality is extended to any
    Python object that can be converted to a |Cosmology|.

        >>> mapping = cosmo2.to_format("mapping")
        >>> cosmology_equal(cosmo1, mapping, format=True)
        True

    Either (or both) arguments can be |Cosmology|-like.

        >>> cosmology_equal(mapping, cosmo2, format=True)
        True

    The list of valid formats, e.g. the |Table| in this example, may be checked
    with ``Cosmology.from_format.list_formats()``.

    As can be seen in the list of formats, not all formats can be
    auto-identified by ``Cosmology.from_format.registry``. Objects of these
    kinds can still be checked for equality, but the correct format string must
    be used.

        >>> yml = cosmo2.to_format("yaml")
        >>> cosmology_equal(cosmo1, yml, format=(None, "yaml"))
        True

    This also works with an array of ``format`` matching the number of
    cosmologies.

        >>> cosmology_equal(mapping, yml, format=[True, "yaml"])
        True
    'u'Return element-wise equality check on the cosmologies.

    .. note::

        Cosmologies are currently scalar in their parameters.

    Parameters
    ----------
    cosmo1, cosmo2 : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by ``format``.

    format : bool or None or str or tuple thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a |Cosmology|. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. Note ``format``
        is broadcast as an object array to match the shape of ``cosmos`` so
        ``format`` cannot determine the output shape.

    allow_equivalent : bool, optional keyword-only
        Whether to allow cosmologies to be equal even if not of the same class.
        For example, an instance of |LambdaCDM| might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like |FlatLambdaCDM|.

    Examples
    --------
    Assuming the following imports

        >>> import astropy.units as u
        >>> from astropy.cosmology import FlatLambdaCDM

    Two identical cosmologies are equal.

        >>> cosmo1 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
        >>> cosmo2 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
        >>> cosmology_equal(cosmo1, cosmo2)
        True

    And cosmologies with different parameters are not.

        >>> cosmo3 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.4)
        >>> cosmology_equal(cosmo1, cosmo3)
        False

    Two cosmologies may be equivalent even if not of the same class. In these
    examples the |LambdaCDM| has :attr:`~astropy.cosmology.LambdaCDM.Ode0` set
    to the same value calculated in |FlatLambdaCDM|.

        >>> from astropy.cosmology import LambdaCDM
        >>> cosmo3 = LambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, 0.7)
        >>> cosmology_equal(cosmo1, cosmo3)
        False
        >>> cosmology_equal(cosmo1, cosmo3, allow_equivalent=True)
        True

    While in this example, the cosmologies are not equivalent.

        >>> cosmo4 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, Tcmb0=3 * u.K)
        >>> cosmology_equal(cosmo3, cosmo4, allow_equivalent=True)
        False

    Also, using the keyword argument, the notion of equality is extended to any
    Python object that can be converted to a |Cosmology|.

        >>> mapping = cosmo2.to_format("mapping")
        >>> cosmology_equal(cosmo1, mapping, format=True)
        True

    Either (or both) arguments can be |Cosmology|-like.

        >>> cosmology_equal(mapping, cosmo2, format=True)
        True

    The list of valid formats, e.g. the |Table| in this example, may be checked
    with ``Cosmology.from_format.list_formats()``.

    As can be seen in the list of formats, not all formats can be
    auto-identified by ``Cosmology.from_format.registry``. Objects of these
    kinds can still be checked for equality, but the correct format string must
    be used.

        >>> yml = cosmo2.to_format("yaml")
        >>> cosmology_equal(cosmo1, yml, format=(None, "yaml"))
        True

    This also works with an array of ``format`` matching the number of
    cosmologies.

        >>> cosmology_equal(mapping, yml, format=[True, "yaml"])
        True
    'b'Return element-wise cosmology non-equality check.

    .. note::

        Cosmologies are currently scalar in their parameters.

    Parameters
    ----------
    cosmo1, cosmo2 : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by ``format``.

    out : ndarray, None, optional
        A location into which the result is stored. If provided, it must have a
        shape that the inputs broadcast to. If not provided or None, a
        freshly-allocated array is returned.

    format : bool or None or str or tuple thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a Cosmology. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. ``format`` is
        broadcast to match the shape of the cosmology arguments. Note that the
        cosmology arguments are not broadcast against ``format``, so it cannot
        determine the output shape.

    allow_equivalent : bool, optional keyword-only
        Whether to allow cosmologies to be equal even if not of the same class.
        For example, an instance of |LambdaCDM| might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like |FlatLambdaCDM|.

    See Also
    --------
    astropy.cosmology.cosmology_equal
        Element-wise equality check, with argument conversion to Cosmology.
    'u'Return element-wise cosmology non-equality check.

    .. note::

        Cosmologies are currently scalar in their parameters.

    Parameters
    ----------
    cosmo1, cosmo2 : |Cosmology|-like
        The objects to compare. Must be convertible to |Cosmology|, as specified
        by ``format``.

    out : ndarray, None, optional
        A location into which the result is stored. If provided, it must have a
        shape that the inputs broadcast to. If not provided or None, a
        freshly-allocated array is returned.

    format : bool or None or str or tuple thereof, optional keyword-only
        Whether to allow the arguments to be converted to a |Cosmology|. This
        allows, e.g. a |Table| to be given instead a Cosmology. `False`
        (default) will not allow conversion. `True` or `None` will, and will use
        the auto-identification to try to infer the correct format. A `str` is
        assumed to be the correct format to use when converting. ``format`` is
        broadcast to match the shape of the cosmology arguments. Note that the
        cosmology arguments are not broadcast against ``format``, so it cannot
        determine the output shape.

    allow_equivalent : bool, optional keyword-only
        Whether to allow cosmologies to be equal even if not of the same class.
        For example, an instance of |LambdaCDM| might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like |FlatLambdaCDM|.

    See Also
    --------
    astropy.cosmology.cosmology_equal
        Element-wise equality check, with argument conversion to Cosmology.
    'u'cosmology._src.funcs.comparison'u'_src.funcs.comparison'u'funcs.comparison'u'comparison'FlagCollectionNDArithmeticMixinNDIOMixinNDSlicingMixinNDData
    An ``NDData`` object with arithmetic. This class is functionally equivalent
    to ``NDData`` in astropy  versions prior to 1.0.

    The key distinction from raw numpy arrays is the presence of
    additional metadata such as uncertainties, a mask, units, flags,
    and/or a coordinate system.

    See also: https://docs.astropy.org/en/stable/nddata/

    Parameters
    ----------
    data : ndarray or `NDData`
        The actual data contained in this `NDData` object. Not that this
        will always be copies by *reference* , so you should make copy
        the ``data`` before passing it in if that's the  desired behavior.

    uncertainty : `~astropy.nddata.NDUncertainty`, optional
        Uncertainties on the data.

    mask : array-like, optional
        Mask for the data, given as a boolean Numpy array or any object that
        can be converted to a boolean Numpy array with a shape
        matching that of the data. The values must be ``False`` where
        the data is *valid* and ``True`` when it is not (like Numpy
        masked arrays). If ``data`` is a numpy masked array, providing
        ``mask`` here will causes the mask from the masked array to be
        ignored.

    flags : array-like or `~astropy.nddata.FlagCollection`, optional
        Flags giving information about each pixel. These can be specified
        either as a Numpy array of any type (or an object which can be converted
        to a Numpy array) with a shape matching that of the
        data, or as a `~astropy.nddata.FlagCollection` instance which has a
        shape matching that of the data.

    wcs : None, optional
        WCS-object containing the world coordinate system for the data.

        .. warning::
            This is not yet defined because the discussion of how best to
            represent this class's WCS system generically is still under
            consideration. For now just leave it as None

    meta : `dict`-like object, optional
        Metadata for this object.  "Metadata" here means all information that
        is included with this object but not part of any other attribute
        of this particular object.  e.g., creation date, unique identifier,
        simulation parameters, exposure time, telescope name, etc.

    unit : `~astropy.units.UnitBase` instance or str, optional
        The units of the data.


    Raises
    ------
    ValueError :
        If the `uncertainty` or `mask` inputs cannot be broadcast (e.g., match
        shape) onto ``data``.
    Overwriting NDDataArrays's current flags with specified flagsclass_nameCannot assign an uncertainty with unit to "Cannot assign an uncertainty with unit ""to " without a unit" without ""a unit"Uncertainty must be an instance of a NDUncertainty objectSetting the unit directly changes the unit without updating the data or uncertainty. Use the .convert_unit_to() method to change the unit and scale values appropriately."Setting the unit directly changes the unit without ""updating the data or uncertainty. Use the "".convert_unit_to() method to change the unit and ""scale values appropriately."dimensions of mask  and data  do not match
        shape tuple of this object's data.
        
        integer size of this object's data.
        
        `numpy.dtype` of this object's data.
        
        integer dimensions of this object's data.
        _flagsdimensions of FlagCollection does not match datadimensions of flags do not match data__array__
        This allows code that requests a Numpy array to use an NDData
        object as a Numpy array.
        masked_array
        This ensures that a masked array is returned if self is masked.
        
        Returns a new `NDData` object whose values have been converted
        to a new unit.

        Parameters
        ----------
        unit : `astropy.units.UnitBase` instance or str
            The unit to convert to.

        equivalencies : list of tuple
           A list of equivalence pairs to try if the units are not
           directly convertible.  See :ref:`astropy:unit_equivalencies`.

        Returns
        -------
        result : `~astropy.nddata.NDData`
            The resulting dataset

        Raises
        ------
        `~astropy.units.UnitsError`
            If units are inconsistent.

        No unit specified on source datauncertainty_values# This module contains a class equivalent to pre-1.0 NDData.# Initialize with the parent...# ...then reset uncertainty to force it to go through the# setter logic below. In base NDData all that is done is to# set self._uncertainty to whatever uncertainty is passed in.# Same thing for mask.# Initial flags because it is no longer handled in NDData# or NDDataBase.# Implement uncertainty as NDUncertainty to support propagation of# uncertainties in arithmetic operations# Raise an error if uncertainty has unit and data does not# Override unit so that we can add a setter.# raised if self._unit has not been set yet, in which case the# warning is irrelevant# Implement mask in a way that converts nicely to a numpy masked array# Check that value is not either type of null mask.# internal representation should be one numpy understands# should work for any uncertainty class# Call __class__ in case we are dealing with an inherited typeb'NDDataArray'u'NDDataArray'b'
    An ``NDData`` object with arithmetic. This class is functionally equivalent
    to ``NDData`` in astropy  versions prior to 1.0.

    The key distinction from raw numpy arrays is the presence of
    additional metadata such as uncertainties, a mask, units, flags,
    and/or a coordinate system.

    See also: https://docs.astropy.org/en/stable/nddata/

    Parameters
    ----------
    data : ndarray or `NDData`
        The actual data contained in this `NDData` object. Not that this
        will always be copies by *reference* , so you should make copy
        the ``data`` before passing it in if that's the  desired behavior.

    uncertainty : `~astropy.nddata.NDUncertainty`, optional
        Uncertainties on the data.

    mask : array-like, optional
        Mask for the data, given as a boolean Numpy array or any object that
        can be converted to a boolean Numpy array with a shape
        matching that of the data. The values must be ``False`` where
        the data is *valid* and ``True`` when it is not (like Numpy
        masked arrays). If ``data`` is a numpy masked array, providing
        ``mask`` here will causes the mask from the masked array to be
        ignored.

    flags : array-like or `~astropy.nddata.FlagCollection`, optional
        Flags giving information about each pixel. These can be specified
        either as a Numpy array of any type (or an object which can be converted
        to a Numpy array) with a shape matching that of the
        data, or as a `~astropy.nddata.FlagCollection` instance which has a
        shape matching that of the data.

    wcs : None, optional
        WCS-object containing the world coordinate system for the data.

        .. warning::
            This is not yet defined because the discussion of how best to
            represent this class's WCS system generically is still under
            consideration. For now just leave it as None

    meta : `dict`-like object, optional
        Metadata for this object.  "Metadata" here means all information that
        is included with this object but not part of any other attribute
        of this particular object.  e.g., creation date, unique identifier,
        simulation parameters, exposure time, telescope name, etc.

    unit : `~astropy.units.UnitBase` instance or str, optional
        The units of the data.


    Raises
    ------
    ValueError :
        If the `uncertainty` or `mask` inputs cannot be broadcast (e.g., match
        shape) onto ``data``.
    'u'
    An ``NDData`` object with arithmetic. This class is functionally equivalent
    to ``NDData`` in astropy  versions prior to 1.0.

    The key distinction from raw numpy arrays is the presence of
    additional metadata such as uncertainties, a mask, units, flags,
    and/or a coordinate system.

    See also: https://docs.astropy.org/en/stable/nddata/

    Parameters
    ----------
    data : ndarray or `NDData`
        The actual data contained in this `NDData` object. Not that this
        will always be copies by *reference* , so you should make copy
        the ``data`` before passing it in if that's the  desired behavior.

    uncertainty : `~astropy.nddata.NDUncertainty`, optional
        Uncertainties on the data.

    mask : array-like, optional
        Mask for the data, given as a boolean Numpy array or any object that
        can be converted to a boolean Numpy array with a shape
        matching that of the data. The values must be ``False`` where
        the data is *valid* and ``True`` when it is not (like Numpy
        masked arrays). If ``data`` is a numpy masked array, providing
        ``mask`` here will causes the mask from the masked array to be
        ignored.

    flags : array-like or `~astropy.nddata.FlagCollection`, optional
        Flags giving information about each pixel. These can be specified
        either as a Numpy array of any type (or an object which can be converted
        to a Numpy array) with a shape matching that of the
        data, or as a `~astropy.nddata.FlagCollection` instance which has a
        shape matching that of the data.

    wcs : None, optional
        WCS-object containing the world coordinate system for the data.

        .. warning::
            This is not yet defined because the discussion of how best to
            represent this class's WCS system generically is still under
            consideration. For now just leave it as None

    meta : `dict`-like object, optional
        Metadata for this object.  "Metadata" here means all information that
        is included with this object but not part of any other attribute
        of this particular object.  e.g., creation date, unique identifier,
        simulation parameters, exposure time, telescope name, etc.

    unit : `~astropy.units.UnitBase` instance or str, optional
        The units of the data.


    Raises
    ------
    ValueError :
        If the `uncertainty` or `mask` inputs cannot be broadcast (e.g., match
        shape) onto ``data``.
    'b'Overwriting NDDataArrays's current flags with specified flags'u'Overwriting NDDataArrays's current flags with specified flags'b'Cannot assign an uncertainty with unit to 'u'Cannot assign an uncertainty with unit to 'b' without a unit'u' without a unit'b'Uncertainty must be an instance of a NDUncertainty object'u'Uncertainty must be an instance of a NDUncertainty object'b'Setting the unit directly changes the unit without updating the data or uncertainty. Use the .convert_unit_to() method to change the unit and scale values appropriately.'u'Setting the unit directly changes the unit without updating the data or uncertainty. Use the .convert_unit_to() method to change the unit and scale values appropriately.'b'dimensions of mask 'u'dimensions of mask 'b' and data 'u' and data 'b' do not match'u' do not match'b'
        shape tuple of this object's data.
        'u'
        shape tuple of this object's data.
        'b'
        integer size of this object's data.
        'u'
        integer size of this object's data.
        'b'
        `numpy.dtype` of this object's data.
        'u'
        `numpy.dtype` of this object's data.
        'b'
        integer dimensions of this object's data.
        'u'
        integer dimensions of this object's data.
        'b'dimensions of FlagCollection does not match data'u'dimensions of FlagCollection does not match data'b'dimensions of flags do not match data'u'dimensions of flags do not match data'b'
        This allows code that requests a Numpy array to use an NDData
        object as a Numpy array.
        'u'
        This allows code that requests a Numpy array to use an NDData
        object as a Numpy array.
        'b'
        This ensures that a masked array is returned if self is masked.
        'u'
        This ensures that a masked array is returned if self is masked.
        'b'
        Returns a new `NDData` object whose values have been converted
        to a new unit.

        Parameters
        ----------
        unit : `astropy.units.UnitBase` instance or str
            The unit to convert to.

        equivalencies : list of tuple
           A list of equivalence pairs to try if the units are not
           directly convertible.  See :ref:`astropy:unit_equivalencies`.

        Returns
        -------
        result : `~astropy.nddata.NDData`
            The resulting dataset

        Raises
        ------
        `~astropy.units.UnitsError`
            If units are inconsistent.

        'u'
        Returns a new `NDData` object whose values have been converted
        to a new unit.

        Parameters
        ----------
        unit : `astropy.units.UnitBase` instance or str
            The unit to convert to.

        equivalencies : list of tuple
           A list of equivalence pairs to try if the units are not
           directly convertible.  See :ref:`astropy:unit_equivalencies`.

        Returns
        -------
        result : `~astropy.nddata.NDData`
            The resulting dataset

        Raises
        ------
        `~astropy.units.UnitsError`
            If units are inconsistent.

        'b'No unit specified on source data'u'No unit specified on source data'u'astropy.nddata.compat'u'nddata.compat'UnifiedIORegistryunregister_readerunregister_writerdefault_registry_make_io_funcmethod_nameMakes a function for a method on UnifiedIORegistry.

    .. todo::

        Make kwarg "registry" not hidden.

    Returns
    -------
    wrapper : callable
        Signature matches method on UnifiedIORegistry.
        Accepts (hidden) kwarg "registry". default is ``default_registry``.
    dir_out# noqa: F822# make a default global-state registry  (not publicly scoped, but often accessed)# this is for backward compatibility when ``io.registry`` was a file.# also need to expose the enclosed registries# written this way in case ever controlled by ScienceState# get and call bound method from registry instance# =============================================================================# JIT function creation and lookup (PEP 562)b'delay_doc_updates'u'delay_doc_updates'b'get_formats'u'get_formats'b'get_reader'u'get_reader'b'get_writer'u'get_writer'b'identify_format'u'identify_format'b'register_identifier'u'register_identifier'b'register_reader'u'register_reader'b'register_writer'u'register_writer'b'unregister_identifier'u'unregister_identifier'b'unregister_reader'u'unregister_reader'b'unregister_writer'u'unregister_writer'b'Makes a function for a method on UnifiedIORegistry.

    .. todo::

        Make kwarg "registry" not hidden.

    Returns
    -------
    wrapper : callable
        Signature matches method on UnifiedIORegistry.
        Accepts (hidden) kwarg "registry". default is ``default_registry``.
    'u'Makes a function for a method on UnifiedIORegistry.

    .. todo::

        Make kwarg "registry" not hidden.

    Returns
    -------
    wrapper : callable
        Signature matches method on UnifiedIORegistry.
        Accepts (hidden) kwarg "registry". default is ``default_registry``.
    'u'astropy.io.registry.compat'u'io.registry.compat'u'registry.compat'astropy.io.fits.hdu.table_CompBinTableHDU_load_variable_length_data
    We don't want to always load all the tiles so by setting this option
    we can then access the tiles as needed.
    _manages_own_heapb'_CompBinTableHDU'u'_CompBinTableHDU'b'
    We don't want to always load all the tiles so by setting this option
    we can then access the tiles as needed.
    'u'
    We don't want to always load all the tiles so by setting this option
    we can then access the tiles as needed.
    'u'fits.hdu.compressed.compbintable'u'hdu.compressed.compbintable'u'compressed.compbintable'u'compbintable'Module defining the class for a composited sequence of coordinate transformations.

This module contains the class :class:`~astropy.coordinates.CompositeTransform` that
combines a sequence of transformations into a single transformation. The class has the
same API as a single-step transformation, so it can be used interchangeably with a
single-step transformation.
astropy.coordinates.transformations.affineastropy.coordinates.transformations.functionCompositeTransform
    A transformation constructed by combining together a series of single-step
    transformations.

    Note that the intermediate frame objects are constructed using any frame
    attributes in ``toframe`` or ``fromframe`` that overlap with the intermediate
    frame (``toframe`` favored over ``fromframe`` if there's a conflict).  Any frame
    attributes that are not present use the defaults.

    Parameters
    ----------
    transforms : sequence of `~astropy.coordinates.CoordinateTransform` object
        The sequence of transformations to apply.
    fromsys : class
        The coordinate frame class to start from.
    tosys : class
        The coordinate frame class to transform into.
    priority : float or int
        The priority if this transform when finding the shortest
        coordinate transform path - large numbers are lower priorities.
    register_graph : `~astropy.coordinates.TransformGraph` or None
        A graph to register this transformation with on creation, or
        `None` to leave it unregistered.
    collapse_static_mats : bool
        If `True`, consecutive `~astropy.coordinates.StaticMatrixTransform`
        will be collapsed into a single transformation to speed up the
        calculation.

    collapse_static_mats_combine_statics
        Combines together sequences of StaticMatrixTransform's into a single
        transform and returns it.
        newtranscurrtranslasttranscurr_coordfrattrsinter_frame_attr_nmcurr_toframe_as_single_transform
        Return an encapsulated version of the composite transform so that it appears to
        be a single transform.

        The returned transform internally calls the constituent transforms.  If all of
        the transforms are affine, the merged transform is
        `~astropy.coordinates.DynamicMatrixTransform` (if there are no
        origin shifts) or `~astropy.coordinates.AffineTransform`
        (otherwise).  If at least one of the transforms is not affine, the merged
        transform is
        `~astropy.coordinates.FunctionTransformWithFiniteDifference`.
        fixed_originsingle_transformfrom_cooto_framemerged_attraffine_paramsa_attrb_attrnext_affine_params_combine_affine_paramstransform_typenext_params
    Combine two sets of affine parameters.

    The parameters for an affine transformation are a 3 x 3 Cartesian
    transformation matrix and a displacement vector, which can include an
    attached velocity.  Either type of parameter can be ``None``.
    vecnext_Mnext_vecnew_Mnew_vec_velocitynew_vec# build an intermediate frame with attributes taken from either# `toframe`, or if not there, `fromcoord`, or if not there, use# the defaults# TODO: caching this information when creating the transform may# speed things up a lot# this is safe even in the case where self.transforms is empty, because# coordinate objects are immutable, so copying is not needed# Create a list of the transforms including flattening any constituent CompositeTransform# Check if there may be an origin shift# Dynamically define the transformation function# loopback to the same frame# Create a merged attribute dictionary for any intermediate frames# For any attributes shared by the "from"/"to" frames, the "to" frame takes#   precedence because this is the same choice implemented in __call__()# Step through each transform step (frame A -> frame B)# Extract the relevant attributes for frame A# If frame A is actually the initial frame, preserve its attributes# Extract the relevant attributes for frame B# Obtain the affine parameters for the transform# Note that we insert some dummy data into frame A because the transformation#   machinery requires there to be data present.  Removing that limitation#   is a possible TODO, but some care would need to be taken because some affine#   transforms have branching code depending on the presence of differentials.# Combine the affine parameters with the running set# If there is no origin shift, return only the matrix# The return type depends on whether there is any origin shift# Multiply the transformation matrices if they both exist# Transform the first displacement vector by the second transformation matrix# Calculate the new displacement vector# Adding vectors with velocities takes more steps# TODO: Add support in representation.pyb'Module defining the class for a composited sequence of coordinate transformations.

This module contains the class :class:`~astropy.coordinates.CompositeTransform` that
combines a sequence of transformations into a single transformation. The class has the
same API as a single-step transformation, so it can be used interchangeably with a
single-step transformation.
'u'Module defining the class for a composited sequence of coordinate transformations.

This module contains the class :class:`~astropy.coordinates.CompositeTransform` that
combines a sequence of transformations into a single transformation. The class has the
same API as a single-step transformation, so it can be used interchangeably with a
single-step transformation.
'b'CompositeTransform'u'CompositeTransform'b'
    A transformation constructed by combining together a series of single-step
    transformations.

    Note that the intermediate frame objects are constructed using any frame
    attributes in ``toframe`` or ``fromframe`` that overlap with the intermediate
    frame (``toframe`` favored over ``fromframe`` if there's a conflict).  Any frame
    attributes that are not present use the defaults.

    Parameters
    ----------
    transforms : sequence of `~astropy.coordinates.CoordinateTransform` object
        The sequence of transformations to apply.
    fromsys : class
        The coordinate frame class to start from.
    tosys : class
        The coordinate frame class to transform into.
    priority : float or int
        The priority if this transform when finding the shortest
        coordinate transform path - large numbers are lower priorities.
    register_graph : `~astropy.coordinates.TransformGraph` or None
        A graph to register this transformation with on creation, or
        `None` to leave it unregistered.
    collapse_static_mats : bool
        If `True`, consecutive `~astropy.coordinates.StaticMatrixTransform`
        will be collapsed into a single transformation to speed up the
        calculation.

    'u'
    A transformation constructed by combining together a series of single-step
    transformations.

    Note that the intermediate frame objects are constructed using any frame
    attributes in ``toframe`` or ``fromframe`` that overlap with the intermediate
    frame (``toframe`` favored over ``fromframe`` if there's a conflict).  Any frame
    attributes that are not present use the defaults.

    Parameters
    ----------
    transforms : sequence of `~astropy.coordinates.CoordinateTransform` object
        The sequence of transformations to apply.
    fromsys : class
        The coordinate frame class to start from.
    tosys : class
        The coordinate frame class to transform into.
    priority : float or int
        The priority if this transform when finding the shortest
        coordinate transform path - large numbers are lower priorities.
    register_graph : `~astropy.coordinates.TransformGraph` or None
        A graph to register this transformation with on creation, or
        `None` to leave it unregistered.
    collapse_static_mats : bool
        If `True`, consecutive `~astropy.coordinates.StaticMatrixTransform`
        will be collapsed into a single transformation to speed up the
        calculation.

    'b'
        Combines together sequences of StaticMatrixTransform's into a single
        transform and returns it.
        'u'
        Combines together sequences of StaticMatrixTransform's into a single
        transform and returns it.
        'b'
        Return an encapsulated version of the composite transform so that it appears to
        be a single transform.

        The returned transform internally calls the constituent transforms.  If all of
        the transforms are affine, the merged transform is
        `~astropy.coordinates.DynamicMatrixTransform` (if there are no
        origin shifts) or `~astropy.coordinates.AffineTransform`
        (otherwise).  If at least one of the transforms is not affine, the merged
        transform is
        `~astropy.coordinates.FunctionTransformWithFiniteDifference`.
        'u'
        Return an encapsulated version of the composite transform so that it appears to
        be a single transform.

        The returned transform internally calls the constituent transforms.  If all of
        the transforms are affine, the merged transform is
        `~astropy.coordinates.DynamicMatrixTransform` (if there are no
        origin shifts) or `~astropy.coordinates.AffineTransform`
        (otherwise).  If at least one of the transforms is not affine, the merged
        transform is
        `~astropy.coordinates.FunctionTransformWithFiniteDifference`.
        'b'
    Combine two sets of affine parameters.

    The parameters for an affine transformation are a 3 x 3 Cartesian
    transformation matrix and a displacement vector, which can include an
    attached velocity.  Either type of parameter can be ``None``.
    'u'
    Combine two sets of affine parameters.

    The parameters for an affine transformation are a 3 x 3 Cartesian
    transformation matrix and a displacement vector, which can include an
    attached velocity.  Either type of parameter can be ``None``.
    'u'astropy.coordinates.transformations.composite'u'coordinates.transformations.composite'u'transformations.composite'u'composite'ctypesastropy.io.fits.fitsrecastropy.io.fits.hdu.compressed._quantizationastropy.io.fits.hdu.compressed._tiled_compressionastropy.io.fits.hdu.compressed.utils_validate_tile_shapeastropy.io.fits.hdu.image_bintable_header_to_image_header_image_header_to_empty_bintableCMTYPE_ALIASESCOMPRESSION_TYPESDEFAULT_COMPRESSION_TYPEDEFAULT_DITHER_SEEDDEFAULT_HCOMP_SCALEDEFAULT_HCOMP_SMOOTHDEFAULT_QUANTIZE_LEVELDEFAULT_QUANTIZE_METHODDITHER_SEED_CHECKSUMDITHER_SEED_CLOCK
    Compressed Image HDU class.
    COMPRESSED_IMAGEhcomp_scalehcomp_smoothquantize_methoduint
        Parameters
        ----------
        data : array, optional
            Uncompressed image data

        header : `~astropy.io.fits.Header`, optional
            Header to be associated with the image; when reading the HDU from a
            file (data=DELAYED), the header read from the file

        name : str, optional
            The ``EXTNAME`` value; if this value is `None`, then the name from
            the input image header will be used; if there is no name in the
            input image header then the default name ``COMPRESSED_IMAGE`` is
            used.

        compression_type : str, optional
            Compression algorithm: one of
            ``'RICE_1'``, ``'RICE_ONE'``, ``'PLIO_1'``, ``'GZIP_1'``,
            ``'GZIP_2'``, ``'HCOMPRESS_1'``, ``'NOCOMPRESS'``

        tile_shape : tuple, optional
            Compression tile shape, which should be specified using the default
            Numpy convention for array shapes (C order). The default is to
            treat each row of image as a tile.

        hcomp_scale : float, optional
            HCOMPRESS scale parameter

        hcomp_smooth : float, optional
            HCOMPRESS smooth parameter

        quantize_level : float, optional
            Floating point quantization level; see note below

        quantize_method : int, optional
            Floating point quantization dithering method; can be either
            ``NO_DITHER`` (-1; default), ``SUBTRACTIVE_DITHER_1`` (1), or
            ``SUBTRACTIVE_DITHER_2`` (2); see note below

        dither_seed : int, optional
            Random seed to use for dithering; can be either an integer in the
            range 1 to 1000 (inclusive), ``DITHER_SEED_CLOCK`` (0; default), or
            ``DITHER_SEED_CHECKSUM`` (-1); see note below

        Notes
        -----
        The astropy.io.fits package supports 2 methods of image compression:

            1) The entire FITS file may be externally compressed with the gzip
               or pkzip utility programs, producing a ``*.gz`` or ``*.zip``
               file, respectively.  When reading compressed files of this type,
               Astropy first uncompresses the entire file into a temporary file
               before performing the requested read operations.  The
               astropy.io.fits package does not support writing to these types
               of compressed files.  This type of compression is supported in
               the ``_File`` class, not in the `CompImageHDU` class.  The file
               compression type is recognized by the ``.gz`` or ``.zip`` file
               name extension.

            2) The `CompImageHDU` class supports the FITS tiled image
               compression convention in which the image is subdivided into a
               grid of rectangular tiles, and each tile of pixels is
               individually compressed.  The details of this FITS compression
               convention are described at the `FITS Support Office web site
               <https://fits.gsfc.nasa.gov/registry/tilecompression.html>`_.
               Basically, the compressed image tiles are stored in rows of a
               variable length array column in a FITS binary table.  The
               astropy.io.fits recognizes that this binary table extension
               contains an image and treats it as if it were an image
               extension.  Under this tile-compression format, FITS header
               keywords remain uncompressed.  At this time, Astropy does not
               support the ability to extract and uncompress sections of the
               image without having to uncompress the entire image.

        The astropy.io.fits package supports 3 general-purpose compression
        algorithms plus one other special-purpose compression technique that is
        designed for data masks with positive integer pixel values.  The 3
        general purpose algorithms are GZIP, Rice, and HCOMPRESS, and the
        special-purpose technique is the IRAF pixel list compression technique
        (PLIO).  The ``compression_type`` parameter defines the compression
        algorithm to be used.

        The FITS image can be subdivided into any desired rectangular grid of
        compression tiles.  With the GZIP, Rice, and PLIO algorithms, the
        default is to take each row of the image as a tile.  The HCOMPRESS
        algorithm is inherently 2-dimensional in nature, so the default in this
        case is to take 16 rows of the image per tile.  In most cases, it makes
        little difference what tiling pattern is used, so the default tiles are
        usually adequate.  In the case of very small images, it could be more
        efficient to compress the whole image as a single tile.  Note that the
        image dimensions are not required to be an integer multiple of the tile
        dimensions; if not, then the tiles at the edges of the image will be
        smaller than the other tiles.  The ``tile_shape`` parameter may be
        provided as a list of tile sizes, one for each dimension in the image.
        For example a ``tile_shape`` value of ``(100,100)`` would divide a 300 X
        300 image into 9 100 X 100 tiles.

        The 4 supported image compression algorithms are all 'lossless' when
        applied to integer FITS images; the pixel values are preserved exactly
        with no loss of information during the compression and uncompression
        process.  In addition, the HCOMPRESS algorithm supports a 'lossy'
        compression mode that will produce larger amount of image compression.
        This is achieved by specifying a non-zero value for the ``hcomp_scale``
        parameter.  Since the amount of compression that is achieved depends
        directly on the RMS noise in the image, it is usually more convenient
        to specify the ``hcomp_scale`` factor relative to the RMS noise.
        Setting ``hcomp_scale = 2.5`` means use a scale factor that is 2.5
        times the calculated RMS noise in the image tile.  In some cases it may
        be desirable to specify the exact scaling to be used, instead of
        specifying it relative to the calculated noise value.  This may be done
        by specifying the negative of the desired scale value (typically in the
        range -2 to -100).

        Very high compression factors (of 100 or more) can be achieved by using
        large ``hcomp_scale`` values, however, this can produce undesirable
        'blocky' artifacts in the compressed image.  A variation of the
        HCOMPRESS algorithm (called HSCOMPRESS) can be used in this case to
        apply a small amount of smoothing of the image when it is uncompressed
        to help cover up these artifacts.  This smoothing is purely cosmetic
        and does not cause any significant change to the image pixel values.
        Setting the ``hcomp_smooth`` parameter to 1 will engage the smoothing
        algorithm.

        Floating point FITS images (which have ``BITPIX`` = -32 or -64) usually
        contain too much 'noise' in the least significant bits of the mantissa
        of the pixel values to be effectively compressed with any lossless
        algorithm.  Consequently, floating point images are first quantized
        into scaled integer pixel values (and thus throwing away much of the
        noise) before being compressed with the specified algorithm (either
        GZIP, RICE, or HCOMPRESS).  This technique produces much higher
        compression factors than simply using the GZIP utility to externally
        compress the whole FITS file, but it also means that the original
        floating point value pixel values are not exactly preserved.  When done
        properly, this integer scaling technique will only discard the
        insignificant noise while still preserving all the real information in
        the image.  The amount of precision that is retained in the pixel
        values is controlled by the ``quantize_level`` parameter.  Larger
        values will result in compressed images whose pixels more closely match
        the floating point pixel values, but at the same time the amount of
        compression that is achieved will be reduced.  Users should experiment
        with different values for this parameter to determine the optimal value
        that preserves all the useful information in the image, without
        needlessly preserving all the 'noise' which will hurt the compression
        efficiency.

        The default value for the ``quantize_level`` scale factor is 16, which
        means that scaled integer pixel values will be quantized such that the
        difference between adjacent integer values will be 1/16th of the noise
        level in the image background.  An optimized algorithm is used to
        accurately estimate the noise in the image.  As an example, if the RMS
        noise in the background pixels of an image = 32.0, then the spacing
        between adjacent scaled integer pixel values will equal 2.0 by default.
        Note that the RMS noise is independently calculated for each tile of
        the image, so the resulting integer scaling factor may fluctuate
        slightly for each tile.  In some cases, it may be desirable to specify
        the exact quantization level to be used, instead of specifying it
        relative to the calculated noise value.  This may be done by specifying
        the negative of desired quantization level for the value of
        ``quantize_level``.  In the previous example, one could specify
        ``quantize_level = -2.0`` so that the quantized integer levels differ
        by 2.0.  Larger negative values for ``quantize_level`` means that the
        levels are more coarsely-spaced, and will produce higher compression
        factors.

        The quantization algorithm can also apply one of two random dithering
        methods in order to reduce bias in the measured intensity of background
   ..._bintable_bitpix_bintable_to_image_header_cards_get_bintable_without_data_remove_unnecessary_default_extnamesRemove default EXTNAME values if they are unnecessary.

        Some data files (eg from CFHT) can have the default EXTNAME and
        an explicit value.  This method removes the default if a more
        specific header exists. It also removes any duplicate default
        values.
        _keyword_indicesn_extnameextnames_to_remove_compression_typeUnknown compression type provided (supported are {}). Default ({}) compression will be used."Unknown compression type provided (supported are {}). ""Default ({}) compression will be used."
        Convert the current ImageHDU (excluding the actual data) to a BinTableHDU
        with the correct header.
        huge_hdu_axes_generate_dither_seedgenerate_dither_seed
        Whether the data is fully decompressed into self.data - note that is
        a little different to _data_loaded on other HDUs, but it is conceptually
        the same idea in a way.
        
        The decompressed data array.

        Note that accessing this will cause all the tiles to be loaded,
        decompressed, and combined into a single data array. If you do
        not need to access the whole array, consider instead using the
        :attr:`~astropy.io.fits.CompImageHDU.section` property.
        bintable is not set_add_data_to_bintable
        Compress the image data so that it may be written to a file.
        recrecarray_heapoffset_heapsize_tmp_bintable_scale_back_scale_internal_orig_bitpix_orig_blankblank_countblanksimage_blankstable_blanksseedSeed must be an integerSeed for random dithering must be either between 1 and 10000 inclusive, 0 for autogeneration from the system clock, or -1 for autogeneration from a checksum of the first image tile (got "Seed for random dithering must be either between 1 and ""10000 inclusive, 0 for autogeneration from the system ""clock, or -1 for autogeneration from a checksum of the first ""image tile (got "tile_dimsfirst_tilec_ulongmodf
        Efficiently access a section of the image array

        This property can be used to access a section of the data without
        loading and decompressing the entire array into memory.

        The :class:`~astropy.io.fits.CompImageSection` object returned by this
        attribute is not meant to be used directly by itself. Rather, slices of
        the section return the appropriate slice of the data, and loads *only*
        that section into memory. Any valid basic Numpy index can be used to
        slice :class:`~astropy.io.fits.CompImageSection`.

        Note that accessing data using :attr:`CompImageHDU.section` will always
        load tiles one at a time from disk, and therefore when accessing a large
        fraction of the data (or slicing it in a way that would cause most tiles
        to be loaded) you may obtain better performance by using
        :attr:`CompImageHDU.data`.
        errs_filtered'XTENSION' card does not exist.'PCOUNT' card does not exist.'GCOUNT' card does not exist.Cannot set CompImageHDU._data_offsetCannot set CompImageHDU._header_offsetCannot set CompImageHDU._data_size# NOTE: for now we don't ever read in CompImageHDU directly from# files, instead we read in BinTableHDU and pass it in here. In# future if we do want to read CompImageHDU in directly, we can# use the following code.# if data is DELAYED:#     # Reading the HDU from a file#     self._bintable = _CompBinTableHDU(data=data, header=header)# else:# If bintable is passed in, it should be a BinTableHDU# Create at least a skeleton HDU that matches the input# header and data (if any were input)# TODO: just for parameter validation, e.g. tile shape - we shouldn't# ideally need this and should instead validate the values as they are# set above.# Only continue if there is more than one found# Keep the first (they are all the same)# Remove them all in reverse order to keep the index unchanged.# Determine based on the size of the input data whether to use the Q# column format to store compressed data or the P format.# The Q format is used only if the uncompressed data is larger than# 4 GB.  This is not a perfect heuristic, as one can contrive an input# array which, when compressed, the entire binary table representing# the compressed data is larger than 4GB.  That said, this is the same# heuristic used by CFITSIO, so this should give consistent results.# And the cases where this heuristic is insufficient are extreme and# almost entirely contrived corner cases, so it will do for now# TODO: test above# NOTE: for now the function below modifies the compressed binary table# bintable._header in-place, but this could be refactored in future to# return the compressed header.# If there is no internal binary table, the HDU was not created from a# file and therefore the data is just the one on the parent ImageHDU# Since .section has general code to load any arbitrary part of the# data, we can just use this# Clean up any possible doubled EXTNAME keywords that use# the default. Do this on the original header to ensure# duplicates are removed cleanly.# Convert compressed header to image header and save# it off to self._image_header so it can be referenced later# unambiguously# If a bintable already exists internally we should update that instead# of using a whole new BinTableHDU so that mode='update' works.# Each time we assign the bintable data to the BinTableHDU, some of# the blank keywords get removed, so at this point, just before# writing, we should make sure that the number of blank cards in# the final binary table to be written matches the number of blanks# in the image header.# Determine the tile dimensions from the ZTILEn keywords# Get the first tile by using the tile dimensions as the end# indices of slices (starting from 0)# The checksum algorithm used is literally just the sum of the bytes# of the tile data (not its actual floating point values).  Integer# overflow is irrelevant.# Since CFITSIO uses an unsigned long (which may be different on# different platforms) go ahead and truncate the sum to its# unsigned long value and take the result modulo 10000# This isn't exactly the same algorithm as CFITSIO, but that's okay# since the result is meant to be arbitrary. The primary difference# is that CFITSIO incorporates the HDU number into the result in# the hopes of heading off the possibility of the same seed being# generated for two HDUs at the same time.  Here instead we just# add in the HDU object's id# The following is the default _verify for ImageHDU# However in some cases the decompressed header is actually like a# PrimaryHDU header rather than an ImageHDU header, in which case# there are certain errors we can ignore# We should never set _data_offset to a non-None value. We need to# implement this setter as one of the parent classes sets _data_offset# to None in __init__.b'
    Compressed Image HDU class.
    'u'
    Compressed Image HDU class.
    'b'COMPRESSED_IMAGE'u'COMPRESSED_IMAGE'b'
        Parameters
        ----------
        data : array, optional
            Uncompressed image data

        header : `~astropy.io.fits.Header`, optional
            Header to be associated with the image; when reading the HDU from a
            file (data=DELAYED), the header read from the file

        name : str, optional
            The ``EXTNAME`` value; if this value is `None`, then the name from
            the input image header will be used; if there is no name in the
            input image header then the default name ``COMPRESSED_IMAGE`` is
            used.

        compression_type : str, optional
            Compression algorithm: one of
            ``'RICE_1'``, ``'RICE_ONE'``, ``'PLIO_1'``, ``'GZIP_1'``,
            ``'GZIP_2'``, ``'HCOMPRESS_1'``, ``'NOCOMPRESS'``

        tile_shape : tuple, optional
            Compression tile shape, which should be specified using the default
            Numpy convention for array shapes (C order). The default is to
            treat each row of image as a tile.

        hcomp_scale : float, optional
            HCOMPRESS scale parameter

        hcomp_smooth : float, optional
            HCOMPRESS smooth parameter

        quantize_level : float, optional
            Floating point quantization level; see note below

        quantize_method : int, optional
            Floating point quantization dithering method; can be either
            ``NO_DITHER`` (-1; default), ``SUBTRACTIVE_DITHER_1`` (1), or
            ``SUBTRACTIVE_DITHER_2`` (2); see note below

        dither_seed : int, optional
            Random seed to use for dithering; can be either an integer in the
            range 1 to 1000 (inclusive), ``DITHER_SEED_CLOCK`` (0; default), or
            ``DITHER_SEED_CHECKSUM`` (-1); see note below

        Notes
        -----
        The astropy.io.fits package supports 2 methods of image compression:

            1) The entire FITS file may be externally compressed with the gzip
               or pkzip utility programs, producing a ``*.gz`` or ``*.zip``
               file, respectively.  When reading compressed files of this type,
               Astropy first uncompresses the entire file into a temporary file
               before performing the requested read operations.  The
               astropy.io.fits package does not support writing to these types
               of compressed files.  This type of compression is supported in
               the ``_File`` class, not in the `CompImageHDU` class.  The file
               compression type is recognized by the ``.gz`` or ``.zip`` file
               name extension.

            2) The `CompImageHDU` class supports the FITS tiled image
               compression convention in which the image is subdivided into a
               grid of rectangular tiles, and each tile of pixels is
               individually compressed.  The details of this FITS compression
               convention are described at the `FITS Support Office web site
               <https://fits.gsfc.nasa.gov/registry/tilecompression.html>`_.
               Basically, the compressed image tiles are stored in rows of a
               variable length array column in a FITS binary table.  The
               astropy.io.fits recognizes that this binary table extension
               contains an image and treats it as if it were an image
               extension.  Under this tile-compression format, FITS header
               keywords remain uncompressed.  At this time, Astropy does not
               support the ability to extract and uncompress sections of the
               image without having to uncompress the entire image.

        The astropy.io.fits package supports 3 general-purpose compression
        algorithms plus one other special-purpose compression technique that is
        designed for data masks with positive integer pixel values.  The 3
        general purpose algorithms are GZIP, Rice, and HCOMPRESS, and the
        special-purpose technique is the IRAF pixel list compression technique
        (PLIO).  The ``compression_type`` parameter defines the compression
        algorithm to be used.

        The FITS image can be subdivided into any desired rectangular grid of
        compression tiles.  With the GZIP, Rice, and PLIO algorithms, the
        default is to take each row of the image as a tile.  The HCOMPRESS
        algorithm is inherently 2-dimensional in nature, so the default in this
        case is to take 16 rows of the image per tile.  In most cases, it makes
        little difference what tiling pattern is used, so the default tiles are
        usually adequate.  In the case of very small images, it could be more
        efficient to compress the whole image as a single tile.  Note that the
        image dimensions are not required to be an integer multiple of the tile
        dimensions; if not, then the tiles at the edges of the image will be
        smaller than the other tiles.  The ``tile_shape`` parameter may be
        provided as a list of tile sizes, one for each dimension in the image.
        For example a ``tile_shape`` value of ``(100,100)`` would divide a 300 X
        300 image into 9 100 X 100 tiles.

        The 4 supported image compression algorithms are all 'lossless' when
        applied to integer FITS images; the pixel values are preserved exactly
        with no loss of information during the compression and uncompression
        process.  In addition, the HCOMPRESS algorithm supports a 'lossy'
        compression mode that will produce larger amount of image compression.
        This is achieved by specifying a non-zero value for the ``hcomp_scale``
        parameter.  Since the amount of compression that is achieved depends
        directly on the RMS noise in the image, it is usually more convenient
        to specify the ``hcomp_scale`` factor relative to the RMS noise.
        Setting ``hcomp_scale = 2.5`` means use a scale factor that is 2.5
        times the calculated RMS noise in the image tile.  In some cases it may
        be desirable to specify the exact scaling to be used, instead of
        specifying it relative to the calculated noise value.  This may be done
        by specifying the negative of the desired scale value (typically in the
        range -2 to -100).

        Very high compression factors (of 100 or more) can be achieved by using
        large ``hcomp_scale`` values, however, this can produce undesirable
        'blocky' artifacts in the compressed image.  A variation of the
        HCOMPRESS algorithm (called HSCOMPRESS) can be used in this case to
        apply a small amount of smoothing of the image when it is uncompressed
        to help cover up these artifacts.  This smoothing is purely cosmetic
        and does not cause any significant change to the image pixel values.
        Setting the ``hcomp_smooth`` parameter to 1 will engage the smoothing
        algorithm.

        Floating point FITS images (which have ``BITPIX`` = -32 or -64) usually
        contain too much 'noise' in the least significant bits of the mantissa
        of the pixel values to be effectively compressed with any lossless
        algorithm.  Consequently, floating point images are first quantized
        into scaled integer pixel values (and thus throwing away much of the
        noise) before being compressed with the specified algorithm (either
        GZIP, RICE, or HCOMPRESS).  This technique produces much higher
        compression factors than simply using the GZIP utility to externally
        compress the whole FITS file, but it also means that the original
        floating point value pixel values are not exactly preserved.  When done
        properly, this integer scaling technique will only discard the
        insignificant noise while still preserving all the real information in
        the image.  The amount of precision that is retained in the pixel
        values is controlled by the ``quantize_level`` parameter.  Larger
        values will result in compressed images whose pixels more closely match
        the floating point pixel values, but at the same time the amount of
        compression that is achieved will be reduced.  Users should experiment
        with different values for this parameter to determine the optimal value
        that preserves all the useful information in the image, without
        needlessly preserving all the 'noise' which will hurt the compression
        efficiency.

        The default value for the ``quantize_level`` scale factor is 16, which
        means that scaled integer pixel values will be quantized such that the
        difference between adjacent integer values will be 1/16th of the noise
        level in the image background.  An optimized algorithm is used to
        accurately estimate the noise in the image.  As an example, if the RMS
        noise in the background pixels of an image = 32.0, then the spacing
        between adjacent scaled integer pixel values will equal 2.0 by default.
        Note that the RMS noise is independently calculated for each tile of
        the image, so the resulting integer scaling factor may fluctuate
        slightly for each tile.  In some cases, it may be desirable to specify
        the exact quantization level to be used, instead of specifying it
        relative to the calculated noise value.  This may be done by specifying
        the negative of desired quantization level for the value of
        ``quantize_level``.  In the previous example, one could specify
        ``quantize_level = -2.0`` so that the quantized integer levels differ
        by 2.0.  Larger negative values for ``quantize_level`` means that the
        levels are more coarsely-spaced, and will produce higher compression
        factors.

        The quantization algorithm can also apply one of two random dithering
        methods in order to reduce bias in the measured intensity of background
 ...u'
        Parameters
        ----------
        data : array, optional
            Uncompressed image data

        header : `~astropy.io.fits.Header`, optional
            Header to be associated with the image; when reading the HDU from a
            file (data=DELAYED), the header read from the file

        name : str, optional
            The ``EXTNAME`` value; if this value is `None`, then the name from
            the input image header will be used; if there is no name in the
            input image header then the default name ``COMPRESSED_IMAGE`` is
            used.

        compression_type : str, optional
            Compression algorithm: one of
            ``'RICE_1'``, ``'RICE_ONE'``, ``'PLIO_1'``, ``'GZIP_1'``,
            ``'GZIP_2'``, ``'HCOMPRESS_1'``, ``'NOCOMPRESS'``

        tile_shape : tuple, optional
            Compression tile shape, which should be specified using the default
            Numpy convention for array shapes (C order). The default is to
            treat each row of image as a tile.

        hcomp_scale : float, optional
            HCOMPRESS scale parameter

        hcomp_smooth : float, optional
            HCOMPRESS smooth parameter

        quantize_level : float, optional
            Floating point quantization level; see note below

        quantize_method : int, optional
            Floating point quantization dithering method; can be either
            ``NO_DITHER`` (-1; default), ``SUBTRACTIVE_DITHER_1`` (1), or
            ``SUBTRACTIVE_DITHER_2`` (2); see note below

        dither_seed : int, optional
            Random seed to use for dithering; can be either an integer in the
            range 1 to 1000 (inclusive), ``DITHER_SEED_CLOCK`` (0; default), or
            ``DITHER_SEED_CHECKSUM`` (-1); see note below

        Notes
        -----
        The astropy.io.fits package supports 2 methods of image compression:

            1) The entire FITS file may be externally compressed with the gzip
               or pkzip utility programs, producing a ``*.gz`` or ``*.zip``
               file, respectively.  When reading compressed files of this type,
               Astropy first uncompresses the entire file into a temporary file
               before performing the requested read operations.  The
               astropy.io.fits package does not support writing to these types
               of compressed files.  This type of compression is supported in
               the ``_File`` class, not in the `CompImageHDU` class.  The file
               compression type is recognized by the ``.gz`` or ``.zip`` file
               name extension.

            2) The `CompImageHDU` class supports the FITS tiled image
               compression convention in which the image is subdivided into a
               grid of rectangular tiles, and each tile of pixels is
               individually compressed.  The details of this FITS compression
               convention are described at the `FITS Support Office web site
               <https://fits.gsfc.nasa.gov/registry/tilecompression.html>`_.
               Basically, the compressed image tiles are stored in rows of a
               variable length array column in a FITS binary table.  The
               astropy.io.fits recognizes that this binary table extension
               contains an image and treats it as if it were an image
               extension.  Under this tile-compression format, FITS header
               keywords remain uncompressed.  At this time, Astropy does not
               support the ability to extract and uncompress sections of the
               image without having to uncompress the entire image.

        The astropy.io.fits package supports 3 general-purpose compression
        algorithms plus one other special-purpose compression technique that is
        designed for data masks with positive integer pixel values.  The 3
        general purpose algorithms are GZIP, Rice, and HCOMPRESS, and the
        special-purpose technique is the IRAF pixel list compression technique
        (PLIO).  The ``compression_type`` parameter defines the compression
        algorithm to be used.

        The FITS image can be subdivided into any desired rectangular grid of
        compression tiles.  With the GZIP, Rice, and PLIO algorithms, the
        default is to take each row of the image as a tile.  The HCOMPRESS
        algorithm is inherently 2-dimensional in nature, so the default in this
        case is to take 16 rows of the image per tile.  In most cases, it makes
        little difference what tiling pattern is used, so the default tiles are
        usually adequate.  In the case of very small images, it could be more
        efficient to compress the whole image as a single tile.  Note that the
        image dimensions are not required to be an integer multiple of the tile
        dimensions; if not, then the tiles at the edges of the image will be
        smaller than the other tiles.  The ``tile_shape`` parameter may be
        provided as a list of tile sizes, one for each dimension in the image.
        For example a ``tile_shape`` value of ``(100,100)`` would divide a 300 X
        300 image into 9 100 X 100 tiles.

        The 4 supported image compression algorithms are all 'lossless' when
        applied to integer FITS images; the pixel values are preserved exactly
        with no loss of information during the compression and uncompression
        process.  In addition, the HCOMPRESS algorithm supports a 'lossy'
        compression mode that will produce larger amount of image compression.
        This is achieved by specifying a non-zero value for the ``hcomp_scale``
        parameter.  Since the amount of compression that is achieved depends
        directly on the RMS noise in the image, it is usually more convenient
        to specify the ``hcomp_scale`` factor relative to the RMS noise.
        Setting ``hcomp_scale = 2.5`` means use a scale factor that is 2.5
        times the calculated RMS noise in the image tile.  In some cases it may
        be desirable to specify the exact scaling to be used, instead of
        specifying it relative to the calculated noise value.  This may be done
        by specifying the negative of the desired scale value (typically in the
        range -2 to -100).

        Very high compression factors (of 100 or more) can be achieved by using
        large ``hcomp_scale`` values, however, this can produce undesirable
        'blocky' artifacts in the compressed image.  A variation of the
        HCOMPRESS algorithm (called HSCOMPRESS) can be used in this case to
        apply a small amount of smoothing of the image when it is uncompressed
        to help cover up these artifacts.  This smoothing is purely cosmetic
        and does not cause any significant change to the image pixel values.
        Setting the ``hcomp_smooth`` parameter to 1 will engage the smoothing
        algorithm.

        Floating point FITS images (which have ``BITPIX`` = -32 or -64) usually
        contain too much 'noise' in the least significant bits of the mantissa
        of the pixel values to be effectively compressed with any lossless
        algorithm.  Consequently, floating point images are first quantized
        into scaled integer pixel values (and thus throwing away much of the
        noise) before being compressed with the specified algorithm (either
        GZIP, RICE, or HCOMPRESS).  This technique produces much higher
        compression factors than simply using the GZIP utility to externally
        compress the whole FITS file, but it also means that the original
        floating point value pixel values are not exactly preserved.  When done
        properly, this integer scaling technique will only discard the
        insignificant noise while still preserving all the real information in
        the image.  The amount of precision that is retained in the pixel
        values is controlled by the ``quantize_level`` parameter.  Larger
        values will result in compressed images whose pixels more closely match
        the floating point pixel values, but at the same time the amount of
        compression that is achieved will be reduced.  Users should experiment
        with different values for this parameter to determine the optimal value
        that preserves all the useful information in the image, without
        needlessly preserving all the 'noise' which will hurt the compression
        efficiency.

        The default value for the ``quantize_level`` scale factor is 16, which
        means that scaled integer pixel values will be quantized such that the
        difference between adjacent integer values will be 1/16th of the noise
        level in the image background.  An optimized algorithm is used to
        accurately estimate the noise in the image.  As an example, if the RMS
        noise in the background pixels of an image = 32.0, then the spacing
        between adjacent scaled integer pixel values will equal 2.0 by default.
        Note that the RMS noise is independently calculated for each tile of
        the image, so the resulting integer scaling factor may fluctuate
        slightly for each tile.  In some cases, it may be desirable to specify
        the exact quantization level to be used, instead of specifying it
        relative to the calculated noise value.  This may be done by specifying
        the negative of desired quantization level for the value of
        ``quantize_level``.  In the previous example, one could specify
        ``quantize_level = -2.0`` so that the quantized integer levels differ
        by 2.0.  Larger negative values for ``quantize_level`` means that the
        levels are more coarsely-spaced, and will produce higher compression
        factors.

        The quantization algorithm can also apply one of two random dithering
        methods in order to reduce bias in the measured intensity of background
 ...b'Remove default EXTNAME values if they are unnecessary.

        Some data files (eg from CFHT) can have the default EXTNAME and
        an explicit value.  This method removes the default if a more
        specific header exists. It also removes any duplicate default
        values.
        'u'Remove default EXTNAME values if they are unnecessary.

        Some data files (eg from CFHT) can have the default EXTNAME and
        an explicit value.  This method removes the default if a more
        specific header exists. It also removes any duplicate default
        values.
        'b'Unknown compression type provided (supported are {}). Default ({}) compression will be used.'u'Unknown compression type provided (supported are {}). Default ({}) compression will be used.'b'
        Convert the current ImageHDU (excluding the actual data) to a BinTableHDU
        with the correct header.
        'u'
        Convert the current ImageHDU (excluding the actual data) to a BinTableHDU
        with the correct header.
        'b'
        Whether the data is fully decompressed into self.data - note that is
        a little different to _data_loaded on other HDUs, but it is conceptually
        the same idea in a way.
        'u'
        Whether the data is fully decompressed into self.data - note that is
        a little different to _data_loaded on other HDUs, but it is conceptually
        the same idea in a way.
        'b'
        The decompressed data array.

        Note that accessing this will cause all the tiles to be loaded,
        decompressed, and combined into a single data array. If you do
        not need to access the whole array, consider instead using the
        :attr:`~astropy.io.fits.CompImageHDU.section` property.
        'u'
        The decompressed data array.

        Note that accessing this will cause all the tiles to be loaded,
        decompressed, and combined into a single data array. If you do
        not need to access the whole array, consider instead using the
        :attr:`~astropy.io.fits.CompImageHDU.section` property.
        'b'tile_shape'u'tile_shape'b'bintable is not set'u'bintable is not set'b'
        Compress the image data so that it may be written to a file.
        'u'
        Compress the image data so that it may be written to a file.
        'b'Seed must be an integer'u'Seed must be an integer'b'Seed for random dithering must be either between 1 and 10000 inclusive, 0 for autogeneration from the system clock, or -1 for autogeneration from a checksum of the first image tile (got 'u'Seed for random dithering must be either between 1 and 10000 inclusive, 0 for autogeneration from the system clock, or -1 for autogeneration from a checksum of the first image tile (got 'b'
        Efficiently access a section of the image array

        This property can be used to access a section of the data without
        loading and decompressing the entire array into memory.

        The :class:`~astropy.io.fits.CompImageSection` object returned by this
        attribute is not meant to be used directly by itself. Rather, slices of
        the section return the appropriate slice of the data, and loads *only*
        that section into memory. Any valid basic Numpy index can be used to
        slice :class:`~astropy.io.fits.CompImageSection`.

        Note that accessing data using :attr:`CompImageHDU.section` will always
        load tiles one at a time from disk, and therefore when accessing a large
        fraction of the data (or slicing it in a way that would cause most tiles
        to be loaded) you may obtain better performance by using
        :attr:`CompImageHDU.data`.
        'u'
        Efficiently access a section of the image array

        This property can be used to access a section of the data without
        loading and decompressing the entire array into memory.

        The :class:`~astropy.io.fits.CompImageSection` object returned by this
        attribute is not meant to be used directly by itself. Rather, slices of
        the section return the appropriate slice of the data, and loads *only*
        that section into memory. Any valid basic Numpy index can be used to
        slice :class:`~astropy.io.fits.CompImageSection`.

        Note that accessing data using :attr:`CompImageHDU.section` will always
        load tiles one at a time from disk, and therefore when accessing a large
        fraction of the data (or slicing it in a way that would cause most tiles
        to be loaded) you may obtain better performance by using
        :attr:`CompImageHDU.data`.
        'b''XTENSION' card does not exist.'u''XTENSION' card does not exist.'b''PCOUNT' card does not exist.'u''PCOUNT' card does not exist.'b''GCOUNT' card does not exist.'u''GCOUNT' card does not exist.'b'Cannot set CompImageHDU._data_offset'u'Cannot set CompImageHDU._data_offset'b'Cannot set CompImageHDU._header_offset'u'Cannot set CompImageHDU._header_offset'b'Cannot set CompImageHDU._data_size'u'Cannot set CompImageHDU._data_size'u'fits.hdu.compressed.compressed'u'hdu.compressed.compressed'u'compressed.compressed'C:/Users/Asus/AppData/Local/Programs/Python/Python310/Lib/concurrentdoctesttomllibUTCpackaging.requirementsRequirementpackaging.specifiersSpecifierSetsphinx.utilsphinx.util.typing_INVALID_BUILTIN_CLASSESpathlib.PathgetLoggermissing_requirementsextra == "docs"reqreq_packagespecifierreq_specifierPackageNotFoundErrorprereleasesThe following packages could not be found and are required to build the documentation:
%s
Please install the "docs" requirements."The following packages could not be found and are required to ""build the documentation:\n""%s"'\nPlease install the "docs" requirements.'    * sphinx_astropy.conf.v2exclude_patternsextensionshtml_theme_optionsintersphinx_mappingnumpydoc_xref_aliasesnumpydoc_xref_astropy_aliasesnumpydoc_xref_ignorelargefigure.figsizefigure.subplot.hspacetightsavefig.bboxsavefig.facecolorplot_rcparamsplot_apply_rcparamsplot_html_show_source_linkpngsvgplot_formatsplot_pre_codeneeds_sphinxhttps://pyerfa.readthedocs.io/en/stable/pyerfahttps://docs.pytest.org/en/stable/https://ipython.readthedocs.io/en/stable/ipythonhttps://pandas.pydata.org/pandas-docs/stable/pandashttps://sphinx-automodapi.readthedocs.io/en/stable/sphinx_automodapihttps://asdf-astropy.readthedocs.io/en/latest/asdf-astropyhttps://filesystem-spec.readthedocs.io/en/latest/fsspechttps://matplotlib.org/cycler/cyclerhttps://docs.dask.org/en/stable/_templateschanges_pkgtemplate.rst**/*.inc.rsttemplates_pathmatplotlib.sphinxext.rolessphinx_changelogsphinx_designsphinxcontrib.globalsubsrbloadpyprojectregister_optionflagIGNORE_OUTPUTREMOTE_DATAFLOAT_CMPnumpydoc_xref_param_typemixinArgumentsbits`~typing.Any`:term:`python:file-like object`file-like:term:`python:file object`:term:`python:path-like object`path-like:term:`python:module`:term:buffer-likebuffer-like:term:`python:hashable`hashable:term:`color`:class:`python:int`ints:term:`number`:class:`~astropy.units.Quantity`:class:`~astropy.coordinates.BaseRepresentation`Representation:term:`writable file-like object`:term:`readable file-like object`:doc:`HDU </io/fits/api/hdus>`BaseHDUtoc_object_entriesAstropyThe Astropy Developersauthor2011development/*modindex_common_prefixG-R0510VK4B6google_analytics_idanalyticshttps://github.com/astropy/astropygithub_urlTutorialshttps://learn.astropy.org/external_linksuse_edit_page_button_static/astropy_banner_96.pngimage_light_static/astropy_banner_96_dark.pngimage_darklogonavigation_with_keyshttps://www.astropy.org/annoucement_banner.htmlannouncement vhtml_title_static/astropy_logo.icohtml_favicon_statichtml_static_pathastropy.csshtml_css_fileshtml_copy_sourcehtmlhelp_basenameREADTHEDOCS_CANONICAL_URLhtml_baseurl_custom_edit_urlgithub_usergithub_repogithub_versiondoc_pathfile_namedefault_edit_page_url_templateCreate custom 'edit' URLs for API modules since they are dynamically generated.api/astropy..rstastropy_pathmod_dirmod_filenew_file_namefindsourceline_no#Lcosmology.realizationsmodeling.tabular.Tabularcould not find source for cosmology.realizations.availableastropy/cosmology/realizations.pycould not find module for lightdefault_modeREADTHEDOCS_VERSIONversion_slugstableto_be_indexedis_development{{ astropy_custom_edit_url(github_user, github_repo, github_version, doc_path, file_name, default_edit_page_url_template) }}edit_page_url_templatehttps://github.com/{github_user}/{github_repo}/edit/{github_version}/{doc_path}{file_name}astropy_custom_edit_urlREADTHEDOCShtml_contextrobots.txthtml_extra_path.tex Documentationmanuallatex_documents_static/astropy_logo.pdflatex_logoman_pageshttps://github.com/astropy/astropy/issues/github_issues_urledit_on_github_branchnitpickyshow_warning_typesnitpick_ignorenitpick-exceptionsconfig.cachesuppress_warningslinkcheck_retryhttps://journals.aas.org/manuscript-preparation/https://maia.usno.navy.mil/https://www.usno.navy.mil/USNO/time/gps/usno-gps-time-transferhttps://aa.usno.navy.mil/publications/docs/Circular_179.phphttp://data.astropy.orghttps://doi.org/https://ui.adsabs.harvard.eduhttps://www.tandfonline.com/https://stackoverflow.com/https://ieeexplore.ieee.org/https://pyfits.readthedocs.io/en/v3.2.1/https://pkgs.dev.azure.com/astropy-projecthttps://github\.com/astropy/astropy/(?:issues|pull)/\d+linkcheck_ignorelinkcheck_timeoutlinkcheck_anchorslinkcheck_report_timeouts_as_brokenlinkcheck_allow_unauthorizedrstjinjaappdocnamesourceRender pages as a jinja template to hide/show dev docs.index_devfiles_to_renderJinja rendering %stemplatesrender_stringrenderedresolve_astropy_referencecontnode
    Reference targets for ``astropy:`` are special cases.

    Documentation links in astropy can be set up as intersphinx links so that
    affiliate packages do not have to override the docstrings when building
    the docs.

    reftargetastropy:processreftyperefdocreplace_attrdomainsrefdomainresolve_xrefrequires-python>=__minimum_python_version__min_versions:class:`numpy.ndarray`:class:`~astropy.coordinates.EarthLocation``~astropy.coordinates.Angle``~astropy.coordinates.Latitude`:class:`~astropy.coordinates.Longitude``~astropy.coordinates.BaseCoordinateFrame`BaseFrame:class:`~astropy.coordinates.SkyCoord``~astropy.coordinates.SpectralCoord`SpectralCoord:class:`~astropy.cosmology.Cosmology`:meth:`~astropy.cosmology.Cosmology.read`Cosmology.read:meth:`~astropy.cosmology.Cosmology.write`Cosmology.write:meth:`~astropy.cosmology.Cosmology.from_format`Cosmology.from_format:meth:`~astropy.cosmology.Cosmology.to_format`Cosmology.to_format:class:`~astropy.cosmology.FLRW`:class:`~astropy.cosmology.LambdaCDM`:class:`~astropy.cosmology.FlatLambdaCDM`:ref:`astropy_cosmology_realizations_WMAP1`:ref:`astropy_cosmology_realizations_WMAP3`:ref:`astropy_cosmology_realizations_WMAP5`:ref:`astropy_cosmology_realizations_WMAP7`:ref:`astropy_cosmology_realizations_WMAP9`:ref:`astropy_cosmology_realizations_Planck13`:ref:`astropy_cosmology_realizations_Planck15`:ref:`astropy_cosmology_realizations_Planck18`:class:`~astropy.cosmology.FlatCosmologyMixin`:class:`~astropy.cosmology.FlatFLRWMixin`:class:`~astropy.cosmology.default_cosmology`:class:`~astropy.samp.SAMPClient`:class:`~astropy.samp.SAMPIntegratedClient`SAMPIntegratedClient:class:`~astropy.samp.SAMPHubServer`:class:`~astropy.samp.SAMPHubProxy`SAMPHubProxy:class:`~astropy.table.Column`:class:`~astropy.table.MaskedColumn`:class:`~astropy.table.TableColumns`:class:`~astropy.table.Row`:class:`~astropy.table.Table`:class:`~astropy.table.QTable`:class:`~astropy.time.Time`:class:`~astropy.time.TimeDelta`:class:`~astropy.timeseries.TimeSeries`:class:`~astropy.timeseries.BinnedTimeSeries`:class:`~astropy.uncertainty.Distribution`Distribution:class:`~astropy.units.PhysicalType`PhysicalType:class:`~astropy.units.UnitBase`:class:`~astropy.units.StructuredUnit`:class:`~astropy.utils.masked.Masked`minimum_python_versionminimum_numpy_versionminimum_pyerfa_versionminimum_matplotlib_versionminimum_scipy_versionminimum_asdf_astropy_versionpackagingminimum_packaging_versionpyyamlminimum_pyyaml_versionminimum_ipython_versionpyarrowminimum_pyarrow_versionminimum_fsspec_versions3fsminimum_s3fs_versionglobal_substitutionshttps://www.python.orgPythonhttps://www.python.org/dev/peps/pep-0008PEP8https://mail.python.org/mailman/listinfo/astropyAstropy mailing listhttp://groups.google.com/group/astropy-devastropy-dev mailing listhttps://numpy.orgNumPyhttps://pypi.org/project/numpydocnumpydochttps://github.com/liberfa/erfaERFAhttp://pyerfa.readthedocs.orgPyERFAhttps://matplotlib.orgMatplotlibhttp://www.iausofa.org/index.htmlSOFAhttps://www.scipy.orgSciPyhttps://packaging.pypa.iohttps://ipython.orgIPythonhttps://pip.pypa.iohttps://pipenv.pypa.io/en/latestpipenvhttps://pypi.org/project/virtualenvvirtualenvhttps://pypi.org/project/virtualenvwrappervirtualenvwrapperhttps://conda.io/docshttps://docs.conda.io/en/latest/miniconda.htmlminicondahttps://pytest.org/en/latest/index.htmlhttps://github.com/astropy/pytest-astropypytest-astropyhttps://github.com/astropy/pytest-doctestpluspytest-doctestplushttps://github.com/astropy/pytest-remotedatapytest-remotedatahttps://filesystem-spec.readthedocs.iohttps://s3fs.readthedocs.iohttp://www.starlink.ac.uk/stilSTILhttp://www.starlink.ac.uk/stiltsSTILTShttp://www.starlink.ac.uk/topcatTOPCAThttps://packaging-guide.openastronomy.org/en/latestOpenAstronomy Packaging Guidehttps://www.hdfgroup.org/HDF5HDF5http://www.h5py.orgh5pyhttps://parquet.apache.orgParquetlinks_to_become_substitutions` <>`_processed_linkssource-readmissing-reference400# Astropy documentation build configuration file.# This file is execfile()d with the current directory set to its containing dir.# Note that not all possible configuration values are present in this file.# All configuration values have a default. Some values are defined in# the global Astropy configuration which is loaded here before anything else.# If extensions (or modules to document with autodoc) are in another directory,# add these directories to sys.path here. If the directory is relative to the# documentation root, use os.path.abspath to make it absolute, like shown here.# sys.path.insert(0, os.path.abspath('..'))# IMPORTANT: the above commented section was generated by sphinx-quickstart, but# is *NOT* appropriate for astropy or Astropy affiliated packages. It is left# commented out with this explanation to make it clear why this should not be# done. If the sys.path entry above is added, when the astropy.sphinx.conf# import occurs, it will import the *source* version of astropy instead of the# version installed (if invoked as "make html" or directly with sphinx), or the# version in the build directory.# Thus, any C-extensions that are needed to build the documentation will *not*# be accessible, and the documentation will not build correctly.# See sphinx_astropy.conf for which values are set there.# xref: https://github.com/sphinx-doc/sphinx/issues/13232#issuecomment-2608708175# from docs import global_substitutions# -- Check for missing dependencies -------------------------------------------# noqa: E402, F403# noqa: E402# -- Plot configuration -------------------------------------------------------# Don't use the default - which includes a numpy and matplotlib import# -- General configuration ----------------------------------------------------# If your documentation needs a minimal Sphinx version, state it here.# The intersphinx_mapping in sphinx_astropy.sphinx refers to astropy for# the benefit of other packages who want to refer to objects in the# astropy core.  However, we don't want to cyclically reference astropy in its# own build so we remove it here.# add any custom intersphinx for astropy# List of patterns, relative to source directory, that match files and# directories to ignore when looking for source files.# .inc.rst mean *include* files, don't have sphinx process them# Add any paths that contain templates here, relative to this directory.# in case parent conf.py defines it# Grab minversion from pyproject.toml# Manually register doctest options since matplotlib 3.5 messed up allowing them# from pytest-doctestplus# Whether to create cross-references for the parameter types in the# Parameters, Other Parameters, Returns and Yields sections of the docstring.# Words not to cross-reference. Most likely, these are common words used in# parameter type descriptions that may be confused for classes of the same# name. The base set comes from sphinx-astropy. We add more here.# aka something that would be annotated with `typing.Any`# needed in subclassing numpy  # TODO! revisit# TODO! not need to ignore.# Mappings to fully qualified paths (or correct ReST references) for the# aliases/shortcuts used when specifying the types of parameters.# Numpy provides some defaults# https://github.com/numpy/numpydoc/blob/b352cd7635f2ea7748722f410a31f937d92545cc/numpydoc/xref.py#L62-L94# and a base set comes from sphinx-astropy.# so here we mostly need to define Astropy-specific x-refs# python & adjacent# for matplotlib# for numpy# for astropy# Add from sphinx-astropy 1) glossary aliases 2) physical types.# Turn off table of contents entries for functions and classes# -- Project information ------------------------------------------------------# The version info for the project you're documenting, acts as replacement for# |version| and |release|, also used in various other places throughout the# built documents.# The full version, including alpha/beta/rc tags.# The short X.Y version.# Only include dev docs in dev version.# -- Options for the module index ---------------------------------------------# -- Options for HTML output ---------------------------------------------------# https://github.com/pydata/pydata-sphinx-theme/issues/1492# The name for this set of Sphinx documents.  If None, it defaults to# "<project> v<release> documentation".# Output file base name for HTML help builder.# Set canonical URL from the Read the Docs Domain# this is a dynamically generated API page# noqa: F405# Warn if not just a cosmology instance, or a wcs compiled function.# Fall back for items that do not even have a module. Hope for the best.# A dictionary of values to pass into the template engine's context for all pages.# Tell Jinja2 templates the build is running on Read the Docs# Add any extra paths that contain custom files (such as robots.txt or# .htaccess) here, relative to this directory. These files are copied# directly to the root of the documentation.# -- Options for LaTeX output --------------------------------------------------# Grouping the document tree into LaTeX files. List of tuples# (source start file, target name, title, author, documentclass [howto/manual]).# -- Options for manual page output --------------------------------------------# One entry per manual page. List of tuples# (source start file, name, description, authors, manual section).# Setting this URL is required by sphinx-astropy# Enable nitpicky mode - which ensures that all references in the docs# resolve.# See docs/nitpick-exceptions file for the actual listing.# our rebuild is okay# -- Options for linkcheck output -------------------------------------------# CI blocked by service provider# 403 Client Error: Forbidden# 418 Client Error: I'm a teapot# defunct page in CHANGES.rst# Make sure we're outputting HTML# should the node be processed?# str or None# This allows Astropy to use intersphinx links to itself and have# them resolve to local links. Downstream packages will see intersphinx.# TODO: Remove this when https://github.com/sphinx-doc/sphinx/issues/9169 is implemented upstream.# make link local# convert astropy intersphinx targets to local links.# there are a few types of intersphinx link patterns, as described in# https://docs.readthedocs.io/en/stable/guides/intersphinx.html# also need to replace the doc link# Delegate to the ref node's original domain/target (typically :ref:)# Otherwise return None which should delegate to intersphinx# The following global_substitutions can be used throughout the# documentation via sphinxcontrib-globalsubs. The key to the dictionary# is the name of the case-sensitive substitution. For example, if the# key is `"SkyCoord"`, then it can be used as `|SkyCoord|` throughout# the documentation.# NumPy# Coordinates# Cosmology# SAMP# Table# Time# Timeseries# Distribution# Units# Minimum versions# Because sphinxcontrib-globalsubs does not work for regular reStructuredText# links, we first define the links and then process them into the form# of a reStructuredText external link.# Python# Astropy# erfa# matplotlib# sofa# scipy# packaging# IPython# pip# pipenv# virtualenv# conda# pytest# fsspec# s3fs# TOPCAT# OpenAstronomy# Miscellaneous# Generate the page from Jinja template# Set this to higher priority than intersphinx; this way when building# docs astropy: targets will go to the local docs instead of the# intersphinx mappingb'pathlib.Path'u'pathlib.Path'b'extra == "docs"'u'extra == "docs"'b';'u';'b'The following packages could not be found and are required to build the documentation:
%s
Please install the "docs" requirements.'u'The following packages could not be found and are required to build the documentation:
%s
Please install the "docs" requirements.'b'    * 'u'    * 'b'large'u'large'b'figure.figsize'u'figure.figsize'b'figure.subplot.hspace'u'figure.subplot.hspace'b'tight'u'tight'b'savefig.bbox'u'savefig.bbox'b'savefig.facecolor'u'savefig.facecolor'b'png'u'png'b'svg'u'svg'b'pdf'u'pdf'b'3.0'u'3.0'b'https://pyerfa.readthedocs.io/en/stable/'u'https://pyerfa.readthedocs.io/en/stable/'b'pyerfa'u'pyerfa'b'https://docs.pytest.org/en/stable/'u'https://docs.pytest.org/en/stable/'b'pytest'u'pytest'b'https://ipython.readthedocs.io/en/stable/'u'https://ipython.readthedocs.io/en/stable/'b'ipython'u'ipython'b'https://pandas.pydata.org/pandas-docs/stable/'u'https://pandas.pydata.org/pandas-docs/stable/'b'pandas'b'https://sphinx-automodapi.readthedocs.io/en/stable/'u'https://sphinx-automodapi.readthedocs.io/en/stable/'b'sphinx_automodapi'u'sphinx_automodapi'b'https://asdf-astropy.readthedocs.io/en/latest/'u'https://asdf-astropy.readthedocs.io/en/latest/'b'asdf-astropy'u'asdf-astropy'b'https://filesystem-spec.readthedocs.io/en/latest/'u'https://filesystem-spec.readthedocs.io/en/latest/'b'fsspec'u'fsspec'b'https://matplotlib.org/cycler/'u'https://matplotlib.org/cycler/'b'cycler'u'cycler'b'https://docs.dask.org/en/stable/'u'https://docs.dask.org/en/stable/'b'dask'u'dask'b'_templates'u'_templates'b'changes'u'changes'b'_pkgtemplate.rst'u'_pkgtemplate.rst'b'**/*.inc.rst'u'**/*.inc.rst'b'templates_path'u'templates_path'b'matplotlib.sphinxext.roles'u'matplotlib.sphinxext.roles'b'sphinx_changelog'u'sphinx_changelog'b'sphinx_design'u'sphinx_design'b'sphinxcontrib.globalsubs'u'sphinxcontrib.globalsubs'b'rb'u'rb'b'IGNORE_OUTPUT'u'IGNORE_OUTPUT'b'REMOTE_DATA'u'REMOTE_DATA'b'FLOAT_CMP'u'FLOAT_CMP'b'mixin'u'mixin'b'Any'u'Any'b'Arguments'u'Arguments'b'Path'u'Path'b'flag'u'flag'b'bits'u'bits'b'`~typing.Any`'u'`~typing.Any`'b':term:`python:file-like object`'u':term:`python:file-like object`'b'file-like'u'file-like'b':term:`python:file object`'u':term:`python:file object`'b':term:`python:path-like object`'u':term:`python:path-like object`'b'path-like'u'path-like'b':term:`python:module`'u':term:`python:module`'b'module'u'module'b':term:buffer-like'u':term:buffer-like'b'buffer-like'u'buffer-like'b':term:`python:hashable`'u':term:`python:hashable`'b'hashable'u'hashable'b':term:`color`'u':term:`color`'b':class:`python:int`'u':class:`python:int`'b'ints'u'ints'b':term:`number`'u':term:`number`'b'number'u'number'b':class:`~astropy.units.Quantity`'u':class:`~astropy.units.Quantity`'b'Quantity'u'Quantity'b':class:`~astropy.coordinates.BaseRepresentation`'u':class:`~astropy.coordinates.BaseRepresentation`'b'Representation'u'Representation'b':term:`writable file-like object`'u':term:`writable file-like object`'b'writable'u'writable'b':term:`readable file-like object`'u':term:`readable file-like object`'b'readable'u'readable'b':doc:`HDU </io/fits/api/hdus>`'u':doc:`HDU </io/fits/api/hdus>`'b'BaseHDU'u'BaseHDU'b'Astropy'u'Astropy'b'The Astropy Developers'u'The Astropy Developers'u'2011'b'development/*'u'development/*'b'G-R0510VK4B6'u'G-R0510VK4B6'b'google_analytics_id'u'google_analytics_id'b'analytics'u'analytics'b'https://github.com/astropy/astropy'u'https://github.com/astropy/astropy'b'github_url'u'github_url'b'Tutorials'u'Tutorials'b'https://learn.astropy.org/'u'https://learn.astropy.org/'b'url'u'url'b'external_links'u'external_links'b'use_edit_page_button'u'use_edit_page_button'b'_static/astropy_banner_96.png'u'_static/astropy_banner_96.png'b'image_light'u'image_light'b'_static/astropy_banner_96_dark.png'u'_static/astropy_banner_96_dark.png'b'image_dark'u'image_dark'b'logo'u'logo'b'navigation_with_keys'u'navigation_with_keys'b'https://www.astropy.org/annoucement_banner.html'u'https://www.astropy.org/annoucement_banner.html'b'announcement'u'announcement'b' v'u' v'b'_static/astropy_logo.ico'u'_static/astropy_logo.ico'b'_static'u'_static'b'astropy.css'u'astropy.css'b'doc'u'doc'b'READTHEDOCS_CANONICAL_URL'u'READTHEDOCS_CANONICAL_URL'b'Create custom 'edit' URLs for API modules since they are dynamically generated.'u'Create custom 'edit' URLs for API modules since they are dynamically generated.'b'api/astropy.'u'api/astropy.'b'.rst'u'.rst'b'__module__'u'__module__'b'#L'u'#L'b'cosmology.realizations'u'cosmology.realizations'b'modeling.tabular.Tabular'u'modeling.tabular.Tabular'b'astropy.wcs'b'could not find source for 'u'could not find source for 'b'cosmology.realizations.available'u'cosmology.realizations.available'b'astropy/cosmology/'u'astropy/cosmology/'b'realizations.py'u'realizations.py'b'could not find module for 'u'could not find module for 'b'light'u'light'b'default_mode'u'default_mode'b'READTHEDOCS_VERSION'u'READTHEDOCS_VERSION'b'version_slug'u'version_slug'b'stable'u'stable'b'to_be_indexed'u'to_be_indexed'b'is_development'u'is_development'b'github_user'u'github_user'b'github_repo'u'github_repo'b'github_version'u'github_version'b'doc_path'u'doc_path'b'{{ astropy_custom_edit_url(github_user, github_repo, github_version, doc_path, file_name, default_edit_page_url_template) }}'u'{{ astropy_custom_edit_url(github_user, github_repo, github_version, doc_path, file_name, default_edit_page_url_template) }}'b'edit_page_url_template'u'edit_page_url_template'b'https://github.com/{github_user}/{github_repo}/edit/{github_version}/{doc_path}{file_name}'u'https://github.com/{github_user}/{github_repo}/edit/{github_version}/{doc_path}{file_name}'b'default_edit_page_url_template'u'default_edit_page_url_template'b'astropy_custom_edit_url'u'astropy_custom_edit_url'b'READTHEDOCS'u'READTHEDOCS'b'robots.txt'u'robots.txt'b'index'u'index'b'.tex'u'.tex'b' Documentation'u' Documentation'b'manual'u'manual'b'_static/astropy_logo.pdf'u'_static/astropy_logo.pdf'b'https://github.com/astropy/astropy/issues/'u'https://github.com/astropy/astropy/issues/'b'nitpick-exceptions'u'nitpick-exceptions'b'config.cache'u'config.cache'b'https://journals.aas.org/manuscript-preparation/'u'https://journals.aas.org/manuscript-preparation/'b'https://maia.usno.navy.mil/'u'https://maia.usno.navy.mil/'b'https://www.usno.navy.mil/USNO/time/gps/usno-gps-time-transfer'u'https://www.usno.navy.mil/USNO/time/gps/usno-gps-time-transfer'b'https://aa.usno.navy.mil/publications/docs/Circular_179.php'u'https://aa.usno.navy.mil/publications/docs/Circular_179.php'b'http://data.astropy.org'u'http://data.astropy.org'b'https://doi.org/'u'https://doi.org/'b'https://ui.adsabs.harvard.edu'u'https://ui.adsabs.harvard.edu'b'https://www.tandfonline.com/'u'https://www.tandfonline.com/'b'https://stackoverflow.com/'u'https://stackoverflow.com/'b'https://ieeexplore.ieee.org/'u'https://ieeexplore.ieee.org/'b'https://pyfits.readthedocs.io/en/v3.2.1/'u'https://pyfits.readthedocs.io/en/v3.2.1/'b'https://pkgs.dev.azure.com/astropy-project'u'https://pkgs.dev.azure.com/astropy-project'b'https://github\.com/astropy/astropy/(?:issues|pull)/\d+'u'https://github\.com/astropy/astropy/(?:issues|pull)/\d+'b'Render pages as a jinja template to hide/show dev docs.'u'Render pages as a jinja template to hide/show dev docs.'b'html'u'html'b'index_dev'u'index_dev'b'Jinja rendering %s'u'Jinja rendering %s'b'
    Reference targets for ``astropy:`` are special cases.

    Documentation links in astropy can be set up as intersphinx links so that
    affiliate packages do not have to override the docstrings when building
    the docs.

    'u'
    Reference targets for ``astropy:`` are special cases.

    Documentation links in astropy can be set up as intersphinx links so that
    affiliate packages do not have to override the docstrings when building
    the docs.

    'b'reftarget'u'reftarget'b'astropy:'u'astropy:'b'reftype'u'reftype'b'refdoc'u'refdoc'b'refdomain'u'refdomain'b'project'u'project'b'requires-python'u'requires-python'b'>='u'>='b':class:`numpy.ndarray`'u':class:`numpy.ndarray`'b'ndarray'u'ndarray'b':class:`~astropy.coordinates.EarthLocation`'u':class:`~astropy.coordinates.EarthLocation`'b'EarthLocation'u'EarthLocation'b'`~astropy.coordinates.Angle`'u'`~astropy.coordinates.Angle`'b'Angle'u'Angle'b'`~astropy.coordinates.Latitude`'u'`~astropy.coordinates.Latitude`'b'Latitude'u'Latitude'b':class:`~astropy.coordinates.Longitude`'u':class:`~astropy.coordinates.Longitude`'b'Longitude'u'Longitude'b'`~astropy.coordinates.BaseCoordinateFrame`'u'`~astropy.coordinates.BaseCoordinateFrame`'b'BaseFrame'u'BaseFrame'b':class:`~astropy.coordinates.SkyCoord`'u':class:`~astropy.coordinates.SkyCoord`'b'SkyCoord'u'SkyCoord'b'`~astropy.coordinates.SpectralCoord`'u'`~astropy.coordinates.SpectralCoord`'b'SpectralCoord'u'SpectralCoord'b':class:`~astropy.cosmology.Cosmology`'u':class:`~astropy.cosmology.Cosmology`'b':meth:`~astropy.cosmology.Cosmology.read`'u':meth:`~astropy.cosmology.Cosmology.read`'b'Cosmology.read'u'Cosmology.read'b':meth:`~astropy.cosmology.Cosmology.write`'u':meth:`~astropy.cosmology.Cosmology.write`'b'Cosmology.write'u'Cosmology.write'b':meth:`~astropy.cosmology.Cosmology.from_format`'u':meth:`~astropy.cosmology.Cosmology.from_format`'b'Cosmology.from_format'u'Cosmology.from_format'b':meth:`~astropy.cosmology.Cosmology.to_format`'u':meth:`~astropy.cosmology.Cosmology.to_format`'b'Cosmology.to_format'u'Cosmology.to_format'b':class:`~astropy.cosmology.FLRW`'u':class:`~astropy.cosmology.FLRW`'b':class:`~astropy.cosmology.LambdaCDM`'u':class:`~astropy.cosmology.LambdaCDM`'b':class:`~astropy.cosmology.FlatLambdaCDM`'u':class:`~astropy.cosmology.FlatLambdaCDM`'b':ref:`astropy_cosmology_realizations_WMAP1`'u':ref:`astropy_cosmology_realizations_WMAP1`'b':ref:`astropy_cosmology_realizations_WMAP3`'u':ref:`astropy_cosmology_realizations_WMAP3`'b':ref:`astropy_cosmology_realizations_WMAP5`'u':ref:`astropy_cosmology_realizations_WMAP5`'b':ref:`astropy_cosmology_realizations_WMAP7`'u':ref:`astropy_cosmology_realizations_WMAP7`'b':ref:`astropy_cosmology_realizations_WMAP9`'u':ref:`astropy_cosmology_realizations_WMAP9`'b':ref:`astropy_cosmology_realizations_Planck13`'u':ref:`astropy_cosmology_realizations_Planck13`'b':ref:`astropy_cosmology_realizations_Planck15`'u':ref:`astropy_cosmology_realizations_Planck15`'b':ref:`astropy_cosmology_realizations_Planck18`'u':ref:`astropy_cosmology_realizations_Planck18`'b':class:`~astropy.cosmology.FlatCosmologyMixin`'u':class:`~astropy.cosmology.FlatCosmologyMixin`'b':class:`~astropy.cosmology.FlatFLRWMixin`'u':class:`~astropy.cosmology.FlatFLRWMixin`'b':class:`~astropy.cosmology.default_cosmology`'u':class:`~astropy.cosmology.default_cosmology`'b':class:`~astropy.samp.SAMPClient`'u':class:`~astropy.samp.SAMPClient`'b':class:`~astropy.samp.SAMPIntegratedClient`'u':class:`~astropy.samp.SAMPIntegratedClient`'b'SAMPIntegratedClient'u'SAMPIntegratedClient'b':class:`~astropy.samp.SAMPHubServer`'u':class:`~astropy.samp.SAMPHubServer`'b'SAMPHubServer'u'SAMPHubServer'b':class:`~astropy.samp.SAMPHubProxy`'u':class:`~astropy.samp.SAMPHubProxy`'b'SAMPHubProxy'u'SAMPHubProxy'b':class:`~astropy.table.Column`'u':class:`~astropy.table.Column`'b':class:`~astropy.table.MaskedColumn`'u':class:`~astropy.table.MaskedColumn`'b':class:`~astropy.table.TableColumns`'u':class:`~astropy.table.TableColumns`'b':class:`~astropy.table.Row`'u':class:`~astropy.table.Row`'b':class:`~astropy.table.Table`'u':class:`~astropy.table.Table`'b':class:`~astropy.table.QTable`'u':class:`~astropy.table.QTable`'b':class:`~astropy.time.Time`'u':class:`~astropy.time.Time`'b'Time'u'Time'b':class:`~astropy.time.TimeDelta`'u':class:`~astropy.time.TimeDelta`'b'TimeDelta'u'TimeDelta'b':class:`~astropy.timeseries.TimeSeries`'u':class:`~astropy.timeseries.TimeSeries`'b'TimeSeries'u'TimeSeries'b':class:`~astropy.timeseries.BinnedTimeSeries`'u':class:`~astropy.timeseries.BinnedTimeSeries`'b':class:`~astropy.uncertainty.Distribution`'u':class:`~astropy.uncertainty.Distribution`'b'Distribution'u'Distribution'b':class:`~astropy.units.PhysicalType`'u':class:`~astropy.units.PhysicalType`'b'PhysicalType'u'PhysicalType'b':class:`~astropy.units.UnitBase`'u':class:`~astropy.units.UnitBase`'b'Unit'u'Unit'b':class:`~astropy.units.StructuredUnit`'u':class:`~astropy.units.StructuredUnit`'b'StructuredUnit'u'StructuredUnit'b':class:`~astropy.utils.masked.Masked`'u':class:`~astropy.utils.masked.Masked`'b'Masked'u'Masked'b'minimum_python_version'u'minimum_python_version'b'minimum_numpy_version'u'minimum_numpy_version'b'minimum_pyerfa_version'u'minimum_pyerfa_version'b'minimum_matplotlib_version'u'minimum_matplotlib_version'b'minimum_scipy_version'u'minimum_scipy_version'b'minimum_asdf_astropy_version'u'minimum_asdf_astropy_version'b'packaging'u'packaging'b'minimum_packaging_version'u'minimum_packaging_version'b'pyyaml'u'pyyaml'b'minimum_pyyaml_version'u'minimum_pyyaml_version'b'minimum_ipython_version'u'minimum_ipython_version'b'pyarrow'u'pyarrow'b'minimum_pyarrow_version'u'minimum_pyarrow_version'b'minimum_fsspec_version'u'minimum_fsspec_version'b's3fs'u's3fs'b'minimum_s3fs_version'u'minimum_s3fs_version'b'https://www.python.org'u'https://www.python.org'b'Python'u'Python'b'https://www.python.org/dev/peps/pep-0008'u'https://www.python.org/dev/peps/pep-0008'b'PEP8'u'PEP8'b'https://mail.python.org/mailman/listinfo/astropy'u'https://mail.python.org/mailman/listinfo/astropy'b'Astropy mailing list'u'Astropy mailing list'b'http://groups.google.com/group/astropy-dev'u'http://groups.google.com/group/astropy-dev'b'astropy-dev mailing list'u'astropy-dev mailing list'b'https://numpy.org'u'https://numpy.org'b'NumPy'u'NumPy'b'https://pypi.org/project/numpydoc'u'https://pypi.org/project/numpydoc'b'numpydoc'u'numpydoc'b'https://github.com/liberfa/erfa'u'https://github.com/liberfa/erfa'b'ERFA'u'ERFA'b'http://pyerfa.readthedocs.org'u'http://pyerfa.readthedocs.org'b'PyERFA'u'PyERFA'b'https://matplotlib.org'u'https://matplotlib.org'b'Matplotlib'u'Matplotlib'b'http://www.iausofa.org/index.html'u'http://www.iausofa.org/index.html'b'SOFA'u'SOFA'b'https://www.scipy.org'u'https://www.scipy.org'b'SciPy'u'SciPy'b'https://packaging.pypa.io'u'https://packaging.pypa.io'b'https://ipython.org'u'https://ipython.org'b'IPython'u'IPython'b'https://pip.pypa.io'u'https://pip.pypa.io'b'pip'u'pip'b'https://pipenv.pypa.io/en/latest'u'https://pipenv.pypa.io/en/latest'b'pipenv'u'pipenv'b'https://pypi.org/project/virtualenv'u'https://pypi.org/project/virtualenv'b'virtualenv'u'virtualenv'b'https://pypi.org/project/virtualenvwrapper'u'https://pypi.org/project/virtualenvwrapper'b'virtualenvwrapper'u'virtualenvwrapper'b'https://conda.io/docs'u'https://conda.io/docs'b'conda'u'conda'b'https://docs.conda.io/en/latest/miniconda.html'u'https://docs.conda.io/en/latest/miniconda.html'b'miniconda'u'miniconda'b'https://pytest.org/en/latest/index.html'u'https://pytest.org/en/latest/index.html'b'https://github.com/astropy/pytest-astropy'u'https://github.com/astropy/pytest-astropy'b'pytest-astropy'u'pytest-astropy'b'https://github.com/astropy/pytest-doctestplus'u'https://github.com/astropy/pytest-doctestplus'b'pytest-doctestplus'u'pytest-doctestplus'b'https://github.com/astropy/pytest-remotedata'u'https://github.com/astropy/pytest-remotedata'b'pytest-remotedata'u'pytest-remotedata'b'https://filesystem-spec.readthedocs.io'u'https://filesystem-spec.readthedocs.io'b'https://s3fs.readthedocs.io'u'https://s3fs.readthedocs.io'b'http://www.starlink.ac.uk/stil'u'http://www.starlink.ac.uk/stil'b'STIL'u'STIL'b'http://www.starlink.ac.uk/stilts'u'http://www.starlink.ac.uk/stilts'b'STILTS'u'STILTS'b'http://www.starlink.ac.uk/topcat'u'http://www.starlink.ac.uk/topcat'b'TOPCAT'u'TOPCAT'b'https://packaging-guide.openastronomy.org/en/latest'u'https://packaging-guide.openastronomy.org/en/latest'b'OpenAstronomy Packaging Guide'u'OpenAstronomy Packaging Guide'b'https://www.hdfgroup.org/HDF5'u'https://www.hdfgroup.org/HDF5'b'HDF5'u'HDF5'b'http://www.h5py.org'u'http://www.h5py.org'b'h5py'u'h5py'b'https://parquet.apache.org'u'https://parquet.apache.org'b'Parquet'u'Parquet'b'`'u'`'b' <'u' <'b'>`_'u'>`_'b'source-read'u'source-read'b'missing-reference'u'missing-reference'u'docs.conf'
Configures the codata and iaudata used, possibly using user configuration.
phys_versionastro_version.constants.# Note: doing this in __init__ causes import problems with units,# as si.py and cgs.py have to import the result.b'
Configures the codata and iaudata used, possibly using user configuration.
'u'
Configures the codata and iaudata used, possibly using user configuration.
'b'.constants.'u'.constants.'u'astropy.constants.config'u'constants.config'codecsBOM_UTF8BOM_UTF16BOM_UTF16_BEBOM_UTF16_LEcompilerutf_8utf16_beutf_16utf16_leBOMSu16utf16utf-16utf_16_beutf-16beutf_16_leutf-16leutfBOM_LISTBOM_SETmatch_utf8'%s'squotdquot%snoquot 
	'"wspace_plus"""%s"""tsquot'''%s'''tdquotDEFAULT_INDENT_TYPEDEFAULT_INTERPOLATIONConfigObjErrorNestingErrorParseErrorDuplicateErrorConfigspecErrorConfigObjSimpleValInterpolationErrorInterpolationLoopErrorMissingInterpolationOptionRepeatSectionErrorReloadErrorUnreprErrorUnknownTypeflatten_errorsget_extra_valuesconfigparserMAX_INTERPOL_DEPTHinterpolationraise_errorslist_valuescreate_emptyfile_errorconfigspecstringifyindent_typedefault_encodingunreprwrite_empty_valuesOPTION_DEFAULTSgetObja=getChildrenBuilderbuild_Listbuild_Constbuild_Dictelbuild_Tuplebuild_NameUndefined Namebuild_AddAddbuild_Getattrexprattrnamebuild_UnarySubbuild_UnaryAdd_builderastliteral_eval
    This is the base class for all errors that ConfigObj raises.
    It is a subclass of SyntaxError.
    line_number
    This error indicates a level of nesting that doesn't match.
    
    This error indicates that a line is badly written.
    It is neither a valid ``key = value`` line,
    nor a valid section marker line.
    
    A 'reload' operation failed.
    This exception is a subclass of ``IOError``.
    reload failed, filename is not set.
    The keyword or section specified already exists.
    
    An error occured whilst parsing a configspec.
    Base class for the two interpolation errors.Maximum interpolation depth exceeded in string interpolation.interpolation loop detected in value "%s".
    This error indicates additional sections in a section with a
    ``__many__`` (repeated) section.
    A value specified for interpolation was missing.missing option "%s" in interpolation.An error parsing in unrepr mode.InterpolationEngine
    A helper class to help perform string interpolation.

    This class is an abstract base class; its descendants perform
    the actual work.
    %\(([^)]*)\)s_KEYCRE_cookieinterpolaterecursive_interpolatebacktrailThe function that does the actual work.

            ``value``: the string we're trying to interpolate.
            ``section``: the section in which that string was found
            ``backtrail``: a dict to keep track of where we've been,
            to detect and prevent infinite recursion loops

            This is similar to a depth-first-search algorithm.
            _parse_matchreplacementspannew_search_start_fetchHelper function to fetch values from owning section.

        Returns a 2-tuple: the value, and the section where it was found.
        save_interpcurrent_sectionDEFAULTImplementation-dependent helper function.

        Will be passed a match object corresponding to the interpolation
        key we just found (e.g., "%(foo)s" or "$foo"). Should look up that
        key in the appropriate config file section (using the ``_fetch()``
        helper function) and return a 3-tuple: (key, value, section)

        ``key`` is the name of the key we're looking for
        ``value`` is the value found for that key
        ``section`` is a reference to the section where it was found

        ``key`` and ``section`` should be None if no further
        interpolation should be performed on the resulting value
        (e.g., if we interpolated "$$" and returned "$").
        ConfigParserInterpolationBehaves like ConfigParser.TemplateInterpolationBehaves like string.Template._delimiter
        \$(?:
          (?P<escaped>\$)              |   # Two $ signs
          (?P<named>[_a-z][_a-z0-9]*)  |   # $name format
          {(?P<braced>[^}]*)}              # ${name} format
        )
        namedbracedescapedinterpolation_engines__newobj__
    A dictionary-like object that represents a section in a config file.

    It does string interpolation if the 'interpolation' attribute
    of the 'main' object is set to True.

    Interpolation is tried first from this object, then from the 'DEFAULT'
    section of this object, next from the parent and its 'DEFAULT' section,
    and so on until the main object is reached.

    A Section will behave like an ordered dictionary - following the
    order of the ``scalars`` and ``sections`` attributes.
    You can use this to change the order of members.

    Iteration follows the order: scalars, then sections.
    depthindict
        * parent is the section above
        * depth is the depth level of this section
        * main is the main ConfigObj
        * indict is a dictionary to initialise the section with
        _initialisescalarssectionsinline_commentsdefault_valuesextra_values_created_interpolate_interpolation_engineengineclass_Fetch the item and do string interpolation._check
        Correctly set a value.

        Making dictionary values Section instances.
        (We have to special case 'Section' instances - which are also dicts)

        Keys must be strings.
        Values need only be strings (or lists of strings) if
        ``main.stringify`` is set.

        ``unrepr`` must be set when setting a value to a dictionary, without
        creating a new sub-section.
        The key "%s" is not a string.new_depthValue is not a string "%s".Remove items from the sequence when deleting.A version of ``get`` that doesn't bypass string interpolation.
        A version of update that uses our ``__setitem__``.
        
        'D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised'
        Pops the first (key,val)sequence: 'popitem(): dictionary is empty'
        A version of clear that also affects scalars/sections
        Also clears comments and configspec.

        Leaves other attributes alone :
            depth/main/parent are not affected
        A version of setdefault that sets sequence if appropriate.D.items() -> list of D's (key, value) pairs, as 2-tuplesD.keys() -> list of D's keysD.values() -> list of D's valuesiteritemsD.iteritems() -> an iterator over the (key, value) items of DiterkeysD.iterkeys() -> an iterator over the keys of DitervaluesD.itervalues() -> an iterator over the values of Dx.__repr__() <==> repr(x)_getval{%s}%s: %sx.__str__() <==> str(x)
        Return a deepcopy of self as a dictionary.

        All members that are ``Section`` instances are recursively turned to
        ordinary dictionaries - by calling their ``dict`` method.

        >>> n = a.dict()
        >>> n == a
        1
        >>> n is a
        0
        newdictthis_entry
        A recursive update - useful for merging config files.

        >>> a = '''[section1]
        ...     option1 = True
        ...     [[subsection]]
        ...     more_options = False
        ...     # end of file'''.splitlines()
        >>> b = '''# File is user.ini
        ...     [section1]
        ...     option1 = False
        ...     # end of file'''.splitlines()
        >>> c1 = ConfigObj(b)
        >>> c2 = ConfigObj(a)
        >>> c2.merge(c1)
        >>> c2
        ConfigObj({'section1': {'option1': 'False', 'subsection': {'more_options': 'False'}}})
        renameoldkeynewkey
        Change a keyname to another, without changing position in sequence.

        Implemented so that transformations can be made on keys,
        as well as on values. (used by encode and decode)

        Also renames comments.
        the_listKey "%s" not found.inline_commentcall_on_sectionskeywargs
        Walk every member and call a function on the keyword and value.

        Return a dictionary of the return values

        If the function raises an exception, raise the errror
        unless ``raise_errors=False``, in which case set the return value to
        ``False``.

        Any unrecognized keyword arguments you pass to walk, will be pased on
        to the function you pass in.

        Note: if ``call_on_sections`` is ``True`` then - on encountering a
        subsection, *first* the function is called for the *whole* subsection,
        and then recurses into it's members. This means your function must be
        able to handle strings, dictionaries and lists. This allows you
        to change the key of subsections as well as for ordinary members. The
        return value when called on the whole subsection has to be discarded.

        See  the encode and decode methods for examples, including functions.

        .. admonition:: caution

            You can use ``walk`` to transform the names of members of a section
            but you mustn't add or delete members.

        >>> config = '''[XXXXsection]
        ... XXXXkey = XXXXvalue'''.splitlines()
        >>> cfg = ConfigObj(config)
        >>> cfg
        ConfigObj({'XXXXsection': {'XXXXkey': 'XXXXvalue'}})
        >>> def transform(section, key):
        ...     val = section[key]
        ...     newkey = key.replace('XXXX', 'CLIENT1')
        ...     section.rename(key, newkey)
        ...     if isinstance(val, (tuple, list, dict)):
        ...         pass
        ...     else:
        ...         val = val.replace('XXXX', 'CLIENT1')
        ...         section[newkey] = val
        >>> cfg.walk(transform, call_on_sections=True)
        {'CLIENT1section': {'CLIENT1key': None}}
        >>> cfg
        ConfigObj({'CLIENT1section': {'CLIENT1key': 'CLIENT1value'}})
        as_bool
        Accepts a key as input. The corresponding value must be a string or
        the objects (``True`` or 1) or (``False`` or 0). We allow 0 and 1 to
        retain compatibility with Python 2.2.

        If the string is one of  ``True``, ``On``, ``Yes``, or ``1`` it returns
        ``True``.

        If the string is one of  ``False``, ``Off``, ``No``, or ``0`` it returns
        ``False``.

        ``as_bool`` is not case sensitive.

        Any other input will raise a ``ValueError``.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_bool('a')
        Traceback (most recent call last):
        ValueError: Value "fish" is neither True nor False
        >>> a['b'] = 'True'
        >>> a.as_bool('b')
        1
        >>> a['b'] = 'off'
        >>> a.as_bool('b')
        0
        _boolsValue "%s" is neither True nor Falseas_int
        A convenience method which coerces the specified value to an integer.

        If the value is an invalid literal for ``int``, a ``ValueError`` will
        be raised.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_int('a')
        Traceback (most recent call last):
        ValueError: invalid literal for int() with base 10: 'fish'
        >>> a['b'] = '1'
        >>> a.as_int('b')
        1
        >>> a['b'] = '3.2'
        >>> a.as_int('b')
        Traceback (most recent call last):
        ValueError: invalid literal for int() with base 10: '3.2'
        as_float
        A convenience method which coerces the specified value to a float.

        If the value is an invalid literal for ``float``, a ``ValueError`` will
        be raised.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_float('a')  #doctest: +IGNORE_EXCEPTION_DETAIL
        Traceback (most recent call last):
        ValueError: invalid literal for float(): fish
        >>> a['b'] = '1'
        >>> a.as_float('b')
        1.0
        >>> a['b'] = '3.2'
        >>> a.as_float('b')  #doctest: +ELLIPSIS
        3.2...
        as_list
        A convenience method which fetches the specified value, guaranteeing
        that it is a list.

        >>> a = ConfigObj()
        >>> a['a'] = 1
        >>> a.as_list('a')
        [1]
        >>> a['a'] = (1,)
        >>> a.as_list('a')
        [1]
        >>> a['a'] = [1]
        >>> a.as_list('a')
        [1]
        restore_default
        Restore (and return) default value for the specified key.

        This method will only work for a ConfigObj that was created
        with a configspec and has been validated.

        If there is no default value for this key, ``KeyError`` is raised.
        restore_defaults
        Recursively restore default values to all members
        that have them.

        This method will only work for a ConfigObj that was created
        with a configspec and has been validated.

        It doesn't delete or modify entries without default values.
        An object to read, create, and write config files.^ # line start
        (\s*)                   # indentation
        (                       # keyword
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'"=].*?)       # no quotes
        )
        \s*=\s*                 # divider
        (.*)                    # value (including list values and comments)
        $   # line end
        r'''^
        (\s*)                     # 1: indentation
        ((?:\[\s*)+)              # 2: section marker open
        (                         # 3: section name open
            (?:"\s*\S.*?\s*")|    # at least one non-space with double quotes
            (?:'\s*\S.*?\s*')|    # at least one non-space with single quotes
            (?:[^'"\s].*?)        # at least one non-space unquoted
        )                         # section name close
        ((?:\s*\])+)              # 4: section marker close
        \s*(\#.*)?                # 5: optional comment
        $_sectionmarker^
        (?:
            (?:
                (
                    (?:
                        (?:
                            (?:".*?")|              # double quotes
                            (?:'.*?')|              # single quotes
                            (?:[^'",\#][^,\#]*?)    # unquoted
                        )
                        \s*,\s*                     # comma
                    )*      # match all list items ending in a comma (if any)
                )
                (
                    (?:".*?")|                      # double quotes
                    (?:'.*?')|                      # single quotes
                    (?:[^'",\#\s][^,]*?)|           # unquoted
                    (?:(?<!,))                      # Empty value
                )?          # last item in a list - or string value
            )|
            (,)             # alternatively a single comma - empty list
        )
        \s*(\#.*)?          # optional comment
        $_valueexp
        (
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'",\#]?.*?)       # unquoted
        )
        \s*,\s*                 # comma
        _listvalueexp^
        (
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'"\#].*?)|     # unquoted
            (?:)                # Empty value
        )
        \s*(\#.*)?              # optional comment
        $_nolistvalue^'''(.*?)'''\s*(#.*)?$_single_line_single^"""(.*?)"""\s*(#.*)?$_single_line_double^(.*?)'''\s*(#.*)?$_multi_line_single^(.*?)"""\s*(#.*)?$_multi_line_double'''_triple_quoteyesnoinfile_inspec
        Parse a config file or create a config file object.

        ``ConfigObj(infile=None, configspec=None, encoding=None,
                    interpolation=True, raise_errors=False, list_values=True,
                    create_empty=False, file_error=False, stringify=True,
                    indent_type=None, default_encoding=None, unrepr=False,
                    write_empty_values=False, _inspec=False)``
        _optionsPassing in an options dictionary to ConfigObj() is deprecated. Use **options instead.'Passing in an options dictionary to ConfigObj() is ''deprecated. Use **options instead.'Unrecognized option "%s".keyword_value_original_configspec_loadisfileConfig file not found: "%s".set_sectionin_sectionthis_section_errors_handle_configspecinfile must be a filename, file like object, or list of lines._handle_bom
_parseat line %s.Parsing failed with several errors.
First error %sBOMinitial_commentfinal_comment%s({%s})
        Handle any BOM, and decode if necessary.

        If an encoding is specified, that *must* be used - but the BOM should
        still be removed (and the BOM attribute set).

        (If the encoding is wrongly specified, then a BOM for an alternative
        encoding won't be discovered or removed.)

        If an encoding is not specified, UTF8 or UTF16 BOM will be detected and
        removed. The BOM attribute will be set. UTF16 will be decoded to
        unicode.

        NOTE: This method must not be called with an empty ``infile``.

        Specifying the *wrong* encoding is likely to cause a
        ``UnicodeDecodeError``.

        ``infile`` must always be returned as a list of lines, but may be
        passed in as a single string.
        _decodeencfinal_encodingnewline_a_to_uaStringDecode ASCII strings to unicode if a self.encoding is specified.
        Decode infile to unicode. Using the specified encoding.

        if is a string, it also needs converting to a list.
        _decode_elementDecode element to unicode if necessary._str
        Used by ``stringify`` within validate, to turn non-string values
        into strings.
        Actually parse the config file.temp_list_valuescomment_listdone_startmaxlinecur_indexreset_commentslinematsect_opensect_namesect_close[cur_depth]_handle_errorCannot compute the section depth_match_depthCannot compute nesting levelSection too nested_unquoteDuplicate section nameInvalid line ({0!r}) (matched as neither section nor keyword)_multilineUnknown name or type in valueParse error from unrepr-ing multiline valueParse error in multiline valueParse error from unrepr-ing value_handle_valueParse error in valueDuplicate keyword namesect
        Given a section and a depth level, walk back through the sections
        parents to see if the depth level matches a previous section.

        Return a reference to the right section,
        or raise a SyntaxError.
        ErrorClass
        Handle an error according to the error settings.

        Either raise the error or store it.
        The error will have occured at ``cur_index``
        {0} at line {1}.Return an unquoted version of a value_quote
        Return a safely quoted version of a value.

        Raise a ConfigObjError if the value cannot be safely quoted.
        If multiline is ``True`` (default) then use triple quotes
        if necessary.

        * Don't quote values that don't need it.
        * Recursively quote members of a list and return a comma joined list.
        * Multiline is ``False`` for lists.
        * Obey list syntax for empty and single member lists.

        If ``list_values=False`` then the value is only quoted if it contains
        a ``\n`` (is multiline) or '#'.

        If ``write_empty_values`` is set, and the value is an empty string, it
        won't be quoted.
        Value "%s" is not a string.no_lists_no_quotesneed_triplehash_triple_quotecheck_for_singlequotValue "%s" cannot be safely quoted._get_single_quote_get_triple_quote
        Given a value string, unquote, remove comment,
        handle lists. (including empty and single member lists)
        empty_listExtract the value, where we are in a multiline situation.newvaluesingle_linemulti_lineretvalParse the configspec.Parsing configspec failed: %sReading configspec failed: %s_set_configspec
        Called by validate. Handles setting the configspec on subsections
        including sections to be validated by __many__
        __many__many_write_lineindent_stringWrite an individual line, for the write method%s%s%s%s%s_write_markerWrite a section marker line_handle_commentDeal with a comment. # outfile
        Write the current ConfigObj as a file

        tekNico: FIXME: use StringIO instead of real files

        >>> filename = a.filename
        >>> a.filename = 'test.ini'
        >>> a.write()
        >>> a.filename = filename
        >>> a == ConfigObj('test.ini', raise_errors=True)
        1
        >>> import os
        >>> os.remove('test.ini')
        cspint_valstripped_linecomment_lineoutput_bytespreserve_errors
        Test the ConfigObj against a configspec.

        It uses the ``validator`` object from *validate.py*.

        To run ``validate`` on the current ConfigObj, call: ::

            test = config.validate(validator)

        (Normally having previously passed in the configspec when the ConfigObj
        was created - you can dynamically assign a dictionary of checks to the
        ``configspec`` attribute of a section though).

        It returns ``True`` if everything passes, or a dictionary of
        pass/fails (True/False). If every member of a subsection passes, it
        will just have the value ``True``. (It also returns ``False`` if all
        members fail).

        In addition, it converts the values from strings to their native
        types if their checks pass (and ``stringify`` is set).

        If ``preserve_errors`` is ``True`` (``False`` is default) then instead
        of a marking a fail with a ``False``, it will preserve the actual
        exception object. This can contain info about the reason for failure.
        For example the ``VdtValueTooSmallError`` indicates that the value
        supplied was too small. If a value (or section) is missing it will
        still be marked as ``False``.

        You must have the validate module to use ``preserve_errors=True``.

        You can then use the ``flatten_errors`` function to turn your nested
        results dictionary into a flattened list of failures - useful for
        displaying meaningful error messages.
        No configspec supplied.VdtMissingValue_vdtMissingValuevalidate_entryspecmissingret_trueret_falseget_default_valuebaseErrorClassunvalidatedincorrect_sectionsincorrect_scalars___many___Value %r was provided as a sectionSection %r was provided as a single valueresetClear ConfigObj instance and restore to 'freshly created' state.reload
        Reload a ConfigObj from file.

        This method raises a ``ReloadError`` if the ConfigObj doesn't have
        a filename attribute pointing to a file.
        current_options
    A simple validator.
    Can be used to check that all members expected are present.

    To use it, provide a configspec with all your members in (the value given
    will be ignored). Pass an instance of ``SimpleVal`` to the ``validate``
    method of your ``ConfigObj``. ``validate`` will return ``True`` if all
    members are present, or a dictionary with True/False meaning
    present/missing. (Whole missing sections will be replaced with ``False``)
    memberA dummy check method, always returns the value unchanged.cfglevels
    An example function that will turn a nested dictionary of results
    (as returned by ``ConfigObj.validate``) into a flat list.

    ``cfg`` is the ConfigObj instance being checked, ``res`` is the results
    dictionary returned by ``validate``.

    (This is a recursive function, so you shouldn't use the ``levels`` or
    ``results`` arguments - they are used by the function.)

    Returns a list of keys that failed. Each member of the list is a tuple::

        ([list of sections...], key, result)

    If ``validate`` was called with ``preserve_errors=False`` (the default)
    then ``result`` will always be ``False``.

    *list of sections* is a flattened list of sections that the key was found
    in.

    If the section was missing (or a section was expected and a scalar provided
    - or vice-versa) then key will be ``None``.

    If the value (or section) was missing then ``result`` will be ``False``.

    If ``validate`` was called with ``preserve_errors=True`` and a value
    was present, but failed the check, then ``result`` will be the exception
    object returned. You can use this as a string that describes the failure.

    For example *The value "3" is of the wrong type*.
    _prepend
    Find all the values and sections not in the configspec from a validated
    ConfigObj.

    ``get_extra_values`` returns a list of tuples where each tuple represents
    either an extra section, or an extra value.

    The tuples contain two values, a tuple representing the section the value
    is in and the name of the extra values. For extra values in the top level
    section the first member will be an empty tuple. For values in the 'foo'
    section the first member will be ``('foo',)``. For members in the 'bar'
    subsection of the 'foo' section the first member will be ``('foo', 'bar')``.

    NOTE: If you call ``get_extra_values`` on a ConfigObj instance that hasn't
    been validated it will return an empty list.
    *A programming language is a medium of expression.* - Paul Graham# configobj.py# A config file reader/writer that supports nested sections in config files.# Copyright (C) 2005-2014:# (name) : (email)# Michael Foord: fuzzyman AT voidspace DOT org DOT uk# Nicola Larosa: nico AT tekNico DOT net# Rob Dennis: rdennis AT gmail DOT com# Eli Courtwright: eli AT courtwright DOT org# This software is licensed under the terms of the BSD license.# http://opensource.org/licenses/BSD-3-Clause# ConfigObj 5 - main repository for documentation and issue tracking:# https://github.com/DiffSK/configobj# imported lazily to avoid startup performance hit if it isn't used# A dictionary mapping BOM to# the encoding to decode with, and what to set the# encoding attribute to.# All legal variants of the BOM codecs.# TODO: the list of aliases is not meant to be exhaustive, is there a#   better way ?# Map of encodings to the BOM to write.# Quote strings used for writing values# Sentinel for use in getattr calls to replace hasattr# option may be set to one of ('', ' ', '\t')# this could be replaced if six is used for compatibility, or there are no# more assertions about items being a string# An undefined Name# this is supposed to be safe# compiled regexp to use in self.interpolate()# the Section instance that "owns" this engine# short-cut# Have we been here already?# Yes - infinite loop detected# Place a marker on our backtrail so we won't come back here again# Now start the actual work# The actual parsing of the match is implementation-dependent,# so delegate to our helper function# That's the signal that no further interpolation is needed# Further interpolation may be needed to obtain final value# Replace the matched string with its final value# Pick up the next interpolation key, if any, for next time# through the while loop# Now safe to come back here again; remove marker from backtrail# Back in interpolate(), all we have to do is kick off the recursive# function with appropriate starting values# switch off interpolation before we try and fetch anything !# Start at section that "owns" this InterpolationEngine# try the current section first# try "DEFAULT" next# move up to parent and try again# top-level's parent is itself# reached top level, time to give up# restore interpolation to previous value before returning# Valid name (in or out of braces): fetch value from section# Escaped delimiter (e.g., $$): return single delimiter# Return None for key and section to indicate it's time to stop# Anything else: ignore completely, just return it unchanged# Hack for pickle# used for nesting level *and* interpolation# used for the interpolation attribute# level of nesting depth of this Section# purely for information# we do this explicitly so that __setitem__ is used properly# (rather than just passing to ``dict.__init__``)# the sequence of scalar values in this Section# the sequence of sections in this Section# for comments :-)# the configspec# for defaults# do we already have an interpolation engine?# not yet: first time running _interpolate(), so pick the engine# note that "if name:" would be incorrect here# backwards-compatibility: interpolation=True means use default# so that "Template", "template", etc. all work# invalid value for self.main.interpolation# save reference to engine so we don't have to do this again# let the engine do the actual work# add the comment# remove the entry from defaults# First create the new depth level,# then create the section# Extra methods - not in a normal dictionary# create a copy rather than a reference# scalars first# bound again in case name has changed# then sections# previous result is discarded# TODO: Why do we raise a KeyError here?# this regexp pulls list values out as a single string# or single values and comments# FIXME: this regex adds a '' to the end of comma terminated lists#   workaround in ``_handle_value``# use findall to get the members of a list value# this regexp is used for the value# when lists are switched off# regexes for finding triple quoted values on one line# Used by the ``istrue`` Section method# init the superclass# TODO: check the values too.# XXXX this ignores an explicit list_values = True in combination# with _inspec. The user should *never* do that anyway, but still...# raise an error if the file doesn't exist# file doesn't already exist# this is a good test that the filename specified# isn't impossible - like on a non-existent device# initialise self# the Section class handles creating subsections# get a copy of our ConfigObj# This supports file like objects# needs splitting into lines - but needs doing *after* decoding# in case it's not an 8 bit encoding# don't do it for the empty ConfigObj# infile is now *always* a list# Set the newlines attribute (first line ending it finds)# and strip trailing '\n' or '\r' from lines# if we had any errors, now is the time to raise them# set the errors attribute; it's a list of tuples:# (error_type, message, line_number)# set the config attribute# delete private attributes# initialise a few variables# Clear section attributes as well# No need to check for a BOM# the encoding specified doesn't have one# just decode# it's already decoded and there's no need to do anything# else, just use the _decode utility method to handle# listifying appropriately# encoding explicitly supplied# And it could have an associated BOM# TODO: if encoding is just UTF16 - we ought to check for both# TODO: big endian and little endian versions.# For UTF16 we try big endian and little endian# skip UTF8### BOM discovered##self.BOM = True# Don't need to remove BOM# If we get this far, will *probably* raise a DecodeError# As it doesn't appear to start with a BOM# Must be UTF8# BOM removed# No encoding specified - so we need to check for UTF8/UTF16# didn't specify a BOM, or it's not a bytestring# BOM discovered# UTF8# remove BOM# UTF-8# UTF16 - have to decode# No BOM discovered and no encoding specified, default to UTF-8# NOTE: Could raise a ``UnicodeDecodeError``# NOTE: The isinstance test here handles mixed lists of unicode/string# NOTE: But the decode will break on any non-string values# NOTE: Or could raise a ``UnicodeDecodeError``# TODO: this may need to be modified# intentially 'str' because it's just whatever the "normal"# string type is for the python version we're dealing with# do we have anything on the line ?# preserve initial comment# first we check if it's a section marker# is a section line# the new section is dropping back to a previous level# the new section is a sibling of the current section# the new section is a child the current section# create the new section# it's not a section marker,# so it should be a valid ``key = value`` line# is a keyword value# value will include any inline comment# check for a multiline value# extract comment and lists# add the key.# we set unrepr because if we have got this far we will never# be creating a new section# no indentation used, set the type accordingly# preserve the final comment# we've reached the top level already# shouldn't get here# raise the error - parsing stops here# store the error# reraise when parsing has finished# should only happen during parsing of lists# Only if multiline is set, so that it is used for values not# keys, and not values that are part of a list# we don't quote if ``list_values=False``# for normal values either single or double quotes will do# will only happen if multiline is off - e.g. '\n' in key# if value has '\n' or "'" *and* '"', it will need triple quotes# Parsing a configspec so don't handle comments# do we look for lists in values ?# NOTE: we don't unquote here# the value is badly constructed, probably badly quoted,# or an invalid list# change this if you want to accept empty values# NOTE: note there is no error handling from here if the regex# is wrong: then incorrect values will slip through# the single comma - meaning an empty list# handle empty values# FIXME: the '' is a workaround because our regex now matches#   '' at the end of a list if it has a trailing comma# not a list value# somehow the triple quote is missing# end of multiline, process it# we've got to the end of the config, oops...# a badly formed line# FIXME: Should we check that the configspec was created with the#        correct settings ? (i.e. ``list_values=False``)# FIXME: Should these errors have a reference#        to the already parsed ConfigObj ?# copy comments# Could be a scalar when we expect a section# NOTE: the calls to self._quote here handles non-StringType values.# Public methods# this can be true if initialised from a dictionary# don't write out default values# a section# output a list of lines# might need to encode# NOTE: This will *screw* UTF16, each line will start with the BOM# Add the UTF8 BOM# Turn the list to a string, joined with correct newlines# Windows specific hack to avoid writing '\r\r\n'# We do this once to remove a top level dependency on the validate module# Which makes importing configobj faster# section.default_values.clear() #??# No default, bad default or validator has no 'get_default_value'# (e.g. SimpleVal)# preserve the error# if we are doing type conversion# or the value is a supplied default# preserve lists# convert the None from a default to a ''# reserved names# missing entries# or entries from defaults# Missing sections will have been created as empty ones when the# configspec was read.# FIXME: this means DEFAULT is not copied in copy mode# If the section wasn't created (i.e. it wasn't missing)# then we can't return False, we need to preserve errors# If we are preserving errors, but all# the failures are from missing sections / values# then we can return False. Otherwise there is a# real failure that we need to preserve.# FIXME: Should be done by '_initialise', but ConfigObj constructor (and reload)#        requires an empty dictionary# Just to be sure ;-)# first time called# Go down one level# Go up one levelb'utf_8'u'utf_8'b'utf16_be'u'utf16_be'b'utf_16'u'utf_16'b'utf16_le'u'utf16_le'b'u16'u'u16'b'utf16'u'utf16'b'utf-16'u'utf-16'b'utf_16_be'u'utf_16_be'b'utf-16be'u'utf-16be'b'utf_16_le'u'utf_16_le'b'utf-16le'u'utf-16le'b'utf'u'utf'b''%s''u''%s''b'"%s"'u'"%s"'b'%s'u'%s'b' 
	'"'u' 
	'"'b'"""%s"""'u'"""%s"""'b''''%s''''u''''%s''''b'DEFAULT_INDENT_TYPE'u'DEFAULT_INDENT_TYPE'b'DEFAULT_INTERPOLATION'u'DEFAULT_INTERPOLATION'b'ConfigObjError'u'ConfigObjError'b'NestingError'u'NestingError'b'ParseError'u'ParseError'b'DuplicateError'u'DuplicateError'b'ConfigspecError'u'ConfigspecError'b'ConfigObj'u'ConfigObj'b'SimpleVal'u'SimpleVal'b'InterpolationError'u'InterpolationError'b'InterpolationLoopError'u'InterpolationLoopError'b'MissingInterpolationOption'u'MissingInterpolationOption'b'RepeatSectionError'u'RepeatSectionError'b'ReloadError'u'ReloadError'b'UnreprError'u'UnreprError'b'UnknownType'u'UnknownType'b'flatten_errors'u'flatten_errors'b'get_extra_values'u'get_extra_values'b'configparser'u'configparser'b'interpolation'u'interpolation'b'raise_errors'u'raise_errors'b'list_values'u'list_values'b'create_empty'u'create_empty'b'file_error'u'file_error'b'configspec'u'configspec'b'stringify'u'stringify'b'indent_type'u'indent_type'b'encoding'u'encoding'b'default_encoding'u'default_encoding'b'unrepr'u'unrepr'b'write_empty_values'u'write_empty_values'b'a='u'a='b'Undefined Name'u'Undefined Name'b'Add'u'Add'b'
    This is the base class for all errors that ConfigObj raises.
    It is a subclass of SyntaxError.
    'u'
    This is the base class for all errors that ConfigObj raises.
    It is a subclass of SyntaxError.
    'b'
    This error indicates a level of nesting that doesn't match.
    'u'
    This error indicates a level of nesting that doesn't match.
    'b'
    This error indicates that a line is badly written.
    It is neither a valid ``key = value`` line,
    nor a valid section marker line.
    'u'
    This error indicates that a line is badly written.
    It is neither a valid ``key = value`` line,
    nor a valid section marker line.
    'b'
    A 'reload' operation failed.
    This exception is a subclass of ``IOError``.
    'u'
    A 'reload' operation failed.
    This exception is a subclass of ``IOError``.
    'b'reload failed, filename is not set.'u'reload failed, filename is not set.'b'
    The keyword or section specified already exists.
    'u'
    The keyword or section specified already exists.
    'b'
    An error occured whilst parsing a configspec.
    'u'
    An error occured whilst parsing a configspec.
    'b'Base class for the two interpolation errors.'u'Base class for the two interpolation errors.'b'Maximum interpolation depth exceeded in string interpolation.'u'Maximum interpolation depth exceeded in string interpolation.'b'interpolation loop detected in value "%s".'u'interpolation loop detected in value "%s".'b'
    This error indicates additional sections in a section with a
    ``__many__`` (repeated) section.
    'u'
    This error indicates additional sections in a section with a
    ``__many__`` (repeated) section.
    'b'A value specified for interpolation was missing.'u'A value specified for interpolation was missing.'b'missing option "%s" in interpolation.'u'missing option "%s" in interpolation.'b'An error parsing in unrepr mode.'u'An error parsing in unrepr mode.'b'
    A helper class to help perform string interpolation.

    This class is an abstract base class; its descendants perform
    the actual work.
    'u'
    A helper class to help perform string interpolation.

    This class is an abstract base class; its descendants perform
    the actual work.
    'b'%\(([^)]*)\)s'u'%\(([^)]*)\)s'b'The function that does the actual work.

            ``value``: the string we're trying to interpolate.
            ``section``: the section in which that string was found
            ``backtrail``: a dict to keep track of where we've been,
            to detect and prevent infinite recursion loops

            This is similar to a depth-first-search algorithm.
            'u'The function that does the actual work.

            ``value``: the string we're trying to interpolate.
            ``section``: the section in which that string was found
            ``backtrail``: a dict to keep track of where we've been,
            to detect and prevent infinite recursion loops

            This is similar to a depth-first-search algorithm.
            'b'Helper function to fetch values from owning section.

        Returns a 2-tuple: the value, and the section where it was found.
        'u'Helper function to fetch values from owning section.

        Returns a 2-tuple: the value, and the section where it was found.
        'b'DEFAULT'u'DEFAULT'b'Implementation-dependent helper function.

        Will be passed a match object corresponding to the interpolation
        key we just found (e.g., "%(foo)s" or "$foo"). Should look up that
        key in the appropriate config file section (using the ``_fetch()``
        helper function) and return a 3-tuple: (key, value, section)

        ``key`` is the name of the key we're looking for
        ``value`` is the value found for that key
        ``section`` is a reference to the section where it was found

        ``key`` and ``section`` should be None if no further
        interpolation should be performed on the resulting value
        (e.g., if we interpolated "$$" and returned "$").
        'u'Implementation-dependent helper function.

        Will be passed a match object corresponding to the interpolation
        key we just found (e.g., "%(foo)s" or "$foo"). Should look up that
        key in the appropriate config file section (using the ``_fetch()``
        helper function) and return a 3-tuple: (key, value, section)

        ``key`` is the name of the key we're looking for
        ``value`` is the value found for that key
        ``section`` is a reference to the section where it was found

        ``key`` and ``section`` should be None if no further
        interpolation should be performed on the resulting value
        (e.g., if we interpolated "$$" and returned "$").
        'b'Behaves like ConfigParser.'u'Behaves like ConfigParser.'b'Behaves like string.Template.'u'Behaves like string.Template.'b'
        \$(?:
          (?P<escaped>\$)              |   # Two $ signs
          (?P<named>[_a-z][_a-z0-9]*)  |   # $name format
          {(?P<braced>[^}]*)}              # ${name} format
        )
        'u'
        \$(?:
          (?P<escaped>\$)              |   # Two $ signs
          (?P<named>[_a-z][_a-z0-9]*)  |   # $name format
          {(?P<braced>[^}]*)}              # ${name} format
        )
        'b'named'u'named'b'braced'u'braced'b'escaped'u'escaped'b'template'u'template'b'
    A dictionary-like object that represents a section in a config file.

    It does string interpolation if the 'interpolation' attribute
    of the 'main' object is set to True.

    Interpolation is tried first from this object, then from the 'DEFAULT'
    section of this object, next from the parent and its 'DEFAULT' section,
    and so on until the main object is reached.

    A Section will behave like an ordered dictionary - following the
    order of the ``scalars`` and ``sections`` attributes.
    You can use this to change the order of members.

    Iteration follows the order: scalars, then sections.
    'u'
    A dictionary-like object that represents a section in a config file.

    It does string interpolation if the 'interpolation' attribute
    of the 'main' object is set to True.

    Interpolation is tried first from this object, then from the 'DEFAULT'
    section of this object, next from the parent and its 'DEFAULT' section,
    and so on until the main object is reached.

    A Section will behave like an ordered dictionary - following the
    order of the ``scalars`` and ``sections`` attributes.
    You can use this to change the order of members.

    Iteration follows the order: scalars, then sections.
    'b'
        * parent is the section above
        * depth is the depth level of this section
        * main is the main ConfigObj
        * indict is a dictionary to initialise the section with
        'u'
        * parent is the section above
        * depth is the depth level of this section
        * main is the main ConfigObj
        * indict is a dictionary to initialise the section with
        'b'Fetch the item and do string interpolation.'u'Fetch the item and do string interpolation.'b'
        Correctly set a value.

        Making dictionary values Section instances.
        (We have to special case 'Section' instances - which are also dicts)

        Keys must be strings.
        Values need only be strings (or lists of strings) if
        ``main.stringify`` is set.

        ``unrepr`` must be set when setting a value to a dictionary, without
        creating a new sub-section.
        'u'
        Correctly set a value.

        Making dictionary values Section instances.
        (We have to special case 'Section' instances - which are also dicts)

        Keys must be strings.
        Values need only be strings (or lists of strings) if
        ``main.stringify`` is set.

        ``unrepr`` must be set when setting a value to a dictionary, without
        creating a new sub-section.
        'b'The key "%s" is not a string.'u'The key "%s" is not a string.'b'Value is not a string "%s".'u'Value is not a string "%s".'b'Remove items from the sequence when deleting.'u'Remove items from the sequence when deleting.'b'A version of ``get`` that doesn't bypass string interpolation.'u'A version of ``get`` that doesn't bypass string interpolation.'b'
        A version of update that uses our ``__setitem__``.
        'u'
        A version of update that uses our ``__setitem__``.
        'b'
        'D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised'
        'u'
        'D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised'
        'b'Pops the first (key,val)'u'Pops the first (key,val)'b': 'popitem(): dictionary is empty''u': 'popitem(): dictionary is empty''b'
        A version of clear that also affects scalars/sections
        Also clears comments and configspec.

        Leaves other attributes alone :
            depth/main/parent are not affected
        'u'
        A version of clear that also affects scalars/sections
        Also clears comments and configspec.

        Leaves other attributes alone :
            depth/main/parent are not affected
        'b'A version of setdefault that sets sequence if appropriate.'u'A version of setdefault that sets sequence if appropriate.'b'D.items() -> list of D's (key, value) pairs, as 2-tuples'u'D.items() -> list of D's (key, value) pairs, as 2-tuples'b'D.keys() -> list of D's keys'u'D.keys() -> list of D's keys'b'D.values() -> list of D's values'u'D.values() -> list of D's values'b'D.iteritems() -> an iterator over the (key, value) items of D'u'D.iteritems() -> an iterator over the (key, value) items of D'b'D.iterkeys() -> an iterator over the keys of D'u'D.iterkeys() -> an iterator over the keys of D'b'D.itervalues() -> an iterator over the values of D'u'D.itervalues() -> an iterator over the values of D'b'x.__repr__() <==> repr(x)'u'x.__repr__() <==> repr(x)'b'{%s}'u'{%s}'b'%s: %s'u'%s: %s'b'x.__str__() <==> str(x)'u'x.__str__() <==> str(x)'b'
        Return a deepcopy of self as a dictionary.

        All members that are ``Section`` instances are recursively turned to
        ordinary dictionaries - by calling their ``dict`` method.

        >>> n = a.dict()
        >>> n == a
        1
        >>> n is a
        0
        'u'
        Return a deepcopy of self as a dictionary.

        All members that are ``Section`` instances are recursively turned to
        ordinary dictionaries - by calling their ``dict`` method.

        >>> n = a.dict()
        >>> n == a
        1
        >>> n is a
        0
        'b'
        A recursive update - useful for merging config files.

        >>> a = '''[section1]
        ...     option1 = True
        ...     [[subsection]]
        ...     more_options = False
        ...     # end of file'''.splitlines()
        >>> b = '''# File is user.ini
        ...     [section1]
        ...     option1 = False
        ...     # end of file'''.splitlines()
        >>> c1 = ConfigObj(b)
        >>> c2 = ConfigObj(a)
        >>> c2.merge(c1)
        >>> c2
        ConfigObj({'section1': {'option1': 'False', 'subsection': {'more_options': 'False'}}})
        'u'
        A recursive update - useful for merging config files.

        >>> a = '''[section1]
        ...     option1 = True
        ...     [[subsection]]
        ...     more_options = False
        ...     # end of file'''.splitlines()
        >>> b = '''# File is user.ini
        ...     [section1]
        ...     option1 = False
        ...     # end of file'''.splitlines()
        >>> c1 = ConfigObj(b)
        >>> c2 = ConfigObj(a)
        >>> c2.merge(c1)
        >>> c2
        ConfigObj({'section1': {'option1': 'False', 'subsection': {'more_options': 'False'}}})
        'b'
        Change a keyname to another, without changing position in sequence.

        Implemented so that transformations can be made on keys,
        as well as on values. (used by encode and decode)

        Also renames comments.
        'u'
        Change a keyname to another, without changing position in sequence.

        Implemented so that transformations can be made on keys,
        as well as on values. (used by encode and decode)

        Also renames comments.
        'b'Key "%s" not found.'u'Key "%s" not found.'b'
        Walk every member and call a function on the keyword and value.

        Return a dictionary of the return values

        If the function raises an exception, raise the errror
        unless ``raise_errors=False``, in which case set the return value to
        ``False``.

        Any unrecognized keyword arguments you pass to walk, will be pased on
        to the function you pass in.

        Note: if ``call_on_sections`` is ``True`` then - on encountering a
        subsection, *first* the function is called for the *whole* subsection,
        and then recurses into it's members. This means your function must be
        able to handle strings, dictionaries and lists. This allows you
        to change the key of subsections as well as for ordinary members. The
        return value when called on the whole subsection has to be discarded.

        See  the encode and decode methods for examples, including functions.

        .. admonition:: caution

            You can use ``walk`` to transform the names of members of a section
            but you mustn't add or delete members.

        >>> config = '''[XXXXsection]
        ... XXXXkey = XXXXvalue'''.splitlines()
        >>> cfg = ConfigObj(config)
        >>> cfg
        ConfigObj({'XXXXsection': {'XXXXkey': 'XXXXvalue'}})
        >>> def transform(section, key):
        ...     val = section[key]
        ...     newkey = key.replace('XXXX', 'CLIENT1')
        ...     section.rename(key, newkey)
        ...     if isinstance(val, (tuple, list, dict)):
        ...         pass
        ...     else:
        ...         val = val.replace('XXXX', 'CLIENT1')
        ...         section[newkey] = val
        >>> cfg.walk(transform, call_on_sections=True)
        {'CLIENT1section': {'CLIENT1key': None}}
        >>> cfg
        ConfigObj({'CLIENT1section': {'CLIENT1key': 'CLIENT1value'}})
        'u'
        Walk every member and call a function on the keyword and value.

        Return a dictionary of the return values

        If the function raises an exception, raise the errror
        unless ``raise_errors=False``, in which case set the return value to
        ``False``.

        Any unrecognized keyword arguments you pass to walk, will be pased on
        to the function you pass in.

        Note: if ``call_on_sections`` is ``True`` then - on encountering a
        subsection, *first* the function is called for the *whole* subsection,
        and then recurses into it's members. This means your function must be
        able to handle strings, dictionaries and lists. This allows you
        to change the key of subsections as well as for ordinary members. The
        return value when called on the whole subsection has to be discarded.

        See  the encode and decode methods for examples, including functions.

        .. admonition:: caution

            You can use ``walk`` to transform the names of members of a section
            but you mustn't add or delete members.

        >>> config = '''[XXXXsection]
        ... XXXXkey = XXXXvalue'''.splitlines()
        >>> cfg = ConfigObj(config)
        >>> cfg
        ConfigObj({'XXXXsection': {'XXXXkey': 'XXXXvalue'}})
        >>> def transform(section, key):
        ...     val = section[key]
        ...     newkey = key.replace('XXXX', 'CLIENT1')
        ...     section.rename(key, newkey)
        ...     if isinstance(val, (tuple, list, dict)):
        ...         pass
        ...     else:
        ...         val = val.replace('XXXX', 'CLIENT1')
        ...         section[newkey] = val
        >>> cfg.walk(transform, call_on_sections=True)
        {'CLIENT1section': {'CLIENT1key': None}}
        >>> cfg
        ConfigObj({'CLIENT1section': {'CLIENT1key': 'CLIENT1value'}})
        'b'
        Accepts a key as input. The corresponding value must be a string or
        the objects (``True`` or 1) or (``False`` or 0). We allow 0 and 1 to
        retain compatibility with Python 2.2.

        If the string is one of  ``True``, ``On``, ``Yes``, or ``1`` it returns
        ``True``.

        If the string is one of  ``False``, ``Off``, ``No``, or ``0`` it returns
        ``False``.

        ``as_bool`` is not case sensitive.

        Any other input will raise a ``ValueError``.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_bool('a')
        Traceback (most recent call last):
        ValueError: Value "fish" is neither True nor False
        >>> a['b'] = 'True'
        >>> a.as_bool('b')
        1
        >>> a['b'] = 'off'
        >>> a.as_bool('b')
        0
        'u'
        Accepts a key as input. The corresponding value must be a string or
        the objects (``True`` or 1) or (``False`` or 0). We allow 0 and 1 to
        retain compatibility with Python 2.2.

        If the string is one of  ``True``, ``On``, ``Yes``, or ``1`` it returns
        ``True``.

        If the string is one of  ``False``, ``Off``, ``No``, or ``0`` it returns
        ``False``.

        ``as_bool`` is not case sensitive.

        Any other input will raise a ``ValueError``.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_bool('a')
        Traceback (most recent call last):
        ValueError: Value "fish" is neither True nor False
        >>> a['b'] = 'True'
        >>> a.as_bool('b')
        1
        >>> a['b'] = 'off'
        >>> a.as_bool('b')
        0
        'b'Value "%s" is neither True nor False'u'Value "%s" is neither True nor False'b'
        A convenience method which coerces the specified value to an integer.

        If the value is an invalid literal for ``int``, a ``ValueError`` will
        be raised.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_int('a')
        Traceback (most recent call last):
        ValueError: invalid literal for int() with base 10: 'fish'
        >>> a['b'] = '1'
        >>> a.as_int('b')
        1
        >>> a['b'] = '3.2'
        >>> a.as_int('b')
        Traceback (most recent call last):
        ValueError: invalid literal for int() with base 10: '3.2'
        'u'
        A convenience method which coerces the specified value to an integer.

        If the value is an invalid literal for ``int``, a ``ValueError`` will
        be raised.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_int('a')
        Traceback (most recent call last):
        ValueError: invalid literal for int() with base 10: 'fish'
        >>> a['b'] = '1'
        >>> a.as_int('b')
        1
        >>> a['b'] = '3.2'
        >>> a.as_int('b')
        Traceback (most recent call last):
        ValueError: invalid literal for int() with base 10: '3.2'
        'b'
        A convenience method which coerces the specified value to a float.

        If the value is an invalid literal for ``float``, a ``ValueError`` will
        be raised.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_float('a')  #doctest: +IGNORE_EXCEPTION_DETAIL
        Traceback (most recent call last):
        ValueError: invalid literal for float(): fish
        >>> a['b'] = '1'
        >>> a.as_float('b')
        1.0
        >>> a['b'] = '3.2'
        >>> a.as_float('b')  #doctest: +ELLIPSIS
        3.2...
        'u'
        A convenience method which coerces the specified value to a float.

        If the value is an invalid literal for ``float``, a ``ValueError`` will
        be raised.

        >>> a = ConfigObj()
        >>> a['a'] = 'fish'
        >>> a.as_float('a')  #doctest: +IGNORE_EXCEPTION_DETAIL
        Traceback (most recent call last):
        ValueError: invalid literal for float(): fish
        >>> a['b'] = '1'
        >>> a.as_float('b')
        1.0
        >>> a['b'] = '3.2'
        >>> a.as_float('b')  #doctest: +ELLIPSIS
        3.2...
        'b'
        A convenience method which fetches the specified value, guaranteeing
        that it is a list.

        >>> a = ConfigObj()
        >>> a['a'] = 1
        >>> a.as_list('a')
        [1]
        >>> a['a'] = (1,)
        >>> a.as_list('a')
        [1]
        >>> a['a'] = [1]
        >>> a.as_list('a')
        [1]
        'u'
        A convenience method which fetches the specified value, guaranteeing
        that it is a list.

        >>> a = ConfigObj()
        >>> a['a'] = 1
        >>> a.as_list('a')
        [1]
        >>> a['a'] = (1,)
        >>> a.as_list('a')
        [1]
        >>> a['a'] = [1]
        >>> a.as_list('a')
        [1]
        'b'
        Restore (and return) default value for the specified key.

        This method will only work for a ConfigObj that was created
        with a configspec and has been validated.

        If there is no default value for this key, ``KeyError`` is raised.
        'u'
        Restore (and return) default value for the specified key.

        This method will only work for a ConfigObj that was created
        with a configspec and has been validated.

        If there is no default value for this key, ``KeyError`` is raised.
        'b'
        Recursively restore default values to all members
        that have them.

        This method will only work for a ConfigObj that was created
        with a configspec and has been validated.

        It doesn't delete or modify entries without default values.
        'u'
        Recursively restore default values to all members
        that have them.

        This method will only work for a ConfigObj that was created
        with a configspec and has been validated.

        It doesn't delete or modify entries without default values.
        'b'An object to read, create, and write config files.'u'An object to read, create, and write config files.'b'^ # line start
        (\s*)                   # indentation
        (                       # keyword
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'"=].*?)       # no quotes
        )
        \s*=\s*                 # divider
        (.*)                    # value (including list values and comments)
        $   # line end
        'u'^ # line start
        (\s*)                   # indentation
        (                       # keyword
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'"=].*?)       # no quotes
        )
        \s*=\s*                 # divider
        (.*)                    # value (including list values and comments)
        $   # line end
        'b'^
        (\s*)                     # 1: indentation
        ((?:\[\s*)+)              # 2: section marker open
        (                         # 3: section name open
            (?:"\s*\S.*?\s*")|    # at least one non-space with double quotes
            (?:'\s*\S.*?\s*')|    # at least one non-space with single quotes
            (?:[^'"\s].*?)        # at least one non-space unquoted
        )                         # section name close
        ((?:\s*\])+)              # 4: section marker close
        \s*(\#.*)?                # 5: optional comment
        $'u'^
        (\s*)                     # 1: indentation
        ((?:\[\s*)+)              # 2: section marker open
        (                         # 3: section name open
            (?:"\s*\S.*?\s*")|    # at least one non-space with double quotes
            (?:'\s*\S.*?\s*')|    # at least one non-space with single quotes
            (?:[^'"\s].*?)        # at least one non-space unquoted
        )                         # section name close
        ((?:\s*\])+)              # 4: section marker close
        \s*(\#.*)?                # 5: optional comment
        $'b'^
        (?:
            (?:
                (
                    (?:
                        (?:
                            (?:".*?")|              # double quotes
                            (?:'.*?')|              # single quotes
                            (?:[^'",\#][^,\#]*?)    # unquoted
                        )
                        \s*,\s*                     # comma
                    )*      # match all list items ending in a comma (if any)
                )
                (
                    (?:".*?")|                      # double quotes
                    (?:'.*?')|                      # single quotes
                    (?:[^'",\#\s][^,]*?)|           # unquoted
                    (?:(?<!,))                      # Empty value
                )?          # last item in a list - or string value
            )|
            (,)             # alternatively a single comma - empty list
        )
        \s*(\#.*)?          # optional comment
        $'u'^
        (?:
            (?:
                (
                    (?:
                        (?:
                            (?:".*?")|              # double quotes
                            (?:'.*?')|              # single quotes
                            (?:[^'",\#][^,\#]*?)    # unquoted
                        )
                        \s*,\s*                     # comma
                    )*      # match all list items ending in a comma (if any)
                )
                (
                    (?:".*?")|                      # double quotes
                    (?:'.*?')|                      # single quotes
                    (?:[^'",\#\s][^,]*?)|           # unquoted
                    (?:(?<!,))                      # Empty value
                )?          # last item in a list - or string value
            )|
            (,)             # alternatively a single comma - empty list
        )
        \s*(\#.*)?          # optional comment
        $'b'
        (
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'",\#]?.*?)       # unquoted
        )
        \s*,\s*                 # comma
        'u'
        (
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'",\#]?.*?)       # unquoted
        )
        \s*,\s*                 # comma
        'b'^
        (
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'"\#].*?)|     # unquoted
            (?:)                # Empty value
        )
        \s*(\#.*)?              # optional comment
        $'u'^
        (
            (?:".*?")|          # double quotes
            (?:'.*?')|          # single quotes
            (?:[^'"\#].*?)|     # unquoted
            (?:)                # Empty value
        )
        \s*(\#.*)?              # optional comment
        $'b'^'''(.*?)'''\s*(#.*)?$'u'^'''(.*?)'''\s*(#.*)?$'b'^"""(.*?)"""\s*(#.*)?$'u'^"""(.*?)"""\s*(#.*)?$'b'^(.*?)'''\s*(#.*)?$'u'^(.*?)'''\s*(#.*)?$'b'^(.*?)"""\s*(#.*)?$'u'^(.*?)"""\s*(#.*)?$'b'''''u'''''b'"""'u'"""'b'yes'u'yes'b'no'u'no'b'on'u'on'b'off'u'off'b'true'u'true'b'false'u'false'b'
        Parse a config file or create a config file object.

        ``ConfigObj(infile=None, configspec=None, encoding=None,
                    interpolation=True, raise_errors=False, list_values=True,
                    create_empty=False, file_error=False, stringify=True,
                    indent_type=None, default_encoding=None, unrepr=False,
                    write_empty_values=False, _inspec=False)``
        'u'
        Parse a config file or create a config file object.

        ``ConfigObj(infile=None, configspec=None, encoding=None,
                    interpolation=True, raise_errors=False, list_values=True,
                    create_empty=False, file_error=False, stringify=True,
                    indent_type=None, default_encoding=None, unrepr=False,
                    write_empty_values=False, _inspec=False)``
        'b'Passing in an options dictionary to ConfigObj() is deprecated. Use **options instead.'u'Passing in an options dictionary to ConfigObj() is deprecated. Use **options instead.'b'Unrecognized option "%s".'u'Unrecognized option "%s".'b'Config file not found: "%s".'u'Config file not found: "%s".'b'infile must be a filename, file like object, or list of lines.'u'infile must be a filename, file like object, or list of lines.'b''u''b'
'u'
'b'at line %s.'u'at line %s.'b'Parsing failed with several errors.
First error %s'u'Parsing failed with several errors.
First error %s'b'%s({%s})'u'%s({%s})'b'
        Handle any BOM, and decode if necessary.

        If an encoding is specified, that *must* be used - but the BOM should
        still be removed (and the BOM attribute set).

        (If the encoding is wrongly specified, then a BOM for an alternative
        encoding won't be discovered or removed.)

        If an encoding is not specified, UTF8 or UTF16 BOM will be detected and
        removed. The BOM attribute will be set. UTF16 will be decoded to
        unicode.

        NOTE: This method must not be called with an empty ``infile``.

        Specifying the *wrong* encoding is likely to cause a
        ``UnicodeDecodeError``.

        ``infile`` must always be returned as a list of lines, but may be
        passed in as a single string.
        'u'
        Handle any BOM, and decode if necessary.

        If an encoding is specified, that *must* be used - but the BOM should
        still be removed (and the BOM attribute set).

        (If the encoding is wrongly specified, then a BOM for an alternative
        encoding won't be discovered or removed.)

        If an encoding is not specified, UTF8 or UTF16 BOM will be detected and
        removed. The BOM attribute will be set. UTF16 will be decoded to
        unicode.

        NOTE: This method must not be called with an empty ``infile``.

        Specifying the *wrong* encoding is likely to cause a
        ``UnicodeDecodeError``.

        ``infile`` must always be returned as a list of lines, but may be
        passed in as a single string.
        'b'Decode ASCII strings to unicode if a self.encoding is specified.'u'Decode ASCII strings to unicode if a self.encoding is specified.'b'
        Decode infile to unicode. Using the specified encoding.

        if is a string, it also needs converting to a list.
        'u'
        Decode infile to unicode. Using the specified encoding.

        if is a string, it also needs converting to a list.
        'b'Decode element to unicode if necessary.'u'Decode element to unicode if necessary.'b'
        Used by ``stringify`` within validate, to turn non-string values
        into strings.
        'u'
        Used by ``stringify`` within validate, to turn non-string values
        into strings.
        'b'Actually parse the config file.'u'Actually parse the config file.'b'['u'['b']'u']'b'Cannot compute the section depth'u'Cannot compute the section depth'b'Cannot compute nesting level'u'Cannot compute nesting level'b'Section too nested'u'Section too nested'b'Duplicate section name'u'Duplicate section name'b'Invalid line ({0!r}) (matched as neither section nor keyword)'u'Invalid line ({0!r}) (matched as neither section nor keyword)'b'Unknown name or type in value'u'Unknown name or type in value'b'Parse error from unrepr-ing multiline value'u'Parse error from unrepr-ing multiline value'b'Parse error in multiline value'u'Parse error in multiline value'b'Parse error from unrepr-ing value'u'Parse error from unrepr-ing value'b'Parse error in value'u'Parse error in value'b'Duplicate keyword name'u'Duplicate keyword name'b'
        Given a section and a depth level, walk back through the sections
        parents to see if the depth level matches a previous section.

        Return a reference to the right section,
        or raise a SyntaxError.
        'u'
        Given a section and a depth level, walk back through the sections
        parents to see if the depth level matches a previous section.

        Return a reference to the right section,
        or raise a SyntaxError.
        'b'
        Handle an error according to the error settings.

        Either raise the error or store it.
        The error will have occured at ``cur_index``
        'u'
        Handle an error according to the error settings.

        Either raise the error or store it.
        The error will have occured at ``cur_index``
        'b'{0} at line {1}.'u'{0} at line {1}.'b'Return an unquoted version of a value'u'Return an unquoted version of a value'b'
        Return a safely quoted version of a value.

        Raise a ConfigObjError if the value cannot be safely quoted.
        If multiline is ``True`` (default) then use triple quotes
        if necessary.

        * Don't quote values that don't need it.
        * Recursively quote members of a list and return a comma joined list.
        * Multiline is ``False`` for lists.
        * Obey list syntax for empty and single member lists.

        If ``list_values=False`` then the value is only quoted if it contains
        a ``\n`` (is multiline) or '#'.

        If ``write_empty_values`` is set, and the value is an empty string, it
        won't be quoted.
        'u'
        Return a safely quoted version of a value.

        Raise a ConfigObjError if the value cannot be safely quoted.
        If multiline is ``True`` (default) then use triple quotes
        if necessary.

        * Don't quote values that don't need it.
        * Recursively quote members of a list and return a comma joined list.
        * Multiline is ``False`` for lists.
        * Obey list syntax for empty and single member lists.

        If ``list_values=False`` then the value is only quoted if it contains
        a ``\n`` (is multiline) or '#'.

        If ``write_empty_values`` is set, and the value is an empty string, it
        won't be quoted.
        'b'Value "%s" is not a string.'u'Value "%s" is not a string.'b'""'u'""'b'Value "%s" cannot be safely quoted.'u'Value "%s" cannot be safely quoted.'b'
        Given a value string, unquote, remove comment,
        handle lists. (including empty and single member lists)
        'u'
        Given a value string, unquote, remove comment,
        handle lists. (including empty and single member lists)
        'b'Extract the value, where we are in a multiline situation.'u'Extract the value, where we are in a multiline situation.'b'Parse the configspec.'u'Parse the configspec.'b'Parsing configspec failed: %s'u'Parsing configspec failed: %s'b'Reading configspec failed: %s'u'Reading configspec failed: %s'b'
        Called by validate. Handles setting the configspec on subsections
        including sections to be validated by __many__
        'u'
        Called by validate. Handles setting the configspec on subsections
        including sections to be validated by __many__
        'b'__many__'u'__many__'b'Write an individual line, for the write method'u'Write an individual line, for the write method'b'%s%s%s%s%s'u'%s%s%s%s%s'b'Write a section marker line'u'Write a section marker line'b'Deal with a comment.'u'Deal with a comment.'b' # 'u' # 'b'
        Write the current ConfigObj as a file

        tekNico: FIXME: use StringIO instead of real files

        >>> filename = a.filename
        >>> a.filename = 'test.ini'
        >>> a.write()
        >>> a.filename = filename
        >>> a == ConfigObj('test.ini', raise_errors=True)
        1
        >>> import os
        >>> os.remove('test.ini')
        'u'
        Write the current ConfigObj as a file

        tekNico: FIXME: use StringIO instead of real files

        >>> filename = a.filename
        >>> a.filename = 'test.ini'
        >>> a.write()
        >>> a.filename = filename
        >>> a == ConfigObj('test.ini', raise_errors=True)
        1
        >>> import os
        >>> os.remove('test.ini')
        'b'mode'u'mode'b'
        Test the ConfigObj against a configspec.

        It uses the ``validator`` object from *validate.py*.

        To run ``validate`` on the current ConfigObj, call: ::

            test = config.validate(validator)

        (Normally having previously passed in the configspec when the ConfigObj
        was created - you can dynamically assign a dictionary of checks to the
        ``configspec`` attribute of a section though).

        It returns ``True`` if everything passes, or a dictionary of
        pass/fails (True/False). If every member of a subsection passes, it
        will just have the value ``True``. (It also returns ``False`` if all
        members fail).

        In addition, it converts the values from strings to their native
        types if their checks pass (and ``stringify`` is set).

        If ``preserve_errors`` is ``True`` (``False`` is default) then instead
        of a marking a fail with a ``False``, it will preserve the actual
        exception object. This can contain info about the reason for failure.
        For example the ``VdtValueTooSmallError`` indicates that the value
        supplied was too small. If a value (or section) is missing it will
        still be marked as ``False``.

        You must have the validate module to use ``preserve_errors=True``.

        You can then use the ``flatten_errors`` function to turn your nested
        results dictionary into a flattened list of failures - useful for
        displaying meaningful error messages.
        'u'
        Test the ConfigObj against a configspec.

        It uses the ``validator`` object from *validate.py*.

        To run ``validate`` on the current ConfigObj, call: ::

            test = config.validate(validator)

        (Normally having previously passed in the configspec when the ConfigObj
        was created - you can dynamically assign a dictionary of checks to the
        ``configspec`` attribute of a section though).

        It returns ``True`` if everything passes, or a dictionary of
        pass/fails (True/False). If every member of a subsection passes, it
        will just have the value ``True``. (It also returns ``False`` if all
        members fail).

        In addition, it converts the values from strings to their native
        types if their checks pass (and ``stringify`` is set).

        If ``preserve_errors`` is ``True`` (``False`` is default) then instead
        of a marking a fail with a ``False``, it will preserve the actual
        exception object. This can contain info about the reason for failure.
        For example the ``VdtValueTooSmallError`` indicates that the value
        supplied was too small. If a value (or section) is missing it will
        still be marked as ``False``.

        You must have the validate module to use ``preserve_errors=True``.

        You can then use the ``flatten_errors`` function to turn your nested
        results dictionary into a flattened list of failures - useful for
        displaying meaningful error messages.
        'b'No configspec supplied.'u'No configspec supplied.'b'___many___'u'___many___'b'Value %r was provided as a section'u'Value %r was provided as a section'b'Section %r was provided as a single value'u'Section %r was provided as a single value'b'Clear ConfigObj instance and restore to 'freshly created' state.'u'Clear ConfigObj instance and restore to 'freshly created' state.'b'
        Reload a ConfigObj from file.

        This method raises a ``ReloadError`` if the ConfigObj doesn't have
        a filename attribute pointing to a file.
        'u'
        Reload a ConfigObj from file.

        This method raises a ``ReloadError`` if the ConfigObj doesn't have
        a filename attribute pointing to a file.
        'b'
    A simple validator.
    Can be used to check that all members expected are present.

    To use it, provide a configspec with all your members in (the value given
    will be ignored). Pass an instance of ``SimpleVal`` to the ``validate``
    method of your ``ConfigObj``. ``validate`` will return ``True`` if all
    members are present, or a dictionary with True/False meaning
    present/missing. (Whole missing sections will be replaced with ``False``)
    'u'
    A simple validator.
    Can be used to check that all members expected are present.

    To use it, provide a configspec with all your members in (the value given
    will be ignored). Pass an instance of ``SimpleVal`` to the ``validate``
    method of your ``ConfigObj``. ``validate`` will return ``True`` if all
    members are present, or a dictionary with True/False meaning
    present/missing. (Whole missing sections will be replaced with ``False``)
    'b'A dummy check method, always returns the value unchanged.'u'A dummy check method, always returns the value unchanged.'b'
    An example function that will turn a nested dictionary of results
    (as returned by ``ConfigObj.validate``) into a flat list.

    ``cfg`` is the ConfigObj instance being checked, ``res`` is the results
    dictionary returned by ``validate``.

    (This is a recursive function, so you shouldn't use the ``levels`` or
    ``results`` arguments - they are used by the function.)

    Returns a list of keys that failed. Each member of the list is a tuple::

        ([list of sections...], key, result)

    If ``validate`` was called with ``preserve_errors=False`` (the default)
    then ``result`` will always be ``False``.

    *list of sections* is a flattened list of sections that the key was found
    in.

    If the section was missing (or a section was expected and a scalar provided
    - or vice-versa) then key will be ``None``.

    If the value (or section) was missing then ``result`` will be ``False``.

    If ``validate`` was called with ``preserve_errors=True`` and a value
    was present, but failed the check, then ``result`` will be the exception
    object returned. You can use this as a string that describes the failure.

    For example *The value "3" is of the wrong type*.
    'u'
    An example function that will turn a nested dictionary of results
    (as returned by ``ConfigObj.validate``) into a flat list.

    ``cfg`` is the ConfigObj instance being checked, ``res`` is the results
    dictionary returned by ``validate``.

    (This is a recursive function, so you shouldn't use the ``levels`` or
    ``results`` arguments - they are used by the function.)

    Returns a list of keys that failed. Each member of the list is a tuple::

        ([list of sections...], key, result)

    If ``validate`` was called with ``preserve_errors=False`` (the default)
    then ``result`` will always be ``False``.

    *list of sections* is a flattened list of sections that the key was found
    in.

    If the section was missing (or a section was expected and a scalar provided
    - or vice-versa) then key will be ``None``.

    If the value (or section) was missing then ``result`` will be ``False``.

    If ``validate`` was called with ``preserve_errors=True`` and a value
    was present, but failed the check, then ``result`` will be the exception
    object returned. You can use this as a string that describes the failure.

    For example *The value "3" is of the wrong type*.
    'b'
    Find all the values and sections not in the configspec from a validated
    ConfigObj.

    ``get_extra_values`` returns a list of tuples where each tuple represents
    either an extra section, or an extra value.

    The tuples contain two values, a tuple representing the section the value
    is in and the name of the extra values. For extra values in the top level
    section the first member will be an empty tuple. For values in the 'foo'
    section the first member will be ``('foo',)``. For members in the 'bar'
    subsection of the 'foo' section the first member will be ``('foo', 'bar')``.

    NOTE: If you call ``get_extra_values`` on a ConfigObj instance that hasn't
    been validated it will return an empty list.
    'u'
    Find all the values and sections not in the configspec from a validated
    ConfigObj.

    ``get_extra_values`` returns a list of tuples where each tuple represents
    either an extra section, or an extra value.

    The tuples contain two values, a tuple representing the section the value
    is in and the name of the extra values. For extra values in the top level
    section the first member will be an empty tuple. For values in the 'foo'
    section the first member will be ``('foo',)``. For members in the 'bar'
    subsection of the 'foo' section the first member will be ``('foo', 'bar')``.

    NOTE: If you call ``get_extra_values`` on a ConfigObj instance that hasn't
    been validated it will return an empty list.
    'b'*A programming language is a medium of expression.* - Paul Graham'u'*A programming language is a medium of expression.* - Paul Graham'u'astropy.extern.configobj.configobj'u'extern.configobj.configobj'u'configobj.configobj'This module contains classes and functions to standardize access to
configuration files for Astropy and affiliated packages.

.. note::
    The configuration system makes use of the 'configobj' package, which stores
    configuration in a text format like that used in the standard library
    `ConfigParser`. More information and documentation for configobj can be
    found at https://configobj.readthedocs.io .
pkgutilnullcontextgetdocTextWrapperastropy.extern.configobjconfigobjsilenceget_config_dir_pathGeneratorInvalidConfigurationItemWarningcreate_config_filegenerate_configget_configreload_configA Warning that is issued when the configuration value specified in the
    astropy configuration file does not match the type expected for that
    configuration value.
    ConfigurationDefaultMissingErrorAn exception that is raised when the configuration defaults (which
    should be generated at build-time) are missing.
    ConfigurationDefaultMissingWarningA warning that is issued when the configuration defaults (which
    should be generated at build-time) are missing.
    ConfigurationChangedWarning
    A warning that the configuration options have changed.
    
    A namespace of configuration items.  Each subpackage with
    configuration items should define a subclass of this class,
    containing `ConfigItem` instances as members.

    For example::

        class Conf(_config.ConfigNamespace):
            unicode_output = _config.ConfigItem(
                False,
                'Use Unicode characters when outputting values, ...')
            use_color = _config.ConfigItem(
                sys.platform != 'win32',
                'When True, use ANSI color escape sequences when ...',
                aliases=['astropy.utils.console.USE_COLOR'])
        conf = Conf()
    docstring

current_moduleConfiguration parameters for ``

Iterate over configuration item names.Iterate over configuration item values.Iterate over configuration item ``(name, value)`` pairs.helpPrint info about configuration items.

        Parameters
        ----------
        name : `str`, optional
            Name of the configuration item to be described. If no name is
            provided then info about all the configuration items will be
            printed.

        Examples
        --------
        >>> from astropy import conf
        >>> conf.help("unicode_output")
        ConfigItem: unicode_output
          cfgtype='boolean'
          defaultvalue=False
          description='When True, use Unicode characters when outputting values, and displaying widgets at the console.'
          module=astropy
          value=False
        ' is not among configuration items set_temp
        Temporarily set a configuration value.

        Parameters
        ----------
        attr : str
            Configuration item name

        value : object
            The value to set temporarily.

        Examples
        --------
        >>> import astropy
        >>> with astropy.conf.set_temp('use_color', False):
        ...     pass
        ...     # console output will not contain color
        >>> # console output contains color again...
        No configuration parameter '
        Reload a configuration item from the configuration file.

        Parameters
        ----------
        attr : str, optional
            The name of the configuration parameter to reload.  If not
            provided, reload all configuration parameters.
        
        Reset a configuration item to its default.

        Parameters
        ----------
        attr : str, optional
            The name of the configuration parameter to reload.  If not
            provided, reset all configuration parameters.
        propdefaultvalue
    A setting and associated value stored in a configuration file.

    These objects should be created as members of
    `ConfigNamespace` subclasses, for example::

        class _Conf(config.ConfigNamespace):
            unicode_output = config.ConfigItem(
                False,
                'Use Unicode characters when outputting values, and writing widgets '
                'to the console.')
        conf = _Conf()

    Parameters
    ----------
    defaultvalue : object, optional
        The default value for this item. If this is a list of strings, this
        item will be interpreted as an 'options' value - this item must be one
        of those values, and the first in the list will be taken as the default
        value.

    description : str or None, optional
        A description of this item (will be shown as a comment in the
        configuration file)

    cfgtype : str or None, optional
        A type specifier like those used as the *values* of a particular key
        in a ``configspec`` file of ``configobj``. If None, the type will be
        inferred from the default value.

    module : str or None, optional
        The full module name that this item is associated with. The first
        element (e.g. 'astropy' if this is 'astropy.config.configuration')
        will be used to determine the name of the configuration file, while
        the remaining items determine the section. If None, the package will be
        inferred from the package within which this object's initializer is
        called.

    aliases : str, or list of str, optional
        The deprecated location(s) of this configuration item.  If the
        config item is not found at the new location, it will be
        searched for at all of the old locations.

    Raises
    ------
    RuntimeError
        If ``module`` is `None`, but the module this item is created from
        cannot be determined.
    Validator
    A type specifier like those used as the *values* of a particular key in a
    ``configspec`` file of ``configobj``.
    rootname
    Rootname sets the base path for all config files.
    Cannot automatically determine get_config module, because it is not called from inside a valid module"Cannot automatically determine get_config module, ""because it is not called from inside a valid module"dvstroption(boolean_validate_val
        Sets the current value of this ``ConfigItem``.

        This also updates the comments that give the description and type
        information.

        Parameters
        ----------
        value
            The value this item should be set to.

        Raises
        ------
        TypeError
            If the provided ``value`` is not valid for this ``ConfigItem``.
        ValidateErrorProvided value for configuration item  not valid: " not valid:"
        Sets this item to a specified value only inside a with block.

        Use as::

            ITEM = ConfigItem('ITEM', 'default', 'description')

            with ITEM.set_temp('newval'):
                #... do something that wants ITEM's value to be 'newval' ...
                print(ITEM)

            # ITEM is now 'default' after the with block

        Parameters
        ----------
        value
            The value to set this item to inside the with block.

        initvalReloads the value of this ``ConfigItem`` from the relevant
        configuration file.

        Returns
        -------
        val : object
            The new value loaded from the configuration file.

        baseobjsecnamecobjnewobj: name= value= at 0x" at"" 0x"  cfgtype=  defaultvalue=  description=  module=  value=Returns the value of this ``ConfigItem``.

        Returns
        -------
        val : object
            This item's value, with a type determined by the ``cfgtype``
            attribute.

        Raises
        ------
        TypeError
            If the configuration value as stored is not this item's type.

        section_nameat the top-levelin section [aliasnew_moduleConfig parameter ''  of the file '" of the file"" '"get_config_filename' is deprecated. Use '"' is"" deprecated. Use '""'" instead.' is given by more than one alias ("' is given"" by more than one alias"" ("). Using the first.")."" Using the first."Configuration value not valid: Validates the provided value based on cfgtype and returns the
        type-cast value.

        throws the underlying configobj exception if it fails
        _cfgobjspackageormod
    Get the filename of the config file associated with the given
    package or module.
    _override_config_fileGets the configuration object or section associated with a particular
    package or module.

    Parameters
    ----------
    packageormod : str or None
        The package for which to retrieve the configuration object. If a
        string, it must be a valid package name, or if ``None``, the package from
        which this function is called will be used.

    reload : bool, optional
        Reload the file, even if we have it cached.

    rootname : str or None
        Name of the root configuration directory. If ``None`` and
        ``packageormod`` is ``None``, this defaults to be the name of
        the package from which this function is called. If ``None`` and
        ``packageormod`` is not ``None``, this defaults to ``astropy``.

    Returns
    -------
    cfgobj : ``configobj.ConfigObj`` or ``configobj.Section``
        If the requested package is a base package, this will be the
        ``configobj.ConfigObj`` for that package, or if it is a subpackage or
        module, it will return the relevant ``configobj.Section`` object.

    Raises
    ------
    RuntimeError
        If ``packageormod`` is `None`, but the package this item is created
        from cannot be determined.
    Cannot automatically determine get_config module, msg1because it is not called from inside a valid modulemsg2_autopkgpackageormodsplpkgnamecfgfnwith_suffix.cfgGenerates a configuration file, from the list of `ConfigItem`
    objects for each subpackage.

    .. versionadded:: 4.1

    Parameters
    ----------
    pkgname : str or None
        The package for which to retrieve the configuration object.
    filename : str or file-like or None
        If None, the default configuration path is taken from `get_config`.

    verbosityfilter_warningswalk_packagesmodule_findersetup_package## initial_indentsubsequent_indent78ExitStackPathLikeenter_contextfpsubclassesprocessedprint_module]

 = ,

,

" ="Reloads configuration settings from a configuration file for the root
    package of the requested package/module.

    This overwrites any changes that may have been made in `ConfigItem`
    objects.  This applies for any items that are based on this file, which
    is determined by the *root* package of ``packageormod``
    (e.g. ``'astropy.cfg'`` for the ``'astropy.config.configuration'``
    module).

    Parameters
    ----------
    packageormod : str or None
        The package or module name - see `get_config` for details.
    rootname : str or None
        Name of the root configuration directory - see `get_config`
        for details.
    is_unedited_config_filetemplate_content
    Determines if a config file can be safely replaced because it doesn't
    actually contain any meaningful content, i.e. if it contains only comments
    or is completely empty.
    StringIOraw_cfgpkg
    Create the default configuration file for the specified package.
    If the file already exists, it is updated only if it has not been
    modified.  Otherwise the ``overwrite`` flag is needed to overwrite it.

    Parameters
    ----------
    pkg : str
        The package to be updated.
    rootname : str
        Name of the root configuration directory.
    overwrite : bool
        Force updating the file if it already exists.

    Returns
    -------
    updated : bool
        If the profile was updated, `True`, otherwise `False`.

    doupdateis_filelatin-1fwThe configuration file has been successfully written to The configuration file already exists and seems to have been customized, so it has not been updated. Use overwrite=True if you really want to update it."The configuration file already exists and seems to ""have been customized, so it has not been updated. ""Use overwrite=True if you really want to update it."# these are not in __all__ because it's not intended that a user ever see them# this is used in astropy/__init__.py# this is used to make validation faster so a Validator object doesn't# have to be created every time# now determine cfgtype if it is not given# it is an options list# cache value on the descriptor itself, to avoid repeated accesses# to the ConfigObj object which is much slower# store value on the ConfigObj instance...# and on the descriptor# a ConfigObj's parent is itself, so we look for the parent with that# note that this will normally use the *class* attribute `_validator`,# but if some arcane reason is needed for making a special one for an# instance or sub-class, it will be used# this dictionary stores the primary copy of the ConfigObj's for each# root package# This is used by testing to override the config file, so we can test# with various config files that exercise different features of the# config system.# so we don't break affiliated packages# This feature is intended only for use by the unit tests# This can happen when HOME is not set# This caches the object, so if the file becomes accessible, this# function won't see it unless the module is reloaded# not the root package# Skip test and setup_package modules# Skip private modules# assume it's a file object, or io.StringIO# Parse the subclasses, ordered by their module name# Skip modules for other packages, e.g. astropy modules that# would be imported when running the function for astroquery.# Check that modules are not processed twice, which can happen# when they are imported in another module.# If this is the first item of the module, we print the# module name, but not if this is the root package...# look for the section that is its own parent - that's the base object# If any of the items is set, return False# local import to prevent using the logger before it is configured# generate the default config template# if the file already exists, check that it has not been modifiedb'This module contains classes and functions to standardize access to
configuration files for Astropy and affiliated packages.

.. note::
    The configuration system makes use of the 'configobj' package, which stores
    configuration in a text format like that used in the standard library
    `ConfigParser`. More information and documentation for configobj can be
    found at https://configobj.readthedocs.io .
'u'This module contains classes and functions to standardize access to
configuration files for Astropy and affiliated packages.

.. note::
    The configuration system makes use of the 'configobj' package, which stores
    configuration in a text format like that used in the standard library
    `ConfigParser`. More information and documentation for configobj can be
    found at https://configobj.readthedocs.io .
'b'ConfigItem'u'ConfigItem'b'ConfigNamespace'u'ConfigNamespace'b'InvalidConfigurationItemWarning'u'InvalidConfigurationItemWarning'b'create_config_file'u'create_config_file'b'generate_config'u'generate_config'b'get_config'u'get_config'b'reload_config'u'reload_config'b'A Warning that is issued when the configuration value specified in the
    astropy configuration file does not match the type expected for that
    configuration value.
    'u'A Warning that is issued when the configuration value specified in the
    astropy configuration file does not match the type expected for that
    configuration value.
    'b'An exception that is raised when the configuration defaults (which
    should be generated at build-time) are missing.
    'u'An exception that is raised when the configuration defaults (which
    should be generated at build-time) are missing.
    'b'A warning that is issued when the configuration defaults (which
    should be generated at build-time) are missing.
    'u'A warning that is issued when the configuration defaults (which
    should be generated at build-time) are missing.
    'b'
    A warning that the configuration options have changed.
    'u'
    A warning that the configuration options have changed.
    'b'
    A namespace of configuration items.  Each subpackage with
    configuration items should define a subclass of this class,
    containing `ConfigItem` instances as members.

    For example::

        class Conf(_config.ConfigNamespace):
            unicode_output = _config.ConfigItem(
                False,
                'Use Unicode characters when outputting values, ...')
            use_color = _config.ConfigItem(
                sys.platform != 'win32',
                'When True, use ANSI color escape sequences when ...',
                aliases=['astropy.utils.console.USE_COLOR'])
        conf = Conf()
    'u'
    A namespace of configuration items.  Each subpackage with
    configuration items should define a subclass of this class,
    containing `ConfigItem` instances as members.

    For example::

        class Conf(_config.ConfigNamespace):
            unicode_output = _config.ConfigItem(
                False,
                'Use Unicode characters when outputting values, ...')
            use_color = _config.ConfigItem(
                sys.platform != 'win32',
                'When True, use ANSI color escape sequences when ...',
                aliases=['astropy.utils.console.USE_COLOR'])
        conf = Conf()
    'b'

'u'

'b'Configuration parameters for `'u'Configuration parameters for `'b'`

'u'`

'b'Iterate over configuration item names.'u'Iterate over configuration item names.'b'Iterate over configuration item values.'u'Iterate over configuration item values.'b'Iterate over configuration item ``(name, value)`` pairs.'u'Iterate over configuration item ``(name, value)`` pairs.'b'Print info about configuration items.

        Parameters
        ----------
        name : `str`, optional
            Name of the configuration item to be described. If no name is
            provided then info about all the configuration items will be
            printed.

        Examples
        --------
        >>> from astropy import conf
        >>> conf.help("unicode_output")
        ConfigItem: unicode_output
          cfgtype='boolean'
          defaultvalue=False
          description='When True, use Unicode characters when outputting values, and displaying widgets at the console.'
          module=astropy
          value=False
        'u'Print info about configuration items.

        Parameters
        ----------
        name : `str`, optional
            Name of the configuration item to be described. If no name is
            provided then info about all the configuration items will be
            printed.

        Examples
        --------
        >>> from astropy import conf
        >>> conf.help("unicode_output")
        ConfigItem: unicode_output
          cfgtype='boolean'
          defaultvalue=False
          description='When True, use Unicode characters when outputting values, and displaying widgets at the console.'
          module=astropy
          value=False
        'b'' is not among configuration items 'u'' is not among configuration items 'b'
        Temporarily set a configuration value.

        Parameters
        ----------
        attr : str
            Configuration item name

        value : object
            The value to set temporarily.

        Examples
        --------
        >>> import astropy
        >>> with astropy.conf.set_temp('use_color', False):
        ...     pass
        ...     # console output will not contain color
        >>> # console output contains color again...
        'u'
        Temporarily set a configuration value.

        Parameters
        ----------
        attr : str
            Configuration item name

        value : object
            The value to set temporarily.

        Examples
        --------
        >>> import astropy
        >>> with astropy.conf.set_temp('use_color', False):
        ...     pass
        ...     # console output will not contain color
        >>> # console output contains color again...
        'b'No configuration parameter ''u'No configuration parameter ''b'
        Reload a configuration item from the configuration file.

        Parameters
        ----------
        attr : str, optional
            The name of the configuration parameter to reload.  If not
            provided, reload all configuration parameters.
        'u'
        Reload a configuration item from the configuration file.

        Parameters
        ----------
        attr : str, optional
            The name of the configuration parameter to reload.  If not
            provided, reload all configuration parameters.
        'b'
        Reset a configuration item to its default.

        Parameters
        ----------
        attr : str, optional
            The name of the configuration parameter to reload.  If not
            provided, reset all configuration parameters.
        'u'
        Reset a configuration item to its default.

        Parameters
        ----------
        attr : str, optional
            The name of the configuration parameter to reload.  If not
            provided, reset all configuration parameters.
        'b'
    A setting and associated value stored in a configuration file.

    These objects should be created as members of
    `ConfigNamespace` subclasses, for example::

        class _Conf(config.ConfigNamespace):
            unicode_output = config.ConfigItem(
                False,
                'Use Unicode characters when outputting values, and writing widgets '
                'to the console.')
        conf = _Conf()

    Parameters
    ----------
    defaultvalue : object, optional
        The default value for this item. If this is a list of strings, this
        item will be interpreted as an 'options' value - this item must be one
        of those values, and the first in the list will be taken as the default
        value.

    description : str or None, optional
        A description of this item (will be shown as a comment in the
        configuration file)

    cfgtype : str or None, optional
        A type specifier like those used as the *values* of a particular key
        in a ``configspec`` file of ``configobj``. If None, the type will be
        inferred from the default value.

    module : str or None, optional
        The full module name that this item is associated with. The first
        element (e.g. 'astropy' if this is 'astropy.config.configuration')
        will be used to determine the name of the configuration file, while
        the remaining items determine the section. If None, the package will be
        inferred from the package within which this object's initializer is
        called.

    aliases : str, or list of str, optional
        The deprecated location(s) of this configuration item.  If the
        config item is not found at the new location, it will be
        searched for at all of the old locations.

    Raises
    ------
    RuntimeError
        If ``module`` is `None`, but the module this item is created from
        cannot be determined.
    'u'
    A setting and associated value stored in a configuration file.

    These objects should be created as members of
    `ConfigNamespace` subclasses, for example::

        class _Conf(config.ConfigNamespace):
            unicode_output = config.ConfigItem(
                False,
                'Use Unicode characters when outputting values, and writing widgets '
                'to the console.')
        conf = _Conf()

    Parameters
    ----------
    defaultvalue : object, optional
        The default value for this item. If this is a list of strings, this
        item will be interpreted as an 'options' value - this item must be one
        of those values, and the first in the list will be taken as the default
        value.

    description : str or None, optional
        A description of this item (will be shown as a comment in the
        configuration file)

    cfgtype : str or None, optional
        A type specifier like those used as the *values* of a particular key
        in a ``configspec`` file of ``configobj``. If None, the type will be
        inferred from the default value.

    module : str or None, optional
        The full module name that this item is associated with. The first
        element (e.g. 'astropy' if this is 'astropy.config.configuration')
        will be used to determine the name of the configuration file, while
        the remaining items determine the section. If None, the package will be
        inferred from the package within which this object's initializer is
        called.

    aliases : str, or list of str, optional
        The deprecated location(s) of this configuration item.  If the
        config item is not found at the new location, it will be
        searched for at all of the old locations.

    Raises
    ------
    RuntimeError
        If ``module`` is `None`, but the module this item is created from
        cannot be determined.
    'b'
    A type specifier like those used as the *values* of a particular key in a
    ``configspec`` file of ``configobj``.
    'u'
    A type specifier like those used as the *values* of a particular key in a
    ``configspec`` file of ``configobj``.
    'b'
    Rootname sets the base path for all config files.
    'u'
    Rootname sets the base path for all config files.
    'b'Cannot automatically determine get_config module, because it is not called from inside a valid module'u'Cannot automatically determine get_config module, because it is not called from inside a valid module'b'option('u'option('b'boolean'u'boolean'b'integer'u'integer'b'string'u'string'b'
        Sets the current value of this ``ConfigItem``.

        This also updates the comments that give the description and type
        information.

        Parameters
        ----------
        value
            The value this item should be set to.

        Raises
        ------
        TypeError
            If the provided ``value`` is not valid for this ``ConfigItem``.
        'u'
        Sets the current value of this ``ConfigItem``.

        This also updates the comments that give the description and type
        information.

        Parameters
        ----------
        value
            The value this item should be set to.

        Raises
        ------
        TypeError
            If the provided ``value`` is not valid for this ``ConfigItem``.
        'b'Provided value for configuration item 'u'Provided value for configuration item 'b' not valid: 'u' not valid: 'b'
        Sets this item to a specified value only inside a with block.

        Use as::

            ITEM = ConfigItem('ITEM', 'default', 'description')

            with ITEM.set_temp('newval'):
                #... do something that wants ITEM's value to be 'newval' ...
                print(ITEM)

            # ITEM is now 'default' after the with block

        Parameters
        ----------
        value
            The value to set this item to inside the with block.

        'u'
        Sets this item to a specified value only inside a with block.

        Use as::

            ITEM = ConfigItem('ITEM', 'default', 'description')

            with ITEM.set_temp('newval'):
                #... do something that wants ITEM's value to be 'newval' ...
                print(ITEM)

            # ITEM is now 'default' after the with block

        Parameters
        ----------
        value
            The value to set this item to inside the with block.

        'b'Reloads the value of this ``ConfigItem`` from the relevant
        configuration file.

        Returns
        -------
        val : object
            The new value loaded from the configuration file.

        'u'Reloads the value of this ``ConfigItem`` from the relevant
        configuration file.

        Returns
        -------
        val : object
            The new value loaded from the configuration file.

        'b': name='u': name='b' value='u' value='b' at 0x'u' at 0x'b'  cfgtype='u'  cfgtype='b'  defaultvalue='u'  defaultvalue='b'  description='u'  description='b'  module='u'  module='b'  value='u'  value='b'Returns the value of this ``ConfigItem``.

        Returns
        -------
        val : object
            This item's value, with a type determined by the ``cfgtype``
            attribute.

        Raises
        ------
        TypeError
            If the configuration value as stored is not this item's type.

        'u'Returns the value of this ``ConfigItem``.

        Returns
        -------
        val : object
            This item's value, with a type determined by the ``cfgtype``
            attribute.

        Raises
        ------
        TypeError
            If the configuration value as stored is not this item's type.

        'b'at the top-level'u'at the top-level'b'in section ['u'in section ['b'Config parameter ''u'Config parameter ''b'' 'u'' 'b' of the file ''u' of the file ''b'' is deprecated. Use ''u'' is deprecated. Use ''b' instead.'u' instead.'b'' is given by more than one alias ('u'' is given by more than one alias ('b'). Using the first.'u'). Using the first.'b'Configuration value not valid: 'u'Configuration value not valid: 'b'Validates the provided value based on cfgtype and returns the
        type-cast value.

        throws the underlying configobj exception if it fails
        'u'Validates the provided value based on cfgtype and returns the
        type-cast value.

        throws the underlying configobj exception if it fails
        'b'
    Get the filename of the config file associated with the given
    package or module.
    'u'
    Get the filename of the config file associated with the given
    package or module.
    'b'Gets the configuration object or section associated with a particular
    package or module.

    Parameters
    ----------
    packageormod : str or None
        The package for which to retrieve the configuration object. If a
        string, it must be a valid package name, or if ``None``, the package from
        which this function is called will be used.

    reload : bool, optional
        Reload the file, even if we have it cached.

    rootname : str or None
        Name of the root configuration directory. If ``None`` and
        ``packageormod`` is ``None``, this defaults to be the name of
        the package from which this function is called. If ``None`` and
        ``packageormod`` is not ``None``, this defaults to ``astropy``.

    Returns
    -------
    cfgobj : ``configobj.ConfigObj`` or ``configobj.Section``
        If the requested package is a base package, this will be the
        ``configobj.ConfigObj`` for that package, or if it is a subpackage or
        module, it will return the relevant ``configobj.Section`` object.

    Raises
    ------
    RuntimeError
        If ``packageormod`` is `None`, but the package this item is created
        from cannot be determined.
    'u'Gets the configuration object or section associated with a particular
    package or module.

    Parameters
    ----------
    packageormod : str or None
        The package for which to retrieve the configuration object. If a
        string, it must be a valid package name, or if ``None``, the package from
        which this function is called will be used.

    reload : bool, optional
        Reload the file, even if we have it cached.

    rootname : str or None
        Name of the root configuration directory. If ``None`` and
        ``packageormod`` is ``None``, this defaults to be the name of
        the package from which this function is called. If ``None`` and
        ``packageormod`` is not ``None``, this defaults to ``astropy``.

    Returns
    -------
    cfgobj : ``configobj.ConfigObj`` or ``configobj.Section``
        If the requested package is a base package, this will be the
        ``configobj.ConfigObj`` for that package, or if it is a subpackage or
        module, it will return the relevant ``configobj.Section`` object.

    Raises
    ------
    RuntimeError
        If ``packageormod`` is `None`, but the package this item is created
        from cannot be determined.
    'b'Cannot automatically determine get_config module, 'u'Cannot automatically determine get_config module, 'b'because it is not called from inside a valid module'u'because it is not called from inside a valid module'b'.cfg'u'.cfg'b'Generates a configuration file, from the list of `ConfigItem`
    objects for each subpackage.

    .. versionadded:: 4.1

    Parameters
    ----------
    pkgname : str or None
        The package for which to retrieve the configuration object.
    filename : str or file-like or None
        If None, the default configuration path is taken from `get_config`.

    'u'Generates a configuration file, from the list of `ConfigItem`
    objects for each subpackage.

    .. versionadded:: 4.1

    Parameters
    ----------
    pkgname : str or None
        The package for which to retrieve the configuration object.
    filename : str or file-like or None
        If None, the default configuration path is taken from `get_config`.

    'b'setup_package'u'setup_package'b'## 'u'## 'b']

'u']

'b' = ,

'u' = ,

'b',

'u',

'b'Reloads configuration settings from a configuration file for the root
    package of the requested package/module.

    This overwrites any changes that may have been made in `ConfigItem`
    objects.  This applies for any items that are based on this file, which
    is determined by the *root* package of ``packageormod``
    (e.g. ``'astropy.cfg'`` for the ``'astropy.config.configuration'``
    module).

    Parameters
    ----------
    packageormod : str or None
        The package or module name - see `get_config` for details.
    rootname : str or None
        Name of the root configuration directory - see `get_config`
        for details.
    'u'Reloads configuration settings from a configuration file for the root
    package of the requested package/module.

    This overwrites any changes that may have been made in `ConfigItem`
    objects.  This applies for any items that are based on this file, which
    is determined by the *root* package of ``packageormod``
    (e.g. ``'astropy.cfg'`` for the ``'astropy.config.configuration'``
    module).

    Parameters
    ----------
    packageormod : str or None
        The package or module name - see `get_config` for details.
    rootname : str or None
        Name of the root configuration directory - see `get_config`
        for details.
    'b'
    Determines if a config file can be safely replaced because it doesn't
    actually contain any meaningful content, i.e. if it contains only comments
    or is completely empty.
    'u'
    Determines if a config file can be safely replaced because it doesn't
    actually contain any meaningful content, i.e. if it contains only comments
    or is completely empty.
    'b'
    Create the default configuration file for the specified package.
    If the file already exists, it is updated only if it has not been
    modified.  Otherwise the ``overwrite`` flag is needed to overwrite it.

    Parameters
    ----------
    pkg : str
        The package to be updated.
    rootname : str
        Name of the root configuration directory.
    overwrite : bool
        Force updating the file if it already exists.

    Returns
    -------
    updated : bool
        If the profile was updated, `True`, otherwise `False`.

    'u'
    Create the default configuration file for the specified package.
    If the file already exists, it is updated only if it has not been
    modified.  Otherwise the ``overwrite`` flag is needed to overwrite it.

    Parameters
    ----------
    pkg : str
        The package to be updated.
    rootname : str
        Name of the root configuration directory.
    overwrite : bool
        Force updating the file if it already exists.

    Returns
    -------
    updated : bool
        If the profile was updated, `True`, otherwise `False`.

    'b'latin-1'u'latin-1'b'The configuration file has been successfully written to 'u'The configuration file has been successfully written to 'b'The configuration file already exists and seems to have been customized, so it has not been updated. Use overwrite=True if you really want to update it.'u'The configuration file already exists and seems to have been customized, so it has not been updated. Use overwrite=True if you really want to update it.'u'astropy.config.configuration'u'config.configuration'u'configuration'Configure the tests for :mod:`astropy._src.cosmology.parameter`.astropy.cosmology._src.tests.helperclean_registryastropy.tests.helperpickle_protocolb'Configure the tests for :mod:`astropy._src.cosmology.parameter`.'u'Configure the tests for :mod:`astropy._src.cosmology.parameter`.'u'_src.tests.parameter.conftest'u'tests.parameter.conftest'u'parameter.conftest'u'conftest'Configure the tests for :mod:`astropy.cosmology`.Sequencefilter_keys_from_itemsfilter_outFilter ``m``, returning key-value pairs not including keys in ``filter``.

    Parameters
    ----------
    m : mapping[K, V]
        A mapping from which to remove keys in ``filter_out``.
    filter_out : sequence[K]
        Sequence of keys to filter out from ``m``.

    Returns
    -------
    iterable[K, V]
        Iterable of ``(key, value)`` pairs with the ``filter_out`` keys removed.
    b'Configure the tests for :mod:`astropy.cosmology`.'u'Configure the tests for :mod:`astropy.cosmology`.'b'Filter ``m``, returning key-value pairs not including keys in ``filter``.

    Parameters
    ----------
    m : mapping[K, V]
        A mapping from which to remove keys in ``filter_out``.
    filter_out : sequence[K]
        Sequence of keys to filter out from ``m``.

    Returns
    -------
    iterable[K, V]
        Iterable of ``(key, value)`` pairs with the ``filter_out`` keys removed.
    'u'Filter ``m``, returning key-value pairs not including keys in ``filter``.

    Parameters
    ----------
    m : mapping[K, V]
        A mapping from which to remove keys in ``filter_out``.
    filter_out : sequence[K]
        Sequence of keys to filter out from ``m``.

    Returns
    -------
    iterable[K, V]
        Iterable of ``(key, value)`` pairs with the ``filter_out`` keys removed.
    'u'_src.tests.flrw.conftest'u'tests.flrw.conftest'u'flrw.conftest'
This file contains pytest configuration settings that are astropy-specific
(i.e.  those that would not necessarily be shared by affiliated packages
making use of astropy's test runner).
pytest_astropy_header.displayPYTEST_HEADER_MODULESTESTED_VERSIONSHAS_MATPLOTLIBmplmatplotlibrc_cacheignore_matplotlibrcpyplotpltstyleafter_resetfast_thread_switchingFixture that reduces thread switching interval.

    This makes it easier to provoke race conditions.
    pytest_configureastropy.utils.iersiers_confauto_download_pytest_runningrcdefaultsuseAggXDG_CONFIG_HOME_xdg_config_home_origXDG_CACHE_HOME_xdg_cache_home_origastropy_configastropy_cacheastropy_headercythonCythonskimageScikit-imagethreadpoolctlthreadpool_limitsPYTEST_XDIST_WORKER_COUNTxdist_worker_countcpu_countmax_threadsthreads_per_workerpytest_unconfigurepytest_terminal_summaryterminalreporterOutput a warning to IPython users in case any tests failed.__IPYTHON__failedensure_newlinewrite_lineSome tests may fail when run from the IPython prompt; especially, but not limited to tests involving logging and warning handling.  Unless you are certain as to the cause of the failure, please check that the failure occurs outside IPython as well.  See https://docs.astropy.org/en/stable/known_issues.html#failing-logging-tests-when-running-the-tests-in-ipython for more information."Some tests may fail when run from the IPython prompt; ""especially, but not limited to tests involving logging and warning ""handling.  Unless you are certain as to the cause of the failure, ""please check that the failure occurs outside IPython as well.  See ""https://docs.astropy.org/en/stable/known_issues.html#failing-logging-""tests-when-running-the-tests-in-ipython for more information."bold# This is a fixture for tests that use matplotlib but not pytest-mpl# (which already handles rcParams)# Ensure number of columns and lines is deterministic for testing# Disable IERS auto download for testing# do not assign to matplotlibrc_cache in function scope# Make sure we use temporary directories for the config and cache# so that the tests are insensitive to local configuration. Note that this# is also set in the test runner, but we need to also set it here for# things to work properly in parallel mode# Limit the number of threads used by each worker when pytest-xdist is in# use.  Lifted from https://github.com/scipy/scipy/pull/14441# and https://github.com/scikit-learn/scikit-learn/pull/25918# use number of physical cores, assume hyperthreading# Undo settings related to number of lines/columns to show# Undo IERS auto download setting for testing# this name is only defined if running within ipython/jupyter# Only issue the warning when there are actually failuresb'
This file contains pytest configuration settings that are astropy-specific
(i.e.  those that would not necessarily be shared by affiliated packages
making use of astropy's test runner).
'u'
This file contains pytest configuration settings that are astropy-specific
(i.e.  those that would not necessarily be shared by affiliated packages
making use of astropy's test runner).
'b'Fixture that reduces thread switching interval.

    This makes it easier to provoke race conditions.
    'u'Fixture that reduces thread switching interval.

    This makes it easier to provoke race conditions.
    'b'Agg'u'Agg'b'XDG_CONFIG_HOME'u'XDG_CONFIG_HOME'b'XDG_CACHE_HOME'u'XDG_CACHE_HOME'b'astropy_config'u'astropy_config'b'astropy_cache'u'astropy_cache'b'erfa'u'erfa'b'cython'u'cython'b'Cython'u'Cython'b'skimage'u'skimage'b'Scikit-image'u'Scikit-image'b'asdf_astropy'u'asdf_astropy'b'PYTEST_XDIST_WORKER_COUNT'u'PYTEST_XDIST_WORKER_COUNT'b'max_width'u'max_width'b'max_lines'u'max_lines'b'auto_download'u'auto_download'b'Output a warning to IPython users in case any tests failed.'u'Output a warning to IPython users in case any tests failed.'b'failed'u'failed'b'Some tests may fail when run from the IPython prompt; especially, but not limited to tests involving logging and warning handling.  Unless you are certain as to the cause of the failure, please check that the failure occurs outside IPython as well.  See https://docs.astropy.org/en/stable/known_issues.html#failing-logging-tests-when-running-the-tests-in-ipython for more information.'u'Some tests may fail when run from the IPython prompt; especially, but not limited to tests involving logging and warning handling.  Unless you are certain as to the cause of the failure, please check that the failure occurs outside IPython as well.  See https://docs.astropy.org/en/stable/known_issues.html#failing-logging-tests-when-running-the-tests-in-ipython for more information.'u'astropy.conftest'home_is_datahome_is_data, pathlibidsmonkeypatch
    Pytest fixture to run a test case both with and without tilde paths.

    In the tilde-path case, calls like self.data('filename.fits') will
    produce '~/filename.fits', and environment variables will be temporarily
    modified so that '~' resolves to the data directory.
    set_home_as_dataset_paths_via_pathlibhome_is_temp
    Pytest fixture to run a test case both with and without tilde paths.

    In the tilde-path case, calls like self.temp('filename.fits') will
    produce '~/filename.fits', and environment variables will be temporarily
    modified so that '~' resolves to the temp directory. These files will also
    be tracked so that, after the test case, we can verify no files were written
    to a literal tilde path.
    set_home_as_tempFitsTestCasesetup_methoddata_dirfits-test-temp_dirtemp_files_useduse_pathlibteardown_methodtemp_filetemp_file_no_tildetriessleepcopy_fileCopies a backup of a test data file to the temp dir and sets its
        mode to writeable.
        expandusertempS_IREADS_IWRITEReturns the path to a test data file.Returns the full path to a file in the test temp dir.real_target
        This overrides the HOME environment variable, so that paths beginning
        with '~/' expand to the data directory. Used by the `home_is_data`
        fixture.
        HOMEUSERPROFILE
        This overrides the HOME environment variable, so that paths beginning
        with '~/' expand to the temp directory. In conjunction with
        self.temp(), temporary files are tracked as they are created, so we can
        verify they end up in the temporary directory and not unexpected places
        in the filesystem. Used by the `home_is_temp` fixture.
        # This checks the value specified in the fixture annotation# `request.instance` refers to the test case that's using this fixture.# Restore global settings to defaults# TODO: Replace this when there's a better way to in the config API to# force config values to their defaults# Verify that no files were written to a literal tilde path# Probably couldn't delete the file because for whatever# reason a handle to it is still open/hasn't been# garbage-collected# Record the '~' path and the intended path, for use# in `home_is_temp`# For Unix# For Windowsb'str'u'str'b'pathlib'u'pathlib'b'home_is_data'u'home_is_data'b'home_is_data, pathlib'u'home_is_data, pathlib'b'
    Pytest fixture to run a test case both with and without tilde paths.

    In the tilde-path case, calls like self.data('filename.fits') will
    produce '~/filename.fits', and environment variables will be temporarily
    modified so that '~' resolves to the data directory.
    'u'
    Pytest fixture to run a test case both with and without tilde paths.

    In the tilde-path case, calls like self.data('filename.fits') will
    produce '~/filename.fits', and environment variables will be temporarily
    modified so that '~' resolves to the data directory.
    'b'
    Pytest fixture to run a test case both with and without tilde paths.

    In the tilde-path case, calls like self.temp('filename.fits') will
    produce '~/filename.fits', and environment variables will be temporarily
    modified so that '~' resolves to the temp directory. These files will also
    be tracked so that, after the test case, we can verify no files were written
    to a literal tilde path.
    'u'
    Pytest fixture to run a test case both with and without tilde paths.

    In the tilde-path case, calls like self.temp('filename.fits') will
    produce '~/filename.fits', and environment variables will be temporarily
    modified so that '~' resolves to the temp directory. These files will also
    be tracked so that, after the test case, we can verify no files were written
    to a literal tilde path.
    'b'fits-test-'u'fits-test-'b'temp_dir'u'temp_dir'b'enable_record_valued_keyword_cards'u'enable_record_valued_keyword_cards'b'extension_name_case_sensitive'u'extension_name_case_sensitive'b'strip_header_whitespace'u'strip_header_whitespace'b'use_memmap'u'use_memmap'b'Copies a backup of a test data file to the temp dir and sets its
        mode to writeable.
        'u'Copies a backup of a test data file to the temp dir and sets its
        mode to writeable.
        'b'Returns the path to a test data file.'u'Returns the path to a test data file.'b'Returns the full path to a file in the test temp dir.'u'Returns the full path to a file in the test temp dir.'b'
        This overrides the HOME environment variable, so that paths beginning
        with '~/' expand to the data directory. Used by the `home_is_data`
        fixture.
        'u'
        This overrides the HOME environment variable, so that paths beginning
        with '~/' expand to the data directory. Used by the `home_is_data`
        fixture.
        'b'HOME'u'HOME'b'USERPROFILE'u'USERPROFILE'b'
        This overrides the HOME environment variable, so that paths beginning
        with '~/' expand to the temp directory. In conjunction with
        self.temp(), temporary files are tracked as they are created, so we can
        verify they end up in the temporary directory and not unexpected places
        in the filesystem. Used by the `home_is_temp` fixture.
        'u'
        This overrides the HOME environment variable, so that paths beginning
        with '~/' expand to the temp directory. In conjunction with
        self.temp(), temporary files are tracked as they are created, so we can
        verify they end up in the temporary directory and not unexpected places
        in the filesystem. Used by the `home_is_temp` fixture.
        'u'io.fits.tests.conftest'u'fits.tests.conftest'u'tests.conftest'
All of the pytest fixtures used by astropy.table are defined here.

`conftest.py` is a "special" module name for pytest that is always
imported, but is not looked in for tests, and it is the recommended
place to put fixtures that are shared between modules.  These fixtures
can not be defined in a module by a different name and still be shared
between modules.
pickleastropy.table.table_helpersArrayWrapperMaskedTableMyRowMyColumnMyMaskedColumnMyTableColumnsMyTableFormatterMyTableunmaskedsubclasstable_typesTableTypestable_dataTableData%iuadbmbub%fmcCOLSDATASubclassTabletableclassHIGHEST_PROTOCOL
    Fixture to run all the tests for all available pickle protocols.
    table_type180.0wrap_anglelongitude11.0latitude200120022003jyearjdskycoordsphericalrepcartesianrepsphericaldiffarraywrapbyteswaparrayswap<i4,|S1ndarraylil>i4,|S1ndarraybigStokesCoordstokescoordMIXIN_COLSearthlocationsphericalrepdiffmixin_cols
    Fixture to return a set of columns for mixin testing which includes
    an index column 'i', two string cols 'a', 'b' (for joins etc), and
    one of the available mixin column types.
    _get_test_table a b c d 2 c 7.0 0 2 b 5.0 1 2 b 6.0 2 2 a 4.0 3 0 a 0.0 4 1 b 3.0 5 1 a 2.0 6 1 a 1.0 7tacolumn cT1bBasic tableT1Basic table with or without index on integer column aT1qBasic table where a column is integer or QuantityT1mBasic table with or without index on column a, where a is integer or Quantityis_quantityoperation_table_type# Fixture to run all the Column tests for both an unmasked (ndarray)# and masked (MaskedArray) column.# Fixture to run all tests for both an unmasked (ndarray) and masked# (MaskedArray) column.# Stuff for testing mixin columnsb'
All of the pytest fixtures used by astropy.table are defined here.

`conftest.py` is a "special" module name for pytest that is always
imported, but is not looked in for tests, and it is the recommended
place to put fixtures that are shared between modules.  These fixtures
can not be defined in a module by a different name and still be shared
between modules.
'u'
All of the pytest fixtures used by astropy.table are defined here.

`conftest.py` is a "special" module name for pytest that is always
imported, but is not looked in for tests, and it is the recommended
place to put fixtures that are shared between modules.  These fixtures
can not be defined in a module by a different name and still be shared
between modules.
'b'masked'b'unmasked'u'unmasked'b'subclass'u'subclass'b'%i'u'%i'b'ma'u'ma'b'ua'u'ua'b'db'u'db'b'mb'u'mb'b'ub'u'ub'b'dc'u'dc'b'%f'u'%f'b'mc'u'mc'b'
    Fixture to run all the tests for all available pickle protocols.
    'u'
    Fixture to run all the tests for all available pickle protocols.
    'b'quantity'u'quantity'b'longitude'u'longitude'b'latitude'u'latitude'b'jyear'u'jyear'b'jd'u'jd'b'timedelta'u'timedelta'b'skycoord'u'skycoord'b'sphericalrep'u'sphericalrep'b'cartesianrep'u'cartesianrep'b'sphericaldiff'u'sphericaldiff'b'arraywrap'u'arraywrap'b'arrayswap'u'arrayswap'b'<i4,|S1'u'<i4,|S1'b'ndarraylil'u'ndarraylil'b'>i4,|S1'u'>i4,|S1'b'ndarraybig'u'ndarraybig'b'stokescoord'u'stokescoord'b'earthlocation'u'earthlocation'b'sphericalrepdiff'u'sphericalrepdiff'b'
    Fixture to return a set of columns for mixin testing which includes
    an index column 'i', two string cols 'a', 'b' (for joins etc), and
    one of the available mixin column types.
    'u'
    Fixture to return a set of columns for mixin testing which includes
    an index column 'i', two string cols 'a', 'b' (for joins etc), and
    one of the available mixin column types.
    'b' a b c d'u' a b c d'b' 2 c 7.0 0'u' 2 c 7.0 0'b' 2 b 5.0 1'u' 2 b 5.0 1'b' 2 b 6.0 2'u' 2 b 6.0 2'b' 2 a 4.0 3'u' 2 a 4.0 3'b' 0 a 0.0 4'u' 0 a 0.0 4'b' 1 b 3.0 5'u' 1 b 3.0 5'b' 1 a 2.0 6'u' 1 a 2.0 6'b' 1 a 1.0 7'u' 1 a 1.0 7'b'ta'u'ta'b'column c'u'column c'b'Basic table'u'Basic table'b'Basic table with or without index on integer column a'u'Basic table with or without index on integer column a'b'Basic table where a column is integer or Quantity'u'Basic table where a column is integer or Quantity'b'Basic table with or without index on column a, where a is integer or Quantity'u'Basic table with or without index on column a, where a is integer or Quantity'u'astropy.table.tests.conftest'u'table.tests.conftest'spectral_1d_fitswcsFREQcunit3000000000.03.0e94000000000.04.0e9Frequencytime_1d_fitswcsTIME30042mjdrefcelestial_2d_fitswcsRA---CARDEC--CARRight AscensionDeclinationspectral_cube_3d_fitswcs2.5cube_4d_fitswcsSpectral1DLowLevelWCSem.freq_pixel_shape_pixel_boundspixel_array3e94e9world_arrayspectral_1d_ape14_wcsCelestial2DLowLevelWCSpos.eq.rapos.eq.decpxpywxwyspherical.lon.degreespherical.lat.degreecelestial_2d_ape14_wcsb'FREQ'u'FREQ'b'Frequency'u'Frequency'b'TIME'u'TIME'b'RA---CAR'u'RA---CAR'b'DEC--CAR'u'DEC--CAR'b'Right Ascension'u'Right Ascension'b'Declination'u'Declination'b'em.freq'u'em.freq'b'pos.eq.ra'u'pos.eq.ra'b'pos.eq.dec'u'pos.eq.dec'b'spherical.lon.degree'u'spherical.lon.degree'b'spherical.lat.degree'u'spherical.lat.degree'u'astropy.wcs.wcsapi.conftest'u'wcs.wcsapi.conftest'u'wcsapi.conftest'_docdirRun doctests in isolated tmp_path so outputs do not end up in repo.pluginmanagergetplugindoctestplusdoctest_plugin_doctest_textfile_item_clsio.rstold_cwdgetfixturevaluetmp_path# This file needs to be included here to make sure commands such# as ``pytest docs/...`` works, since this# will ignore the conftest.py file at the root of the repository# and the one in astropy/conftest.py# so that the tests are insensitive to local configuration.# Note that we don't need to change the environment variables back or remove# them after testing, because they are only changed for the duration of the# Python process, and this configuration only matters if running pytest# directly, not from e.g. an IPython session.# Trigger ONLY for doctestplus# Don't apply this fixture to io.rst.  It reads files and doesn't write.# Implementation from https://github.com/pytest-dev/pytest/discussions/10437b'Run doctests in isolated tmp_path so outputs do not end up in repo.'u'Run doctests in isolated tmp_path so outputs do not end up in repo.'b'doctestplus'u'doctestplus'b'io.rst'u'io.rst'b'tmp_path'u'tmp_path'u'docs.conftest'hypothesispytest_report_headerCI: undefined
ARCH_ON_CI: "\n""ARCH_ON_CI: "
IS_CRON: "IS_CRON: "register_profiledeadlineprint_blobderandomizeHealthCheckdiffering_executorssuppress_health_checkfuzzingmax_examplesaarch64load_profileHYPOTHESIS_PROFILE# This file is the main file used when running tests with pytest directly,# in particular if running e.g. ``pytest docs/``.# This has to be in the root dir or it will not display in CI.# This gets added after the pytest-astropy-header output.# Tell Hypothesis that we might be running slow tests, to print the seed blob# so we can easily reproduce failures from CI, and derive a fuzzing profile# to try many more inputs when we detect a scheduled build or when specifically# requested using the HYPOTHESIS_PROFILE=fuzz environment variable or# `pytest --hypothesis-profile=fuzz ...` argument.# disabling HealthCheck.differing_executors to allow double test# see https://github.com/astropy/astropy/issues/17299b'CI: 'u'CI: 'b'CI'u'CI'b'undefined'u'undefined'b'
ARCH_ON_CI: 'u'
ARCH_ON_CI: 'b'ARCH_ON_CI'u'ARCH_ON_CI'b'
IS_CRON: 'u'
IS_CRON: 'b'IS_CRON'u'IS_CRON'b'ci'u'ci'b'fuzzing'u'fuzzing'b'aarch64'u'aarch64'b'ppc64le'u'ppc64le'b'HYPOTHESIS_PROFILE'u'HYPOTHESIS_PROFILE'fitsio_param_to_astropy_paramqlevelqmethod_map_expand
    Expands a list of N iterables of parameters into a flat list with all
    combinations of all parameters.
    expandedeleALL_INTEGER_DTYPESALL_FLOAT_DTYPESsessioncomp_param_dtypecompression_paramnumpy_rng# Convert fitsio kwargs to astropy kwargs# Map quantize_level# The params here are compression type, parameters for the compression /# quantise and dtype# Test all compression types with default compression parameters for# all integers# GZIP and NOCOMPRESS support lossless non-quantized floating point data# All compression types can also take quantized floating point input# Rather than running all quantization parameters for all algorithms# split up the algorithms to reduce the total number of tests.# Note no PLIO here as that's intended for masks, i.e. data which can't# be generated with quantization.b'quantize_level'u'quantize_level'b'qlevel'u'qlevel'b'quantize_method'u'quantize_method'b'qmethod'u'qmethod'b'missing'u'missing'b'
    Expands a list of N iterables of parameters into a flat list with all
    combinations of all parameters.
    'u'
    Expands a list of N iterables of parameters into a flat list with all
    combinations of all parameters.
    'b'4'u'4'b'8'u'8'b'session'u'session'u'hdu.compressed.tests.conftest'u'compressed.tests.conftest'u'cosmology._src.tests.conftest'u'_src.tests.conftest'helperSimModelTABtab_wcs_2di150tab_wcsh_2ditab_wcs_2di_fprj_TABPrjprmprjTAN# generate FITS HDU list:# create WCS object:b'function'b'TAN'u'TAN'u'astropy.wcs.tests.conftest'u'wcs.tests.conftest'register_hdf5register_parquetregister_parquet_votable# This file connects any readers/writers defined in io.misc to the# astropy.table.Table classu'astropy.io.misc.connect'u'io.misc.connect'u'misc.connect'astropy.io.registryio_registryHAS_PANDASNOT_OVERWRITING_MSGPANDAS_FMTSfwfjsonpandas.PANDAS_PREFIX_IMPORTS_HAS_BS4_HAS_LXML_HAS_HTML5LIBimport_html_libsTry importing dependencies for reading HTML.

    This is copied from pandas.io.html
    HAS_BS4HAS_HTML5LIBHAS_LXML_pandas_readfilespecProvide io Table connector to read table using pandas.pandas must be installed to use pandas table readerpdpandas_fmtread_read_funcread_kwargsflavordffrom_pandas_pandas_writetblProvide io Table connector to write table using pandas.write_kwargsto_pandasto_write_method# This file connects the readers/writers to the astropy.table.Table class# Astropy users normally expect to not have an index, so default to turn# off writing the index.  This structure allows for astropy-specific# customization of all options.# No writer# Imports for reading HTML# import things we need# but make this done on a first use basis# chop the 'pandas.' in front# Get defaults and then override with user-supplied values# Special case: pandas defaults to HTML lxml for reading, but does not attempt# to fall back to bs4 + html5lib.  So do that now for convenience if user has# not specifically selected a flavor.  If things go wrong the pandas exception# with instruction to install a library will come up.# Special case for HTML# filespec is not always a path-like# skip invalid arguments# only error if file already exists# Full format specifierb'PANDAS_FMTS'u'PANDAS_FMTS'b'fwf'u'fwf'b'json'u'json'b'pandas.'u'pandas.'b'Try importing dependencies for reading HTML.

    This is copied from pandas.io.html
    'u'Try importing dependencies for reading HTML.

    This is copied from pandas.io.html
    'b'Provide io Table connector to read table using pandas.'u'Provide io Table connector to read table using pandas.'b'pandas must be installed to use pandas table reader'u'pandas must be installed to use pandas table reader'b'read_'u'read_'b'flavor'u'flavor'b'bs4'u'bs4'b'Provide io Table connector to write table using pandas.'u'Provide io Table connector to write table using pandas.'b'to_'u'to_'u'io.misc.pandas.connect'u'misc.pandas.connect'u'pandas.connect'astropy.table.columntreeTableElementVOTableFilefilepath
    Reads the header of a file to determine if it is a VOTable file.

    Parameters
    ----------
    origin : str or readable file-like
        Path or file object containing a VOTABLE_ xml file.

    Returns
    -------
    is_votable : bool
        Returns `True` if the given file is a VOTable file.
    read_table_votabletable_iduse_names_over_ids
    Read a Table object from an VO table file.

    Parameters
    ----------
    input : str or `~astropy.io.votable.tree.VOTableFile` or `~astropy.io.votable.tree.TableElement`
        If a string, the filename to read the table from. If a
        :class:`~astropy.io.votable.tree.VOTableFile` or
        :class:`~astropy.io.votable.tree.TableElement` object, the object to extract
        the table from.

    table_id : str or int, optional
        The table to read in.  If a `str`, it is an ID corresponding
        to the ID of the table in the file (not all VOTable files
        assign IDs to their tables).  If an `int`, it is the index of
        the table in the file, starting at 0.

    use_names_over_ids : bool, optional
        When `True` use the ``name`` attributes of columns as the names
        of columns in the `~astropy.table.Table` instance.  Since names
        are not guaranteed to be unique, this may cause some columns
        to be renamed by appending numbers to the end.  Otherwise
        (default), use the ID attributes as the column names.

    verify : {'ignore', 'warn', 'exception'}, optional
        When ``'exception'``, raise an error when the file violates the spec,
        otherwise either issue a warning (``'warn'``) or silently continue
        (``'ignore'``). Warnings may be controlled using the standard Python
        mechanisms.  See the `warnings` module in the Python standard library
        for more information. When not provided, uses the configuration setting
        ``astropy.io.votable.verify``, which defaults to ``'ignore'``.

    **kwargs
        Additional keyword arguments are passed on to `astropy.io.votable.parse`.
    table_id_mappingtablesiter_tablesMultiple tables found: table id should be set via the table_id= argument. The available tables are "Multiple tables found: table id should be set via"" the table_id= argument. The available tables are", or integers less than ", or integers less than"No tables with id= foundTable index  is out of range.  tables found" tables"" found"No table foundwrite_table_votabletabledata_format
    Write a Table object to an VO table file.

    Parameters
    ----------
    input : Table
        The table to write out.

    output : str
        The filename to write the table to.

    table_id : str, optional
        The table ID to use. If this is not specified, the 'ID' keyword in the
        ``meta`` object of the table will be used.

    overwrite : bool, optional
        Whether to overwrite any existing file without warning.

    tabledata_format : str, optional
        The format of table data to write.  Must be one of ``tabledata``
        (text representation), ``binary`` or ``binary2``.  Default is
        ``tabledata``.  See :ref:`astropy:votable-serialization`.
    not_isinstanceunsupported_colsunsupported_namescannot write table with mixin column(s)  to VOTabletable_fileto_xmlvotablewrite_table_votable_parquetcolumn_metadata
    This function allows writing a VOTable (XML) with PARQUET
    serialization. This functionality is currently not
    supported by Astropy (with the reason that this method
    requires writing multiple files: a VOTable/XML and
    PARQUET table). This function presents a wrapper, which
    allows to do this. The concept is simple and probably
    can be improved substantially. We first save the PARQUET
    table using Astropy functionality. Then, we create a
    VOTable with binary serialization. The latter is modified
    later to include an external reference to the create
    PARQUET table file.

    Parameters
    ----------
    input : `~astropy.table.Table`
        The table to write out.

    output : str
        The filename to write the table to.

    column_metadata : dict
        Contains the metadata for the columns such as "unit" or
        "ucd" or "utype".
        (Example: {"id": {"unit": "", "ucd": "meta.id", "utype": "none"},
                   "mass": {"unit": "solMass", "ucd": "phys.mass", "utype": "none"}})
    overwrite : bool, optional
        Whether to overwrite any existing file without warning.

    Returns
    -------
    This function creates a VOTable serialized in Parquet.
    Two files are written:
    1. The VOTable (XML file) including the column metadata and a
        ``STREAM`` tag that embeds the PARQUET table.
    2. The PARQUET table itself.

    Both files are stored at the same location. The name of the
    VOTable is ``output``, and the name of the embedded PARQUET
    file is f"{output}.parquet".
    .parquetparquet_filenamefile:isabs//path_typevotablefileresourcesucdutypebinary<BINARY>line_start</BINARY>line_stop<PARQUET type="VOTable-remote-file">
<STREAM href=""/>
</PARQUET>
votable.parquet# Parse all table objects# Convert to an astropy.table.Table object# Only those columns which are instances of BaseColumn or Quantity can be written# Check if output file already exists# Create a new VOTable file# Write out file# VOTable with embedded/linked Parquet file ## First save the PARQUET file.# Second, save table as binary VOT file. We will modify this file# later to incorporate the FITS stream. Note that we use here the full# table data so we get the datatype and arraysize correct. Later# we can maybe make this more efficient and instead write the# VOTable file from scratch, especially the FIELDS, which are the# most important.# Add the fields# Maybe there is a smarter way to do this iteratively.# Now reopen the binary file and replace the binary part with# the stream relating to the FITS file. This all is a bit flimsy# and needs to be made more bullet-proof.# get start and end of <BINARY> tag# Add the extension tag# We assume here that it is extension #1.# remove last line# write new file# We register the "votable.parquet" reader format for consistency with# the writer, even though the format is recognized by the "votable" readerb'
    Reads the header of a file to determine if it is a VOTable file.

    Parameters
    ----------
    origin : str or readable file-like
        Path or file object containing a VOTABLE_ xml file.

    Returns
    -------
    is_votable : bool
        Returns `True` if the given file is a VOTable file.
    'u'
    Reads the header of a file to determine if it is a VOTable file.

    Parameters
    ----------
    origin : str or readable file-like
        Path or file object containing a VOTABLE_ xml file.

    Returns
    -------
    is_votable : bool
        Returns `True` if the given file is a VOTable file.
    'b'
    Read a Table object from an VO table file.

    Parameters
    ----------
    input : str or `~astropy.io.votable.tree.VOTableFile` or `~astropy.io.votable.tree.TableElement`
        If a string, the filename to read the table from. If a
        :class:`~astropy.io.votable.tree.VOTableFile` or
        :class:`~astropy.io.votable.tree.TableElement` object, the object to extract
        the table from.

    table_id : str or int, optional
        The table to read in.  If a `str`, it is an ID corresponding
        to the ID of the table in the file (not all VOTable files
        assign IDs to their tables).  If an `int`, it is the index of
        the table in the file, starting at 0.

    use_names_over_ids : bool, optional
        When `True` use the ``name`` attributes of columns as the names
        of columns in the `~astropy.table.Table` instance.  Since names
        are not guaranteed to be unique, this may cause some columns
        to be renamed by appending numbers to the end.  Otherwise
        (default), use the ID attributes as the column names.

    verify : {'ignore', 'warn', 'exception'}, optional
        When ``'exception'``, raise an error when the file violates the spec,
        otherwise either issue a warning (``'warn'``) or silently continue
        (``'ignore'``). Warnings may be controlled using the standard Python
        mechanisms.  See the `warnings` module in the Python standard library
        for more information. When not provided, uses the configuration setting
        ``astropy.io.votable.verify``, which defaults to ``'ignore'``.

    **kwargs
        Additional keyword arguments are passed on to `astropy.io.votable.parse`.
    'u'
    Read a Table object from an VO table file.

    Parameters
    ----------
    input : str or `~astropy.io.votable.tree.VOTableFile` or `~astropy.io.votable.tree.TableElement`
        If a string, the filename to read the table from. If a
        :class:`~astropy.io.votable.tree.VOTableFile` or
        :class:`~astropy.io.votable.tree.TableElement` object, the object to extract
        the table from.

    table_id : str or int, optional
        The table to read in.  If a `str`, it is an ID corresponding
        to the ID of the table in the file (not all VOTable files
        assign IDs to their tables).  If an `int`, it is the index of
        the table in the file, starting at 0.

    use_names_over_ids : bool, optional
        When `True` use the ``name`` attributes of columns as the names
        of columns in the `~astropy.table.Table` instance.  Since names
        are not guaranteed to be unique, this may cause some columns
        to be renamed by appending numbers to the end.  Otherwise
        (default), use the ID attributes as the column names.

    verify : {'ignore', 'warn', 'exception'}, optional
        When ``'exception'``, raise an error when the file violates the spec,
        otherwise either issue a warning (``'warn'``) or silently continue
        (``'ignore'``). Warnings may be controlled using the standard Python
        mechanisms.  See the `warnings` module in the Python standard library
        for more information. When not provided, uses the configuration setting
        ``astropy.io.votable.verify``, which defaults to ``'ignore'``.

    **kwargs
        Additional keyword arguments are passed on to `astropy.io.votable.parse`.
    'b'Multiple tables found: table id should be set via the table_id= argument. The available tables are 'u'Multiple tables found: table id should be set via the table_id= argument. The available tables are 'b', or integers less than 'u', or integers less than 'b'No tables with id='u'No tables with id='b' found'u' found'b'Table index 'u'Table index 'b' is out of range. 'u' is out of range. 'b' tables found'u' tables found'b'No table found'u'No table found'b'
    Write a Table object to an VO table file.

    Parameters
    ----------
    input : Table
        The table to write out.

    output : str
        The filename to write the table to.

    table_id : str, optional
        The table ID to use. If this is not specified, the 'ID' keyword in the
        ``meta`` object of the table will be used.

    overwrite : bool, optional
        Whether to overwrite any existing file without warning.

    tabledata_format : str, optional
        The format of table data to write.  Must be one of ``tabledata``
        (text representation), ``binary`` or ``binary2``.  Default is
        ``tabledata``.  See :ref:`astropy:votable-serialization`.
    'u'
    Write a Table object to an VO table file.

    Parameters
    ----------
    input : Table
        The table to write out.

    output : str
        The filename to write the table to.

    table_id : str, optional
        The table ID to use. If this is not specified, the 'ID' keyword in the
        ``meta`` object of the table will be used.

    overwrite : bool, optional
        Whether to overwrite any existing file without warning.

    tabledata_format : str, optional
        The format of table data to write.  Must be one of ``tabledata``
        (text representation), ``binary`` or ``binary2``.  Default is
        ``tabledata``.  See :ref:`astropy:votable-serialization`.
    'b'cannot write table with mixin column(s) 'u'cannot write table with mixin column(s) 'b' to VOTable'u' to VOTable'b'votable'b'
    This function allows writing a VOTable (XML) with PARQUET
    serialization. This functionality is currently not
    supported by Astropy (with the reason that this method
    requires writing multiple files: a VOTable/XML and
    PARQUET table). This function presents a wrapper, which
    allows to do this. The concept is simple and probably
    can be improved substantially. We first save the PARQUET
    table using Astropy functionality. Then, we create a
    VOTable with binary serialization. The latter is modified
    later to include an external reference to the create
    PARQUET table file.

    Parameters
    ----------
    input : `~astropy.table.Table`
        The table to write out.

    output : str
        The filename to write the table to.

    column_metadata : dict
        Contains the metadata for the columns such as "unit" or
        "ucd" or "utype".
        (Example: {"id": {"unit": "", "ucd": "meta.id", "utype": "none"},
                   "mass": {"unit": "solMass", "ucd": "phys.mass", "utype": "none"}})
    overwrite : bool, optional
        Whether to overwrite any existing file without warning.

    Returns
    -------
    This function creates a VOTable serialized in Parquet.
    Two files are written:
    1. The VOTable (XML file) including the column metadata and a
        ``STREAM`` tag that embeds the PARQUET table.
    2. The PARQUET table itself.

    Both files are stored at the same location. The name of the
    VOTable is ``output``, and the name of the embedded PARQUET
    file is f"{output}.parquet".
    'u'
    This function allows writing a VOTable (XML) with PARQUET
    serialization. This functionality is currently not
    supported by Astropy (with the reason that this method
    requires writing multiple files: a VOTable/XML and
    PARQUET table). This function presents a wrapper, which
    allows to do this. The concept is simple and probably
    can be improved substantially. We first save the PARQUET
    table using Astropy functionality. Then, we create a
    VOTable with binary serialization. The latter is modified
    later to include an external reference to the create
    PARQUET table file.

    Parameters
    ----------
    input : `~astropy.table.Table`
        The table to write out.

    output : str
        The filename to write the table to.

    column_metadata : dict
        Contains the metadata for the columns such as "unit" or
        "ucd" or "utype".
        (Example: {"id": {"unit": "", "ucd": "meta.id", "utype": "none"},
                   "mass": {"unit": "solMass", "ucd": "phys.mass", "utype": "none"}})
    overwrite : bool, optional
        Whether to overwrite any existing file without warning.

    Returns
    -------
    This function creates a VOTable serialized in Parquet.
    Two files are written:
    1. The VOTable (XML file) including the column metadata and a
        ``STREAM`` tag that embeds the PARQUET table.
    2. The PARQUET table itself.

    Both files are stored at the same location. The name of the
    VOTable is ``output``, and the name of the embedded PARQUET
    file is f"{output}.parquet".
    'b'.parquet'u'.parquet'b'file:'u'file:'b'//'u'//'b'ucd'u'ucd'b'utype'u'utype'b'binary'u'binary'b'<BINARY>'u'<BINARY>'b'</BINARY>'u'</BINARY>'b'<PARQUET type="VOTable-remote-file">
'u'<PARQUET type="VOTable-remote-file">
'b'<STREAM href="'u'<STREAM href="'b'"/>
'u'"/>
'b'</PARQUET>
'u'</PARQUET>
'b'votable.parquet'u'votable.parquet'u'astropy.io.votable.connect'u'io.votable.connect'u'votable.connect'serialize_context_asfits_appendtable_to_hduFITS_SIGNATUREfits_openNAXIS1NAXIS2REMOVE_KEYWORDS)[0-9]+COLUMN_KEYWORD_REGEXPis_column_keyword
    Determine whether `origin` is a FITS file.

    Parameters
    ----------
    origin : str or readable file-like
        Path or file object containing a potential FITS file.

    Returns
    -------
    is_fits : bool
        Returns `True` if the given file is a FITS file.
    .fits.fits.gz.fit.fit.gz.fts.fts.gz_decode_mixinsDecode a Table ``tbl`` that has astropy Columns + appropriate meta-data into
    the corresponding table with mixin columns (as appropriate).
    --BEGIN-ASTROPY-SERIALIZED-COLUMNS--i0--END-ASTROPY-SERIALIZED-COLUMNS--continuation_line7071get_header_from_yaml__serialized_columns__datatype_construct_mixins_from_columnsread_table_fitsastropy_nativememmapcharacter_as_bytesunit_parse_strictmask_invalidstrip_spaces
    Read a Table object from an FITS file.

    If the ``astropy_native`` argument is ``True``, then input FITS columns
    which are representations of an astropy core object will be converted to
    that class and stored in the ``Table`` as "mixin columns".  Currently this
    is limited to FITS columns which adhere to the FITS Time standard, in which
    case they will be converted to a `~astropy.time.Time` column in the output
    table.

    Parameters
    ----------
    input : str or file-like or compatible `astropy.io.fits` HDU object
        If a string, the filename to read the table from. If a file object, or
        a compatible HDU object, the object to extract the table from. The
        following `astropy.io.fits` HDU objects can be used as input:
        - :class:`~astropy.io.fits.hdu.table.TableHDU`
        - :class:`~astropy.io.fits.hdu.table.BinTableHDU`
        - :class:`~astropy.io.fits.hdu.table.GroupsHDU`
        - :class:`~astropy.io.fits.hdu.hdulist.HDUList`
    hdu : int or str, optional
        The HDU to read the table from.
    astropy_native : bool, optional
        Read in FITS columns as native astropy objects where possible instead
        of standard Table Column objects. Default is False.
    memmap : bool, optional
        Whether to use memory mapping, which accesses data on disk as needed. If
        you are only accessing part of the data, this is often more efficient.
        If you want to access all the values in the table, and you are able to
        fit the table in memory, you may be better off leaving memory mapping
        off. However, if your table would not fit in memory, you should set this
        to `True`.
        When set to `True` then ``mask_invalid`` and ``strip_spaces`` are set
        to `False` since the masking and whitespace removal would cause loading
        the full data array.
    character_as_bytes : bool, optional
        If `True`, string columns are stored as Numpy byte arrays (dtype ``S``)
        and are converted on-the-fly to unicode strings when accessing
        individual elements. If you need to use Numpy unicode arrays (dtype
        ``U``) internally, you should set this to `False`, but note that this
        will use more memory. If set to `False`, string columns will not be
        memory-mapped even if ``memmap`` is `True`.
    unit_parse_strict : str, optional
        Behaviour when encountering invalid column units in the FITS header.
        Default is "warn", which will emit a ``UnitsWarning`` and create a
        :class:`~astropy.units.core.UnrecognizedUnit`.
        Values are the ones allowed by the ``parse_strict`` argument of
        :class:`~astropy.units.core.Unit`: ``raise``, ``warn`` and ``silent``.
    mask_invalid : bool, optional
        By default the code masks NaNs in float columns and empty strings in
        string columns. Set this parameter to `False` to avoid the performance
        penalty of doing this masking step. The masking is always deactivated
        when using ``memmap=True`` (see above).
    strip_spaces : bool, optional
        Strip trailing whitespace in string columns, default is False and will be
        changed to True in the next major release. This is deactivated when
        using ``memmap=True`` (see above).

    ihduhdu_itemhdu= was not specified but multiple tables are present, reading in first available table (hdu="hdu= was not specified but multiple tables"" are present, reading in first available"" table (hdu="index_ofNo table found in hdu=hdiSpecified hdu= not foundNo table found in specified hdu=, reading in first available table (hdu=", reading in first available table ""(hdu=") instead. This will result in an error in future versions!") instead. This will"" result in an error in future versions!"coltypebytes_inexactfitstimefits_to_time_encode_mixinsEncode a Table ``tbl`` that may have mixin columns to a Table with only
    astropy Columns + appropriate meta-data to allow subsequent decoding.
    itercolsinfo_lostexclude_classesencode_tblmeta_copyser_coltbl_meta_copyget_yaml_from_tablemeta_yaml_lineswrite_table_fits
    Write a Table object to a FITS file.

    Parameters
    ----------
    input : Table
        The table to write out.
    output : str or os.PathLike[str] or file-like
        The filename to write the table to.
    overwrite : bool
        Whether to overwrite any existing file without warning.
    append : bool
        Whether to append the table to an existing file
    table_hdu# Keywords to remove for all tables that are read in# Column-specific keywords regex# If available read in __serialized_columns__ meta info which is stored# in FITS COMMENTS between two sentinels.# The YAML data are split into COMMENT cards, with lines longer than 70# characters being split with a continuation character \ (backslash).# Strip the backslashes and join together.# Add serialized column information to table meta for use in constructing mixins# Use the `datatype` attribute info to update column attributes that are# NOT already handled via standard FITS column keys (name, dtype, unit).# Construct new table with mixins, using tbl.meta['__serialized_columns__']# as guidance.# hdu might not be an integer, so we first need to convert it# to the correct HDU index# using memmap is not compatible with masking invalid value and# removing trailing whitespace by default so we deactivate that# use data[col.name] rather than col.array to make sure that the data# is scaled correctly if needed.# Check if column is masked. Here, we make a guess based on the# presence of FITS mask values. For integer columns, this is simply# the null header, for float and complex, the presence of NaN, and for# string, empty strings.# Since Multi-element columns with dtypes such as '2f8' have a subdtype,# we should look up the type of column on that.# Also propagate TNULL (for ints) or the FITS default null value for# floats and strings to the column's fill_value to ensure round trips# preserve null values.# Return a MaskedColumn even if no elements are masked so# we roundtrip better.# Copy over units# Copy over display format# Create Table object# TODO: deal properly with unsigned integers# Avoid circular imports, and also only import if necessary.# Convert to io.ascii format# key is duplicate# TODO: implement masking# Decode any mixin columns that have been stored as standard Columns.# Determine if information will be lost without serializing meta.  This is hardcoded# to the set difference between column info attributes and what FITS can store# natively (name, dtype, unit).  See _get_col_attributes() in table/meta.py for where# this comes from.# Convert the table to one with no mixins, only Column objects.  This adds# meta data which is extracted with meta.get_yaml_from_table.  This ignores# Time-subclass columns and leave them in the table so that the downstream# FITS Time handling does the right thing.# If the encoded table is unchanged then there were no mixins.  But if there# is column metadata (format, description, meta) that would be lost, then# still go through the serialized columns machinery.# Copy the meta dict if it was not copied by represent_mixins_as_columns.# We will modify .meta['comments'] below and we do not want to see these# comments in the input table.# Get the YAML serialization of information describing the table columns.# This is reusing ECSV code that combined existing table.meta with with# the extra __serialized_columns__ key.  For FITS the table.meta is handled# by the native FITS connect code, so don't include that in the YAML# output.# encode_tbl might not have a __serialized_columns__ key if there were no mixins,# but machinery below expects it to be available, so just make an empty dict.# Split line into 70 character chunks for COMMENT cards# Encode any mixin columns into standard Columns.# verify=False stops it reading and checking the existing file.b'NAXIS1'u'NAXIS1'b'NAXIS2'u'NAXIS2'b')[0-9]+'u')[0-9]+'b'
    Determine whether `origin` is a FITS file.

    Parameters
    ----------
    origin : str or readable file-like
        Path or file object containing a potential FITS file.

    Returns
    -------
    is_fits : bool
        Returns `True` if the given file is a FITS file.
    'u'
    Determine whether `origin` is a FITS file.

    Parameters
    ----------
    origin : str or readable file-like
        Path or file object containing a potential FITS file.

    Returns
    -------
    is_fits : bool
        Returns `True` if the given file is a FITS file.
    'b'.fits'u'.fits'b'.fits.gz'u'.fits.gz'b'.fit'u'.fit'b'.fit.gz'u'.fit.gz'b'.fts'u'.fts'b'.fts.gz'u'.fts.gz'b'Decode a Table ``tbl`` that has astropy Columns + appropriate meta-data into
    the corresponding table with mixin columns (as appropriate).
    'u'Decode a Table ``tbl`` that has astropy Columns + appropriate meta-data into
    the corresponding table with mixin columns (as appropriate).
    'b'--BEGIN-ASTROPY-SERIALIZED-COLUMNS--'u'--BEGIN-ASTROPY-SERIALIZED-COLUMNS--'b'--END-ASTROPY-SERIALIZED-COLUMNS--'u'--END-ASTROPY-SERIALIZED-COLUMNS--'b'__serialized_columns__'u'__serialized_columns__'b'datatype'u'datatype'b'
    Read a Table object from an FITS file.

    If the ``astropy_native`` argument is ``True``, then input FITS columns
    which are representations of an astropy core object will be converted to
    that class and stored in the ``Table`` as "mixin columns".  Currently this
    is limited to FITS columns which adhere to the FITS Time standard, in which
    case they will be converted to a `~astropy.time.Time` column in the output
    table.

    Parameters
    ----------
    input : str or file-like or compatible `astropy.io.fits` HDU object
        If a string, the filename to read the table from. If a file object, or
        a compatible HDU object, the object to extract the table from. The
        following `astropy.io.fits` HDU objects can be used as input:
        - :class:`~astropy.io.fits.hdu.table.TableHDU`
        - :class:`~astropy.io.fits.hdu.table.BinTableHDU`
        - :class:`~astropy.io.fits.hdu.table.GroupsHDU`
        - :class:`~astropy.io.fits.hdu.hdulist.HDUList`
    hdu : int or str, optional
        The HDU to read the table from.
    astropy_native : bool, optional
        Read in FITS columns as native astropy objects where possible instead
        of standard Table Column objects. Default is False.
    memmap : bool, optional
        Whether to use memory mapping, which accesses data on disk as needed. If
        you are only accessing part of the data, this is often more efficient.
        If you want to access all the values in the table, and you are able to
        fit the table in memory, you may be better off leaving memory mapping
        off. However, if your table would not fit in memory, you should set this
        to `True`.
        When set to `True` then ``mask_invalid`` and ``strip_spaces`` are set
        to `False` since the masking and whitespace removal would cause loading
        the full data array.
    character_as_bytes : bool, optional
        If `True`, string columns are stored as Numpy byte arrays (dtype ``S``)
        and are converted on-the-fly to unicode strings when accessing
        individual elements. If you need to use Numpy unicode arrays (dtype
        ``U``) internally, you should set this to `False`, but note that this
        will use more memory. If set to `False`, string columns will not be
        memory-mapped even if ``memmap`` is `True`.
    unit_parse_strict : str, optional
        Behaviour when encountering invalid column units in the FITS header.
        Default is "warn", which will emit a ``UnitsWarning`` and create a
        :class:`~astropy.units.core.UnrecognizedUnit`.
        Values are the ones allowed by the ``parse_strict`` argument of
        :class:`~astropy.units.core.Unit`: ``raise``, ``warn`` and ``silent``.
    mask_invalid : bool, optional
        By default the code masks NaNs in float columns and empty strings in
        string columns. Set this parameter to `False` to avoid the performance
        penalty of doing this masking step. The masking is always deactivated
        when using ``memmap=True`` (see above).
    strip_spaces : bool, optional
        Strip trailing whitespace in string columns, default is False and will be
        changed to True in the next major release. This is deactivated when
        using ``memmap=True`` (see above).

    'u'
    Read a Table object from an FITS file.

    If the ``astropy_native`` argument is ``True``, then input FITS columns
    which are representations of an astropy core object will be converted to
    that class and stored in the ``Table`` as "mixin columns".  Currently this
    is limited to FITS columns which adhere to the FITS Time standard, in which
    case they will be converted to a `~astropy.time.Time` column in the output
    table.

    Parameters
    ----------
    input : str or file-like or compatible `astropy.io.fits` HDU object
        If a string, the filename to read the table from. If a file object, or
        a compatible HDU object, the object to extract the table from. The
        following `astropy.io.fits` HDU objects can be used as input:
        - :class:`~astropy.io.fits.hdu.table.TableHDU`
        - :class:`~astropy.io.fits.hdu.table.BinTableHDU`
        - :class:`~astropy.io.fits.hdu.table.GroupsHDU`
        - :class:`~astropy.io.fits.hdu.hdulist.HDUList`
    hdu : int or str, optional
        The HDU to read the table from.
    astropy_native : bool, optional
        Read in FITS columns as native astropy objects where possible instead
        of standard Table Column objects. Default is False.
    memmap : bool, optional
        Whether to use memory mapping, which accesses data on disk as needed. If
        you are only accessing part of the data, this is often more efficient.
        If you want to access all the values in the table, and you are able to
        fit the table in memory, you may be better off leaving memory mapping
        off. However, if your table would not fit in memory, you should set this
        to `True`.
        When set to `True` then ``mask_invalid`` and ``strip_spaces`` are set
        to `False` since the masking and whitespace removal would cause loading
        the full data array.
    character_as_bytes : bool, optional
        If `True`, string columns are stored as Numpy byte arrays (dtype ``S``)
        and are converted on-the-fly to unicode strings when accessing
        individual elements. If you need to use Numpy unicode arrays (dtype
        ``U``) internally, you should set this to `False`, but note that this
        will use more memory. If set to `False`, string columns will not be
        memory-mapped even if ``memmap`` is `True`.
    unit_parse_strict : str, optional
        Behaviour when encountering invalid column units in the FITS header.
        Default is "warn", which will emit a ``UnitsWarning`` and create a
        :class:`~astropy.units.core.UnrecognizedUnit`.
        Values are the ones allowed by the ``parse_strict`` argument of
        :class:`~astropy.units.core.Unit`: ``raise``, ``warn`` and ``silent``.
    mask_invalid : bool, optional
        By default the code masks NaNs in float columns and empty strings in
        string columns. Set this parameter to `False` to avoid the performance
        penalty of doing this masking step. The masking is always deactivated
        when using ``memmap=True`` (see above).
    strip_spaces : bool, optional
        Strip trailing whitespace in string columns, default is False and will be
        changed to True in the next major release. This is deactivated when
        using ``memmap=True`` (see above).

    'b'hdu= was not specified but multiple tables are present, reading in first available table (hdu='u'hdu= was not specified but multiple tables are present, reading in first available table (hdu='b'No table found in hdu='u'No table found in hdu='b'Specified hdu='u'Specified hdu='b' not found'u' not found'b'No table found in specified hdu='u'No table found in specified hdu='b', reading in first available table (hdu='u', reading in first available table (hdu='b') instead. This will result in an error in future versions!'u') instead. This will result in an error in future versions!'b'Encode a Table ``tbl`` that may have mixin columns to a Table with only
    astropy Columns + appropriate meta-data to allow subsequent decoding.
    'u'Encode a Table ``tbl`` that may have mixin columns to a Table with only
    astropy Columns + appropriate meta-data to allow subsequent decoding.
    'b'
    Write a Table object to a FITS file.

    Parameters
    ----------
    input : Table
        The table to write out.
    output : str or os.PathLike[str] or file-like
        The filename to write the table to.
    overwrite : bool
        Whether to overwrite any existing file without warning.
    append : bool
        Whether to append the table to an existing file
    'u'
    Write a Table object to a FITS file.

    Parameters
    ----------
    input : Table
        The table to write out.
    output : str or os.PathLike[str] or file-like
        The filename to write the table to.
    overwrite : bool
        Whether to overwrite any existing file without warning.
    append : bool
        Whether to append the table to an existing file
    'u'astropy.io.fits.connect'u'io.fits.connect'u'fits.connect'serialize_method_asTableReadTableWriteRead and parse a data table and return as a Table.

    This function provides the Table interface to the astropy unified I/O
    layer.  This allows easily reading a file in many supported data formats
    using syntax such as::

      >>> from astropy.table import Table
      >>> dat = Table.read('table.dat', format='ascii')
      >>> events = Table.read('events.fits', format='fits')

    Get help on the available readers for ``Table`` using the``help()`` method::

      >>> Table.read.help()  # Get help reading Table and list supported formats
      >>> Table.read.help('fits')  # Get detailed help on Table FITS reader
      >>> Table.read.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args : tuple, optional
        Positional arguments passed through to data reader. If supplied the
        first argument is typically the input filename.
    format : str
        File format specifier.
    units : list, dict, optional
        List or dict of units to apply to columns
    descriptions : list, dict, optional
        List or dict of descriptions to apply to columns
    **kwargs : dict, optional
        Keyword arguments passed through to data reader.

    Returns
    -------
    out : `~astropy.table.Table`
        Table corresponding to file contents

    Notes
    -----
    _clsdescriptionscould not convert reader output to  class._set_column_attribute
    Write this Table object out in the specified format.

    This function provides the Table interface to the astropy unified I/O
    layer.  This allows easily writing a file in many supported data formats
    using syntax such as::

      >>> from astropy.table import Table
      >>> dat = Table([[1, 2], [3, 4]], names=('a', 'b'))
      >>> dat.write('table.dat', format='ascii')

    Get help on the available writers for ``Table`` using the``help()`` method::

      >>> Table.write.help()  # Get help writing Table and list supported formats
      >>> Table.write.help('fits')  # Get detailed help on Table FITS writer
      >>> Table.write.list_formats()  # Print list of available formats

    The ``serialize_method`` argument is explained in the section on
    `Table serialization methods
    <https://docs.astropy.org/en/latest/io/unified.html#table-serialization-methods>`_.

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args : tuple, optional
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    format : str
        File format specifier.
    serialize_method : str, dict, optional
        Serialization method specifier for columns.
    **kwargs : dict, optional
        Keyword arguments passed through to data writer.

    Notes
    -----
    _instance# uses default global registry# For some readers (e.g., ascii.ecsv), the returned `out` class is not# guaranteed to be the same as the desired output `cls`.  If so,# try coercing to desired class without copying (io.registry.read# would normally do a copy).  The normal case here is swapping# Table <=> QTable.b'TableRead'u'TableRead'b'TableWrite'u'TableWrite'b'Read and parse a data table and return as a Table.

    This function provides the Table interface to the astropy unified I/O
    layer.  This allows easily reading a file in many supported data formats
    using syntax such as::

      >>> from astropy.table import Table
      >>> dat = Table.read('table.dat', format='ascii')
      >>> events = Table.read('events.fits', format='fits')

    Get help on the available readers for ``Table`` using the``help()`` method::

      >>> Table.read.help()  # Get help reading Table and list supported formats
      >>> Table.read.help('fits')  # Get detailed help on Table FITS reader
      >>> Table.read.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args : tuple, optional
        Positional arguments passed through to data reader. If supplied the
        first argument is typically the input filename.
    format : str
        File format specifier.
    units : list, dict, optional
        List or dict of units to apply to columns
    descriptions : list, dict, optional
        List or dict of descriptions to apply to columns
    **kwargs : dict, optional
        Keyword arguments passed through to data reader.

    Returns
    -------
    out : `~astropy.table.Table`
        Table corresponding to file contents

    Notes
    -----
    'u'Read and parse a data table and return as a Table.

    This function provides the Table interface to the astropy unified I/O
    layer.  This allows easily reading a file in many supported data formats
    using syntax such as::

      >>> from astropy.table import Table
      >>> dat = Table.read('table.dat', format='ascii')
      >>> events = Table.read('events.fits', format='fits')

    Get help on the available readers for ``Table`` using the``help()`` method::

      >>> Table.read.help()  # Get help reading Table and list supported formats
      >>> Table.read.help('fits')  # Get detailed help on Table FITS reader
      >>> Table.read.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args : tuple, optional
        Positional arguments passed through to data reader. If supplied the
        first argument is typically the input filename.
    format : str
        File format specifier.
    units : list, dict, optional
        List or dict of units to apply to columns
    descriptions : list, dict, optional
        List or dict of descriptions to apply to columns
    **kwargs : dict, optional
        Keyword arguments passed through to data reader.

    Returns
    -------
    out : `~astropy.table.Table`
        Table corresponding to file contents

    Notes
    -----
    'b'descriptions'u'descriptions'b'could not convert reader output to 'u'could not convert reader output to 'b' class.'u' class.'b'
    Write this Table object out in the specified format.

    This function provides the Table interface to the astropy unified I/O
    layer.  This allows easily writing a file in many supported data formats
    using syntax such as::

      >>> from astropy.table import Table
      >>> dat = Table([[1, 2], [3, 4]], names=('a', 'b'))
      >>> dat.write('table.dat', format='ascii')

    Get help on the available writers for ``Table`` using the``help()`` method::

      >>> Table.write.help()  # Get help writing Table and list supported formats
      >>> Table.write.help('fits')  # Get detailed help on Table FITS writer
      >>> Table.write.list_formats()  # Print list of available formats

    The ``serialize_method`` argument is explained in the section on
    `Table serialization methods
    <https://docs.astropy.org/en/latest/io/unified.html#table-serialization-methods>`_.

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args : tuple, optional
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    format : str
        File format specifier.
    serialize_method : str, dict, optional
        Serialization method specifier for columns.
    **kwargs : dict, optional
        Keyword arguments passed through to data writer.

    Notes
    -----
    'u'
    Write this Table object out in the specified format.

    This function provides the Table interface to the astropy unified I/O
    layer.  This allows easily writing a file in many supported data formats
    using syntax such as::

      >>> from astropy.table import Table
      >>> dat = Table([[1, 2], [3, 4]], names=('a', 'b'))
      >>> dat.write('table.dat', format='ascii')

    Get help on the available writers for ``Table`` using the``help()`` method::

      >>> Table.write.help()  # Get help writing Table and list supported formats
      >>> Table.write.help('fits')  # Get detailed help on Table FITS writer
      >>> Table.write.list_formats()  # Print list of available formats

    The ``serialize_method`` argument is explained in the section on
    `Table serialization methods
    <https://docs.astropy.org/en/latest/io/unified.html#table-serialization-methods>`_.

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args : tuple, optional
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    format : str
        File format specifier.
    serialize_method : str, dict, optional
        Serialization method specifier for columns.
    **kwargs : dict, optional
        Keyword arguments passed through to data writer.

    Notes
    -----
    'u'astropy.table.connect'u'table.connect'io_read^ascii\.io_writeio_identify_get_connectors_tableFORMAT_CLASSESASCII table in any supported format (uses guessing)io_format:class:`~class_linkcan_writeSuffixWritecolname%-b'^ascii\.'u'^ascii\.'b'ASCII table in any supported format (uses guessing)'u'ASCII table in any supported format (uses guessing)'b'_description'u'_description'b':class:`~'u':class:`~'b'_io_registry_suffix'u'_io_registry_suffix'b'_io_registry_can_write'u'_io_registry_can_write'b'Suffix'u'Suffix'b'Write'u'Write'b'Description'u'Description'b'%-'u'%-'u'astropy.io.ascii.connect'u'io.ascii.connect'u'ascii.connect'CosmologyFromFormatCosmologyReadCosmologyToFormatCosmologyWriteconvert_registryreadwrite_registry_src.ioThe module `astropy.cosmology.connect` is deprecated since v7.1 and will be removed in a future version. Import from `astropy.cosmology.io` instead."The module `astropy.cosmology.connect` is deprecated since v7.1 and will be ""removed in a future version. Import from `astropy.cosmology.io` instead."b'CosmologyFromFormat'u'CosmologyFromFormat'b'CosmologyRead'u'CosmologyRead'b'CosmologyToFormat'u'CosmologyToFormat'b'CosmologyWrite'u'CosmologyWrite'b'convert_registry'u'convert_registry'b'readwrite_registry'u'readwrite_registry'b'The module `astropy.cosmology.connect` is deprecated since v7.1 and will be removed in a future version. Import from `astropy.cosmology.io` instead.'u'The module `astropy.cosmology.connect` is deprecated since v7.1 and will be removed in a future version. Import from `astropy.cosmology.io` instead.'u'astropy.cosmology.connect'u'cosmology.connect'astropy.cosmology._src.unitsastropy.cosmology._src.io.builtin.model_CosmologyModelastropy.cosmology._src.typing_CosmoT_MTRead and parse data to a `~astropy.cosmology.Cosmology`.

    This function provides the Cosmology interface to the Astropy unified I/O
    layer. This allows easily reading a file in supported data formats using
    syntax such as::

        >>> from astropy.cosmology import Cosmology
        >>> cosmo1 = Cosmology.read('<file name>')

    When the ``read`` method is called from a subclass the subclass will
    provide a keyword argument ``cosmology=<class>`` to the registered read
    method. The method uses this cosmology class, regardless of the class
    indicated in the file, and sets parameters' default values from the class'
    signature.

    Get help on the available readers using the ``help()`` method::

      >>> Cosmology.read.help()  # Get help reading and list supported formats
      >>> Cosmology.read.help(format='<format>')  # Get detailed help on a format
      >>> Cosmology.read.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args
        Positional arguments passed through to data reader. If supplied the
        first argument is typically the input filename.
    format : str (optional, keyword-only)
        File format specifier.
    **kwargs
        Keyword arguments passed through to data reader.

    Returns
    -------
    out : `~astropy.cosmology.Cosmology` subclass instance
        `~astropy.cosmology.Cosmology` corresponding to file contents.

    Notes
    -----
    keyword argument `cosmology` must be either the class "keyword argument `cosmology` must be either the class " or its qualified name 'Write this Cosmology object out in the specified format.

    This function provides the Cosmology interface to the astropy unified I/O
    layer. This allows easily writing a file in supported data formats
    using syntax such as::

      >>> from astropy.cosmology import Planck18
      >>> Planck18.write('<file name>')

    Get help on the available writers for ``Cosmology`` using the ``help()``
    method::

      >>> Cosmology.write.help()  # Get help writing and list supported formats
      >>> Cosmology.write.help(format='<format>')  # Get detailed help on format
      >>> Cosmology.write.list_formats()  # Print list of available formats

    Parameters
    ----------
    *args
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    format : str (optional, keyword-only)
        File format specifier.
    **kwargs
        Keyword arguments passed through to data writer.

    Notes
    -----
    Transform object to a `~astropy.cosmology.Cosmology`.

    This function provides the Cosmology interface to the Astropy unified I/O
    layer. This allows easily parsing supported data formats using
    syntax such as::

      >>> from astropy.cosmology import Cosmology
      >>> cosmo1 = Cosmology.from_format(cosmo_mapping, format='mapping')

    When the ``from_format`` method is called from a subclass the subclass will
    provide a keyword argument ``cosmology=<class>`` to the registered parser.
    The method uses this cosmology class, regardless of the class indicated in
    the data, and sets parameters' default values from the class' signature.

    Get help on the available readers using the ``help()`` method::

      >>> Cosmology.from_format.help()  # Get help and list supported formats
      >>> Cosmology.from_format.help('<format>')  # Get detailed help on a format
      >>> Cosmology.from_format.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    obj : object
        The object to parse according to 'format'
    *args
        Positional arguments passed through to data parser.
    format : str or None, optional keyword-only
        Object format specifier. For `None` (default) CosmologyFromFormat tries
        to identify the correct format.
    **kwargs
        Keyword arguments passed through to data parser.
        Parsers should accept the following keyword arguments:

        - cosmology : the class (or string name thereof) to use / check when
                      constructing the cosmology instance.

    Returns
    -------
    out : `~astropy.cosmology.Cosmology` subclass instance
        `~astropy.cosmology.Cosmology` corresponding to ``obj`` contents.
    astropy.modelastropy.rowTransform this Cosmology to another format.

    This function provides the Cosmology interface to the astropy unified I/O
    layer. This allows easily transforming to supported data formats
    using syntax such as::

      >>> from astropy.cosmology import Planck18
      >>> Planck18.to_format("mapping")
      {'cosmology': astropy.cosmology.core.FlatLambdaCDM,
       'name': 'Planck18',
       'H0': <Quantity 67.66 km / (Mpc s)>,
       'Om0': 0.30966,
       ...

    Get help on the available representations for ``Cosmology`` using the
    ``help()`` method::

      >>> Cosmology.to_format.help()  # Get help and list supported formats
      >>> Cosmology.to_format.help('<format>')  # Get detailed help on format
      >>> Cosmology.to_format.list_formats()  # Print list of available formats

    Parameters
    ----------
    format : str
        Format specifier.
    *args
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    **kwargs
        Keyword arguments passed through to data writer.
    # NOTE: private b/c RTD error# type: ignore[type-arg]# ==============================================================================# Read / Write# so subclasses can override, also pass the class as a kwarg.# allows for `FlatLambdaCDM.read` and# `Cosmology.read(..., cosmology=FlatLambdaCDM)`# set, if not present# check that it is the correct cosmology, can be wrong if user# passes in e.g. `w0wzCDM.read(..., cosmology=FlatLambdaCDM)`# Format Interchange# for transforming instances, e.g. Cosmology <-> dict# ===============================================================# __call__ overloads# note: format: ... | None means the format can be auto-detected from the input.# specific mapping option, where the mapping class is specified.b'_MT'u'_MT'b'Mapping'u'Mapping'b'Read and parse data to a `~astropy.cosmology.Cosmology`.

    This function provides the Cosmology interface to the Astropy unified I/O
    layer. This allows easily reading a file in supported data formats using
    syntax such as::

        >>> from astropy.cosmology import Cosmology
        >>> cosmo1 = Cosmology.read('<file name>')

    When the ``read`` method is called from a subclass the subclass will
    provide a keyword argument ``cosmology=<class>`` to the registered read
    method. The method uses this cosmology class, regardless of the class
    indicated in the file, and sets parameters' default values from the class'
    signature.

    Get help on the available readers using the ``help()`` method::

      >>> Cosmology.read.help()  # Get help reading and list supported formats
      >>> Cosmology.read.help(format='<format>')  # Get detailed help on a format
      >>> Cosmology.read.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args
        Positional arguments passed through to data reader. If supplied the
        first argument is typically the input filename.
    format : str (optional, keyword-only)
        File format specifier.
    **kwargs
        Keyword arguments passed through to data reader.

    Returns
    -------
    out : `~astropy.cosmology.Cosmology` subclass instance
        `~astropy.cosmology.Cosmology` corresponding to file contents.

    Notes
    -----
    'u'Read and parse data to a `~astropy.cosmology.Cosmology`.

    This function provides the Cosmology interface to the Astropy unified I/O
    layer. This allows easily reading a file in supported data formats using
    syntax such as::

        >>> from astropy.cosmology import Cosmology
        >>> cosmo1 = Cosmology.read('<file name>')

    When the ``read`` method is called from a subclass the subclass will
    provide a keyword argument ``cosmology=<class>`` to the registered read
    method. The method uses this cosmology class, regardless of the class
    indicated in the file, and sets parameters' default values from the class'
    signature.

    Get help on the available readers using the ``help()`` method::

      >>> Cosmology.read.help()  # Get help reading and list supported formats
      >>> Cosmology.read.help(format='<format>')  # Get detailed help on a format
      >>> Cosmology.read.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    *args
        Positional arguments passed through to data reader. If supplied the
        first argument is typically the input filename.
    format : str (optional, keyword-only)
        File format specifier.
    **kwargs
        Keyword arguments passed through to data reader.

    Returns
    -------
    out : `~astropy.cosmology.Cosmology` subclass instance
        `~astropy.cosmology.Cosmology` corresponding to file contents.

    Notes
    -----
    'b'keyword argument `cosmology` must be either the class 'u'keyword argument `cosmology` must be either the class 'b' or its qualified name ''u' or its qualified name ''b'Write this Cosmology object out in the specified format.

    This function provides the Cosmology interface to the astropy unified I/O
    layer. This allows easily writing a file in supported data formats
    using syntax such as::

      >>> from astropy.cosmology import Planck18
      >>> Planck18.write('<file name>')

    Get help on the available writers for ``Cosmology`` using the ``help()``
    method::

      >>> Cosmology.write.help()  # Get help writing and list supported formats
      >>> Cosmology.write.help(format='<format>')  # Get detailed help on format
      >>> Cosmology.write.list_formats()  # Print list of available formats

    Parameters
    ----------
    *args
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    format : str (optional, keyword-only)
        File format specifier.
    **kwargs
        Keyword arguments passed through to data writer.

    Notes
    -----
    'u'Write this Cosmology object out in the specified format.

    This function provides the Cosmology interface to the astropy unified I/O
    layer. This allows easily writing a file in supported data formats
    using syntax such as::

      >>> from astropy.cosmology import Planck18
      >>> Planck18.write('<file name>')

    Get help on the available writers for ``Cosmology`` using the ``help()``
    method::

      >>> Cosmology.write.help()  # Get help writing and list supported formats
      >>> Cosmology.write.help(format='<format>')  # Get detailed help on format
      >>> Cosmology.write.list_formats()  # Print list of available formats

    Parameters
    ----------
    *args
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    format : str (optional, keyword-only)
        File format specifier.
    **kwargs
        Keyword arguments passed through to data writer.

    Notes
    -----
    'b'Transform object to a `~astropy.cosmology.Cosmology`.

    This function provides the Cosmology interface to the Astropy unified I/O
    layer. This allows easily parsing supported data formats using
    syntax such as::

      >>> from astropy.cosmology import Cosmology
      >>> cosmo1 = Cosmology.from_format(cosmo_mapping, format='mapping')

    When the ``from_format`` method is called from a subclass the subclass will
    provide a keyword argument ``cosmology=<class>`` to the registered parser.
    The method uses this cosmology class, regardless of the class indicated in
    the data, and sets parameters' default values from the class' signature.

    Get help on the available readers using the ``help()`` method::

      >>> Cosmology.from_format.help()  # Get help and list supported formats
      >>> Cosmology.from_format.help('<format>')  # Get detailed help on a format
      >>> Cosmology.from_format.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    obj : object
        The object to parse according to 'format'
    *args
        Positional arguments passed through to data parser.
    format : str or None, optional keyword-only
        Object format specifier. For `None` (default) CosmologyFromFormat tries
        to identify the correct format.
    **kwargs
        Keyword arguments passed through to data parser.
        Parsers should accept the following keyword arguments:

        - cosmology : the class (or string name thereof) to use / check when
                      constructing the cosmology instance.

    Returns
    -------
    out : `~astropy.cosmology.Cosmology` subclass instance
        `~astropy.cosmology.Cosmology` corresponding to ``obj`` contents.
    'u'Transform object to a `~astropy.cosmology.Cosmology`.

    This function provides the Cosmology interface to the Astropy unified I/O
    layer. This allows easily parsing supported data formats using
    syntax such as::

      >>> from astropy.cosmology import Cosmology
      >>> cosmo1 = Cosmology.from_format(cosmo_mapping, format='mapping')

    When the ``from_format`` method is called from a subclass the subclass will
    provide a keyword argument ``cosmology=<class>`` to the registered parser.
    The method uses this cosmology class, regardless of the class indicated in
    the data, and sets parameters' default values from the class' signature.

    Get help on the available readers using the ``help()`` method::

      >>> Cosmology.from_format.help()  # Get help and list supported formats
      >>> Cosmology.from_format.help('<format>')  # Get detailed help on a format
      >>> Cosmology.from_format.list_formats()  # Print list of available formats

    See also: https://docs.astropy.org/en/stable/io/unified.html

    Parameters
    ----------
    obj : object
        The object to parse according to 'format'
    *args
        Positional arguments passed through to data parser.
    format : str or None, optional keyword-only
        Object format specifier. For `None` (default) CosmologyFromFormat tries
        to identify the correct format.
    **kwargs
        Keyword arguments passed through to data parser.
        Parsers should accept the following keyword arguments:

        - cosmology : the class (or string name thereof) to use / check when
                      constructing the cosmology instance.

    Returns
    -------
    out : `~astropy.cosmology.Cosmology` subclass instance
        `~astropy.cosmology.Cosmology` corresponding to ``obj`` contents.
    'b'astropy.model'u'astropy.model'b'astropy.row'u'astropy.row'b'astropy.table'b'mapping'u'mapping'b'yaml'u'yaml'b'Transform this Cosmology to another format.

    This function provides the Cosmology interface to the astropy unified I/O
    layer. This allows easily transforming to supported data formats
    using syntax such as::

      >>> from astropy.cosmology import Planck18
      >>> Planck18.to_format("mapping")
      {'cosmology': astropy.cosmology.core.FlatLambdaCDM,
       'name': 'Planck18',
       'H0': <Quantity 67.66 km / (Mpc s)>,
       'Om0': 0.30966,
       ...

    Get help on the available representations for ``Cosmology`` using the
    ``help()`` method::

      >>> Cosmology.to_format.help()  # Get help and list supported formats
      >>> Cosmology.to_format.help('<format>')  # Get detailed help on format
      >>> Cosmology.to_format.list_formats()  # Print list of available formats

    Parameters
    ----------
    format : str
        Format specifier.
    *args
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    **kwargs
        Keyword arguments passed through to data writer.
    'u'Transform this Cosmology to another format.

    This function provides the Cosmology interface to the astropy unified I/O
    layer. This allows easily transforming to supported data formats
    using syntax such as::

      >>> from astropy.cosmology import Planck18
      >>> Planck18.to_format("mapping")
      {'cosmology': astropy.cosmology.core.FlatLambdaCDM,
       'name': 'Planck18',
       'H0': <Quantity 67.66 km / (Mpc s)>,
       'Om0': 0.30966,
       ...

    Get help on the available representations for ``Cosmology`` using the
    ``help()`` method::

      >>> Cosmology.to_format.help()  # Get help and list supported formats
      >>> Cosmology.to_format.help('<format>')  # Get detailed help on format
      >>> Cosmology.to_format.list_formats()  # Print list of available formats

    Parameters
    ----------
    format : str
        Format specifier.
    *args
        Positional arguments passed through to data writer. If supplied the
        first argument is the output filename.
    **kwargs
        Keyword arguments passed through to data writer.
    'u'cosmology._src.io.connect'u'_src.io.connect'u'io.connect'
Handles the "Console" unit format.

    Output-only format for to display pretty formatting at the
    console.

    For example::

      >>> import astropy.units as u
      >>> print(u.Ry.decompose().to_string('console'))  # doctest: +FLOAT_CMP
      2.1798721*10^-18 m^2 kg s^-2
      >>> print(u.Ry.decompose().to_string('console', fraction='multiline'))  # doctest: +FLOAT_CMP
                       m^2 kg
      2.1798721*10^-18 ------
                        s^2
      >>> print(u.Ry.decompose().to_string('console', fraction='inline'))  # doctest: +FLOAT_CMP
      2.1798721*10^-18 m^2 kg / s^2
    _line^fraclength{{0:<s}}{{1:^s}}# Change default of fraction to False, i.e., we typeset# without a fraction by default.b'
Handles the "Console" unit format.
'u'
Handles the "Console" unit format.
'b'
    Output-only format for to display pretty formatting at the
    console.

    For example::

      >>> import astropy.units as u
      >>> print(u.Ry.decompose().to_string('console'))  # doctest: +FLOAT_CMP
      2.1798721*10^-18 m^2 kg s^-2
      >>> print(u.Ry.decompose().to_string('console', fraction='multiline'))  # doctest: +FLOAT_CMP
                       m^2 kg
      2.1798721*10^-18 ------
                        s^2
      >>> print(u.Ry.decompose().to_string('console', fraction='inline'))  # doctest: +FLOAT_CMP
      2.1798721*10^-18 m^2 kg / s^2
    'u'
    Output-only format for to display pretty formatting at the
    console.

    For example::

      >>> import astropy.units as u
      >>> print(u.Ry.decompose().to_string('console'))  # doctest: +FLOAT_CMP
      2.1798721*10^-18 m^2 kg s^-2
      >>> print(u.Ry.decompose().to_string('console', fraction='multiline'))  # doctest: +FLOAT_CMP
                       m^2 kg
      2.1798721*10^-18 ------
                        s^2
      >>> print(u.Ry.decompose().to_string('console', fraction='inline'))  # doctest: +FLOAT_CMP
      2.1798721*10^-18 m^2 kg / s^2
    'b'^'u'^'b'{{0:<'u'{{0:<'b's}}{{1:^'u's}}{{1:^'b's}}'u's}}'u'astropy.units.format.console'u'units.format.console'u'format.console'u'console'
Utilities for console input and output.
multiprocessingstructget_terminal_sizefcntltermios_CAN_RESIZE_TERMINALHAS_IPYKERNELHAS_IPYTHONHAS_IPYWIDGETSProgressBarProgressBarOrSpinnerSpinnerhuman_file_sizehuman_timeprint_code_lineterminal_size_IPythonSingleton class given access to IPython streams, etc.OutStream_OutStreamipykernel.iostreamipyio_ipyioIPython.utils
    Returns `True` if ``file`` is a tty.

    Most built-in Python file-like objects have an `isatty` member,
    but some user-defined types may not, so this assumes those are not
    ttys.
    current_processMainProcesscurrent_threadMainThread6.1shutil.get_terminal_size
    Returns a tuple (height, width) containing the height and width of
    the terminal.

    This function will look for the width in height in multiple areas
    before falling back on the width and height in astropy's
    configuration.
    packHHHHioctlTIOCGWINSZunpackxpixelsypixelsunable to get terminal sizeLINESCOLUMNSReturns a string wrapped in ANSI color codes for coloring the text in a terminal.

    ::

        colored_text = color_text('Here is a message', 'blue')

    This won't actually effect the text until it is printed to the
    terminal.

    Parameters
    ----------
    text : str
        The string to return, bounded by the color codes.
    color : str
        An ANSI terminal color name. Must be one of:
        black, red, green, brown, blue, magenta, cyan, lightgrey,
        default, darkgrey, lightred, lightgreen, yellow, lightblue,
        lightmagenta, lightcyan, white, or '' (the empty string).
    0;30black0;310;320;33brown0;340;350;36cyan0;37lightgrey0;391;30darkgrey1;31lightred1;321;331;34lightblue1;35lightmagenta1;36lightcyan1;37whitecolor_mappingcolor_code[[0m_write_with_fallbackWrite the supplied string with the given write function like
    ``write(s)``, but use a writer for the locale's preferred encoding in case
    of a UnicodeEncodeError.  Failing that attempt to write with 'utf-8' or
    'latin-1'.
    getpreferredencodinggetwriterWriter
    Prints colors and styles to the terminal uses ANSI escape
    sequences.

    ::

       color_print('This is the color ', 'default', 'GREEN', 'green')

    Parameters
    ----------
    positional args : str
        The positional arguments come in pairs (*msg*, *color*), where
        *msg* is the string to display and *color* is the color to
        display it in.

        *color* is an ANSI terminal color name.  Must be one of:
        black, red, green, brown, blue, magenta, cyan, lightgrey,
        default, darkgrey, lightred, lightgreen, yellow, lightblue,
        lightmagenta, lightcyan, white, or '' (the empty string).

    file : :term:`file-like (writeable)`, optional
        Where to write to.  Defaults to `sys.stdout`.  If file is not
        a tty (as determined by calling its `isatty` member, if one
        exists), no coloring will be included.

    end : str, optional
        The ending of the message.  Defaults to ``\n``.  The end will
        be printed after resetting any color or font state.
    
    Returns a human-friendly time string that is always exactly 6
    characters long.

    Depending on the number of seconds given, can be one of::

        1w 3d
        2d 4h
        1h 5m
        1m 4s
          15s

    Will be in color if console coloring is turned on.

    Parameters
    ----------
    seconds : int
        The number of seconds to represent

    Returns
    -------
    time : str
        A human-friendly representation of the given number of seconds
        that is always exactly 6 characters.
    52   unit1limit1unit2limit2  ~inf
    Returns a human-friendly string representing a file size
    that is 2-4 characters long.

    For example, depending on the number of bytes given, can be one
    of::

        256b
        64k
        1.1G

    Parameters
    ----------
    size : int
        The size of the file (in bytes)

    Returns
    -------
    size : str
        A human-friendly representation of the size of the file
     kMGTPEZYsuffixesnum_scale?str_value_mapfunc
    A function wrapper to support ProgressBar.map().
    _funci_arg
    A class to display a progress bar in the terminal.

    It is designed to be used either with the ``with`` statement::

        with ProgressBar(len(items)) as bar:
            for item in enumerate(items):
                bar.update()

    or as a generator::

        for item in ProgressBar(items):
            item.process()
    total_or_itemsipython_widget
        Parameters
        ----------
        total_or_items : int or sequence
            If an int, the number of increments in the process being
            tracked.  If a sequence, the items to iterate over.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any, or special case hacks
            to detect the IPython console), the progress bar will be
            completely silent.
        _silent_update_silent_items_totalFirst argument must be int or sequence_start_time_human_total_ipython_widget_signal_set_should_handle_resize_handle_resizeSIGWINCHsignumterminal_width_bar_lengthSIG_DFLrv
        Update progress bar via the console or notebook accordingly.
        _current_value_update_ipython_widget_update_console
        Update the progress bar to the given value (out of the total
        given to the constructor).
        fracbar_fill|      ETA 
        Update the progress bar to the given value (out of a total
        given to the constructor).

        This method is for use in the IPython notebook 2+.
        _widgetipywidgets is not installedipywidgetswidgetsFloatProgressIPython.displaydisplay100multiprocessmultiprocessing_start_methodMap function over items while displaying a progress bar with percentage complete.

        The map operation may run in arbitrary order on the items, but the results are
        returned in sequential order.

        ::

            def work(i):
                print(i)

            ProgressBar.map(work, range(50))

        Parameters
        ----------
        function : function
            Function to call for each step

        items : sequence
            Sequence where each element is a tuple of arguments to pass to
            *function*.

        multiprocess : bool, int, optional
            If `True`, use the `multiprocessing` module to distribute each task
            to a different processor core. If a number greater than 1, then use
            that number of cores.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any), the scrollbar will
            be completely silent.

        step : int, optional
            Update the progress bar at least every *step* steps (default: 100).
            If ``multiprocess`` is `True`, this will affect the size
            of the chunks of ``items`` that are submitted as separate tasks
            to the process pool.  A large step size may make the job
            complete faster if ``items`` is very long.

        multiprocessing_start_method : str, optional
            Useful primarily for testing; if in doubt leave it as the default.
            When using multiprocessing, certain anomalies occur when starting
            processes with the "spawn" method (the only option on Windows);
            other anomalies occur with the "fork" method (the default on
            Linux).
        map_unorderedMap function over items, reporting the progress.

        Does a `map` operation while displaying a progress bar with
        percentage complete. The map operation may run on arbitrary order
        on the items, and the results may be returned in arbitrary order.

        ::

            def work(i):
                print(i)

            ProgressBar.map(work, range(50))

        Parameters
        ----------
        function : function
            Function to call for each step

        items : sequence
            Sequence where each element is a tuple of arguments to pass to
            *function*.

        multiprocess : bool, int, optional
            If `True`, use the `multiprocessing` module to distribute each task
            to a different processor core. If a number greater than 1, then use
            that number of cores.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any), the scrollbar will
            be completely silent.

        step : int, optional
            Update the progress bar at least every *step* steps (default: 100).
            If ``multiprocess`` is `True`, this will affect the size
            of the chunks of ``items`` that are submitted as separate tasks
            to the process pool.  A large step size may make the job
            complete faster if ``items`` is very long.

        multiprocessing_start_method : str, optional
            Useful primarily for testing; if in doubt leave it as the default.
            When using multiprocessing, certain anomalies occur when starting
            processes with the "spawn" method (the only option on Windows);
            other anomalies occur with the "fork" method (the default on
            Linux).
        concurrent.futuresProcessPoolExecutoras_completeddefault_stepget_contextctxmp_contextmax_workerssubmit
    A class to display a spinner in the terminal.

    It is designed to be used with the ``with`` statement::

        with Spinner("Reticulating splines", "green") as s:
            for item in enumerate(items):
                s.update()
    _default_unicode_chars-/|\_default_ascii_charschars
        Parameters
        ----------
        msg : str
            The message to print

        color : str, optional
            An ANSI terminal color name.  Must be one of: black, red,
            green, brown, blue, magenta, cyan, lightgrey, default,
            darkgrey, lightred, lightgreen, yellow, lightblue,
            lightmagenta, lightcyan, white.

        file : :term:`file-like (writeable)`, optional
            The file to write the spinner to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any, or special case hacks
            to detect the IPython console), the spinner will be
            completely silent.

        step : int, optional
            Only update the spinner every *step* steps

        chars : str, optional
            The character sequence to use for the spinner
        _msg_color_step_chars_silent_iterator_iter_iteratortry_fallback ... [Done] [Failed]Update the spin wheel in the terminal.

        Parameters
        ----------
        value : int, optional
            Ignored (present just for compatibility with `ProgressBar.update`).

        
    A class that displays either a `ProgressBar` or `Spinner`
    depending on whether the total size of the operation is
    known or not.

    It is designed to be used with the ``with`` statement::

        if file.has_length():
            length = file.get_length()
        else:
            length = None
        bytes_read = 0
        with ProgressBarOrSpinner(length) as bar:
            while file.read(blocksize):
                bytes_read += blocksize
                bar.update(bytes_read)
    total
        Parameters
        ----------
        total : int or None
            If an int, the number of increments in the process being
            tracked and a `ProgressBar` is displayed.  If `None`, a
            `Spinner` is displayed.

        msg : str
            The message to display above the `ProgressBar` or
            alongside the `Spinner`.

        color : str, optional
            The color of ``msg``, if any.  Must be an ANSI terminal
            color name.  Must be one of: black, red, green, brown,
            blue, magenta, cyan, lightgrey, default, darkgrey,
            lightred, lightgreen, yellow, lightblue, lightmagenta,
            lightcyan, white.

        file : :term:`file-like (writeable)`, optional
            The file to write the to.  Defaults to `sys.stdout`.  If
            ``file`` is not a tty (as determined by calling its `isatty`
            member, if any), only ``msg`` will be displayed: the
            `ProgressBar` or `Spinner` will be silent.
        _is_spinner_obj
        Update the progress bar to the given value (out of the total
        given to the constructor.
        tabwidth
    Prints a line of source code, highlighting a particular character
    position in the line.  Useful for displaying the context of error
    messages.

    If the line is more than ``width`` characters, the line is truncated
    accordingly and '' characters are inserted at the front and/or
    end.

    It looks like this::

        there_is_a_syntax_error_here :
                                     ^

    Parameters
    ----------
    line : unicode
        The line of code to display

    col : int, optional
        The character in the line to highlight.  ``col`` must be less
        than ``len(line)``.

    file : :term:`file-like (writeable)`, optional
        Where to write to.  Defaults to `sys.stdout`.

    tabwidth : int, optional
        The number of spaces per tab (``'\t'``) character.  Default
        is 8.  All tabs will be converted to spaces to ensure that the
        caret lines up with the correct column.

    width : int, optional
        The width of the display, beyond which the line will be
        truncated.  Defaults to 70 (this matches the default in the
        standard library's `textwrap` module).
    ...col must be less than the line length.ntabsnew_colGetchGet a single character from standard input without screen echo.

    Returns
    -------
    char : str (one character)
    _GetchWindowsimpl_GetchUnixttytcgetattrold_settingssetrawtcsetattrTCSADRAINmsvcrtgetch# concurrent.futures imports moved inside functions using them to avoid# import failure when running in pyodide/Emscripten# see if POSIX standard variables will work# fall back on configuration variables, or if not# set, (25, 80)# On Windows do not colorize text unless in IPython# Let's try the next approach...# If this doesn't work let the exception bubble up; I'm out of ideas# Some file objects support writing unicode sensibly on some Python# versions; if this fails try creating a writer using the locale's# preferred encoding. If that fails too give up.# Import units only if necessary because the import takes a# significant time [#4649]# Update self.value# Choose the appropriate environment# Create and display an empty progress bar widget,# if none exists.# Import only if an IPython widget, i.e., widget in iPython NB# Calculate percent completion, and update progress bar# concurrent.futures import here to avoid import failure when running# in pyodide/Emscripten# If even _write_with_fallback failed for any reason just give# up on trying to use the unicode characters# No good will come of using this again# The following three Getch* classes implement unbuffered character reading from# stdin on Windows, and Unix.  This is taken directly from ActiveState# Code Recipes:# http://code.activestate.com/recipes/134892-getch-like-unbuffered-character-reading-from-stdin/b'
Utilities for console input and output.
'u'
Utilities for console input and output.
'b'ProgressBar'u'ProgressBar'b'ProgressBarOrSpinner'u'ProgressBarOrSpinner'b'Spinner'u'Spinner'b'color_print'u'color_print'b'human_file_size'u'human_file_size'b'human_time'u'human_time'b'isatty'u'isatty'b'print_code_line'u'print_code_line'b'terminal_size'u'terminal_size'b'Singleton class given access to IPython streams, etc.'u'Singleton class given access to IPython streams, etc.'b'_OutStream'u'_OutStream'b'_ipyio'u'_ipyio'b'
    Returns `True` if ``file`` is a tty.

    Most built-in Python file-like objects have an `isatty` member,
    but some user-defined types may not, so this assumes those are not
    ttys.
    'u'
    Returns `True` if ``file`` is a tty.

    Most built-in Python file-like objects have an `isatty` member,
    but some user-defined types may not, so this assumes those are not
    ttys.
    'b'MainProcess'u'MainProcess'b'MainThread'u'MainThread'b'stdout'u'stdout'b'6.1'u'6.1'b'shutil.get_terminal_size'u'shutil.get_terminal_size'b'
    Returns a tuple (height, width) containing the height and width of
    the terminal.

    This function will look for the width in height in multiple areas
    before falling back on the width and height in astropy's
    configuration.
    'u'
    Returns a tuple (height, width) containing the height and width of
    the terminal.

    This function will look for the width in height in multiple areas
    before falling back on the width and height in astropy's
    configuration.
    'b'HHHH'u'HHHH'b'unable to get terminal size'u'unable to get terminal size'b'LINES'u'LINES'b'COLUMNS'u'COLUMNS'b'Returns a string wrapped in ANSI color codes for coloring the text in a terminal.

    ::

        colored_text = color_text('Here is a message', 'blue')

    This won't actually effect the text until it is printed to the
    terminal.

    Parameters
    ----------
    text : str
        The string to return, bounded by the color codes.
    color : str
        An ANSI terminal color name. Must be one of:
        black, red, green, brown, blue, magenta, cyan, lightgrey,
        default, darkgrey, lightred, lightgreen, yellow, lightblue,
        lightmagenta, lightcyan, white, or '' (the empty string).
    'u'Returns a string wrapped in ANSI color codes for coloring the text in a terminal.

    ::

        colored_text = color_text('Here is a message', 'blue')

    This won't actually effect the text until it is printed to the
    terminal.

    Parameters
    ----------
    text : str
        The string to return, bounded by the color codes.
    color : str
        An ANSI terminal color name. Must be one of:
        black, red, green, brown, blue, magenta, cyan, lightgrey,
        default, darkgrey, lightred, lightgreen, yellow, lightblue,
        lightmagenta, lightcyan, white, or '' (the empty string).
    'b'0;30'u'0;30'b'black'u'black'b'0;31'u'0;31'b'0;32'u'0;32'b'0;33'u'0;33'b'brown'u'brown'b'0;34'u'0;34'b'0;35'u'0;35'b'0;36'u'0;36'b'cyan'u'cyan'b'0;37'u'0;37'b'lightgrey'u'lightgrey'b'0;39'u'0;39'b'1;30'u'1;30'b'darkgrey'u'darkgrey'b'1;31'u'1;31'b'lightred'u'lightred'b'1;32'u'1;32'b'1;33'u'1;33'b'1;34'u'1;34'b'lightblue'u'lightblue'b'1;35'u'1;35'b'lightmagenta'u'lightmagenta'b'1;36'u'1;36'b'lightcyan'u'lightcyan'b'1;37'u'1;37'b'white'u'white'b'['u'['b'[0m'u'[0m'b'Write the supplied string with the given write function like
    ``write(s)``, but use a writer for the locale's preferred encoding in case
    of a UnicodeEncodeError.  Failing that attempt to write with 'utf-8' or
    'latin-1'.
    'u'Write the supplied string with the given write function like
    ``write(s)``, but use a writer for the locale's preferred encoding in case
    of a UnicodeEncodeError.  Failing that attempt to write with 'utf-8' or
    'latin-1'.
    'b'
    Prints colors and styles to the terminal uses ANSI escape
    sequences.

    ::

       color_print('This is the color ', 'default', 'GREEN', 'green')

    Parameters
    ----------
    positional args : str
        The positional arguments come in pairs (*msg*, *color*), where
        *msg* is the string to display and *color* is the color to
        display it in.

        *color* is an ANSI terminal color name.  Must be one of:
        black, red, green, brown, blue, magenta, cyan, lightgrey,
        default, darkgrey, lightred, lightgreen, yellow, lightblue,
        lightmagenta, lightcyan, white, or '' (the empty string).

    file : :term:`file-like (writeable)`, optional
        Where to write to.  Defaults to `sys.stdout`.  If file is not
        a tty (as determined by calling its `isatty` member, if one
        exists), no coloring will be included.

    end : str, optional
        The ending of the message.  Defaults to ``\n``.  The end will
        be printed after resetting any color or font state.
    'u'
    Prints colors and styles to the terminal uses ANSI escape
    sequences.

    ::

       color_print('This is the color ', 'default', 'GREEN', 'green')

    Parameters
    ----------
    positional args : str
        The positional arguments come in pairs (*msg*, *color*), where
        *msg* is the string to display and *color* is the color to
        display it in.

        *color* is an ANSI terminal color name.  Must be one of:
        black, red, green, brown, blue, magenta, cyan, lightgrey,
        default, darkgrey, lightred, lightgreen, yellow, lightblue,
        lightmagenta, lightcyan, white, or '' (the empty string).

    file : :term:`file-like (writeable)`, optional
        Where to write to.  Defaults to `sys.stdout`.  If file is not
        a tty (as determined by calling its `isatty` member, if one
        exists), no coloring will be included.

    end : str, optional
        The ending of the message.  Defaults to ``\n``.  The end will
        be printed after resetting any color or font state.
    'b'
    Returns a human-friendly time string that is always exactly 6
    characters long.

    Depending on the number of seconds given, can be one of::

        1w 3d
        2d 4h
        1h 5m
        1m 4s
          15s

    Will be in color if console coloring is turned on.

    Parameters
    ----------
    seconds : int
        The number of seconds to represent

    Returns
    -------
    time : str
        A human-friendly representation of the given number of seconds
        that is always exactly 6 characters.
    'u'
    Returns a human-friendly time string that is always exactly 6
    characters long.

    Depending on the number of seconds given, can be one of::

        1w 3d
        2d 4h
        1h 5m
        1m 4s
          15s

    Will be in color if console coloring is turned on.

    Parameters
    ----------
    seconds : int
        The number of seconds to represent

    Returns
    -------
    time : str
        A human-friendly representation of the given number of seconds
        that is always exactly 6 characters.
    'b'   'u'   'b'  ~inf'u'  ~inf'b'
    Returns a human-friendly string representing a file size
    that is 2-4 characters long.

    For example, depending on the number of bytes given, can be one
    of::

        256b
        64k
        1.1G

    Parameters
    ----------
    size : int
        The size of the file (in bytes)

    Returns
    -------
    size : str
        A human-friendly representation of the size of the file
    'u'
    Returns a human-friendly string representing a file size
    that is 2-4 characters long.

    For example, depending on the number of bytes given, can be one
    of::

        256b
        64k
        1.1G

    Parameters
    ----------
    size : int
        The size of the file (in bytes)

    Returns
    -------
    size : str
        A human-friendly representation of the size of the file
    'b' kMGTPEZY'u' kMGTPEZY'b'?'u'?'b'
    A function wrapper to support ProgressBar.map().
    'u'
    A function wrapper to support ProgressBar.map().
    'b'
    A class to display a progress bar in the terminal.

    It is designed to be used either with the ``with`` statement::

        with ProgressBar(len(items)) as bar:
            for item in enumerate(items):
                bar.update()

    or as a generator::

        for item in ProgressBar(items):
            item.process()
    'u'
    A class to display a progress bar in the terminal.

    It is designed to be used either with the ``with`` statement::

        with ProgressBar(len(items)) as bar:
            for item in enumerate(items):
                bar.update()

    or as a generator::

        for item in ProgressBar(items):
            item.process()
    'b'
        Parameters
        ----------
        total_or_items : int or sequence
            If an int, the number of increments in the process being
            tracked.  If a sequence, the items to iterate over.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any, or special case hacks
            to detect the IPython console), the progress bar will be
            completely silent.
        'u'
        Parameters
        ----------
        total_or_items : int or sequence
            If an int, the number of increments in the process being
            tracked.  If a sequence, the items to iterate over.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any, or special case hacks
            to detect the IPython console), the progress bar will be
            completely silent.
        'b'First argument must be int or sequence'u'First argument must be int or sequence'b'
        Update progress bar via the console or notebook accordingly.
        'u'
        Update progress bar via the console or notebook accordingly.
        'b'
        Update the progress bar to the given value (out of the total
        given to the constructor).
        'u'
        Update the progress bar to the given value (out of the total
        given to the constructor).
        'b'|'u'|'b'     'u'     'b' ETA 'u' ETA 'b'
        Update the progress bar to the given value (out of a total
        given to the constructor).

        This method is for use in the IPython notebook 2+.
        'u'
        Update the progress bar to the given value (out of a total
        given to the constructor).

        This method is for use in the IPython notebook 2+.
        'b'_widget'u'_widget'b'ipywidgets is not installed'u'ipywidgets is not installed'b'Map function over items while displaying a progress bar with percentage complete.

        The map operation may run in arbitrary order on the items, but the results are
        returned in sequential order.

        ::

            def work(i):
                print(i)

            ProgressBar.map(work, range(50))

        Parameters
        ----------
        function : function
            Function to call for each step

        items : sequence
            Sequence where each element is a tuple of arguments to pass to
            *function*.

        multiprocess : bool, int, optional
            If `True`, use the `multiprocessing` module to distribute each task
            to a different processor core. If a number greater than 1, then use
            that number of cores.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any), the scrollbar will
            be completely silent.

        step : int, optional
            Update the progress bar at least every *step* steps (default: 100).
            If ``multiprocess`` is `True`, this will affect the size
            of the chunks of ``items`` that are submitted as separate tasks
            to the process pool.  A large step size may make the job
            complete faster if ``items`` is very long.

        multiprocessing_start_method : str, optional
            Useful primarily for testing; if in doubt leave it as the default.
            When using multiprocessing, certain anomalies occur when starting
            processes with the "spawn" method (the only option on Windows);
            other anomalies occur with the "fork" method (the default on
            Linux).
        'u'Map function over items while displaying a progress bar with percentage complete.

        The map operation may run in arbitrary order on the items, but the results are
        returned in sequential order.

        ::

            def work(i):
                print(i)

            ProgressBar.map(work, range(50))

        Parameters
        ----------
        function : function
            Function to call for each step

        items : sequence
            Sequence where each element is a tuple of arguments to pass to
            *function*.

        multiprocess : bool, int, optional
            If `True`, use the `multiprocessing` module to distribute each task
            to a different processor core. If a number greater than 1, then use
            that number of cores.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any), the scrollbar will
            be completely silent.

        step : int, optional
            Update the progress bar at least every *step* steps (default: 100).
            If ``multiprocess`` is `True`, this will affect the size
            of the chunks of ``items`` that are submitted as separate tasks
            to the process pool.  A large step size may make the job
            complete faster if ``items`` is very long.

        multiprocessing_start_method : str, optional
            Useful primarily for testing; if in doubt leave it as the default.
            When using multiprocessing, certain anomalies occur when starting
            processes with the "spawn" method (the only option on Windows);
            other anomalies occur with the "fork" method (the default on
            Linux).
        'b'Map function over items, reporting the progress.

        Does a `map` operation while displaying a progress bar with
        percentage complete. The map operation may run on arbitrary order
        on the items, and the results may be returned in arbitrary order.

        ::

            def work(i):
                print(i)

            ProgressBar.map(work, range(50))

        Parameters
        ----------
        function : function
            Function to call for each step

        items : sequence
            Sequence where each element is a tuple of arguments to pass to
            *function*.

        multiprocess : bool, int, optional
            If `True`, use the `multiprocessing` module to distribute each task
            to a different processor core. If a number greater than 1, then use
            that number of cores.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any), the scrollbar will
            be completely silent.

        step : int, optional
            Update the progress bar at least every *step* steps (default: 100).
            If ``multiprocess`` is `True`, this will affect the size
            of the chunks of ``items`` that are submitted as separate tasks
            to the process pool.  A large step size may make the job
            complete faster if ``items`` is very long.

        multiprocessing_start_method : str, optional
            Useful primarily for testing; if in doubt leave it as the default.
            When using multiprocessing, certain anomalies occur when starting
            processes with the "spawn" method (the only option on Windows);
            other anomalies occur with the "fork" method (the default on
            Linux).
        'u'Map function over items, reporting the progress.

        Does a `map` operation while displaying a progress bar with
        percentage complete. The map operation may run on arbitrary order
        on the items, and the results may be returned in arbitrary order.

        ::

            def work(i):
                print(i)

            ProgressBar.map(work, range(50))

        Parameters
        ----------
        function : function
            Function to call for each step

        items : sequence
            Sequence where each element is a tuple of arguments to pass to
            *function*.

        multiprocess : bool, int, optional
            If `True`, use the `multiprocessing` module to distribute each task
            to a different processor core. If a number greater than 1, then use
            that number of cores.

        ipython_widget : bool, optional
            If `True`, the progress bar will display as an IPython
            notebook widget.

        file : :term:`file-like (writeable)`, optional
            The file to write the progress bar to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any), the scrollbar will
            be completely silent.

        step : int, optional
            Update the progress bar at least every *step* steps (default: 100).
            If ``multiprocess`` is `True`, this will affect the size
            of the chunks of ``items`` that are submitted as separate tasks
            to the process pool.  A large step size may make the job
            complete faster if ``items`` is very long.

        multiprocessing_start_method : str, optional
            Useful primarily for testing; if in doubt leave it as the default.
            When using multiprocessing, certain anomalies occur when starting
            processes with the "spawn" method (the only option on Windows);
            other anomalies occur with the "fork" method (the default on
            Linux).
        'b'
    A class to display a spinner in the terminal.

    It is designed to be used with the ``with`` statement::

        with Spinner("Reticulating splines", "green") as s:
            for item in enumerate(items):
                s.update()
    'u'
    A class to display a spinner in the terminal.

    It is designed to be used with the ``with`` statement::

        with Spinner("Reticulating splines", "green") as s:
            for item in enumerate(items):
                s.update()
    'u''b'-/|\'u'-/|\'b'
        Parameters
        ----------
        msg : str
            The message to print

        color : str, optional
            An ANSI terminal color name.  Must be one of: black, red,
            green, brown, blue, magenta, cyan, lightgrey, default,
            darkgrey, lightred, lightgreen, yellow, lightblue,
            lightmagenta, lightcyan, white.

        file : :term:`file-like (writeable)`, optional
            The file to write the spinner to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any, or special case hacks
            to detect the IPython console), the spinner will be
            completely silent.

        step : int, optional
            Only update the spinner every *step* steps

        chars : str, optional
            The character sequence to use for the spinner
        'u'
        Parameters
        ----------
        msg : str
            The message to print

        color : str, optional
            An ANSI terminal color name.  Must be one of: black, red,
            green, brown, blue, magenta, cyan, lightgrey, default,
            darkgrey, lightred, lightgreen, yellow, lightblue,
            lightmagenta, lightcyan, white.

        file : :term:`file-like (writeable)`, optional
            The file to write the spinner to.  Defaults to
            `sys.stdout`.  If ``file`` is not a tty (as determined by
            calling its `isatty` member, if any, or special case hacks
            to detect the IPython console), the spinner will be
            completely silent.

        step : int, optional
            Only update the spinner every *step* steps

        chars : str, optional
            The character sequence to use for the spinner
        'b' ...'u' ...'b' [Done]'u' [Done]'b' [Failed]'u' [Failed]'b'Update the spin wheel in the terminal.

        Parameters
        ----------
        value : int, optional
            Ignored (present just for compatibility with `ProgressBar.update`).

        'u'Update the spin wheel in the terminal.

        Parameters
        ----------
        value : int, optional
            Ignored (present just for compatibility with `ProgressBar.update`).

        'b'
    A class that displays either a `ProgressBar` or `Spinner`
    depending on whether the total size of the operation is
    known or not.

    It is designed to be used with the ``with`` statement::

        if file.has_length():
            length = file.get_length()
        else:
            length = None
        bytes_read = 0
        with ProgressBarOrSpinner(length) as bar:
            while file.read(blocksize):
                bytes_read += blocksize
                bar.update(bytes_read)
    'u'
    A class that displays either a `ProgressBar` or `Spinner`
    depending on whether the total size of the operation is
    known or not.

    It is designed to be used with the ``with`` statement::

        if file.has_length():
            length = file.get_length()
        else:
            length = None
        bytes_read = 0
        with ProgressBarOrSpinner(length) as bar:
            while file.read(blocksize):
                bytes_read += blocksize
                bar.update(bytes_read)
    'b'
        Parameters
        ----------
        total : int or None
            If an int, the number of increments in the process being
            tracked and a `ProgressBar` is displayed.  If `None`, a
            `Spinner` is displayed.

        msg : str
            The message to display above the `ProgressBar` or
            alongside the `Spinner`.

        color : str, optional
            The color of ``msg``, if any.  Must be an ANSI terminal
            color name.  Must be one of: black, red, green, brown,
            blue, magenta, cyan, lightgrey, default, darkgrey,
            lightred, lightgreen, yellow, lightblue, lightmagenta,
            lightcyan, white.

        file : :term:`file-like (writeable)`, optional
            The file to write the to.  Defaults to `sys.stdout`.  If
            ``file`` is not a tty (as determined by calling its `isatty`
            member, if any), only ``msg`` will be displayed: the
            `ProgressBar` or `Spinner` will be silent.
        'u'
        Parameters
        ----------
        total : int or None
            If an int, the number of increments in the process being
            tracked and a `ProgressBar` is displayed.  If `None`, a
            `Spinner` is displayed.

        msg : str
            The message to display above the `ProgressBar` or
            alongside the `Spinner`.

        color : str, optional
            The color of ``msg``, if any.  Must be an ANSI terminal
            color name.  Must be one of: black, red, green, brown,
            blue, magenta, cyan, lightgrey, default, darkgrey,
            lightred, lightgreen, yellow, lightblue, lightmagenta,
            lightcyan, white.

        file : :term:`file-like (writeable)`, optional
            The file to write the to.  Defaults to `sys.stdout`.  If
            ``file`` is not a tty (as determined by calling its `isatty`
            member, if any), only ``msg`` will be displayed: the
            `ProgressBar` or `Spinner` will be silent.
        'b'
        Update the progress bar to the given value (out of the total
        given to the constructor.
        'u'
        Update the progress bar to the given value (out of the total
        given to the constructor.
        'u'
    Prints a line of source code, highlighting a particular character
    position in the line.  Useful for displaying the context of error
    messages.

    If the line is more than ``width`` characters, the line is truncated
    accordingly and '' characters are inserted at the front and/or
    end.

    It looks like this::

        there_is_a_syntax_error_here :
                                     ^

    Parameters
    ----------
    line : unicode
        The line of code to display

    col : int, optional
        The character in the line to highlight.  ``col`` must be less
        than ``len(line)``.

    file : :term:`file-like (writeable)`, optional
        Where to write to.  Defaults to `sys.stdout`.

    tabwidth : int, optional
        The number of spaces per tab (``'\t'``) character.  Default
        is 8.  All tabs will be converted to spaces to ensure that the
        caret lines up with the correct column.

    width : int, optional
        The width of the display, beyond which the line will be
        truncated.  Defaults to 70 (this matches the default in the
        standard library's `textwrap` module).
    'u''b'...'u'...'b'col must be less than the line length.'u'col must be less than the line length.'b'Get a single character from standard input without screen echo.

    Returns
    -------
    char : str (one character)
    'u'Get a single character from standard input without screen echo.

    Returns
    -------
    char : str (one character)
    'u'astropy.utils.console'u'utils.console'astropy.units.quantityConstantMetaMetaclass for `~astropy.constants.Constant`. The primary purpose of this
    is to wrap the double-underscore methods of `~astropy.units.Quantity`
    which is the superclass of `~astropy.constants.Constant`.

    In particular this wraps the operator overloads such as `__add__` to
    prevent their use with constants such as ``e`` from being used in
    expressions without specifying a system.  The wrapper checks to see if the
    constant is listed (by name) in ``Constant._has_incompatible_units``, a set
    of those constants that are defined in different systems of units are
    physically incompatible.  It also performs this check on each `Constant` if
    it hasn't already been performed (the check is deferred until the
    `Constant` is actually used in an expression to speed up import times,
    among other reasons).
    methname_lowerinstances_checked_unitssystemsConstant  does not have physically compatible units across all systems of units and cannot be combined with other values without specifying a system (eg. " does not have physically compatible ""units across all systems of units and cannot be ""combined with other values without specifying a ""system (eg. "__quantity_subclass__A physical or astronomical constant.

    These objects are quantities that are meant to represent physical
    constants.

    Parameters
    ----------
    abbrev : str
        A typical ASCII text abbreviation of the constant, generally
        the same as the Python variable used for this constant.
    name : str
        Full constant name.
    value : numbers.Real
        Constant value. Note that this should be a bare number, not a
        |Quantity|.
    unit : str
        String representation of the constant units.
    uncertainty : numbers.Real
        Absolute uncertainty in constant value. Note that this should be
        a bare number, not a |Quantity|.
    reference : str, optional
        Reference where the value is taken from.
    system : str
        System of units in which the constant is defined. This can be
        `None` when the constant's units can be directly converted
        between systems.
     requires a reference. already has a definition in the " already has a definition in ""the " system from  reference_abbrev_unit_string_reference_system name="name=""value=" uncertainty="uncertainty=" unit="unit=" reference="reference="  Name   = 
  Value  = "  Value  = "
  Uncertainty  = "  Uncertainty  = "
  Unit  = "  Unit  = "
  Reference = "  Reference = "
        Return a copy of this `Constant` instance.  Since they are by
        definition immutable, this merely returns another reference to
        ``self``.
        A typical ASCII text abbreviation of the constant, also generally
        the same as the Python variable used for this constant.
        The full name of the constant.The unit(s) in which this constant is defined.The known absolute uncertainty in this constant's value.The source used for the value of this constant.The system of units in which this constant is defined (typically
        `None` so long as the constant's units can be directly converted
        between systems).
        _instance_or_superIf the Constant is defined in the SI system return that instance of
        the constant, else convert to a Quantity in the appropriate SI units.
        If the Constant is defined in the CGS system return that instance of
        the constant, else convert to a Quantity in the appropriate CGS units.
        An electromagnetic constant.Overridden for EMConstant to raise a `TypeError`
        emphasizing that there are multiple EM extensions to CGS.
        Cannot convert EM constants to cgs because there are different systems for E.M constants within the c.g.s system (ESU, Gaussian, etc.). Instead, directly use the constant with the appropriate suffix (e.g. e.esu, e.gauss, etc.)."Cannot convert EM constants to cgs because there ""are different systems for E.M constants within the ""c.g.s system (ESU, Gaussian, etc.). Instead, ""directly use the constant with the appropriate ""suffix (e.g. e.esu, e.gauss, etc.)."# The wrapper applies to so many of the __ methods that it's easier to# just exclude the ones it doesn't apply to# By-pass Quantity initialization, since units may not yet be# initialized here, and we store the unit in string form.b'Constant'u'Constant'b'EMConstant'u'EMConstant'b'Metaclass for `~astropy.constants.Constant`. The primary purpose of this
    is to wrap the double-underscore methods of `~astropy.units.Quantity`
    which is the superclass of `~astropy.constants.Constant`.

    In particular this wraps the operator overloads such as `__add__` to
    prevent their use with constants such as ``e`` from being used in
    expressions without specifying a system.  The wrapper checks to see if the
    constant is listed (by name) in ``Constant._has_incompatible_units``, a set
    of those constants that are defined in different systems of units are
    physically incompatible.  It also performs this check on each `Constant` if
    it hasn't already been performed (the check is deferred until the
    `Constant` is actually used in an expression to speed up import times,
    among other reasons).
    'u'Metaclass for `~astropy.constants.Constant`. The primary purpose of this
    is to wrap the double-underscore methods of `~astropy.units.Quantity`
    which is the superclass of `~astropy.constants.Constant`.

    In particular this wraps the operator overloads such as `__add__` to
    prevent their use with constants such as ``e`` from being used in
    expressions without specifying a system.  The wrapper checks to see if the
    constant is listed (by name) in ``Constant._has_incompatible_units``, a set
    of those constants that are defined in different systems of units are
    physically incompatible.  It also performs this check on each `Constant` if
    it hasn't already been performed (the check is deferred until the
    `Constant` is actually used in an expression to speed up import times,
    among other reasons).
    'b'Constant 'u'Constant 'b' does not have physically compatible units across all systems of units and cannot be combined with other values without specifying a system (eg. 'u' does not have physically compatible units across all systems of units and cannot be combined with other values without specifying a system (eg. 'b'__new__'u'__new__'b'__array_finalize__'u'__array_finalize__'b'__array_wrap__'u'__array_wrap__'b'__dir__'u'__dir__'b'__getattr__'u'__getattr__'b'__init__'b'__str__'u'__str__'b'__repr__'u'__repr__'b'__hash__'u'__hash__'b'__getitem__'u'__getitem__'b'__bool__'u'__bool__'b'__quantity_subclass__'u'__quantity_subclass__'b'__setstate__'u'__setstate__'b'A physical or astronomical constant.

    These objects are quantities that are meant to represent physical
    constants.

    Parameters
    ----------
    abbrev : str
        A typical ASCII text abbreviation of the constant, generally
        the same as the Python variable used for this constant.
    name : str
        Full constant name.
    value : numbers.Real
        Constant value. Note that this should be a bare number, not a
        |Quantity|.
    unit : str
        String representation of the constant units.
    uncertainty : numbers.Real
        Absolute uncertainty in constant value. Note that this should be
        a bare number, not a |Quantity|.
    reference : str, optional
        Reference where the value is taken from.
    system : str
        System of units in which the constant is defined. This can be
        `None` when the constant's units can be directly converted
        between systems.
    'u'A physical or astronomical constant.

    These objects are quantities that are meant to represent physical
    constants.

    Parameters
    ----------
    abbrev : str
        A typical ASCII text abbreviation of the constant, generally
        the same as the Python variable used for this constant.
    name : str
        Full constant name.
    value : numbers.Real
        Constant value. Note that this should be a bare number, not a
        |Quantity|.
    unit : str
        String representation of the constant units.
    uncertainty : numbers.Real
        Absolute uncertainty in constant value. Note that this should be
        a bare number, not a |Quantity|.
    reference : str, optional
        Reference where the value is taken from.
    system : str
        System of units in which the constant is defined. This can be
        `None` when the constant's units can be directly converted
        between systems.
    'b'default_reference'u'default_reference'b' requires a reference.'u' requires a reference.'b' already has a definition in the 'u' already has a definition in the 'b' system from 'u' system from 'b' reference'u' reference'b' name='u' name='b' uncertainty='u' uncertainty='b' unit='u' unit='b' reference='u' reference='b'  Name   = 'u'  Name   = 'b'
  Value  = 'u'
  Value  = 'b'
  Uncertainty  = 'u'
  Uncertainty  = 'b'
  Unit  = 'u'
  Unit  = 'b'
  Reference = 'u'
  Reference = 'b'
        Return a copy of this `Constant` instance.  Since they are by
        definition immutable, this merely returns another reference to
        ``self``.
        'u'
        Return a copy of this `Constant` instance.  Since they are by
        definition immutable, this merely returns another reference to
        ``self``.
        'b'A typical ASCII text abbreviation of the constant, also generally
        the same as the Python variable used for this constant.
        'u'A typical ASCII text abbreviation of the constant, also generally
        the same as the Python variable used for this constant.
        'b'The full name of the constant.'u'The full name of the constant.'b'The unit(s) in which this constant is defined.'u'The unit(s) in which this constant is defined.'b'The known absolute uncertainty in this constant's value.'u'The known absolute uncertainty in this constant's value.'b'The source used for the value of this constant.'u'The source used for the value of this constant.'b'The system of units in which this constant is defined (typically
        `None` so long as the constant's units can be directly converted
        between systems).
        'u'The system of units in which this constant is defined (typically
        `None` so long as the constant's units can be directly converted
        between systems).
        'b'If the Constant is defined in the SI system return that instance of
        the constant, else convert to a Quantity in the appropriate SI units.
        'u'If the Constant is defined in the SI system return that instance of
        the constant, else convert to a Quantity in the appropriate SI units.
        'b'If the Constant is defined in the CGS system return that instance of
        the constant, else convert to a Quantity in the appropriate CGS units.
        'u'If the Constant is defined in the CGS system return that instance of
        the constant, else convert to a Quantity in the appropriate CGS units.
        'b'cgs'b'_abbrev'u'_abbrev'b'_value'u'_value'b'_unit_string'u'_unit_string'b'_uncertainty'u'_uncertainty'b'_reference'u'_reference'b'_system'u'_system'b'_checked_units'u'_checked_units'b'An electromagnetic constant.'u'An electromagnetic constant.'b'Overridden for EMConstant to raise a `TypeError`
        emphasizing that there are multiple EM extensions to CGS.
        'u'Overridden for EMConstant to raise a `TypeError`
        emphasizing that there are multiple EM extensions to CGS.
        'b'Cannot convert EM constants to cgs because there are different systems for E.M constants within the c.g.s system (ESU, Gaussian, etc.). Instead, directly use the constant with the appropriate suffix (e.g. e.esu, e.gauss, etc.).'u'Cannot convert EM constants to cgs because there are different systems for E.M constants within the c.g.s system (ESU, Gaussian, etc.). Instead, directly use the constant with the appropriate suffix (e.g. e.esu, e.gauss, etc.).'u'astropy.constants.constant'u'constants.constant'u'constant'
Defines constants used in `astropy.samp`.
SAFE_MTYPESSAMP_ICONSAMP_STATUS_ERROR__profile_version__samp.oksamp.warningsamp.app.*samp.msg.progresstable.*image.*coord.*spectrum.*bibcode.*voresource.*data/astropy_icon.png#: General constant for samp.ok status string#: General constant for samp.warning status string#: General constant for samp.error status stringb'
Defines constants used in `astropy.samp`.
'u'
Defines constants used in `astropy.samp`.
'b'SAFE_MTYPES'u'SAFE_MTYPES'b'SAMP_ICON'u'SAMP_ICON'b'SAMP_STATUS_ERROR'u'SAMP_STATUS_ERROR'b'SAMP_STATUS_OK'u'SAMP_STATUS_OK'b'SAMP_STATUS_WARNING'u'SAMP_STATUS_WARNING'b'1.3'u'1.3'b'samp.ok'u'samp.ok'b'samp.warning'u'samp.warning'b'samp.app.*'u'samp.app.*'b'samp.msg.progress'u'samp.msg.progress'b'table.*'u'table.*'b'image.*'u'image.*'b'coord.*'u'coord.*'b'spectrum.*'u'spectrum.*'b'bibcode.*'u'bibcode.*'b'voresource.*'u'voresource.*'b'data/astropy_icon.png'u'data/astropy_icon.png'u'astropy.samp.constants'u'samp.constants'Convenience functions for working with FITS files.

Convenience functions
=====================

The functions in this module provide shortcuts for some of the most basic
operations on FITS files, such as reading and updating the header.  They are
included directly in the 'astropy.io.fits' namespace so that they can be used
like::

    astropy.io.fits.getheader(...)

These functions are primarily for convenience when working with FITS files in
the command-line interpreter.  If performing several operations on the same
file, such as in a script, it is better to *not* use these functions, as each
one must open and re-parse the file.  In such cases it is better to use
:func:`astropy.io.fits.open` and work directly with the
:class:`astropy.io.fits.HDUList` object and underlying HDU objects.

Several of the convenience functions, such as `getheader` and `getdata` support
special arguments for selecting which HDU to use when working with a
multi-extension FITS file.  There are a few supported argument formats for
selecting the HDU.  See the documentation for `getdata` for an
explanation of all the different formats.

.. warning::
    All arguments to convenience functions other than the filename that are
    *not* for selecting the HDU should be passed in as keyword
    arguments.  This is to avoid ambiguity and conflicts with the
    HDU arguments.  For example, to set NAXIS=1 on the Primary HDU:

    Wrong::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', 1)

    The above example will try to set the NAXIS value on the first extension
    HDU to blank.  That is, the argument '1' is assumed to specify an
    HDU.

    Right::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', value=1)

    This will set the NAXIS keyword to 1 on the primary HDU (the default).  To
    specify the first extension HDU use::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', value=1, ext=1)

    This complexity arises out of the attempt to simultaneously support
    multiple argument formats that were used in past versions of PyFITS.
    Unfortunately, it is not possible to support all formats without
    introducing some ambiguity.  A future Astropy release may standardize
    around a single format and officially deprecate the other formats.
FITSDiffHDUDiffFILE_MODEShdu.base_is_dask_arrayfileobj_closedfileobj_modefileobj_namepath_likedelvalgetdatagetheadergetvalprintdiffsetvaltabledumptableload
    Get the header from an HDU of a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        File to get header from.  If an opened file object, its mode
        must be one of the following rb, rb+, or ab+).

    ext, extname, extver
        The rest of the arguments are for HDU specification.  See the
        `getdata` documentation for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.

    Returns
    -------
    header : `Header` object
    _get_file_mode_getextextidx
    Get the data from an HDU of a FITS file (and optionally the
    header).

    Parameters
    ----------
    filename : path-like or file-like
        File to get data from.  If opened, mode must be one of the
        following rb, rb+, or ab+.

    ext
        The rest of the arguments are for HDU specification.
        They are flexible and are best illustrated by examples.

        No extra arguments implies the primary HDU::

            getdata('in.fits')

        .. note::
            Exclusive to ``getdata``: if ``ext`` is not specified
            and primary header contains no data, ``getdata`` attempts
            to retrieve data from first extension HDU.

        By HDU number::

            getdata('in.fits', 0)      # the primary HDU
            getdata('in.fits', 2)      # the second extension HDU
            getdata('in.fits', ext=2)  # the second extension HDU

        By name, i.e., ``EXTNAME`` value (if unique)::

            getdata('in.fits', 'sci')
            getdata('in.fits', extname='sci')  # equivalent

        Note ``EXTNAME`` values are not case sensitive

        By combination of ``EXTNAME`` and EXTVER`` as separate
        arguments or as a tuple::

            getdata('in.fits', 'sci', 2)  # EXTNAME='SCI' & EXTVER=2
            getdata('in.fits', extname='sci', extver=2)  # equivalent
            getdata('in.fits', ('sci', 2))  # equivalent

        Ambiguous or conflicting specifications will raise an exception::

            getdata('in.fits', ext=('sci',1), extname='err', extver=2)

    header : bool, optional
        If `True`, return the data and the header of the specified HDU as a
        tuple.

    lower, upper : bool, optional
        If ``lower`` or ``upper`` are `True`, the field names in the
        returned data object will be converted to lower or upper case,
        respectively.

    view : ndarray, optional
        When given, the data will be returned wrapped in the given ndarray
        subclass by calling::

           data.view(view)

    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.

    Returns
    -------
    array : ndarray or `~numpy.recarray` or `~astropy.io.fits.Group`
        Type depends on the type of the extension being referenced.

        If the optional keyword ``header`` is set to `True`, this
        function will return a (``data``, ``header``) tuple.

    Raises
    ------
    IndexError
        If no data is found in searched HDUs.
    extextnameextverext_givenNo data in HDU #No data in Primary HDU and no extension HDU found.No data in either Primary or first extension HDUs.
    Get a keyword's value from a header in a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object (if opened, mode must be
        one of the following rb, rb+, or ab+).

    keyword : str
        Keyword name

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.

    Returns
    -------
    keyword value : str, int, or float
    aftersavecomment
    Set a keyword's value from a header in a FITS file.

    If the keyword already exists, it's value/comment will be updated.
    If it does not exist, a new card will be created and it will be
    placed before or after the specified location.  If no ``before`` or
    ``after`` is specified, it will be appended at the end.

    When updating more than one keyword in a file, this convenience
    function is a much less efficient approach compared with opening
    the file for update, modifying the header, and closing the file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object If opened, mode must be update
        (rb+).  An opened file object or `~gzip.GzipFile` object will be closed
        upon return.

    keyword : str
        Keyword name

    value : str, int, float, optional
        Keyword value (default: `None`, meaning don't modify)

    comment : str, optional
        Keyword comment, (default: `None`, meaning don't modify)

    before : str, int, optional
        Name of the keyword, or index of the card before which the new card
        will be placed.  The argument ``before`` takes precedence over
        ``after`` if both are specified (default: `None`).

    after : str, int, optional
        Name of the keyword, or index of the card after which the new card will
        be placed. (default: `None`).

    savecomment : bool, optional
        When `True`, preserve the current comment for an existing keyword.  The
        argument ``savecomment`` takes precedence over ``comment`` if both
        specified.  If ``comment`` is not specified then the current comment
        will automatically be preserved  (default: `False`).

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.
    
    Delete all instances of keyword from a header in a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object If opened, mode must be update
        (rb+).  An opened file object or `~gzip.GzipFile` object will be closed
        upon return.

    keyword : str, int
        Keyword name or index

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.
    
    Create a new FITS file using the supplied data/header.

    Parameters
    ----------
    filename : path-like or file-like
        File to write to.  If opened, must be opened in a writable binary
        mode such as 'wb' or 'ab+'.

    data : array or `~numpy.recarray` or `~astropy.io.fits.Group`
        data to write to the new file

    header : `Header` object, optional
        the header associated with ``data``. If `None`, a header
        of the appropriate type is created for the supplied data. This
        argument is optional.

    output_verify : str
        Output verification option.  Must be one of ``"fix"``, ``"silentfix"``,
        ``"ignore"``, ``"warn"``, or ``"exception"``.  May also be any
        combination of ``"fix"`` or ``"silentfix"`` with ``"+ignore"``,
        ``+warn``, or ``+exception" (e.g. ``"fix+warn"``).  See
        :ref:`astropy:verify` for more info.

    overwrite : bool, optional
        If ``True``, overwrite the output file if it exists. Raises an
        ``OSError`` if ``False`` and the output file exists. Default is
        ``False``.

    checksum : bool, optional
        If `True`, adds both ``DATASUM`` and ``CHECKSUM`` cards to the
        headers of all HDU's written to the file.

    Notes
    -----
    gzip, zip, bzip2 and lzma compression algorithms are natively supported.
    Compression mode is determined from the filename extension
    ('.gz', '.zip', '.bz2' or '.xz' respectively).  It is also possible to pass
    a compressed file object, e.g. `gzip.GzipFile`.
    _makehdu
    Convert an `~astropy.table.Table` object to a FITS
    `~astropy.io.fits.BinTableHDU`.

    Parameters
    ----------
    table : astropy.table.Table
        The table to convert.
    character_as_bytes : bool
        Whether to return bytes for string columns when accessed from the HDU.
        By default this is `False` and (unicode) strings are returned, but for
        large tables this may use up a lot of memory.

    Returns
    -------
    table_hdu : `~astropy.io.fits.BinTableHDU`
        The FITS binary table HDU.
    has_mixin_columnstime_to_fitstime_colsas_arraytarraycoldtypefrom_columnsint_formatslogicaltdisp_formatastropy.units.format.fitsUnitScaleErrorThe column '' could not be stored in FITS format because it has a scale '("' could not be stored in FITS ""format because it has a scale '(")' that is not recognized by the FITS standard. Either scale the data or change the units.")' that ""is not recognized by the FITS standard. Either scale ""the data or change the units."The unit '' could not be saved in native FITS format "' could not be saved in ""native FITS format "name: and hence will be lost to non-astropy fits readers. Within astropy, the unit can roundtrip using QTable, though one has to enable the unit before reading."and hence will be lost to non-astropy fits readers. ""Within astropy, the unit can roundtrip using QTable, ""though one has to enable the unit before reading."and cannot be recovered in reading. It can roundtrip within astropy by using QTable both to write and read back, though one has to enable the unit before reading."and cannot be recovered in reading. It can roundtrip ""within astropy by using QTable both to write and read ""back, though one has to enable the unit before reading."__coordinate_columns__coord_metacol_infotrposMeta-data keyword  will be ignored since it conflicts with a FITS reserved keyword" will be ignored since it conflicts ""with a FITS reserved keyword"Attribute `` of type  cannot be added to FITS Header - skipping" cannot be ""added to FITS Header - skipping"
    Append the header/data to FITS file if filename exists, create if not.

    If only ``data`` is supplied, a minimal header is created.

    Parameters
    ----------
    filename : path-like or file-like
        File to write to.  If opened, must be opened for update (rb+) unless it
        is a new file, then it must be opened for append (ab+).  A file or
        `~gzip.GzipFile` object opened for update will be closed after return.

    data : array, :class:`~astropy.table.Table`, or `~astropy.io.fits.Group`
        The new data used for appending.

    header : `Header` object, optional
        The header associated with ``data``.  If `None`, an appropriate header
        will be created for the data object supplied.

    checksum : bool, optional
        When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards to the header
        of the HDU when written to the file.

    verify : bool, optional
        When `True`, the existing FITS file will be read in to verify it for
        correctness before appending.  When `False`, content is simply appended
        to the end of the file.  Setting ``verify`` to `False` can be much
        faster.

    **kwargs
        Additional arguments are passed to:

        - `~astropy.io.fits.writeto` if the file does not exist or is empty.
          In this case ``output_verify`` is the only possible argument.
        - `~astropy.io.fits.open` if ``verify`` is True or if ``filename``
          is a file object.
        - Otherwise no additional arguments can be used.

    _stat_filename_or_fileobjnoexist_or_empty
    Update the specified HDU with the input data/header.

    Parameters
    ----------
    filename : path-like or file-like
        File to update.  If opened, mode must be update (rb+).  An opened file
        object or `~gzip.GzipFile` object will be closed upon return.

    data : array, `~astropy.table.Table`, or `~astropy.io.fits.Group`
        The new data used for updating.

    header : `Header` object, optional
        The header associated with ``data``.  If `None`, an appropriate header
        will be created for the data object supplied.

    ext, extname, extver
        The rest of the arguments are flexible: the 3rd argument can be the
        header associated with the data.  If the 3rd argument is not a
        `Header`, it (and other positional arguments) are assumed to be the
        HDU specification(s).  Header and HDU specs can also be
        keyword arguments.  For example::

            update(file, dat, hdr, 'sci')  # update the 'sci' extension
            update(file, dat, 3)  # update the 3rd extension HDU
            update(file, dat, hdr, 3)  # update the 3rd extension HDU
            update(file, dat, 'sci', 2)  # update the 2nd extension HDU named 'sci'
            update(file, dat, 3, header=hdr)  # update the 3rd extension HDU
            update(file, dat, header=hdr, ext=5)  # update the 5th extension HDU

    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
    new_hdu_ext
    Print the summary information on a FITS file.

    This includes the name, type, length of header, data shape and type
    for each HDU.

    Parameters
    ----------
    filename : path-like or file-like
        FITS file to obtain info from.  If opened, mode must be one of
        the following: rb, rb+, or ab+ (i.e. the file must be readable).

    output : file, bool, optional
        A file-like object to write the output to.  If ``False``, does not
        output to a file and instead returns a list of tuples representing the
        HDU info.  Writes to ``sys.stdout`` by default.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function sets ``ignore_missing_end=True`` by default.
    inputainputb
    Compare two parts of a FITS file, including entire FITS files,
    FITS `HDUList` objects and FITS ``HDU`` objects.

    Parameters
    ----------
    inputa : str, `HDUList` object, or ``HDU`` object
        The filename of a FITS file, `HDUList`, or ``HDU``
        object to compare to ``inputb``.

    inputb : str, `HDUList` object, or ``HDU`` object
        The filename of a FITS file, `HDUList`, or ``HDU``
        object to compare to ``inputa``.

    ext, extname, extver
        Additional positional arguments are for HDU specification if your
        inputs are string filenames (will not work if
        ``inputa`` and ``inputb`` are ``HDU`` objects or `HDUList` objects).
        They are flexible and are best illustrated by examples.  In addition
        to using these arguments positionally you can directly call the
        keyword parameters ``ext``, ``extname``.

        By HDU number::

            printdiff('inA.fits', 'inB.fits', 0)      # the primary HDU
            printdiff('inA.fits', 'inB.fits', 2)      # the second extension HDU
            printdiff('inA.fits', 'inB.fits', ext=2)  # the second extension HDU

        By name, i.e., ``EXTNAME`` value (if unique). ``EXTNAME`` values are
        not case sensitive:

            printdiff('inA.fits', 'inB.fits', 'sci')
            printdiff('inA.fits', 'inB.fits', extname='sci')  # equivalent

        By combination of ``EXTNAME`` and ``EXTVER`` as separate
        arguments or as a tuple::

            printdiff('inA.fits', 'inB.fits', 'sci', 2)    # EXTNAME='SCI'
                                                           # & EXTVER=2
            printdiff('inA.fits', 'inB.fits', extname='sci', extver=2)
                                                           # equivalent
            printdiff('inA.fits', 'inB.fits', ('sci', 2))  # equivalent

        Ambiguous or conflicting specifications will raise an exception::

            printdiff('inA.fits', 'inB.fits',
                      ext=('sci', 1), extname='err', extver=2)

    **kwargs
        Any additional keyword arguments to be passed to
        `~astropy.io.fits.FITSDiff`.

    Notes
    -----
    The primary use for the `printdiff` function is to allow quick print out
    of a FITS difference report and will write to ``sys.stdout``.
    To save the diff report to a file please use `~astropy.io.fits.FITSDiff`
    directly.
    extensionhas_extensionsmodeaclosedamodebclosedbhdulistaextidxahdulistbextidxbhduahdubreportCannot use extension keywords when providing an HDU object.Extension specification with HDUList objects not implemented.datafilecdfilehfile
    Dump a table HDU to a file in ASCII format.  The table may be
    dumped in three separate files, one containing column definitions,
    one containing header parameters, and one for table data.

    Parameters
    ----------
    filename : path-like or file-like
        Input fits file.

    datafile : path-like or file-like, optional
        Output data file.  The default is the root name of the input
        fits file appended with an underscore, followed by the
        extension number (ext), followed by the extension ``.txt``.

    cdfile : path-like or file-like, optional
        Output column definitions file.  The default is `None`,
        no column definitions output is produced.

    hfile : path-like or file-like, optional
        Output header parameters file.  The default is `None`,
        no header parameters output is produced.

    ext : int
        The number of the extension containing the table HDU to be
        dumped.

    overwrite : bool, optional
        If ``True``, overwrite the output file if it exists. Raises an
        ``OSError`` if ``False`` and the output file exists. Default is
        ``False``.

    Notes
    -----
    The primary use for the `tabledump` function is to allow editing in a
    standard text editor of the table data and parameters.  The
    `tableload` function can be used to reassemble the table from the
    three ASCII files.
    tail.txtdump_tdump_file_format
    Create a table from the input ASCII files.  The input is from up
    to three separate files, one containing column definitions, one
    containing header parameters, and one containing column data.  The
    header parameters file is not required.  When the header
    parameters file is absent a minimal header is constructed.

    Parameters
    ----------
    datafile : path-like or file-like
        Input data file containing the table data in ASCII format.

    cdfile : path-like or file-like
        Input column definition file containing the names, formats,
        display formats, physical units, multidimensional array
        dimensions, undefined values, scale factors, and offsets
        associated with the columns in the table.

    hfile : path-like or file-like, optional
        Input parameter definition file containing the header
        parameter definitions to be associated with the table.
        If `None`, a minimal header is constructed.

    Notes
    -----
    The primary use for the `tableload` function is to allow the input of
    ASCII data that was edited in a standard text editor of the table
    data and parameters.  The tabledump function can be used to create the
    initial ASCII files.
    
    Open the input file, return the `HDUList` and the extension.

    This supports several different styles of extension selection.  See the
    :func:`getdata()` documentation for the different possibilities.
    Redundant/conflicting extension arguments(s): {}Too many positional arguments.The ext keyword must be either an extension number (zero-indexed) or a (extname, extver) tuple."The ext keyword must be either an extension number ""(zero-indexed) or a (extname, extver) tuple."The extname argument must be a string.The extver argument must be an integer.extver alone cannot specify an extension.Data must be a numpy array.fspathlocgetsize
    Allow file object to already be opened in any of the valid modes and
    and leave the file in the same state (opened or closed) as when
    the function was called.
    fmodeFile mode of the input file object () cannot be used to read/write FITS files.") cannot be used to ""read/write FITS files."# fallback to the first extension HDU# Change case of names if requested# this data does not have fields# allow different views into the underlying ndarray.  Keep the original# view just in case there is a problem# Avoid circular imports# Header to store Time related metadata# Not all tables with mixin columns are supported# Import is done here, in order to avoid it at build time as erfa is not# yet available then.# Only those columns which are instances of BaseColumn, Quantity or Time can# be written# Create a new HDU object# Fill masked values carefully:# float column's default mask value needs to be Nan and# string column's default mask should be an empty string.# Note: getting the fill value for the structured array is# more reliable than for individual columns for string entries.# (no 'N/A' for a single-element string, where it should be 'N').# Since multi-element columns with dtypes such as '2f8' have# a subdtype, we should look up the type of column on that.# TODO: it might be better to construct the FITS table directly from# the Table columns, rather than go via a structured array.# Binary FITS tables support TNULL *only* for integer data columns# TODO: Determine a schema for handling non-integer masked columns# with non-default fill values in FITS (if at all possible).# Be careful that we do not set null for columns that were not masked!# Set units and format display for output HDU# check for boolean types, special format case# Local imports to avoid importing units when it is not required,# e.g. for command-line scripts# Warn that the unit is lost, but let the details depend on# whether the column was serialized (because it was a# quantity), since then the unit can be recovered by astropy.# Try creating a Unit to issue a warning if the unit is not# FITS compliant# Column-specific override keywords for coordinate columns# Set the column coordinate attributes from data saved earlier.# Note: have to set these, even if we have no data.# Convert to FITS format# The input file or file like object either doesn't exits or is# empty.  Use the writeto convenience function to write the# output to the empty object.# Set a flag in the HDU so that only this HDU gets a checksum# when writing the file.# The arguments to this function are a bit trickier to deal with than others# in this module, since the documentation has promised that the header# argument can be an optional positional argument.# The header can also be a keyword argument--if both are provided the# keyword takes precedence# Set the default value for the ignore_missing_end parameter# Pop extension keywords# Use handy _getext to interpret any ext keywords, but# will need to close a if  fails# Have to close a if b doesn't make it# See below print for note# If input is not a string, can feed HDU objects or HDUList directly,# but can't currently handle extensions# This function is EXCLUSIVELY for printing the diff report to screen# in a one-liner call, hence the use of print instead of logging# allow file object to already be opened in any of the valid modes# and leave the file in the same state (opened or closed) as when# the function was called# Create the default data file name if one was not provided# Dump the data from the HDU to the files# This code would be much simpler if just one way of specifying an# extension were picked.  But now we need to support all possible ways for# the time being.# Must be either an extension number, an extension name, or an# (extname, extver) tuple# The first arg is an extension name; it could still be valid# to provide an extver kwarg# Take whatever we have as the ext argument; we'll validate it# below# Must be an extname and extver# The HDU type was unrecognized, possibly due to a# nonexistent/incomplete headerb'Convenience functions for working with FITS files.

Convenience functions
=====================

The functions in this module provide shortcuts for some of the most basic
operations on FITS files, such as reading and updating the header.  They are
included directly in the 'astropy.io.fits' namespace so that they can be used
like::

    astropy.io.fits.getheader(...)

These functions are primarily for convenience when working with FITS files in
the command-line interpreter.  If performing several operations on the same
file, such as in a script, it is better to *not* use these functions, as each
one must open and re-parse the file.  In such cases it is better to use
:func:`astropy.io.fits.open` and work directly with the
:class:`astropy.io.fits.HDUList` object and underlying HDU objects.

Several of the convenience functions, such as `getheader` and `getdata` support
special arguments for selecting which HDU to use when working with a
multi-extension FITS file.  There are a few supported argument formats for
selecting the HDU.  See the documentation for `getdata` for an
explanation of all the different formats.

.. warning::
    All arguments to convenience functions other than the filename that are
    *not* for selecting the HDU should be passed in as keyword
    arguments.  This is to avoid ambiguity and conflicts with the
    HDU arguments.  For example, to set NAXIS=1 on the Primary HDU:

    Wrong::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', 1)

    The above example will try to set the NAXIS value on the first extension
    HDU to blank.  That is, the argument '1' is assumed to specify an
    HDU.

    Right::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', value=1)

    This will set the NAXIS keyword to 1 on the primary HDU (the default).  To
    specify the first extension HDU use::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', value=1, ext=1)

    This complexity arises out of the attempt to simultaneously support
    multiple argument formats that were used in past versions of PyFITS.
    Unfortunately, it is not possible to support all formats without
    introducing some ambiguity.  A future Astropy release may standardize
    around a single format and officially deprecate the other formats.
'u'Convenience functions for working with FITS files.

Convenience functions
=====================

The functions in this module provide shortcuts for some of the most basic
operations on FITS files, such as reading and updating the header.  They are
included directly in the 'astropy.io.fits' namespace so that they can be used
like::

    astropy.io.fits.getheader(...)

These functions are primarily for convenience when working with FITS files in
the command-line interpreter.  If performing several operations on the same
file, such as in a script, it is better to *not* use these functions, as each
one must open and re-parse the file.  In such cases it is better to use
:func:`astropy.io.fits.open` and work directly with the
:class:`astropy.io.fits.HDUList` object and underlying HDU objects.

Several of the convenience functions, such as `getheader` and `getdata` support
special arguments for selecting which HDU to use when working with a
multi-extension FITS file.  There are a few supported argument formats for
selecting the HDU.  See the documentation for `getdata` for an
explanation of all the different formats.

.. warning::
    All arguments to convenience functions other than the filename that are
    *not* for selecting the HDU should be passed in as keyword
    arguments.  This is to avoid ambiguity and conflicts with the
    HDU arguments.  For example, to set NAXIS=1 on the Primary HDU:

    Wrong::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', 1)

    The above example will try to set the NAXIS value on the first extension
    HDU to blank.  That is, the argument '1' is assumed to specify an
    HDU.

    Right::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', value=1)

    This will set the NAXIS keyword to 1 on the primary HDU (the default).  To
    specify the first extension HDU use::

        astropy.io.fits.setval('myimage.fits', 'NAXIS', value=1, ext=1)

    This complexity arises out of the attempt to simultaneously support
    multiple argument formats that were used in past versions of PyFITS.
    Unfortunately, it is not possible to support all formats without
    introducing some ambiguity.  A future Astropy release may standardize
    around a single format and officially deprecate the other formats.
'b'append'u'append'b'delval'u'delval'b'getdata'u'getdata'b'getheader'u'getheader'b'getval'u'getval'b'printdiff'u'printdiff'b'setval'u'setval'b'table_to_hdu'u'table_to_hdu'b'tabledump'u'tabledump'b'tableload'u'tableload'b'update'u'update'b'
    Get the header from an HDU of a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        File to get header from.  If an opened file object, its mode
        must be one of the following rb, rb+, or ab+).

    ext, extname, extver
        The rest of the arguments are for HDU specification.  See the
        `getdata` documentation for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.

    Returns
    -------
    header : `Header` object
    'u'
    Get the header from an HDU of a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        File to get header from.  If an opened file object, its mode
        must be one of the following rb, rb+, or ab+).

    ext, extname, extver
        The rest of the arguments are for HDU specification.  See the
        `getdata` documentation for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.

    Returns
    -------
    header : `Header` object
    'b'
    Get the data from an HDU of a FITS file (and optionally the
    header).

    Parameters
    ----------
    filename : path-like or file-like
        File to get data from.  If opened, mode must be one of the
        following rb, rb+, or ab+.

    ext
        The rest of the arguments are for HDU specification.
        They are flexible and are best illustrated by examples.

        No extra arguments implies the primary HDU::

            getdata('in.fits')

        .. note::
            Exclusive to ``getdata``: if ``ext`` is not specified
            and primary header contains no data, ``getdata`` attempts
            to retrieve data from first extension HDU.

        By HDU number::

            getdata('in.fits', 0)      # the primary HDU
            getdata('in.fits', 2)      # the second extension HDU
            getdata('in.fits', ext=2)  # the second extension HDU

        By name, i.e., ``EXTNAME`` value (if unique)::

            getdata('in.fits', 'sci')
            getdata('in.fits', extname='sci')  # equivalent

        Note ``EXTNAME`` values are not case sensitive

        By combination of ``EXTNAME`` and EXTVER`` as separate
        arguments or as a tuple::

            getdata('in.fits', 'sci', 2)  # EXTNAME='SCI' & EXTVER=2
            getdata('in.fits', extname='sci', extver=2)  # equivalent
            getdata('in.fits', ('sci', 2))  # equivalent

        Ambiguous or conflicting specifications will raise an exception::

            getdata('in.fits', ext=('sci',1), extname='err', extver=2)

    header : bool, optional
        If `True`, return the data and the header of the specified HDU as a
        tuple.

    lower, upper : bool, optional
        If ``lower`` or ``upper`` are `True`, the field names in the
        returned data object will be converted to lower or upper case,
        respectively.

    view : ndarray, optional
        When given, the data will be returned wrapped in the given ndarray
        subclass by calling::

           data.view(view)

    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.

    Returns
    -------
    array : ndarray or `~numpy.recarray` or `~astropy.io.fits.Group`
        Type depends on the type of the extension being referenced.

        If the optional keyword ``header`` is set to `True`, this
        function will return a (``data``, ``header``) tuple.

    Raises
    ------
    IndexError
        If no data is found in searched HDUs.
    'u'
    Get the data from an HDU of a FITS file (and optionally the
    header).

    Parameters
    ----------
    filename : path-like or file-like
        File to get data from.  If opened, mode must be one of the
        following rb, rb+, or ab+.

    ext
        The rest of the arguments are for HDU specification.
        They are flexible and are best illustrated by examples.

        No extra arguments implies the primary HDU::

            getdata('in.fits')

        .. note::
            Exclusive to ``getdata``: if ``ext`` is not specified
            and primary header contains no data, ``getdata`` attempts
            to retrieve data from first extension HDU.

        By HDU number::

            getdata('in.fits', 0)      # the primary HDU
            getdata('in.fits', 2)      # the second extension HDU
            getdata('in.fits', ext=2)  # the second extension HDU

        By name, i.e., ``EXTNAME`` value (if unique)::

            getdata('in.fits', 'sci')
            getdata('in.fits', extname='sci')  # equivalent

        Note ``EXTNAME`` values are not case sensitive

        By combination of ``EXTNAME`` and EXTVER`` as separate
        arguments or as a tuple::

            getdata('in.fits', 'sci', 2)  # EXTNAME='SCI' & EXTVER=2
            getdata('in.fits', extname='sci', extver=2)  # equivalent
            getdata('in.fits', ('sci', 2))  # equivalent

        Ambiguous or conflicting specifications will raise an exception::

            getdata('in.fits', ext=('sci',1), extname='err', extver=2)

    header : bool, optional
        If `True`, return the data and the header of the specified HDU as a
        tuple.

    lower, upper : bool, optional
        If ``lower`` or ``upper`` are `True`, the field names in the
        returned data object will be converted to lower or upper case,
        respectively.

    view : ndarray, optional
        When given, the data will be returned wrapped in the given ndarray
        subclass by calling::

           data.view(view)

    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.

    Returns
    -------
    array : ndarray or `~numpy.recarray` or `~astropy.io.fits.Group`
        Type depends on the type of the extension being referenced.

        If the optional keyword ``header`` is set to `True`, this
        function will return a (``data``, ``header``) tuple.

    Raises
    ------
    IndexError
        If no data is found in searched HDUs.
    'b'ext'u'ext'b'extname'u'extname'b'extver'u'extver'b'No data in HDU #'u'No data in HDU #'b'No data in Primary HDU and no extension HDU found.'u'No data in Primary HDU and no extension HDU found.'b'No data in either Primary or first extension HDUs.'u'No data in either Primary or first extension HDUs.'b'upper'u'upper'b'
    Get a keyword's value from a header in a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object (if opened, mode must be
        one of the following rb, rb+, or ab+).

    keyword : str
        Keyword name

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.

    Returns
    -------
    keyword value : str, int, or float
    'u'
    Get a keyword's value from a header in a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object (if opened, mode must be
        one of the following rb, rb+, or ab+).

    keyword : str
        Keyword name

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.

    Returns
    -------
    keyword value : str, int, or float
    'b'
    Set a keyword's value from a header in a FITS file.

    If the keyword already exists, it's value/comment will be updated.
    If it does not exist, a new card will be created and it will be
    placed before or after the specified location.  If no ``before`` or
    ``after`` is specified, it will be appended at the end.

    When updating more than one keyword in a file, this convenience
    function is a much less efficient approach compared with opening
    the file for update, modifying the header, and closing the file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object If opened, mode must be update
        (rb+).  An opened file object or `~gzip.GzipFile` object will be closed
        upon return.

    keyword : str
        Keyword name

    value : str, int, float, optional
        Keyword value (default: `None`, meaning don't modify)

    comment : str, optional
        Keyword comment, (default: `None`, meaning don't modify)

    before : str, int, optional
        Name of the keyword, or index of the card before which the new card
        will be placed.  The argument ``before`` takes precedence over
        ``after`` if both are specified (default: `None`).

    after : str, int, optional
        Name of the keyword, or index of the card after which the new card will
        be placed. (default: `None`).

    savecomment : bool, optional
        When `True`, preserve the current comment for an existing keyword.  The
        argument ``savecomment`` takes precedence over ``comment`` if both
        specified.  If ``comment`` is not specified then the current comment
        will automatically be preserved  (default: `False`).

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.
    'u'
    Set a keyword's value from a header in a FITS file.

    If the keyword already exists, it's value/comment will be updated.
    If it does not exist, a new card will be created and it will be
    placed before or after the specified location.  If no ``before`` or
    ``after`` is specified, it will be appended at the end.

    When updating more than one keyword in a file, this convenience
    function is a much less efficient approach compared with opening
    the file for update, modifying the header, and closing the file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object If opened, mode must be update
        (rb+).  An opened file object or `~gzip.GzipFile` object will be closed
        upon return.

    keyword : str
        Keyword name

    value : str, int, float, optional
        Keyword value (default: `None`, meaning don't modify)

    comment : str, optional
        Keyword comment, (default: `None`, meaning don't modify)

    before : str, int, optional
        Name of the keyword, or index of the card before which the new card
        will be placed.  The argument ``before`` takes precedence over
        ``after`` if both are specified (default: `None`).

    after : str, int, optional
        Name of the keyword, or index of the card after which the new card will
        be placed. (default: `None`).

    savecomment : bool, optional
        When `True`, preserve the current comment for an existing keyword.  The
        argument ``savecomment`` takes precedence over ``comment`` if both
        specified.  If ``comment`` is not specified then the current comment
        will automatically be preserved  (default: `False`).

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.
    'b'
    Delete all instances of keyword from a header in a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object If opened, mode must be update
        (rb+).  An opened file object or `~gzip.GzipFile` object will be closed
        upon return.

    keyword : str, int
        Keyword name or index

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.
    'u'
    Delete all instances of keyword from a header in a FITS file.

    Parameters
    ----------
    filename : path-like or file-like
        Name of the FITS file, or file object If opened, mode must be update
        (rb+).  An opened file object or `~gzip.GzipFile` object will be closed
        upon return.

    keyword : str, int
        Keyword name or index

    ext, extname, extver
        The rest of the arguments are for HDU specification.
        See `getdata` for explanations/examples.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function automatically specifies ``do_not_scale_image_data
        = True`` when opening the file so that values can be retrieved from the
        unmodified header.
    'b'
    Create a new FITS file using the supplied data/header.

    Parameters
    ----------
    filename : path-like or file-like
        File to write to.  If opened, must be opened in a writable binary
        mode such as 'wb' or 'ab+'.

    data : array or `~numpy.recarray` or `~astropy.io.fits.Group`
        data to write to the new file

    header : `Header` object, optional
        the header associated with ``data``. If `None`, a header
        of the appropriate type is created for the supplied data. This
        argument is optional.

    output_verify : str
        Output verification option.  Must be one of ``"fix"``, ``"silentfix"``,
        ``"ignore"``, ``"warn"``, or ``"exception"``.  May also be any
        combination of ``"fix"`` or ``"silentfix"`` with ``"+ignore"``,
        ``+warn``, or ``+exception" (e.g. ``"fix+warn"``).  See
        :ref:`astropy:verify` for more info.

    overwrite : bool, optional
        If ``True``, overwrite the output file if it exists. Raises an
        ``OSError`` if ``False`` and the output file exists. Default is
        ``False``.

    checksum : bool, optional
        If `True`, adds both ``DATASUM`` and ``CHECKSUM`` cards to the
        headers of all HDU's written to the file.

    Notes
    -----
    gzip, zip, bzip2 and lzma compression algorithms are natively supported.
    Compression mode is determined from the filename extension
    ('.gz', '.zip', '.bz2' or '.xz' respectively).  It is also possible to pass
    a compressed file object, e.g. `gzip.GzipFile`.
    'u'
    Create a new FITS file using the supplied data/header.

    Parameters
    ----------
    filename : path-like or file-like
        File to write to.  If opened, must be opened in a writable binary
        mode such as 'wb' or 'ab+'.

    data : array or `~numpy.recarray` or `~astropy.io.fits.Group`
        data to write to the new file

    header : `Header` object, optional
        the header associated with ``data``. If `None`, a header
        of the appropriate type is created for the supplied data. This
        argument is optional.

    output_verify : str
        Output verification option.  Must be one of ``"fix"``, ``"silentfix"``,
        ``"ignore"``, ``"warn"``, or ``"exception"``.  May also be any
        combination of ``"fix"`` or ``"silentfix"`` with ``"+ignore"``,
        ``+warn``, or ``+exception" (e.g. ``"fix+warn"``).  See
        :ref:`astropy:verify` for more info.

    overwrite : bool, optional
        If ``True``, overwrite the output file if it exists. Raises an
        ``OSError`` if ``False`` and the output file exists. Default is
        ``False``.

    checksum : bool, optional
        If `True`, adds both ``DATASUM`` and ``CHECKSUM`` cards to the
        headers of all HDU's written to the file.

    Notes
    -----
    gzip, zip, bzip2 and lzma compression algorithms are natively supported.
    Compression mode is determined from the filename extension
    ('.gz', '.zip', '.bz2' or '.xz' respectively).  It is also possible to pass
    a compressed file object, e.g. `gzip.GzipFile`.
    'b'
    Convert an `~astropy.table.Table` object to a FITS
    `~astropy.io.fits.BinTableHDU`.

    Parameters
    ----------
    table : astropy.table.Table
        The table to convert.
    character_as_bytes : bool
        Whether to return bytes for string columns when accessed from the HDU.
        By default this is `False` and (unicode) strings are returned, but for
        large tables this may use up a lot of memory.

    Returns
    -------
    table_hdu : `~astropy.io.fits.BinTableHDU`
        The FITS binary table HDU.
    'u'
    Convert an `~astropy.table.Table` object to a FITS
    `~astropy.io.fits.BinTableHDU`.

    Parameters
    ----------
    table : astropy.table.Table
        The table to convert.
    character_as_bytes : bool
        Whether to return bytes for string columns when accessed from the HDU.
        By default this is `False` and (unicode) strings are returned, but for
        large tables this may use up a lot of memory.

    Returns
    -------
    table_hdu : `~astropy.io.fits.BinTableHDU`
        The FITS binary table HDU.
    'b'The column ''u'The column ''b'' could not be stored in FITS format because it has a scale '('u'' could not be stored in FITS format because it has a scale '('b')' that is not recognized by the FITS standard. Either scale the data or change the units.'u')' that is not recognized by the FITS standard. Either scale the data or change the units.'b'The unit ''u'The unit ''b'' could not be saved in native FITS format 'u'' could not be saved in native FITS format 'b'name: 'u'name: 'b'and hence will be lost to non-astropy fits readers. Within astropy, the unit can roundtrip using QTable, though one has to enable the unit before reading.'u'and hence will be lost to non-astropy fits readers. Within astropy, the unit can roundtrip using QTable, though one has to enable the unit before reading.'b'and cannot be recovered in reading. It can roundtrip within astropy by using QTable both to write and read back, though one has to enable the unit before reading.'u'and cannot be recovered in reading. It can roundtrip within astropy by using QTable both to write and read back, though one has to enable the unit before reading.'b'__coordinate_columns__'u'__coordinate_columns__'b'Meta-data keyword 'u'Meta-data keyword 'b' will be ignored since it conflicts with a FITS reserved keyword'u' will be ignored since it conflicts with a FITS reserved keyword'b'comment'u'comment'b'Attribute `'u'Attribute `'b'` of type 'u'` of type 'b' cannot be added to FITS Header - skipping'u' cannot be added to FITS Header - skipping'b'
    Append the header/data to FITS file if filename exists, create if not.

    If only ``data`` is supplied, a minimal header is created.

    Parameters
    ----------
    filename : path-like or file-like
        File to write to.  If opened, must be opened for update (rb+) unless it
        is a new file, then it must be opened for append (ab+).  A file or
        `~gzip.GzipFile` object opened for update will be closed after return.

    data : array, :class:`~astropy.table.Table`, or `~astropy.io.fits.Group`
        The new data used for appending.

    header : `Header` object, optional
        The header associated with ``data``.  If `None`, an appropriate header
        will be created for the data object supplied.

    checksum : bool, optional
        When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards to the header
        of the HDU when written to the file.

    verify : bool, optional
        When `True`, the existing FITS file will be read in to verify it for
        correctness before appending.  When `False`, content is simply appended
        to the end of the file.  Setting ``verify`` to `False` can be much
        faster.

    **kwargs
        Additional arguments are passed to:

        - `~astropy.io.fits.writeto` if the file does not exist or is empty.
          In this case ``output_verify`` is the only possible argument.
        - `~astropy.io.fits.open` if ``verify`` is True or if ``filename``
          is a file object.
        - Otherwise no additional arguments can be used.

    'u'
    Append the header/data to FITS file if filename exists, create if not.

    If only ``data`` is supplied, a minimal header is created.

    Parameters
    ----------
    filename : path-like or file-like
        File to write to.  If opened, must be opened for update (rb+) unless it
        is a new file, then it must be opened for append (ab+).  A file or
        `~gzip.GzipFile` object opened for update will be closed after return.

    data : array, :class:`~astropy.table.Table`, or `~astropy.io.fits.Group`
        The new data used for appending.

    header : `Header` object, optional
        The header associated with ``data``.  If `None`, an appropriate header
        will be created for the data object supplied.

    checksum : bool, optional
        When `True` adds both ``DATASUM`` and ``CHECKSUM`` cards to the header
        of the HDU when written to the file.

    verify : bool, optional
        When `True`, the existing FITS file will be read in to verify it for
        correctness before appending.  When `False`, content is simply appended
        to the end of the file.  Setting ``verify`` to `False` can be much
        faster.

    **kwargs
        Additional arguments are passed to:

        - `~astropy.io.fits.writeto` if the file does not exist or is empty.
          In this case ``output_verify`` is the only possible argument.
        - `~astropy.io.fits.open` if ``verify`` is True or if ``filename``
          is a file object.
        - Otherwise no additional arguments can be used.

    'b'
    Update the specified HDU with the input data/header.

    Parameters
    ----------
    filename : path-like or file-like
        File to update.  If opened, mode must be update (rb+).  An opened file
        object or `~gzip.GzipFile` object will be closed upon return.

    data : array, `~astropy.table.Table`, or `~astropy.io.fits.Group`
        The new data used for updating.

    header : `Header` object, optional
        The header associated with ``data``.  If `None`, an appropriate header
        will be created for the data object supplied.

    ext, extname, extver
        The rest of the arguments are flexible: the 3rd argument can be the
        header associated with the data.  If the 3rd argument is not a
        `Header`, it (and other positional arguments) are assumed to be the
        HDU specification(s).  Header and HDU specs can also be
        keyword arguments.  For example::

            update(file, dat, hdr, 'sci')  # update the 'sci' extension
            update(file, dat, 3)  # update the 3rd extension HDU
            update(file, dat, hdr, 3)  # update the 3rd extension HDU
            update(file, dat, 'sci', 2)  # update the 2nd extension HDU named 'sci'
            update(file, dat, 3, header=hdr)  # update the 3rd extension HDU
            update(file, dat, header=hdr, ext=5)  # update the 5th extension HDU

    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
    'u'
    Update the specified HDU with the input data/header.

    Parameters
    ----------
    filename : path-like or file-like
        File to update.  If opened, mode must be update (rb+).  An opened file
        object or `~gzip.GzipFile` object will be closed upon return.

    data : array, `~astropy.table.Table`, or `~astropy.io.fits.Group`
        The new data used for updating.

    header : `Header` object, optional
        The header associated with ``data``.  If `None`, an appropriate header
        will be created for the data object supplied.

    ext, extname, extver
        The rest of the arguments are flexible: the 3rd argument can be the
        header associated with the data.  If the 3rd argument is not a
        `Header`, it (and other positional arguments) are assumed to be the
        HDU specification(s).  Header and HDU specs can also be
        keyword arguments.  For example::

            update(file, dat, hdr, 'sci')  # update the 'sci' extension
            update(file, dat, 3)  # update the 3rd extension HDU
            update(file, dat, hdr, 3)  # update the 3rd extension HDU
            update(file, dat, 'sci', 2)  # update the 2nd extension HDU named 'sci'
            update(file, dat, 3, header=hdr)  # update the 3rd extension HDU
            update(file, dat, header=hdr, ext=5)  # update the 5th extension HDU

    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
    'b'
    Print the summary information on a FITS file.

    This includes the name, type, length of header, data shape and type
    for each HDU.

    Parameters
    ----------
    filename : path-like or file-like
        FITS file to obtain info from.  If opened, mode must be one of
        the following: rb, rb+, or ab+ (i.e. the file must be readable).

    output : file, bool, optional
        A file-like object to write the output to.  If ``False``, does not
        output to a file and instead returns a list of tuples representing the
        HDU info.  Writes to ``sys.stdout`` by default.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function sets ``ignore_missing_end=True`` by default.
    'u'
    Print the summary information on a FITS file.

    This includes the name, type, length of header, data shape and type
    for each HDU.

    Parameters
    ----------
    filename : path-like or file-like
        FITS file to obtain info from.  If opened, mode must be one of
        the following: rb, rb+, or ab+ (i.e. the file must be readable).

    output : file, bool, optional
        A file-like object to write the output to.  If ``False``, does not
        output to a file and instead returns a list of tuples representing the
        HDU info.  Writes to ``sys.stdout`` by default.
    **kwargs
        Any additional keyword arguments to be passed to
        `astropy.io.fits.open`.
        *Note:* This function sets ``ignore_missing_end=True`` by default.
    'b'ignore_missing_end'u'ignore_missing_end'b'
    Compare two parts of a FITS file, including entire FITS files,
    FITS `HDUList` objects and FITS ``HDU`` objects.

    Parameters
    ----------
    inputa : str, `HDUList` object, or ``HDU`` object
        The filename of a FITS file, `HDUList`, or ``HDU``
        object to compare to ``inputb``.

    inputb : str, `HDUList` object, or ``HDU`` object
        The filename of a FITS file, `HDUList`, or ``HDU``
        object to compare to ``inputa``.

    ext, extname, extver
        Additional positional arguments are for HDU specification if your
        inputs are string filenames (will not work if
        ``inputa`` and ``inputb`` are ``HDU`` objects or `HDUList` objects).
        They are flexible and are best illustrated by examples.  In addition
        to using these arguments positionally you can directly call the
        keyword parameters ``ext``, ``extname``.

        By HDU number::

            printdiff('inA.fits', 'inB.fits', 0)      # the primary HDU
            printdiff('inA.fits', 'inB.fits', 2)      # the second extension HDU
            printdiff('inA.fits', 'inB.fits', ext=2)  # the second extension HDU

        By name, i.e., ``EXTNAME`` value (if unique). ``EXTNAME`` values are
        not case sensitive:

            printdiff('inA.fits', 'inB.fits', 'sci')
            printdiff('inA.fits', 'inB.fits', extname='sci')  # equivalent

        By combination of ``EXTNAME`` and ``EXTVER`` as separate
        arguments or as a tuple::

            printdiff('inA.fits', 'inB.fits', 'sci', 2)    # EXTNAME='SCI'
                                                           # & EXTVER=2
            printdiff('inA.fits', 'inB.fits', extname='sci', extver=2)
                                                           # equivalent
            printdiff('inA.fits', 'inB.fits', ('sci', 2))  # equivalent

        Ambiguous or conflicting specifications will raise an exception::

            printdiff('inA.fits', 'inB.fits',
                      ext=('sci', 1), extname='err', extver=2)

    **kwargs
        Any additional keyword arguments to be passed to
        `~astropy.io.fits.FITSDiff`.

    Notes
    -----
    The primary use for the `printdiff` function is to allow quick print out
    of a FITS difference report and will write to ``sys.stdout``.
    To save the diff report to a file please use `~astropy.io.fits.FITSDiff`
    directly.
    'u'
    Compare two parts of a FITS file, including entire FITS files,
    FITS `HDUList` objects and FITS ``HDU`` objects.

    Parameters
    ----------
    inputa : str, `HDUList` object, or ``HDU`` object
        The filename of a FITS file, `HDUList`, or ``HDU``
        object to compare to ``inputb``.

    inputb : str, `HDUList` object, or ``HDU`` object
        The filename of a FITS file, `HDUList`, or ``HDU``
        object to compare to ``inputa``.

    ext, extname, extver
        Additional positional arguments are for HDU specification if your
        inputs are string filenames (will not work if
        ``inputa`` and ``inputb`` are ``HDU`` objects or `HDUList` objects).
        They are flexible and are best illustrated by examples.  In addition
        to using these arguments positionally you can directly call the
        keyword parameters ``ext``, ``extname``.

        By HDU number::

            printdiff('inA.fits', 'inB.fits', 0)      # the primary HDU
            printdiff('inA.fits', 'inB.fits', 2)      # the second extension HDU
            printdiff('inA.fits', 'inB.fits', ext=2)  # the second extension HDU

        By name, i.e., ``EXTNAME`` value (if unique). ``EXTNAME`` values are
        not case sensitive:

            printdiff('inA.fits', 'inB.fits', 'sci')
            printdiff('inA.fits', 'inB.fits', extname='sci')  # equivalent

        By combination of ``EXTNAME`` and ``EXTVER`` as separate
        arguments or as a tuple::

            printdiff('inA.fits', 'inB.fits', 'sci', 2)    # EXTNAME='SCI'
                                                           # & EXTVER=2
            printdiff('inA.fits', 'inB.fits', extname='sci', extver=2)
                                                           # equivalent
            printdiff('inA.fits', 'inB.fits', ('sci', 2))  # equivalent

        Ambiguous or conflicting specifications will raise an exception::

            printdiff('inA.fits', 'inB.fits',
                      ext=('sci', 1), extname='err', extver=2)

    **kwargs
        Any additional keyword arguments to be passed to
        `~astropy.io.fits.FITSDiff`.

    Notes
    -----
    The primary use for the `printdiff` function is to allow quick print out
    of a FITS difference report and will write to ``sys.stdout``.
    To save the diff report to a file please use `~astropy.io.fits.FITSDiff`
    directly.
    'b'Cannot use extension keywords when providing an HDU object.'u'Cannot use extension keywords when providing an HDU object.'b'Extension specification with HDUList objects not implemented.'u'Extension specification with HDUList objects not implemented.'b'
    Dump a table HDU to a file in ASCII format.  The table may be
    dumped in three separate files, one containing column definitions,
    one containing header parameters, and one for table data.

    Parameters
    ----------
    filename : path-like or file-like
        Input fits file.

    datafile : path-like or file-like, optional
        Output data file.  The default is the root name of the input
        fits file appended with an underscore, followed by the
        extension number (ext), followed by the extension ``.txt``.

    cdfile : path-like or file-like, optional
        Output column definitions file.  The default is `None`,
        no column definitions output is produced.

    hfile : path-like or file-like, optional
        Output header parameters file.  The default is `None`,
        no header parameters output is produced.

    ext : int
        The number of the extension containing the table HDU to be
        dumped.

    overwrite : bool, optional
        If ``True``, overwrite the output file if it exists. Raises an
        ``OSError`` if ``False`` and the output file exists. Default is
        ``False``.

    Notes
    -----
    The primary use for the `tabledump` function is to allow editing in a
    standard text editor of the table data and parameters.  The
    `tableload` function can be used to reassemble the table from the
    three ASCII files.
    'u'
    Dump a table HDU to a file in ASCII format.  The table may be
    dumped in three separate files, one containing column definitions,
    one containing header parameters, and one for table data.

    Parameters
    ----------
    filename : path-like or file-like
        Input fits file.

    datafile : path-like or file-like, optional
        Output data file.  The default is the root name of the input
        fits file appended with an underscore, followed by the
        extension number (ext), followed by the extension ``.txt``.

    cdfile : path-like or file-like, optional
        Output column definitions file.  The default is `None`,
        no column definitions output is produced.

    hfile : path-like or file-like, optional
        Output header parameters file.  The default is `None`,
        no header parameters output is produced.

    ext : int
        The number of the extension containing the table HDU to be
        dumped.

    overwrite : bool, optional
        If ``True``, overwrite the output file if it exists. Raises an
        ``OSError`` if ``False`` and the output file exists. Default is
        ``False``.

    Notes
    -----
    The primary use for the `tabledump` function is to allow editing in a
    standard text editor of the table data and parameters.  The
    `tableload` function can be used to reassemble the table from the
    three ASCII files.
    'b'.txt'u'.txt'b'
    Create a table from the input ASCII files.  The input is from up
    to three separate files, one containing column definitions, one
    containing header parameters, and one containing column data.  The
    header parameters file is not required.  When the header
    parameters file is absent a minimal header is constructed.

    Parameters
    ----------
    datafile : path-like or file-like
        Input data file containing the table data in ASCII format.

    cdfile : path-like or file-like
        Input column definition file containing the names, formats,
        display formats, physical units, multidimensional array
        dimensions, undefined values, scale factors, and offsets
        associated with the columns in the table.

    hfile : path-like or file-like, optional
        Input parameter definition file containing the header
        parameter definitions to be associated with the table.
        If `None`, a minimal header is constructed.

    Notes
    -----
    The primary use for the `tableload` function is to allow the input of
    ASCII data that was edited in a standard text editor of the table
    data and parameters.  The tabledump function can be used to create the
    initial ASCII files.
    'u'
    Create a table from the input ASCII files.  The input is from up
    to three separate files, one containing column definitions, one
    containing header parameters, and one containing column data.  The
    header parameters file is not required.  When the header
    parameters file is absent a minimal header is constructed.

    Parameters
    ----------
    datafile : path-like or file-like
        Input data file containing the table data in ASCII format.

    cdfile : path-like or file-like
        Input column definition file containing the names, formats,
        display formats, physical units, multidimensional array
        dimensions, undefined values, scale factors, and offsets
        associated with the columns in the table.

    hfile : path-like or file-like, optional
        Input parameter definition file containing the header
        parameter definitions to be associated with the table.
        If `None`, a minimal header is constructed.

    Notes
    -----
    The primary use for the `tableload` function is to allow the input of
    ASCII data that was edited in a standard text editor of the table
    data and parameters.  The tabledump function can be used to create the
    initial ASCII files.
    'b'
    Open the input file, return the `HDUList` and the extension.

    This supports several different styles of extension selection.  See the
    :func:`getdata()` documentation for the different possibilities.
    'u'
    Open the input file, return the `HDUList` and the extension.

    This supports several different styles of extension selection.  See the
    :func:`getdata()` documentation for the different possibilities.
    'b'Redundant/conflicting extension arguments(s): {}'u'Redundant/conflicting extension arguments(s): {}'b'args'u'args'b'Too many positional arguments.'u'Too many positional arguments.'b'The ext keyword must be either an extension number (zero-indexed) or a (extname, extver) tuple.'u'The ext keyword must be either an extension number (zero-indexed) or a (extname, extver) tuple.'b'The extname argument must be a string.'u'The extname argument must be a string.'b'The extver argument must be an integer.'u'The extver argument must be an integer.'b'extver alone cannot specify an extension.'u'extver alone cannot specify an extension.'b'Data must be a numpy array.'u'Data must be a numpy array.'b'
    Allow file object to already be opened in any of the valid modes and
    and leave the file in the same state (opened or closed) as when
    the function was called.
    'u'
    Allow file object to already be opened in any of the valid modes and
    and leave the file in the same state (opened or closed) as when
    the function was called.
    'b'File mode of the input file object ('u'File mode of the input file object ('b') cannot be used to read/write FITS files.'u') cannot be used to read/write FITS files.'u'astropy.io.fits.convenience'u'io.fits.convenience'u'fits.convenience'u'convenience'FValidateCallable_REGISTRY_FVALIDATORS_register_validatorDecorator to register a new kind of validator function.

    Parameters
    ----------
    key : str
    fvalidate : callable[[object, object, Any], Any] or None, optional
        Value validation function.

    Returns
    -------
    ``validator`` or callable[``validator``]
        if validator is None returns a function that takes and registers a
        validator. This allows ``register_validator`` to be used as a
        decorator.
    validator  already registered with Parameter.Register validator function.

        Parameters
        ----------
        fvalidate : callable[[object, object, Any], Any]
            Validation function.

        Returns
        -------
        ``validator``
        Default Parameter value validator.

    Adds/converts units if Parameter has a unit.
    add_enabled_equivalenciesParameter value validator with units, and converted to float. is a non-scalar quantityParameter value validator where value is a positive float. cannot be negative.# fvalidate directly passed# for use as a decorator# ======================================================================b'Decorator to register a new kind of validator function.

    Parameters
    ----------
    key : str
    fvalidate : callable[[object, object, Any], Any] or None, optional
        Value validation function.

    Returns
    -------
    ``validator`` or callable[``validator``]
        if validator is None returns a function that takes and registers a
        validator. This allows ``register_validator`` to be used as a
        decorator.
    'u'Decorator to register a new kind of validator function.

    Parameters
    ----------
    key : str
    fvalidate : callable[[object, object, Any], Any] or None, optional
        Value validation function.

    Returns
    -------
    ``validator`` or callable[``validator``]
        if validator is None returns a function that takes and registers a
        validator. This allows ``register_validator`` to be used as a
        decorator.
    'b'validator 'u'validator 'b' already registered with Parameter.'u' already registered with Parameter.'b'Register validator function.

        Parameters
        ----------
        fvalidate : callable[[object, object, Any], Any]
            Validation function.

        Returns
        -------
        ``validator``
        'u'Register validator function.

        Parameters
        ----------
        fvalidate : callable[[object, object, Any], Any]
            Validation function.

        Returns
        -------
        ``validator``
        'b'Default Parameter value validator.

    Adds/converts units if Parameter has a unit.
    'u'Default Parameter value validator.

    Adds/converts units if Parameter has a unit.
    'b'Parameter value validator with units, and converted to float.'u'Parameter value validator with units, and converted to float.'b' is a non-scalar quantity'u' is a non-scalar quantity'b'Parameter value validator where value is a positive float.'u'Parameter value validator where value is a positive float.'b' cannot be negative.'u' cannot be negative.'u'cosmology._src.parameter.converter'u'_src.parameter.converter'u'parameter.converter'u'converter'
This module handles the conversion of various VOTABLE datatypes
to/from TABLEDATA_ and BINARY_ formats.
xml_escape_cdataE01E02E03E04E05E06E24W01W30W31W39W46W47W49W51W55vo_raisevo_warnwarn_or_raiseConverterget_convertertable_column_to_votable_datatype +pedantic_array_splitter\s+|(?:\s*,\s*)array_splitter
A regex to handle splitting values on either whitespace or commas.

SPEC: Usage of commas is not actually allowed by the spec, but many
files in the wild use them.
    _zero_int_empty_bytes_zero_byte_ensure_bigendian_make_masked_array
    Masked arrays of zero length that also have a mask of zero length
    cause problems in Numpy (at least in 1.6.2).  This function
    creates a masked array from data and a mask, unless it is zero
    length.
    bitarray_to_bool
    Converts a bit array (a string of bits in a bytes object) to a
    boolean Numpy array.

    Parameters
    ----------
    data : bytes
        The bit array.  The most significant byte is read first.

    length : int
        The number of bits to read.  The least significant bits in the
        data bytes beyond length will be ignored.

    Returns
    -------
    array : numpy bool array
    bit_nobool_to_bitarray
    Converts a numpy boolean array to a bit array (a string of bits in
    a bytes object).

    Parameters
    ----------
    value : numpy bool array

    Returns
    -------
    bit_array : bytes
        The first value in the input array will be the most
        significant bit in the result.  The length will be `floor((N +
        7) / 8)` where `N` is the length of `value`.
    
    The base class for all converters.  Each subclass handles
    converting a specific VOTABLE data type to/from the TABLEDATA_ and
    BINARY_ on-disk representations.

    Parameters
    ----------
    field : `~astropy.io.votable.tree.Field`
        object describing the datatype

    config : dict
        The parser configuration dictionary

    pos : tuple
        The position in the XML file where the FIELD object was
        found.  Used for error messages.

    _parse_length>I_write_lengthsupports_empty_values
        Returns True when the field can be completely empty.
        version_1_3_or_later
        Convert the string *value* from the TABLEDATA_ format into an
        object with the correct native in-memory datatype and mask flag.

        Parameters
        ----------
        value : str
            value in TABLEDATA format

        Returns
        -------
        native : tuple
            A two-element tuple of: value, mask.
            The value as a Numpy array or scalar, and *mask* is True
            if the value is missing.
        This datatype must implement a 'parse' method.parse_scalar
        Parse a single scalar of the underlying type of the converter.
        For non-array converters, this is equivalent to parse.  For
        array converters, this is used to parse a single
        element of the array.

        Parameters
        ----------
        value : str
            value in TABLEDATA format

        Returns
        -------
        native : (2,) tuple
            (value, mask)
            The value as a Numpy array or scalar, and *mask* is True
            if the value is missing.
        
        Convert the object *value* (in the native in-memory datatype)
        to a unicode string suitable for serializing in the TABLEDATA_
        format.

        Parameters
        ----------
        value
            The value, the native type corresponding to this converter

        mask : bool
            If `True`, will return the string representation of a
            masked value.

        Returns
        -------
        tabledata_repr : unicode
        This datatype must implement a 'output' method.binparse
        Reads some number of bytes from the BINARY_ format
        representation by calling the function *read*, and returns the
        native in-memory object representation for the datatype
        handled by *self*.

        Parameters
        ----------
        read : function
            A function that given a number of bytes, returns a byte
            string.

        Returns
        -------
        native : (2,) tuple
            (value, mask). The value as a Numpy array or scalar, and *mask* is
            True if the value is missing.
        This datatype must implement a 'binparse' method.binoutput
        Convert the object *value* in the native in-memory datatype to
        a string of bytes suitable for serialization in the BINARY_
        format.

        Parameters
        ----------
        value
            The value, the native type corresponding to this converter

        mask : bool
            If `True`, will return the string representation of a
            masked value.

        Returns
        -------
        bytes : bytes
            The binary representation of the value, suitable for
            serialization in the BINARY_ format.
        This datatype must implement a 'binoutput' method.Char
    Handles the char datatype. (7-bit unsigned characters).

    Missing values are not handled for string or unicode types.
    field_namearraysize_binparse_var_binoutput_var_binparse_fixed_binoutput_fixed_struct_formatUnicodeChar
    Handles the unicodeChar data type. UTF-16-BE.

    Missing values are not handled for string or unicode types.
    unicodeCharencoded
    Handles both fixed and variable-lengths arrays.
    _splitter_pedantic_splitter_splitter_lax_baseVarArray
    Handles variable lengths arrays (i.e. where *arraysize* is '*').
    result_maskArrayVarArray
    Handles an array of variable-length arrays, i.e. where *arraysize*
    ends in '*'.
    parse_partsScalarVarArray
    Handles a variable-length array of numeric scalars.
    NumericArray
    Handles a fixed-length array of numeric scalars.
    vararray_type_arraysize_memsize_bigendian_formatbase_parsebase_outputis_nullfilter_arrayfilteredNumeric
    The base class for all numeric data types.
    array_type_is_nullFloatingPoint
    The base class for floating-point datatypes.
    {!s:>format_parts_output_formatNaN_null_output_null_binoutput_filter_nan_filter_null_parse_pedantic_parse_permissiveisposinf+InFisneginf-InFInvalid floating point value 'Double
    Handles the double datatype.  Double-precision IEEE
    floating-point.
    Float
    Handles the float datatype.  Single-precision IEEE floating-point.
    Integer
    The base class for all the integral datatypes.
    0xval_rangebit_sizeUnsignedByte
    Handles the unsignedByte datatype.  Unsigned 8-bit integer.
    8-bit unsignedShort
    Handles the short datatype.  Signed 16-bit integer.
    327683276716-bitInt
    Handles the int datatype.  Signed 32-bit integer.
    214748364732-bitLong
    Handles the long datatype.  Signed 64-bit integer.
    922337203685477580864-bitComplexArrayVarArray
    Handles an array of variable-length arrays of complex numbers.
    ComplexVarArray
    Handles a variable-length array of complex numbers.
    ComplexArray
    Handles a fixed-size array of complex numbers.
    Complex
    The base class for complex numbers.
    strippedFloatComplex
    Handle floatComplex datatype.  Pair of single-precision IEEE
    floating-point numbers.
    DoubleComplex
    Handle doubleComplex datatype.  Pair of double-precision IEEE
    floating-point numbers.
    BitArray
    Handles an array of bits.
    _bytes\s\s|,Bit
    Handles the bit datatype.
    binary_onebinary_zero0x8BooleanArray
    Handles an array of boolean values.
    binparse_valueBoolean
    Handles the boolean datatype.
    binary_question_markbinary_truebinary_falseTRUEFALSE_binparse_mappingdoubleunsignedBytelongfloatComplexdoubleComplexconverter_mapping
    Get an appropriate converter instance for a given field.

    Parameters
    ----------
    field : astropy.io.votable.tree.Field

    config : dict, optional
        Parser configuration dictionary

    pos : tuple
        Position in the input XML file.  Used for error messages.

    Returns
    -------
    converter : astropy.io.votable.converters.Converter
    last_xfixedcomplex64complex128str_numpy_dtype_to_field_mapping_all_matching_dtypefirst_dtypefirst_shapenumpy_to_votable_dtype
    Converts a numpy dtype and shape to a dictionary of attributes for
    a VOTable FIELD element and correspond to that type.

    Parameters
    ----------
    dtype : Numpy dtype instance

    shape : tuple

    Returns
    -------
    attributes : dict
        A dict containing 'datatype' and 'arraysize' keys that can be
        set on a VOTable FIELD element.
     can not be represented in VOTable
    Given a `astropy.table.Column` instance, returns the attributes
    necessary to create a VOTable FIELD element that corresponds to
    the type of the column.

    This necessarily must perform some heuristics to determine the
    type of variable length arrays fields, since they are not directly
    supported by Numpy.

    If the column has dtype of "object", it performs the following
    tests:

       - If all elements are byte or unicode strings, it creates a
         variable-length byte or unicode field, respectively.

       - If all elements are numpy arrays of the same dtype and with a
         consistent shape in all but the first dimension, it creates a
         variable length array of fixed sized arrays.  If the dtypes
         match, but the shapes do not, a variable length array is
         created.

    If the dtype of the input is not understood, it sets the data type
    to the most inclusive: a variable length unicodeChar array.

    Parameters
    ----------
    column : `astropy.table.Column` instance

    Returns
    -------
    attributes : dict
        A dict containing 'datatype' and 'arraysize' keys that can be
        set on a VOTable FIELD element.
    votable_string_dtype_votable_string_dtype# STDLIB# THIRD-PARTY# ASTROPY# LOCAL# np.ma doesn't like setting mask to []# Warn about non-ascii characters if warnings are enabled.# The output methods for Char assume that value is either str or bytes.# This method needs to return a str, but needs to warn if the str contains# non-ASCII characters.# Check for non-ASCII chars in the bytes object.# Convert the bytes to str regardless of non-ASCII chars.# When mask is already array but value is scalar, this prevents broadcast# IRSA VOTables use the word 'null' to specify empty values,# but this is not defined in the VOTable spec.# Should never raise# With numeric datatypes, special things need to happen for# arrays.# All bets are off, do the most generic thing# For fixed size string columns, datatype here will be unicodeChar,# but honor the original FIELD datatype if present.b'
This module handles the conversion of various VOTABLE datatypes
to/from TABLEDATA_ and BINARY_ formats.
'u'
This module handles the conversion of various VOTABLE datatypes
to/from TABLEDATA_ and BINARY_ formats.
'b'Converter'u'Converter'b'get_converter'u'get_converter'b'table_column_to_votable_datatype'u'table_column_to_votable_datatype'b' +'u' +'b'\s+|(?:\s*,\s*)'u'\s+|(?:\s*,\s*)'b'
A regex to handle splitting values on either whitespace or commas.

SPEC: Usage of commas is not actually allowed by the spec, but many
files in the wild use them.
'u'
A regex to handle splitting values on either whitespace or commas.

SPEC: Usage of commas is not actually allowed by the spec, but many
files in the wild use them.
'b'    'b'
    Masked arrays of zero length that also have a mask of zero length
    cause problems in Numpy (at least in 1.6.2).  This function
    creates a masked array from data and a mask, unless it is zero
    length.
    'u'
    Masked arrays of zero length that also have a mask of zero length
    cause problems in Numpy (at least in 1.6.2).  This function
    creates a masked array from data and a mask, unless it is zero
    length.
    'b'
    Converts a bit array (a string of bits in a bytes object) to a
    boolean Numpy array.

    Parameters
    ----------
    data : bytes
        The bit array.  The most significant byte is read first.

    length : int
        The number of bits to read.  The least significant bits in the
        data bytes beyond length will be ignored.

    Returns
    -------
    array : numpy bool array
    'u'
    Converts a bit array (a string of bits in a bytes object) to a
    boolean Numpy array.

    Parameters
    ----------
    data : bytes
        The bit array.  The most significant byte is read first.

    length : int
        The number of bits to read.  The least significant bits in the
        data bytes beyond length will be ignored.

    Returns
    -------
    array : numpy bool array
    'b'
    Converts a numpy boolean array to a bit array (a string of bits in
    a bytes object).

    Parameters
    ----------
    value : numpy bool array

    Returns
    -------
    bit_array : bytes
        The first value in the input array will be the most
        significant bit in the result.  The length will be `floor((N +
        7) / 8)` where `N` is the length of `value`.
    'u'
    Converts a numpy boolean array to a bit array (a string of bits in
    a bytes object).

    Parameters
    ----------
    value : numpy bool array

    Returns
    -------
    bit_array : bytes
        The first value in the input array will be the most
        significant bit in the result.  The length will be `floor((N +
        7) / 8)` where `N` is the length of `value`.
    'b'
    The base class for all converters.  Each subclass handles
    converting a specific VOTABLE data type to/from the TABLEDATA_ and
    BINARY_ on-disk representations.

    Parameters
    ----------
    field : `~astropy.io.votable.tree.Field`
        object describing the datatype

    config : dict
        The parser configuration dictionary

    pos : tuple
        The position in the XML file where the FIELD object was
        found.  Used for error messages.

    'u'
    The base class for all converters.  Each subclass handles
    converting a specific VOTABLE data type to/from the TABLEDATA_ and
    BINARY_ on-disk representations.

    Parameters
    ----------
    field : `~astropy.io.votable.tree.Field`
        object describing the datatype

    config : dict
        The parser configuration dictionary

    pos : tuple
        The position in the XML file where the FIELD object was
        found.  Used for error messages.

    'b'>I'u'>I'b'
        Returns True when the field can be completely empty.
        'u'
        Returns True when the field can be completely empty.
        'b'version_1_3_or_later'u'version_1_3_or_later'b'
        Convert the string *value* from the TABLEDATA_ format into an
        object with the correct native in-memory datatype and mask flag.

        Parameters
        ----------
        value : str
            value in TABLEDATA format

        Returns
        -------
        native : tuple
            A two-element tuple of: value, mask.
            The value as a Numpy array or scalar, and *mask* is True
            if the value is missing.
        'u'
        Convert the string *value* from the TABLEDATA_ format into an
        object with the correct native in-memory datatype and mask flag.

        Parameters
        ----------
        value : str
            value in TABLEDATA format

        Returns
        -------
        native : tuple
            A two-element tuple of: value, mask.
            The value as a Numpy array or scalar, and *mask* is True
            if the value is missing.
        'b'This datatype must implement a 'parse' method.'u'This datatype must implement a 'parse' method.'b'
        Parse a single scalar of the underlying type of the converter.
        For non-array converters, this is equivalent to parse.  For
        array converters, this is used to parse a single
        element of the array.

        Parameters
        ----------
        value : str
            value in TABLEDATA format

        Returns
        -------
        native : (2,) tuple
            (value, mask)
            The value as a Numpy array or scalar, and *mask* is True
            if the value is missing.
        'u'
        Parse a single scalar of the underlying type of the converter.
        For non-array converters, this is equivalent to parse.  For
        array converters, this is used to parse a single
        element of the array.

        Parameters
        ----------
        value : str
            value in TABLEDATA format

        Returns
        -------
        native : (2,) tuple
            (value, mask)
            The value as a Numpy array or scalar, and *mask* is True
            if the value is missing.
        'b'
        Convert the object *value* (in the native in-memory datatype)
        to a unicode string suitable for serializing in the TABLEDATA_
        format.

        Parameters
        ----------
        value
            The value, the native type corresponding to this converter

        mask : bool
            If `True`, will return the string representation of a
            masked value.

        Returns
        -------
        tabledata_repr : unicode
        'u'
        Convert the object *value* (in the native in-memory datatype)
        to a unicode string suitable for serializing in the TABLEDATA_
        format.

        Parameters
        ----------
        value
            The value, the native type corresponding to this converter

        mask : bool
            If `True`, will return the string representation of a
            masked value.

        Returns
        -------
        tabledata_repr : unicode
        'b'This datatype must implement a 'output' method.'u'This datatype must implement a 'output' method.'b'
        Reads some number of bytes from the BINARY_ format
        representation by calling the function *read*, and returns the
        native in-memory object representation for the datatype
        handled by *self*.

        Parameters
        ----------
        read : function
            A function that given a number of bytes, returns a byte
            string.

        Returns
        -------
        native : (2,) tuple
            (value, mask). The value as a Numpy array or scalar, and *mask* is
            True if the value is missing.
        'u'
        Reads some number of bytes from the BINARY_ format
        representation by calling the function *read*, and returns the
        native in-memory object representation for the datatype
        handled by *self*.

        Parameters
        ----------
        read : function
            A function that given a number of bytes, returns a byte
            string.

        Returns
        -------
        native : (2,) tuple
            (value, mask). The value as a Numpy array or scalar, and *mask* is
            True if the value is missing.
        'b'This datatype must implement a 'binparse' method.'u'This datatype must implement a 'binparse' method.'b'
        Convert the object *value* in the native in-memory datatype to
        a string of bytes suitable for serialization in the BINARY_
        format.

        Parameters
        ----------
        value
            The value, the native type corresponding to this converter

        mask : bool
            If `True`, will return the string representation of a
            masked value.

        Returns
        -------
        bytes : bytes
            The binary representation of the value, suitable for
            serialization in the BINARY_ format.
        'u'
        Convert the object *value* in the native in-memory datatype to
        a string of bytes suitable for serialization in the BINARY_
        format.

        Parameters
        ----------
        value
            The value, the native type corresponding to this converter

        mask : bool
            If `True`, will return the string representation of a
            masked value.

        Returns
        -------
        bytes : bytes
            The binary representation of the value, suitable for
            serialization in the BINARY_ format.
        'b'This datatype must implement a 'binoutput' method.'u'This datatype must implement a 'binoutput' method.'b'
    Handles the char datatype. (7-bit unsigned characters).

    Missing values are not handled for string or unicode types.
    'u'
    Handles the char datatype. (7-bit unsigned characters).

    Missing values are not handled for string or unicode types.
    'b'char'u'char'b'
    Handles the unicodeChar data type. UTF-16-BE.

    Missing values are not handled for string or unicode types.
    'u'
    Handles the unicodeChar data type. UTF-16-BE.

    Missing values are not handled for string or unicode types.
    'b'unicodeChar'u'unicodeChar'b'
    Handles both fixed and variable-lengths arrays.
    'u'
    Handles both fixed and variable-lengths arrays.
    'b'verify'u'verify'b'
    Handles variable lengths arrays (i.e. where *arraysize* is '*').
    'u'
    Handles variable lengths arrays (i.e. where *arraysize* is '*').
    'b'
    Handles an array of variable-length arrays, i.e. where *arraysize*
    ends in '*'.
    'u'
    Handles an array of variable-length arrays, i.e. where *arraysize*
    ends in '*'.
    'b'
    Handles a variable-length array of numeric scalars.
    'u'
    Handles a variable-length array of numeric scalars.
    'b'
    Handles a fixed-length array of numeric scalars.
    'u'
    Handles a fixed-length array of numeric scalars.
    'b'
    The base class for all numeric data types.
    'u'
    The base class for all numeric data types.
    'b'
    The base class for floating-point datatypes.
    'u'
    The base class for floating-point datatypes.
    'b'{!s:>'u'{!s:>'b'NaN'u'NaN'b'.0'u'.0'b'+InF'u'+InF'b'-InF'u'-InF'b'Invalid floating point value ''u'Invalid floating point value ''b'
    Handles the double datatype.  Double-precision IEEE
    floating-point.
    'u'
    Handles the double datatype.  Double-precision IEEE
    floating-point.
    'b'
    Handles the float datatype.  Single-precision IEEE floating-point.
    'u'
    Handles the float datatype.  Single-precision IEEE floating-point.
    'b'
    The base class for all the integral datatypes.
    'u'
    The base class for all the integral datatypes.
    'b'0x'u'0x'b'
    Handles the unsignedByte datatype.  Unsigned 8-bit integer.
    'u'
    Handles the unsignedByte datatype.  Unsigned 8-bit integer.
    'b'8-bit unsigned'u'8-bit unsigned'b'
    Handles the short datatype.  Signed 16-bit integer.
    'u'
    Handles the short datatype.  Signed 16-bit integer.
    'b'16-bit'u'16-bit'b'
    Handles the int datatype.  Signed 32-bit integer.
    'u'
    Handles the int datatype.  Signed 32-bit integer.
    'b'32-bit'u'32-bit'b'
    Handles the long datatype.  Signed 64-bit integer.
    'u'
    Handles the long datatype.  Signed 64-bit integer.
    'b'64-bit'u'64-bit'b'
    Handles an array of variable-length arrays of complex numbers.
    'u'
    Handles an array of variable-length arrays of complex numbers.
    'b'
    Handles a variable-length array of complex numbers.
    'u'
    Handles a variable-length array of complex numbers.
    'b'
    Handles a fixed-size array of complex numbers.
    'u'
    Handles a fixed-size array of complex numbers.
    'b'
    The base class for complex numbers.
    'u'
    The base class for complex numbers.
    'b'
    Handle floatComplex datatype.  Pair of single-precision IEEE
    floating-point numbers.
    'u'
    Handle floatComplex datatype.  Pair of single-precision IEEE
    floating-point numbers.
    'b'
    Handle doubleComplex datatype.  Pair of double-precision IEEE
    floating-point numbers.
    'u'
    Handle doubleComplex datatype.  Pair of double-precision IEEE
    floating-point numbers.
    'b'
    Handles an array of bits.
    'u'
    Handles an array of bits.
    'b'\s'u'\s'b'\s|,'u'\s|,'b'
    Handles the bit datatype.
    'u'
    Handles the bit datatype.
    'b''b'
    Handles an array of boolean values.
    'u'
    Handles an array of boolean values.
    'b'
    Handles the boolean datatype.
    'u'
    Handles the boolean datatype.
    'b'TRUE'u'TRUE'b'FALSE'u'FALSE'b'double'u'double'b'unsignedByte'u'unsignedByte'b'short'b'int'u'int'b'long'u'long'b'floatComplex'u'floatComplex'b'doubleComplex'u'doubleComplex'b'
    Get an appropriate converter instance for a given field.

    Parameters
    ----------
    field : astropy.io.votable.tree.Field

    config : dict, optional
        Parser configuration dictionary

    pos : tuple
        Position in the input XML file.  Used for error messages.

    Returns
    -------
    converter : astropy.io.votable.converters.Converter
    'u'
    Get an appropriate converter instance for a given field.

    Parameters
    ----------
    field : astropy.io.votable.tree.Field

    config : dict, optional
        Parser configuration dictionary

    pos : tuple
        Position in the input XML file.  Used for error messages.

    Returns
    -------
    converter : astropy.io.votable.converters.Converter
    'b'
    Converts a numpy dtype and shape to a dictionary of attributes for
    a VOTable FIELD element and correspond to that type.

    Parameters
    ----------
    dtype : Numpy dtype instance

    shape : tuple

    Returns
    -------
    attributes : dict
        A dict containing 'datatype' and 'arraysize' keys that can be
        set on a VOTable FIELD element.
    'u'
    Converts a numpy dtype and shape to a dictionary of attributes for
    a VOTable FIELD element and correspond to that type.

    Parameters
    ----------
    dtype : Numpy dtype instance

    shape : tuple

    Returns
    -------
    attributes : dict
        A dict containing 'datatype' and 'arraysize' keys that can be
        set on a VOTable FIELD element.
    'b' can not be represented in VOTable'u' can not be represented in VOTable'b'arraysize'u'arraysize'b'
    Given a `astropy.table.Column` instance, returns the attributes
    necessary to create a VOTable FIELD element that corresponds to
    the type of the column.

    This necessarily must perform some heuristics to determine the
    type of variable length arrays fields, since they are not directly
    supported by Numpy.

    If the column has dtype of "object", it performs the following
    tests:

       - If all elements are byte or unicode strings, it creates a
         variable-length byte or unicode field, respectively.

       - If all elements are numpy arrays of the same dtype and with a
         consistent shape in all but the first dimension, it creates a
         variable length array of fixed sized arrays.  If the dtypes
         match, but the shapes do not, a variable length array is
         created.

    If the dtype of the input is not understood, it sets the data type
    to the most inclusive: a variable length unicodeChar array.

    Parameters
    ----------
    column : `astropy.table.Column` instance

    Returns
    -------
    attributes : dict
        A dict containing 'datatype' and 'arraysize' keys that can be
        set on a VOTable FIELD element.
    'u'
    Given a `astropy.table.Column` instance, returns the attributes
    necessary to create a VOTable FIELD element that corresponds to
    the type of the column.

    This necessarily must perform some heuristics to determine the
    type of variable length arrays fields, since they are not directly
    supported by Numpy.

    If the column has dtype of "object", it performs the following
    tests:

       - If all elements are byte or unicode strings, it creates a
         variable-length byte or unicode field, respectively.

       - If all elements are numpy arrays of the same dtype and with a
         consistent shape in all but the first dimension, it creates a
         variable length array of fixed sized arrays.  If the dtypes
         match, but the shapes do not, a variable length array is
         created.

    If the dtype of the input is not understood, it sets the data type
    to the most inclusive: a variable length unicodeChar array.

    Parameters
    ----------
    column : `astropy.table.Column` instance

    Returns
    -------
    attributes : dict
        A dict containing 'datatype' and 'arraysize' keys that can be
        set on a VOTable FIELD element.
    'b'_votable_string_dtype'u'_votable_string_dtype'u'astropy.io.votable.converters'u'io.votable.converters'u'votable.converters'u'converters'Converters for Quantity.UnitTypeErrorUFUNC_HELPERSUNSUPPORTED_UFUNCScan_have_arbitrary_unitcheck_outputconverters_and_unitUfuncHelpersRegistry of unit conversion functions to help ufunc evaluation.

    Based on dict for quick access, but with a missing method to load
    helpers for additional modules such as scipy.special and erfa.

    Such modules should be registered using ``register_module``.
    UNSUPPORTED_lockregister_moduleimporterRegister (but do not import) a set of ufunc helpers.

        Parameters
        ----------
        module : str
            Name of the module with the ufuncs (e.g., 'scipy.special').
        names : iterable of str
            Names of the module ufuncs for which helpers are available.
        importer : callable
            Function that imports the ufuncs and returns a dict of helpers
            keyed by those ufuncs.  If the value is `None`, the ufunc is
            explicitly *not* supported.
        Import the helpers from the given module using its helper function.

        Parameters
        ----------
        module : str
            Name of the module. Has to have been registered beforehand.
        module_info__missing__Called if a ufunc is not found.

        Check if the ufunc is in any of the available modules, and, if so,
        import the helpers for that module.
        Cannot use ufunc '' with quantitiesunknown ufunc .  If you believe this ufunc should be supported, please raise an issue on https://github.com/astropy/astropy".  If you believe this ufunc ""should be supported, please raise an issue on ""https://github.com/astropy/astropy"Test whether the items in value can have arbitrary units.

    Numbers whose value does not change upon a unit change, i.e.,
    zero, infinity, or not-a-number

    Parameters
    ----------
    value : number or array

    Returns
    -------
    bool
        `True` if each member is either zero or not finite, `False` otherwise
    Determine the required converters and the unit of the ufunc result.

    Converters are functions required to convert to a ufunc's expected unit,
    e.g., radian for np.sin; or to ensure units of two inputs are consistent,
    e.g., for np.add.  In these examples, the unit of the result would be
    dimensionless_unscaled for np.sin, and the same consistent unit for np.add.

    Parameters
    ----------
    function : `~numpy.ufunc`
        Numpy universal function
    method : str
        Method with which the function is evaluated, e.g.,
        '__call__', 'reduce', etc.
    *args :  `~astropy.units.Quantity` or ndarray subclass
        Input arguments to the function

    Raises
    ------
    TypeError : when the specified function cannot be used with Quantities
        (e.g., np.logical_or), or when the routine does not know how to handle
        the specified function (in which case an issue should be raised on
        https://github.com/astropy/astropy).
    UnitTypeError : when the conversion to the required (or consistent) units
        is not possible.
    ufunc_helperouterresult_unitCan only apply '' function to dimensionless quantities when other argument is not a quantity (unless the latter is all zero/infinity/nan)."' function to ""dimensionless quantities when other argument is not ""a quantity (unless the latter is all zero/infinity/nan)."Unsupported operand type(s) for ufunc {}: '{}'ataccumulatereduceat only supported for binary functionsUnexpected ufunc method .  If this should work, please raise an issue on https://github.com/astropy/astropy".  If this should work, please ""raise an issue on https://github.com/astropy/astropy"Cannot use '' method on ufunc  with a Quantity instance as the result is not a Quantity." with a ""Quantity instance as the result is not a Quantity." with a Quantity instance as it would change the unit."Quantity instance as it would change the unit."Check that function output can be stored in the output array given.

    Parameters
    ----------
    output : array or `~astropy.units.Quantity` or tuple
        Array that should hold the function output (or tuple of such arrays).
    unit : `~astropy.units.Unit` or None, or tuple
        Unit that the output will have, or `None` for pure numbers (should be
        tuple of same if output is a tuple of outputs).
    inputs : tuple
        Any input arguments.  These should be castable to the output.
    function : callable
        The function that will be producing the output.  If given, used to
        give a more informative error message.

    Returns
    -------
    arrays : ndarray view or tuple thereof
        The view(s) is of ``output``.

    Raises
    ------
    UnitTypeError : If ``unit`` is inconsistent with the class of ``output``

    TypeError : If the ``inputs`` cannot be cast safely to ``output``.
    output_unit_Cannot store non-quantity output{} in {} instance from  functionq_clsCannot store output with unit '{}'{} in {} instance.  Use {} instance instead."Cannot store output with unit '{}'{} ""in {} instance.  Use {} instance instead."result_typecan_castsame_kindArguments cannot be cast safely to inplace output with dtype="Arguments cannot be cast safely to inplace ""output with dtype="Cannot store quantity with dimension {}in a non-Quantity instance."Cannot store quantity with dimension ""{}in a non-Quantity instance."resulting from  function # Upper-case for backwards compatibility# Check if it was loaded while we waited for the lock# A ufunc with the same name is supported by this module.# Of course, this doesn't necessarily mean it is the# right module. So, we try let the importer do its work.# If it fails (e.g., for `scipy.special`), then that's# fine, just raise the TypeError.  If it succeeds, but# the ufunc is not found, that is also fine: we will# enter __missing__ again and either find another# module or get the TypeError there.# Implementation note: in principle, we could just let `None`# mean that something is not implemented, but this means an# extra if clause for the output, slowing down the common# path where a ufunc is supported.# Check whether we support this ufunc, by getting the helper function# (defined in helpers) which returns a list of function(s) that convert the# input(s) to the unit required for the ufunc, as well as the unit the# result will have (a tuple of units if there are multiple outputs).# Find out the units of the arguments passed to the ufunc; usually,# at least one is a quantity, but for two-argument ufuncs, the second# could also be a Numpy array, etc.  These are given unit=None.# Determine possible conversion functions, and the result unit.# for multi-argument ufuncs with a quantity and a non-quantity,# the quantity normally needs to be dimensionless, *except*# if the non-quantity can have arbitrary unit, i.e., when it# is all zero, infinity or NaN.  In that case, the non-quantity# can just have the unit of the quantity# (this allows, e.g., `q > 0.` independent of unit)# Don't fold this loop in the test above: this rare case# should not make the common case slower.# _can_have_arbitrary_unit failed: arg could not be compared# with zero or checked to be finite. Then, ufunc will fail too.# In the case of np.power and np.float_power, the unit itself needs to# be modified by an amount that depends on one of the input values,# so we need to treat this as a special case.# TODO: find a better way to deal with this.# Changing the unit does not work for, e.g., array-shaped# power, but this is OK if we're (scaled) dimensionless.# methods for which the unit should stay the same# ensure there is no 'converter' for indices (2nd argument)# add 'scale' for indices (2nd argument)# for all but __call__ method, scaling is not allowed# NOTE: this cannot be the more logical UnitTypeError, since# then things like np.cumprod will not longer fail (they check# for TypeError).# ``None`` indicates no actual array is needed.  This can happen, e.g.,# with np.modf(a, out=(None, b)).# Check that we're not trying to store a plain Numpy array or a# Quantity with an inconsistent unit (e.g., not angular for Angle).# check we can handle the dtype (e.g., that we are not int# when float is required).  Note that we only do this for Quantity# output; for array output, we defer to numpy's default handling.# Also, any structured dtype are ignored (likely erfa ufuncs).# TODO: make more logical; is this necessary at all?# Turn into ndarray, so we do not loop into array_wrap/array_ufunc# if the output is used to store results of a function.# output is not a Quantity, so cannot obtain a unit.b'Converters for Quantity.'u'Converters for Quantity.'b'UFUNC_HELPERS'u'UFUNC_HELPERS'b'UNSUPPORTED_UFUNCS'u'UNSUPPORTED_UFUNCS'b'can_have_arbitrary_unit'u'can_have_arbitrary_unit'b'check_output'u'check_output'b'converters_and_unit'u'converters_and_unit'b'Registry of unit conversion functions to help ufunc evaluation.

    Based on dict for quick access, but with a missing method to load
    helpers for additional modules such as scipy.special and erfa.

    Such modules should be registered using ``register_module``.
    'u'Registry of unit conversion functions to help ufunc evaluation.

    Based on dict for quick access, but with a missing method to load
    helpers for additional modules such as scipy.special and erfa.

    Such modules should be registered using ``register_module``.
    'b'Register (but do not import) a set of ufunc helpers.

        Parameters
        ----------
        module : str
            Name of the module with the ufuncs (e.g., 'scipy.special').
        names : iterable of str
            Names of the module ufuncs for which helpers are available.
        importer : callable
            Function that imports the ufuncs and returns a dict of helpers
            keyed by those ufuncs.  If the value is `None`, the ufunc is
            explicitly *not* supported.
        'u'Register (but do not import) a set of ufunc helpers.

        Parameters
        ----------
        module : str
            Name of the module with the ufuncs (e.g., 'scipy.special').
        names : iterable of str
            Names of the module ufuncs for which helpers are available.
        importer : callable
            Function that imports the ufuncs and returns a dict of helpers
            keyed by those ufuncs.  If the value is `None`, the ufunc is
            explicitly *not* supported.
        'b'importer'u'importer'b'Import the helpers from the given module using its helper function.

        Parameters
        ----------
        module : str
            Name of the module. Has to have been registered beforehand.
        'u'Import the helpers from the given module using its helper function.

        Parameters
        ----------
        module : str
            Name of the module. Has to have been registered beforehand.
        'b'Called if a ufunc is not found.

        Check if the ufunc is in any of the available modules, and, if so,
        import the helpers for that module.
        'u'Called if a ufunc is not found.

        Check if the ufunc is in any of the available modules, and, if so,
        import the helpers for that module.
        'b'Cannot use ufunc ''u'Cannot use ufunc ''b'' with quantities'u'' with quantities'b'unknown ufunc 'u'unknown ufunc 'b'.  If you believe this ufunc should be supported, please raise an issue on https://github.com/astropy/astropy'u'.  If you believe this ufunc should be supported, please raise an issue on https://github.com/astropy/astropy'b'Test whether the items in value can have arbitrary units.

    Numbers whose value does not change upon a unit change, i.e.,
    zero, infinity, or not-a-number

    Parameters
    ----------
    value : number or array

    Returns
    -------
    bool
        `True` if each member is either zero or not finite, `False` otherwise
    'u'Test whether the items in value can have arbitrary units.

    Numbers whose value does not change upon a unit change, i.e.,
    zero, infinity, or not-a-number

    Parameters
    ----------
    value : number or array

    Returns
    -------
    bool
        `True` if each member is either zero or not finite, `False` otherwise
    'b'Determine the required converters and the unit of the ufunc result.

    Converters are functions required to convert to a ufunc's expected unit,
    e.g., radian for np.sin; or to ensure units of two inputs are consistent,
    e.g., for np.add.  In these examples, the unit of the result would be
    dimensionless_unscaled for np.sin, and the same consistent unit for np.add.

    Parameters
    ----------
    function : `~numpy.ufunc`
        Numpy universal function
    method : str
        Method with which the function is evaluated, e.g.,
        '__call__', 'reduce', etc.
    *args :  `~astropy.units.Quantity` or ndarray subclass
        Input arguments to the function

    Raises
    ------
    TypeError : when the specified function cannot be used with Quantities
        (e.g., np.logical_or), or when the routine does not know how to handle
        the specified function (in which case an issue should be raised on
        https://github.com/astropy/astropy).
    UnitTypeError : when the conversion to the required (or consistent) units
        is not possible.
    'u'Determine the required converters and the unit of the ufunc result.

    Converters are functions required to convert to a ufunc's expected unit,
    e.g., radian for np.sin; or to ensure units of two inputs are consistent,
    e.g., for np.add.  In these examples, the unit of the result would be
    dimensionless_unscaled for np.sin, and the same consistent unit for np.add.

    Parameters
    ----------
    function : `~numpy.ufunc`
        Numpy universal function
    method : str
        Method with which the function is evaluated, e.g.,
        '__call__', 'reduce', etc.
    *args :  `~astropy.units.Quantity` or ndarray subclass
        Input arguments to the function

    Raises
    ------
    TypeError : when the specified function cannot be used with Quantities
        (e.g., np.logical_or), or when the routine does not know how to handle
        the specified function (in which case an issue should be raised on
        https://github.com/astropy/astropy).
    UnitTypeError : when the conversion to the required (or consistent) units
        is not possible.
    'b'__call__'u'__call__'b'outer'u'outer'b'Can only apply ''u'Can only apply ''b'' function to dimensionless quantities when other argument is not a quantity (unless the latter is all zero/infinity/nan).'u'' function to dimensionless quantities when other argument is not a quantity (unless the latter is all zero/infinity/nan).'b'Unsupported operand type(s) for ufunc {}: '{}''u'Unsupported operand type(s) for ufunc {}: '{}''b'at'u'at'b'reduce'u'reduce'b'accumulate'u'accumulate'b'reduceat'u'reduceat'b' only supported for binary functions'u' only supported for binary functions'b'Unexpected ufunc method 'u'Unexpected ufunc method 'b'.  If this should work, please raise an issue on https://github.com/astropy/astropy'u'.  If this should work, please raise an issue on https://github.com/astropy/astropy'b'Cannot use ''u'Cannot use ''b'' method on ufunc 'u'' method on ufunc 'b' with a Quantity instance as the result is not a Quantity.'u' with a Quantity instance as the result is not a Quantity.'b' with a Quantity instance as it would change the unit.'u' with a Quantity instance as it would change the unit.'b'Check that function output can be stored in the output array given.

    Parameters
    ----------
    output : array or `~astropy.units.Quantity` or tuple
        Array that should hold the function output (or tuple of such arrays).
    unit : `~astropy.units.Unit` or None, or tuple
        Unit that the output will have, or `None` for pure numbers (should be
        tuple of same if output is a tuple of outputs).
    inputs : tuple
        Any input arguments.  These should be castable to the output.
    function : callable
        The function that will be producing the output.  If given, used to
        give a more informative error message.

    Returns
    -------
    arrays : ndarray view or tuple thereof
        The view(s) is of ``output``.

    Raises
    ------
    UnitTypeError : If ``unit`` is inconsistent with the class of ``output``

    TypeError : If the ``inputs`` cannot be cast safely to ``output``.
    'u'Check that function output can be stored in the output array given.

    Parameters
    ----------
    output : array or `~astropy.units.Quantity` or tuple
        Array that should hold the function output (or tuple of such arrays).
    unit : `~astropy.units.Unit` or None, or tuple
        Unit that the output will have, or `None` for pure numbers (should be
        tuple of same if output is a tuple of outputs).
    inputs : tuple
        Any input arguments.  These should be castable to the output.
    function : callable
        The function that will be producing the output.  If given, used to
        give a more informative error message.

    Returns
    -------
    arrays : ndarray view or tuple thereof
        The view(s) is of ``output``.

    Raises
    ------
    UnitTypeError : If ``unit`` is inconsistent with the class of ``output``

    TypeError : If the ``inputs`` cannot be cast safely to ``output``.
    'b'Cannot store non-quantity output{} in {} instance'u'Cannot store non-quantity output{} in {} instance'b' from 'u' from 'b' function'u' function'b'Cannot store output with unit '{}'{} in {} instance.  Use {} instance instead.'u'Cannot store output with unit '{}'{} in {} instance.  Use {} instance instead.'b'same_kind'u'same_kind'b'Arguments cannot be cast safely to inplace output with dtype='u'Arguments cannot be cast safely to inplace output with dtype='b'Cannot store quantity with dimension {}in a non-Quantity instance.'u'Cannot store quantity with dimension {}in a non-Quantity instance.'b'resulting from 'u'resulting from 'b' function 'u' function 'u'astropy.units.quantity_helper.converters'u'units.quantity_helper.converters'u'quantity_helper.converters'Convolution Model.CompoundModelConvolution
    Wrapper class for a convolution model.

    Parameters
    ----------
    operator: tuple
        The SPECIAL_OPERATORS entry for the convolution being used.
    model : Model
        The model for the convolution.
    kernel: Model
        The kernel model for the convolution.
    bounding_box : tuple
        A bounding box to define the limits of the integration
        approximation for the convolution.
    resolution : float
        The resolution for the approximation of the convolution.
    cache : bool, optional
        Allow convolution computation to be cached for reuse. This is
        enabled by default.

    Notes
    -----
    This is wrapper is necessary to handle the limitations of the
    pseudospectral convolution binary operator implemented in
    astropy.convolution under `~astropy.convolution.convolve_fft`. In this
    `~astropy.convolution.convolve_fft` it is assumed that the inputs ``array``
    and ``kernel`` span a sufficient portion of the support of the functions of
    the convolution. Consequently, the ``Compound`` created by the
    `~astropy.convolution.convolve_models` function makes the assumption that
    one should pass an input array that sufficiently spans this space. This means
    that slightly different input arrays to this model will result in different
    outputs, even on points of intersection between these arrays.

    This issue is solved by requiring a ``bounding_box`` together with a
    resolution so that one can pre-calculate the entire domain and then
    (by default) cache the convolution values. The function then just
    interpolates the results from this cache.
    kernel_resolution_cache_convolution_convolutionclear_cache
        Clears the cached convolution.
        _get_convolutionmeshscipy.interpolateRegularGridInterpolator_convolution_inputsnot_scalaroutput_shapeValues have differing shapesfull_convolution_outputs# pylint: disable=line-too-long, too-many-lines, too-many-arguments, invalid-nameb'Convolution Model.'u'Convolution Model.'b'
    Wrapper class for a convolution model.

    Parameters
    ----------
    operator: tuple
        The SPECIAL_OPERATORS entry for the convolution being used.
    model : Model
        The model for the convolution.
    kernel: Model
        The kernel model for the convolution.
    bounding_box : tuple
        A bounding box to define the limits of the integration
        approximation for the convolution.
    resolution : float
        The resolution for the approximation of the convolution.
    cache : bool, optional
        Allow convolution computation to be cached for reuse. This is
        enabled by default.

    Notes
    -----
    This is wrapper is necessary to handle the limitations of the
    pseudospectral convolution binary operator implemented in
    astropy.convolution under `~astropy.convolution.convolve_fft`. In this
    `~astropy.convolution.convolve_fft` it is assumed that the inputs ``array``
    and ``kernel`` span a sufficient portion of the support of the functions of
    the convolution. Consequently, the ``Compound`` created by the
    `~astropy.convolution.convolve_models` function makes the assumption that
    one should pass an input array that sufficiently spans this space. This means
    that slightly different input arrays to this model will result in different
    outputs, even on points of intersection between these arrays.

    This issue is solved by requiring a ``bounding_box`` together with a
    resolution so that one can pre-calculate the entire domain and then
    (by default) cache the convolution values. The function then just
    interpolates the results from this cache.
    'u'
    Wrapper class for a convolution model.

    Parameters
    ----------
    operator: tuple
        The SPECIAL_OPERATORS entry for the convolution being used.
    model : Model
        The model for the convolution.
    kernel: Model
        The kernel model for the convolution.
    bounding_box : tuple
        A bounding box to define the limits of the integration
        approximation for the convolution.
    resolution : float
        The resolution for the approximation of the convolution.
    cache : bool, optional
        Allow convolution computation to be cached for reuse. This is
        enabled by default.

    Notes
    -----
    This is wrapper is necessary to handle the limitations of the
    pseudospectral convolution binary operator implemented in
    astropy.convolution under `~astropy.convolution.convolve_fft`. In this
    `~astropy.convolution.convolve_fft` it is assumed that the inputs ``array``
    and ``kernel`` span a sufficient portion of the support of the functions of
    the convolution. Consequently, the ``Compound`` created by the
    `~astropy.convolution.convolve_models` function makes the assumption that
    one should pass an input array that sufficiently spans this space. This means
    that slightly different input arrays to this model will result in different
    outputs, even on points of intersection between these arrays.

    This issue is solved by requiring a ``bounding_box`` together with a
    resolution so that one can pre-calculate the entire domain and then
    (by default) cache the convolution values. The function then just
    interpolates the results from this cache.
    'b'
        Clears the cached convolution.
        'u'
        Clears the cached convolution.
        'b'Values have differing shapes'u'Values have differing shapes'u'astropy.modeling.convolution'u'modeling.convolution'astropy.modeling.convolutionSPECIAL_OPERATORS_convolve_convolveNd_cMAX_NORMALIZATIONKernelKernel1DKernel2DKernelSizeErrorhas_even_axis4854758110812016019224024325627028830032032436037538440543245048048651254057660062564867572072975076880081086490096097210801125115212001215125012801296135014401458150015361600162017281800187519201944202520482160218722502304240024302500256025922700288029163000307231253200324033753456360036453750384038884000405040964320437445004608480048605000512051845400562557605832600060756144625064006480656167506912720072907500768077768000810081928640874890009216937596009720_good_sizes_good_rangescipy.fftBOUNDARY_OPTIONS_next_fast_lengths
    Find optimal or good sizes to pad an array of ``shape`` to for better
    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.
    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise
    looked up from list and scaled by powers of 10, if necessary.
    fftnext_fast_lennewshapeNo next fast length for  found in list of _good_sizes <= " found in list of _good_sizes ""<= "_copy_input_if_needednan_treatmentis_maskedinput should be a Numpy array or something convertible into a float arrayboundarynormalize_kernelpreserve_nannormalization_zero_tol
    Convolve an array with a kernel.

    This routine differs from `scipy.ndimage.convolve` because
    it includes a special treatment for ``NaN`` values. Rather than
    including ``NaN`` values in the array in the convolution calculation, which
    causes large ``NaN`` holes in the convolved array, ``NaN`` values are
    replaced with interpolated values using the kernel as an interpolation
    function.

    Parameters
    ----------
    array : `~astropy.nddata.NDData` or array-like
        The array to convolve. This should be a 1, 2, or 3-dimensional array
        or a list or a set of nested lists representing a 1, 2, or
        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of
        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.
    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those for
        the array, and the dimensions should be odd in all directions.  If a
        masked array, the masked values will be replaced by ``fill_value``.
    boundary : str, optional
        A flag indicating how to handle boundaries:
            * `None`
                Set the ``result`` values to zero where the kernel
                extends beyond the edge of the array.
            * 'fill'
                Set values outside the array boundary to ``fill_value`` (default).
            * 'wrap'
                Periodic boundary that wrap to the other side of ``array``.
            * 'extend'
                Set values outside the array to the nearest ``array``
                value.
    fill_value : float, optional
        The value to use outside the array when using ``boundary='fill'``.
    normalize_kernel : bool, optional
        Whether to normalize the kernel to have a sum of one.
    nan_treatment : {'interpolate', 'fill'}, optional
        The method used to handle NaNs in the input ``array``:
            * ``'interpolate'``: ``NaN`` values are replaced with
              interpolated values using the kernel as an interpolation
              function. Note that if the kernel has a sum equal to
              zero, NaN interpolation is not possible and will raise an
              exception.
            * ``'fill'``: ``NaN`` values are replaced by ``fill_value``
              prior to convolution.
    preserve_nan : bool, optional
        After performing convolution, should pixels that were originally NaN
        again become NaN?
    mask : None or ndarray, optional
        A "mask" array.  Shape must match ``array``, and anything that is masked
        (i.e., not 0/`False`) will be set to NaN for the convolution.  If
        `None`, no masking will be performed unless ``array`` is a masked array.
        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is
        masked if it is masked in either ``mask`` *or* ``array.mask``.
    normalization_zero_tol : float, optional
        The absolute tolerance on whether the kernel is different than zero.
        If the kernel sums to zero to within this precision, it cannot be
        normalized. Default is "1e-8".

    Returns
    -------
    result : `numpy.ndarray`
        An array with the same dimensions and as the input array,
        convolved with kernel.  The data type depends on the input
        array type.  If array is a floating point type, then the
        return array keeps the same data type, otherwise the type
        is ``numpy.float``.

    Notes
    -----
    For masked arrays, masked values are treated as NaNs.  The convolution
    is always done at ``numpy.float`` precision.
    Invalid boundary option: must be one of nan_treatment must be one of 'interpolate','fill'n_threadspassed_kernelpassed_arrayarray_internalkernel_internalKernel size must be odd in all axes.Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate'"Both array and kernel are Kernel instances, hardwiring ""the following parameters: boundary='fill', fill_value=0,"" normalize_Kernel=True, nan_treatment='interpolate'"cannot convolve 0-dimensional arraysconvolve only supports 1, 2, and 3-dimensional arrays at this timearray and kernel have differing number of dimensions.cannot convolve empty arrayarray_shapekernel_shapepad_widthfor boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead."for boundary=None all kernel axes must be smaller than array's - ""use boundary in ['fill', 'extend', 'wrap'] instead."nan_interpolatekernel_sumiscloseatolkernel_sums_to_zeroSetting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'."Setting nan_treatment='interpolate' ""requires the kernel to be normalized, ""but the input kernel has a sum close ""to zero. For a zero-sum kernel and ""data with NaNs, set nan_treatment='fill'."The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < "The kernel can't be normalized, because ""its sum is close to zero. The sum of the ""given kernel is < ". For a zero-sum kernel, set normalize_kernel=False or pass a custom normalization function to normalize_kernel.". ""For a zero-sum kernel, set normalize_kernel=False ""or pass a custom normalization function to ""normalize_kernel."initially_nanembed_result_within_padded_regionarray_to_convolveedgenp_pad_mode_dictnp_pad_modenp_pad_widthpadnan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this."nan_treatment='interpolate', however, NaN values detected ""post convolution. A contiguous region of NaN values, larger ""than the kernel size, are present in the input array. ""Increase the kernel size to avoid this."array_unitnew_resultOnly 1D and 2D Kernels are supported._is_bool_separablefftnifftncropreturn_fftfft_padpsf_padmin_wtallow_hugecomplex_dtypedealias
    Convolve an ndarray with an nd-kernel.  Returns a convolved image with
    ``shape = array.shape``.  Assumes kernel is centered.

    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``
    values in the original image with interpolated values using the kernel as
    an interpolation function.  However, it also includes many additional
    options specific to the implementation.

    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:

    * It can treat ``NaN`` values as zeros or interpolate over them.
    * ``inf`` values are treated as ``NaN``
    * It optionally pads to the nearest faster sizes to improve FFT speed.
      These sizes are optimized for the numpy and scipy implementations, and
      ``fftconvolve`` uses them by default as well; when using other external
      functions (see below), results may vary.
    * Its only valid ``mode`` is 'same' (i.e., the same shape array is returned)
    * It lets you use your own fft, e.g.,
      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or
      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to
      performance improvements, depending on your system configuration.  pyFFTW3
      is threaded, and therefore may yield significant performance benefits on
      multi-core machines at the cost of greater memory requirements.  Specify
      the ``fftn`` and ``ifftn`` keywords to override the default, which is
      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also
      offer somewhat better performance and a multi-threaded option.

    Parameters
    ----------
    array : `numpy.ndarray`
        Array to be convolved with ``kernel``.  It can be of any
        dimensionality, though only 1, 2, and 3d arrays have been tested.
    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those
        for the array.  The dimensions *do not* have to be odd in all directions,
        unlike in the non-fft `convolve` function.  The kernel will be
        normalized if ``normalize_kernel`` is set.  It is assumed to be centered
        (i.e., shifts may result if your kernel is asymmetric)
    boundary : {'fill', 'wrap'}, optional
        A flag indicating how to handle boundaries:

            * 'fill': set values outside the array boundary to fill_value
              (default)
            * 'wrap': periodic boundary

        The `None` and 'extend' parameters are not supported for FFT-based
        convolution.
    fill_value : float, optional
        The value to use outside the array when using boundary='fill'.
    nan_treatment : {'interpolate', 'fill'}, optional
        The method used to handle NaNs in the input ``array``:
            * ``'interpolate'``: ``NaN`` values are replaced with
              interpolated values using the kernel as an interpolation
              function. Note that if the kernel has a sum equal to
              zero, NaN interpolation is not possible and will raise an
              exception.
            * ``'fill'``: ``NaN`` values are replaced by ``fill_value``
              prior to convolution.
    normalize_kernel : callable or boolean, optional
        If specified, this is the function to divide kernel by to normalize it.
        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:
        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to
        ``normalize_kernel = np.sum``.
    normalization_zero_tol : float, optional
        The absolute tolerance on whether the kernel is different than zero.
        If the kernel sums to zero to within this precision, it cannot be
        normalized. Default is "1e-8".
    preserve_nan : bool, optional
        After performing convolution, should pixels that were originally NaN
        again become NaN?
    mask : None or ndarray, optional
        A "mask" array.  Shape must match ``array``, and anything that is masked
        (i.e., not 0/`False`) will be set to NaN for the convolution.  If
        `None`, no masking will be performed unless ``array`` is a masked array.
        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is
        masked if it is masked in either ``mask`` *or* ``array.mask``.
    crop : bool, optional
        Default on.  Return an image of the size of the larger of the input
        image and the kernel.
        If the image and kernel are asymmetric in opposite directions, will
        return the largest image in both directions.
        For example, if an input image has shape [100,3] but a kernel with shape
        [6,6] is used, the output will be [100,6].
    return_fft : bool, optional
        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is
        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.
    fft_pad : bool, optional
        Default on.  Zero-pad image to the nearest size supporting more efficient
        execution of the FFT, generally values factorizable into the first 3-5
        prime numbers.  With ``boundary='wrap'``, this will be disabled.
    psf_pad : bool, optional
        Zero-pad image to be at least the sum of the image sizes to avoid
        edge-wrapping when smoothing.  This is enabled by default with
        ``boundary='fill'``, but it can be overridden with a boolean option.
        ``boundary='wrap'`` and ``psf_pad=True`` are not compatible.
    min_wt : float, optional
        If ignoring ``NaN`` / zeros, force all grid points with a weight less than
        this value to ``NaN`` (the weight of a grid point with *no* ignored
        neighbors is 1.0).
        If ``min_wt`` is zero, then all zero-weight points will be set to zero
        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).
        See the examples below.
    allow_huge : bool, optional
        Allow huge arrays in the FFT?  If False, will raise an exception if the
        array or kernel size is >1 GB.
    fftn : callable, optional
        The fft function.  Can be overridden to use your own ffts,
        e.g. an fftw3 wrapper or scipy's fftn, ``fft=scipy.fftpack.fftn``.
    ifftn : callable, optional
        The inverse fft function. Can be overridden the same way ``fttn``.
    complex_dtype : complex type, optional
        Which complex dtype to use.  `numpy` has a range of options, from 64 to
        256.
    dealias: bool, optional
        Default off. Zero-pad image to enable explicit dealiasing
        of convolution. With ``boundary='wrap'``, this will be disabled.
        Note that for an input of nd dimensions this will increase
        the size of the temporary arrays by at least ``1.5**nd``.
        This may result in significantly more memory usage.

    Returns
    -------
    default : ndarray
        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns
        ``fft(array) * fft(kernel)``.  If crop is not set, returns the
        image, but with the fft-padded size instead of the input size.

    Raises
    ------
    `ValueError`
        If the array is bigger than 1 GB after padding, will raise this
        exception unless ``allow_huge`` is True.

    See Also
    --------
    convolve:
        Convolve is a non-fft version of this code.  It is more memory
        efficient and for small kernels can be faster.

    Notes
    -----
    With ``psf_pad=True`` and a large PSF, the resulting data
    can become large and consume a lot of memory. See Issue
    https://github.com/astropy/astropy/pull/4366 and the update in
    https://github.com/astropy/astropy/pull/11533 for further details.

    Dealiasing of pseudospectral convolutions is necessary for
    numerical stability of the underlying algorithms. A common
    method for handling this is to zero pad the image by at least
    1/2 to eliminate the wavenumbers which have been aliased
    by convolution. This is so that the aliased 1/3 of the
    results of the convolution computation can be thrown out. See
    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2
    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037

    Note that if dealiasing is necessary to your application, but your
    process is memory constrained, you may want to consider using
    FFTW++: https://github.com/dealias/fftwpp. It includes python
    wrappers for a pseudospectral convolution which will implicitly
    dealias your convolution without the need for additional padding.
    Note that one cannot use FFTW++'s convlution directly in this
    method as in handles the entire convolution process internally.
    Additionally, FFTW++ includes other useful pseudospectral methods to
    consider.

    Examples
    --------
    >>> convolve_fft([1, 0, 3], [1, 1, 1])
    array([0.33333333, 1.33333333, 1.        ])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])
    array([0.5, 2. , 1.5])

    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP
    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])

    >>> convolve_fft([1, 2, 3], [1])
    array([1., 2., 3.])

    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment='interpolate')
    array([1., 0., 3.])

    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment='interpolate',
    ...              min_wt=1e-8)
    array([ 1., nan,  3.])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate')
    array([0.5, 2. , 1.5])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',
    ...               normalize_kernel=True)
    array([0.5, 2. , 1.5])

    >>> import scipy.fft  # optional - requires scipy
    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',
    ...               normalize_kernel=True,
    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)
    array([0.5, 2. , 1.5])

    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores
    >>> ...Can't convolve two kernels with convolve_fft.  Use convolve instead.Image and kernel must have same number of dimensionsarrayshapekernshapearray_size_BGBSize Error: Arrays will be .  Use allow_huge=True to override this exception.".  ""Use allow_huge=True to override this exception."nanmaskarraynanmaskkernel"The kernel can't be normalized, because its sum is close ""to zero. The sum of the given kernel is < "". For a zero-sum kernel, set ""normalize_kernel=False or pass a custom normalization ""function to normalize_kernel."kernel_scalenormalized_kernelCannot interpolate NaNs with an unnormalizable kernelThe convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary"The convolve_fft version of boundary=None is ""equivalent to the convolve boundary='fill'.  There is ""no FFT equivalent to convolve's ""zero-if-kernel-leaves-boundary"psf_pad was set to , which overrides the boundary='fill' setting.", which overrides the ""boundary='fill' setting."With boundary='wrap', psf_pad cannot be enabled.With boundary='wrap', fft_pad cannot be enabled.With boundary='wrap', dealias cannot be enabled.The 'extend' option is not implemented for fft-based convolutionmaximumarray_size_Carraysliceskernslicesnewdimsizearraydimsizekerndimsizebigarraybigkernelarrayfftifftshiftkernfftfftmultinterpolate_nanbigimwtwtfftwtfftmultwtsmEncountered NaNs in convolve.  This is disallowed.rifft
    Given a data set containing NaNs, replace the NaNs by interpolating from
    neighboring data points with a given kernel.

    Parameters
    ----------
    array : `numpy.ndarray`
        Array to be convolved with ``kernel``.  It can be of any
        dimensionality, though only 1, 2, and 3d arrays have been tested.
    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those
        for the array.  The dimensions *do not* have to be odd in all directions,
        unlike in the non-fft `convolve` function.  The kernel will be
        normalized if ``normalize_kernel`` is set.  It is assumed to be centered
        (i.e., shifts may result if your kernel is asymmetric).  The kernel
        *must be normalizable* (i.e., its sum cannot be zero).
    convolve : `convolve` or `convolve_fft`
        One of the two convolution functions defined in this package.

    Returns
    -------
    newarray : `numpy.ndarray`
        A copy of the original array with NaN pixels replaced with their
        interpolated counterparts
    newarrayconvolved
    Convolve two models using `~astropy.convolution.convolve_fft`.

    Parameters
    ----------
    model : `~astropy.modeling.core.Model`
        Functional model
    kernel : `~astropy.modeling.core.Model`
        Convolution kernel
    mode : str
        Keyword representing which function to use for convolution.
            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.
            * 'convolve' : use `~astropy.convolution.convolve`.
    **kwargs : dict
        Keyword arguments to me passed either to `~astropy.convolution.convolve`
        or `~astropy.convolution.convolve_fft` depending on ``mode``.

    Returns
    -------
    default : `~astropy.modeling.core.CompoundModel`
        Convolved model
    Mode  is not supported.
    Convolve two models using `~astropy.convolution.convolve_fft`.

    Parameters
    ----------
    model : `~astropy.modeling.core.Model`
        Functional model
    kernel : `~astropy.modeling.core.Model`
        Convolution kernel
    bounding_box : tuple
        The bounding box which encompasses enough of the support of both
        the ``model`` and ``kernel`` so that an accurate convolution can be
        computed.
    resolution : float
        The resolution that one wishes to approximate the convolution
        integral at.
    cache : optional, bool
        Default value True. Allow for the storage of the convolution
        computation for later reuse.
    **kwargs : dict
        Keyword arguments to be passed either to `~astropy.convolution.convolve`
        or `~astropy.convolution.convolve_fft` depending on ``mode``.

    Returns
    -------
    default : `~astropy.modeling.core.CompoundModel`
        Convolved model
    # np.unique([scipy.fft.next_fast_len(i, real=True) for i in range(10000)])# Disabling doctests when scipy isn't present.# Alias input# strip quantity attributes# Copy input# Anything that's masked must be turned into NaNs for the interpolation.# This requires copying. A copy is also needed for nan_treatment == 'fill'# A copy prevents possible function side-effects of the input array.# ``np.ma.maskedarray.filled()`` returns a copy, however there# is no way to specify the return type or order etc. In addition# ``np.nan`` is a ``float`` and there is no conversion to an# ``int`` type. Therefore, a pre-fill copy is needed for non# ``float`` masked arrays. ``asanyarray`` is needed to retain# ``np.ma.maskedarray.filled()``.# A copy is made if and only if order isn't already correct.# Since we're making a copy, we might as well use `subok=False` to save,# what is probably, a negligible amount of memory.# mask != 0 yields a bool mask for all ints/floats/bool# OpenMP support is disabled at the C src code level, changing this will have# no effect.# Keep refs to originals# The C routines all need float type inputs (so, a particular# bit size, endianness, etc.).  So we have to convert, which also# has the effect of making copies so we don't modify the inputs.# After this, the variables we work with will be array_internal, and# kernel_internal.  However -- we do want to keep track of what type# the input array was so we can cast the result to that at the end# if it's a floating point type.  Don't bother with this for lists --# just always push those as float.# It is always necessary to make a copy of kernel (since it is modified),# but, if we just so happen to be lucky enough to have the input array# have exactly the desired type, we just alias to array_internal# Convert kernel to ndarray if not already# Copy or alias array to array_internal# Copy or alias kernel to kernel_internal# Make sure kernel has all odd axes# If both image array and kernel are Kernel instances# constrain convolution method# This must occur before the main alias/copy of ``passed_kernel`` to# ``kernel_internal`` as it is used for filling masked kernels.# -----------------------------------------------------------------------# From this point onwards refer only to ``array_internal`` and# ``kernel_internal``.# Assume both are base np.ndarrays and NOT subclasses e.g. NOT# ``Kernel`` nor ``np.ma.maskedarray`` classes.# For boundary=None only the center space is convolved. All array indices within a# distance kernel.shape//2 from the edge are completely ignored (zeroed).# E.g. (1D list) only the indices len(kernel)//2 : len(array)-len(kernel)//2# are convolved. It is therefore not possible to use this method to convolve an# array by a kernel that is larger (see note below) than the array - as ALL pixels# would be ignored leaving an array of only zeros.# Note: For even kernels the correctness condition is array_shape > kernel_shape.# For odd kernels it is:#     array_shape >= kernel_shape OR#     array_shape > kernel_shape-1 OR#     array_shape > 2*(kernel_shape//2).# Since the latter is equal to the former two for even lengths, the latter condition is# complete.# NaN interpolation significantly slows down the C convolution# computation. Since nan_treatment = 'interpolate', is the default# check whether it is even needed, if not, don't interpolate.# NB: np.isnan(array_internal.sum()) is faster than np.isnan(array_internal).any()# Check if kernel is normalizable# Mark the NaN values so we can replace them later if interpolate_nan is# not set# Avoid any memory allocation within the C code. Allocate output array# here and pass through instead.# This method is faster than using numpy.pad(..., mode='constant')# Use bounds [pad_width[0]:array_shape[0]+pad_width[0]] instead of#            [pad_width[0]:-pad_width[0]]# to account for when the kernel has size of 1 making pad_width = 0.# So far, normalization has only occurred for nan_treatment == 'interpolate'# because this had to happen within the C extension so as to ignore# any NaNs# Convert result to original data type# Try to preserve the input type if it's a floating point type# Checking copied from convolve.py - however, since FFTs have real &# complex components, we change the types.  Only the real part will be# returned! Note that this always makes a copy.# Check kernel is kernel instance# Get array quantity if it exists# Convert array dtype to complex# and ensure that list inputs become arrays# Check that the number of dimensions is compatible# NaN and inf catching# if we want to normalize it, leave it normed!# try this.  If a function is not passed, the code will just crash... I# think type checking would be better but PEPs say otherwise...# the kernel's sum is near-zero, so it can't be scaled# the kernel is normalizable; we'll temporarily normalize it# now and undo the normalization later.# create a boundary region at least as large as the kernel# default is 'True' according to the docstring# force zero; it should not be used# Add shapes elementwise for psf_pad.# default=False# add the sizes along each dimension (bigger)# take the larger shape in each dimension (smaller)# Extend shape by 1/2 for dealiasing# Find ideal size for fft (was power of 2, now any powers of prime factors 2, 3, 5).# default=True# Get optimized sizes from scipy.# perform a second check after padding# For future reference, this can be used to predict "almost exactly"# how much *additional* memory will be used.# size * (array + kernel + kernelfft + arrayfft +#         (kernel*array)fft +#         optional(weight image + weight_fft + weight_ifft) +#         optional(returned_fft))# total_memory_used_GB = (np.prod(newshape)*np.dtype(complex_dtype).itemsize#                        * (5 + 3*((interpolate_nan or ) and kernel_is_normalized))#                        + (1 + (not return_fft)) *#                          np.prod(arrayshape)*np.dtype(complex_dtype).itemsize#                        + np.prod(arrayshape)*np.dtype(bool).itemsize#                        + np.prod(kernshape)*np.dtype(bool).itemsize)#                        ) / 1024.**3# separate each dimension by the padding size...  this is to determine the# appropriate slice size to get back to the input dimensions# need to shift the kernel so that, e.g., [0,0,1,0] -> [1,0,0,0] = unity# You can only get to this point if kernel_is_normalized# need to re-zero weights outside of the image (if it is padded, we# still don't weight those regions)# this check should be unnecessary; call it an insanity check# divide by zeros are expected here; if the weight is zero, we want# the output to be nan or inf# Set anything with no weight to zero (taking into account# slight offsets due to floating-point errors).b'scipy.fft'u'scipy.fft'b'convolve_fft'u'convolve_fft'b'fill'u'fill'b'wrap'u'wrap'b'extend'u'extend'b'
    Find optimal or good sizes to pad an array of ``shape`` to for better
    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.
    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise
    looked up from list and scaled by powers of 10, if necessary.
    'u'
    Find optimal or good sizes to pad an array of ``shape`` to for better
    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.
    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise
    looked up from list and scaled by powers of 10, if necessary.
    'b'No next fast length for 'u'No next fast length for 'b' found in list of _good_sizes <= 'u' found in list of _good_sizes <= 'b'input should be a Numpy array or something convertible into a float array'u'input should be a Numpy array or something convertible into a float array'b'interpolate'u'interpolate'b'
    Convolve an array with a kernel.

    This routine differs from `scipy.ndimage.convolve` because
    it includes a special treatment for ``NaN`` values. Rather than
    including ``NaN`` values in the array in the convolution calculation, which
    causes large ``NaN`` holes in the convolved array, ``NaN`` values are
    replaced with interpolated values using the kernel as an interpolation
    function.

    Parameters
    ----------
    array : `~astropy.nddata.NDData` or array-like
        The array to convolve. This should be a 1, 2, or 3-dimensional array
        or a list or a set of nested lists representing a 1, 2, or
        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of
        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.
    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those for
        the array, and the dimensions should be odd in all directions.  If a
        masked array, the masked values will be replaced by ``fill_value``.
    boundary : str, optional
        A flag indicating how to handle boundaries:
            * `None`
                Set the ``result`` values to zero where the kernel
                extends beyond the edge of the array.
            * 'fill'
                Set values outside the array boundary to ``fill_value`` (default).
            * 'wrap'
                Periodic boundary that wrap to the other side of ``array``.
            * 'extend'
                Set values outside the array to the nearest ``array``
                value.
    fill_value : float, optional
        The value to use outside the array when using ``boundary='fill'``.
    normalize_kernel : bool, optional
        Whether to normalize the kernel to have a sum of one.
    nan_treatment : {'interpolate', 'fill'}, optional
        The method used to handle NaNs in the input ``array``:
            * ``'interpolate'``: ``NaN`` values are replaced with
              interpolated values using the kernel as an interpolation
              function. Note that if the kernel has a sum equal to
              zero, NaN interpolation is not possible and will raise an
              exception.
            * ``'fill'``: ``NaN`` values are replaced by ``fill_value``
              prior to convolution.
    preserve_nan : bool, optional
        After performing convolution, should pixels that were originally NaN
        again become NaN?
    mask : None or ndarray, optional
        A "mask" array.  Shape must match ``array``, and anything that is masked
        (i.e., not 0/`False`) will be set to NaN for the convolution.  If
        `None`, no masking will be performed unless ``array`` is a masked array.
        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is
        masked if it is masked in either ``mask`` *or* ``array.mask``.
    normalization_zero_tol : float, optional
        The absolute tolerance on whether the kernel is different than zero.
        If the kernel sums to zero to within this precision, it cannot be
        normalized. Default is "1e-8".

    Returns
    -------
    result : `numpy.ndarray`
        An array with the same dimensions and as the input array,
        convolved with kernel.  The data type depends on the input
        array type.  If array is a floating point type, then the
        return array keeps the same data type, otherwise the type
        is ``numpy.float``.

    Notes
    -----
    For masked arrays, masked values are treated as NaNs.  The convolution
    is always done at ``numpy.float`` precision.
    'u'
    Convolve an array with a kernel.

    This routine differs from `scipy.ndimage.convolve` because
    it includes a special treatment for ``NaN`` values. Rather than
    including ``NaN`` values in the array in the convolution calculation, which
    causes large ``NaN`` holes in the convolved array, ``NaN`` values are
    replaced with interpolated values using the kernel as an interpolation
    function.

    Parameters
    ----------
    array : `~astropy.nddata.NDData` or array-like
        The array to convolve. This should be a 1, 2, or 3-dimensional array
        or a list or a set of nested lists representing a 1, 2, or
        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of
        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.
    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those for
        the array, and the dimensions should be odd in all directions.  If a
        masked array, the masked values will be replaced by ``fill_value``.
    boundary : str, optional
        A flag indicating how to handle boundaries:
            * `None`
                Set the ``result`` values to zero where the kernel
                extends beyond the edge of the array.
            * 'fill'
                Set values outside the array boundary to ``fill_value`` (default).
            * 'wrap'
                Periodic boundary that wrap to the other side of ``array``.
            * 'extend'
                Set values outside the array to the nearest ``array``
                value.
    fill_value : float, optional
        The value to use outside the array when using ``boundary='fill'``.
    normalize_kernel : bool, optional
        Whether to normalize the kernel to have a sum of one.
    nan_treatment : {'interpolate', 'fill'}, optional
        The method used to handle NaNs in the input ``array``:
            * ``'interpolate'``: ``NaN`` values are replaced with
              interpolated values using the kernel as an interpolation
              function. Note that if the kernel has a sum equal to
              zero, NaN interpolation is not possible and will raise an
              exception.
            * ``'fill'``: ``NaN`` values are replaced by ``fill_value``
              prior to convolution.
    preserve_nan : bool, optional
        After performing convolution, should pixels that were originally NaN
        again become NaN?
    mask : None or ndarray, optional
        A "mask" array.  Shape must match ``array``, and anything that is masked
        (i.e., not 0/`False`) will be set to NaN for the convolution.  If
        `None`, no masking will be performed unless ``array`` is a masked array.
        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is
        masked if it is masked in either ``mask`` *or* ``array.mask``.
    normalization_zero_tol : float, optional
        The absolute tolerance on whether the kernel is different than zero.
        If the kernel sums to zero to within this precision, it cannot be
        normalized. Default is "1e-8".

    Returns
    -------
    result : `numpy.ndarray`
        An array with the same dimensions and as the input array,
        convolved with kernel.  The data type depends on the input
        array type.  If array is a floating point type, then the
        return array keeps the same data type, otherwise the type
        is ``numpy.float``.

    Notes
    -----
    For masked arrays, masked values are treated as NaNs.  The convolution
    is always done at ``numpy.float`` precision.
    'b'Invalid boundary option: must be one of 'u'Invalid boundary option: must be one of 'b'nan_treatment must be one of 'interpolate','fill''u'nan_treatment must be one of 'interpolate','fill''b'Kernel size must be odd in all axes.'u'Kernel size must be odd in all axes.'b'Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate''u'Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate''b'cannot convolve 0-dimensional arrays'u'cannot convolve 0-dimensional arrays'b'convolve only supports 1, 2, and 3-dimensional arrays at this time'u'convolve only supports 1, 2, and 3-dimensional arrays at this time'b'array and kernel have differing number of dimensions.'u'array and kernel have differing number of dimensions.'b'cannot convolve empty array'u'cannot convolve empty array'b'for boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead.'u'for boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead.'b'Setting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'.'u'Setting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'.'b'The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < 'u'The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < 'b'. For a zero-sum kernel, set normalize_kernel=False or pass a custom normalization function to normalize_kernel.'u'. For a zero-sum kernel, set normalize_kernel=False or pass a custom normalization function to normalize_kernel.'b'constant'b'edge'u'edge'b'nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this.'u'nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this.'b'Only 1D and 2D Kernels are supported.'u'Only 1D and 2D Kernels are supported.'b'
    Convolve an ndarray with an nd-kernel.  Returns a convolved image with
    ``shape = array.shape``.  Assumes kernel is centered.

    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``
    values in the original image with interpolated values using the kernel as
    an interpolation function.  However, it also includes many additional
    options specific to the implementation.

    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:

    * It can treat ``NaN`` values as zeros or interpolate over them.
    * ``inf`` values are treated as ``NaN``
    * It optionally pads to the nearest faster sizes to improve FFT speed.
      These sizes are optimized for the numpy and scipy implementations, and
      ``fftconvolve`` uses them by default as well; when using other external
      functions (see below), results may vary.
    * Its only valid ``mode`` is 'same' (i.e., the same shape array is returned)
    * It lets you use your own fft, e.g.,
      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or
      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to
      performance improvements, depending on your system configuration.  pyFFTW3
      is threaded, and therefore may yield significant performance benefits on
      multi-core machines at the cost of greater memory requirements.  Specify
      the ``fftn`` and ``ifftn`` keywords to override the default, which is
      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also
      offer somewhat better performance and a multi-threaded option.

    Parameters
    ----------
    array : `numpy.ndarray`
        Array to be convolved with ``kernel``.  It can be of any
        dimensionality, though only 1, 2, and 3d arrays have been tested.
    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those
        for the array.  The dimensions *do not* have to be odd in all directions,
        unlike in the non-fft `convolve` function.  The kernel will be
        normalized if ``normalize_kernel`` is set.  It is assumed to be centered
        (i.e., shifts may result if your kernel is asymmetric)
    boundary : {'fill', 'wrap'}, optional
        A flag indicating how to handle boundaries:

            * 'fill': set values outside the array boundary to fill_value
              (default)
            * 'wrap': periodic boundary

        The `None` and 'extend' parameters are not supported for FFT-based
        convolution.
    fill_value : float, optional
        The value to use outside the array when using boundary='fill'.
    nan_treatment : {'interpolate', 'fill'}, optional
        The method used to handle NaNs in the input ``array``:
            * ``'interpolate'``: ``NaN`` values are replaced with
              interpolated values using the kernel as an interpolation
              function. Note that if the kernel has a sum equal to
              zero, NaN interpolation is not possible and will raise an
              exception.
            * ``'fill'``: ``NaN`` values are replaced by ``fill_value``
              prior to convolution.
    normalize_kernel : callable or boolean, optional
        If specified, this is the function to divide kernel by to normalize it.
        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:
        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to
        ``normalize_kernel = np.sum``.
    normalization_zero_tol : float, optional
        The absolute tolerance on whether the kernel is different than zero.
        If the kernel sums to zero to within this precision, it cannot be
        normalized. Default is "1e-8".
    preserve_nan : bool, optional
        After performing convolution, should pixels that were originally NaN
        again become NaN?
    mask : None or ndarray, optional
        A "mask" array.  Shape must match ``array``, and anything that is masked
        (i.e., not 0/`False`) will be set to NaN for the convolution.  If
        `None`, no masking will be performed unless ``array`` is a masked array.
        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is
        masked if it is masked in either ``mask`` *or* ``array.mask``.
    crop : bool, optional
        Default on.  Return an image of the size of the larger of the input
        image and the kernel.
        If the image and kernel are asymmetric in opposite directions, will
        return the largest image in both directions.
        For example, if an input image has shape [100,3] but a kernel with shape
        [6,6] is used, the output will be [100,6].
    return_fft : bool, optional
        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is
        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.
    fft_pad : bool, optional
        Default on.  Zero-pad image to the nearest size supporting more efficient
        execution of the FFT, generally values factorizable into the first 3-5
        prime numbers.  With ``boundary='wrap'``, this will be disabled.
    psf_pad : bool, optional
        Zero-pad image to be at least the sum of the image sizes to avoid
        edge-wrapping when smoothing.  This is enabled by default with
        ``boundary='fill'``, but it can be overridden with a boolean option.
        ``boundary='wrap'`` and ``psf_pad=True`` are not compatible.
    min_wt : float, optional
        If ignoring ``NaN`` / zeros, force all grid points with a weight less than
        this value to ``NaN`` (the weight of a grid point with *no* ignored
        neighbors is 1.0).
        If ``min_wt`` is zero, then all zero-weight points will be set to zero
        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).
        See the examples below.
    allow_huge : bool, optional
        Allow huge arrays in the FFT?  If False, will raise an exception if the
        array or kernel size is >1 GB.
    fftn : callable, optional
        The fft function.  Can be overridden to use your own ffts,
        e.g. an fftw3 wrapper or scipy's fftn, ``fft=scipy.fftpack.fftn``.
    ifftn : callable, optional
        The inverse fft function. Can be overridden the same way ``fttn``.
    complex_dtype : complex type, optional
        Which complex dtype to use.  `numpy` has a range of options, from 64 to
        256.
    dealias: bool, optional
        Default off. Zero-pad image to enable explicit dealiasing
        of convolution. With ``boundary='wrap'``, this will be disabled.
        Note that for an input of nd dimensions this will increase
        the size of the temporary arrays by at least ``1.5**nd``.
        This may result in significantly more memory usage.

    Returns
    -------
    default : ndarray
        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns
        ``fft(array) * fft(kernel)``.  If crop is not set, returns the
        image, but with the fft-padded size instead of the input size.

    Raises
    ------
    `ValueError`
        If the array is bigger than 1 GB after padding, will raise this
        exception unless ``allow_huge`` is True.

    See Also
    --------
    convolve:
        Convolve is a non-fft version of this code.  It is more memory
        efficient and for small kernels can be faster.

    Notes
    -----
    With ``psf_pad=True`` and a large PSF, the resulting data
    can become large and consume a lot of memory. See Issue
    https://github.com/astropy/astropy/pull/4366 and the update in
    https://github.com/astropy/astropy/pull/11533 for further details.

    Dealiasing of pseudospectral convolutions is necessary for
    numerical stability of the underlying algorithms. A common
    method for handling this is to zero pad the image by at least
    1/2 to eliminate the wavenumbers which have been aliased
    by convolution. This is so that the aliased 1/3 of the
    results of the convolution computation can be thrown out. See
    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2
    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037

    Note that if dealiasing is necessary to your application, but your
    process is memory constrained, you may want to consider using
    FFTW++: https://github.com/dealias/fftwpp. It includes python
    wrappers for a pseudospectral convolution which will implicitly
    dealias your convolution without the need for additional padding.
    Note that one cannot use FFTW++'s convlution directly in this
    method as in handles the entire convolution process internally.
    Additionally, FFTW++ includes other useful pseudospectral methods to
    consider.

    Examples
    --------
    >>> convolve_fft([1, 0, 3], [1, 1, 1])
    array([0.33333333, 1.33333333, 1.        ])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])
    array([0.5, 2. , 1.5])

    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP
    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])

    >>> convolve_fft([1, 2, 3], [1])
    array([1., 2., 3.])

    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment='interpolate')
    array([1., 0., 3.])

    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment='interpolate',
    ...              min_wt=1e-8)
    array([ 1., nan,  3.])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate')
    array([0.5, 2. , 1.5])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',
    ...               normalize_kernel=True)
    array([0.5, 2. , 1.5])

    >>> import scipy.fft  # optional - requires scipy
    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',
    ...               normalize_kernel=True,
    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)
    array([0.5, 2. , 1.5])

    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores
    >>...u'
    Convolve an ndarray with an nd-kernel.  Returns a convolved image with
    ``shape = array.shape``.  Assumes kernel is centered.

    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``
    values in the original image with interpolated values using the kernel as
    an interpolation function.  However, it also includes many additional
    options specific to the implementation.

    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:

    * It can treat ``NaN`` values as zeros or interpolate over them.
    * ``inf`` values are treated as ``NaN``
    * It optionally pads to the nearest faster sizes to improve FFT speed.
      These sizes are optimized for the numpy and scipy implementations, and
      ``fftconvolve`` uses them by default as well; when using other external
      functions (see below), results may vary.
    * Its only valid ``mode`` is 'same' (i.e., the same shape array is returned)
    * It lets you use your own fft, e.g.,
      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or
      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to
      performance improvements, depending on your system configuration.  pyFFTW3
      is threaded, and therefore may yield significant performance benefits on
      multi-core machines at the cost of greater memory requirements.  Specify
      the ``fftn`` and ``ifftn`` keywords to override the default, which is
      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also
      offer somewhat better performance and a multi-threaded option.

    Parameters
    ----------
    array : `numpy.ndarray`
        Array to be convolved with ``kernel``.  It can be of any
        dimensionality, though only 1, 2, and 3d arrays have been tested.
    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those
        for the array.  The dimensions *do not* have to be odd in all directions,
        unlike in the non-fft `convolve` function.  The kernel will be
        normalized if ``normalize_kernel`` is set.  It is assumed to be centered
        (i.e., shifts may result if your kernel is asymmetric)
    boundary : {'fill', 'wrap'}, optional
        A flag indicating how to handle boundaries:

            * 'fill': set values outside the array boundary to fill_value
              (default)
            * 'wrap': periodic boundary

        The `None` and 'extend' parameters are not supported for FFT-based
        convolution.
    fill_value : float, optional
        The value to use outside the array when using boundary='fill'.
    nan_treatment : {'interpolate', 'fill'}, optional
        The method used to handle NaNs in the input ``array``:
            * ``'interpolate'``: ``NaN`` values are replaced with
              interpolated values using the kernel as an interpolation
              function. Note that if the kernel has a sum equal to
              zero, NaN interpolation is not possible and will raise an
              exception.
            * ``'fill'``: ``NaN`` values are replaced by ``fill_value``
              prior to convolution.
    normalize_kernel : callable or boolean, optional
        If specified, this is the function to divide kernel by to normalize it.
        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:
        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to
        ``normalize_kernel = np.sum``.
    normalization_zero_tol : float, optional
        The absolute tolerance on whether the kernel is different than zero.
        If the kernel sums to zero to within this precision, it cannot be
        normalized. Default is "1e-8".
    preserve_nan : bool, optional
        After performing convolution, should pixels that were originally NaN
        again become NaN?
    mask : None or ndarray, optional
        A "mask" array.  Shape must match ``array``, and anything that is masked
        (i.e., not 0/`False`) will be set to NaN for the convolution.  If
        `None`, no masking will be performed unless ``array`` is a masked array.
        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is
        masked if it is masked in either ``mask`` *or* ``array.mask``.
    crop : bool, optional
        Default on.  Return an image of the size of the larger of the input
        image and the kernel.
        If the image and kernel are asymmetric in opposite directions, will
        return the largest image in both directions.
        For example, if an input image has shape [100,3] but a kernel with shape
        [6,6] is used, the output will be [100,6].
    return_fft : bool, optional
        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is
        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.
    fft_pad : bool, optional
        Default on.  Zero-pad image to the nearest size supporting more efficient
        execution of the FFT, generally values factorizable into the first 3-5
        prime numbers.  With ``boundary='wrap'``, this will be disabled.
    psf_pad : bool, optional
        Zero-pad image to be at least the sum of the image sizes to avoid
        edge-wrapping when smoothing.  This is enabled by default with
        ``boundary='fill'``, but it can be overridden with a boolean option.
        ``boundary='wrap'`` and ``psf_pad=True`` are not compatible.
    min_wt : float, optional
        If ignoring ``NaN`` / zeros, force all grid points with a weight less than
        this value to ``NaN`` (the weight of a grid point with *no* ignored
        neighbors is 1.0).
        If ``min_wt`` is zero, then all zero-weight points will be set to zero
        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).
        See the examples below.
    allow_huge : bool, optional
        Allow huge arrays in the FFT?  If False, will raise an exception if the
        array or kernel size is >1 GB.
    fftn : callable, optional
        The fft function.  Can be overridden to use your own ffts,
        e.g. an fftw3 wrapper or scipy's fftn, ``fft=scipy.fftpack.fftn``.
    ifftn : callable, optional
        The inverse fft function. Can be overridden the same way ``fttn``.
    complex_dtype : complex type, optional
        Which complex dtype to use.  `numpy` has a range of options, from 64 to
        256.
    dealias: bool, optional
        Default off. Zero-pad image to enable explicit dealiasing
        of convolution. With ``boundary='wrap'``, this will be disabled.
        Note that for an input of nd dimensions this will increase
        the size of the temporary arrays by at least ``1.5**nd``.
        This may result in significantly more memory usage.

    Returns
    -------
    default : ndarray
        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns
        ``fft(array) * fft(kernel)``.  If crop is not set, returns the
        image, but with the fft-padded size instead of the input size.

    Raises
    ------
    `ValueError`
        If the array is bigger than 1 GB after padding, will raise this
        exception unless ``allow_huge`` is True.

    See Also
    --------
    convolve:
        Convolve is a non-fft version of this code.  It is more memory
        efficient and for small kernels can be faster.

    Notes
    -----
    With ``psf_pad=True`` and a large PSF, the resulting data
    can become large and consume a lot of memory. See Issue
    https://github.com/astropy/astropy/pull/4366 and the update in
    https://github.com/astropy/astropy/pull/11533 for further details.

    Dealiasing of pseudospectral convolutions is necessary for
    numerical stability of the underlying algorithms. A common
    method for handling this is to zero pad the image by at least
    1/2 to eliminate the wavenumbers which have been aliased
    by convolution. This is so that the aliased 1/3 of the
    results of the convolution computation can be thrown out. See
    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2
    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037

    Note that if dealiasing is necessary to your application, but your
    process is memory constrained, you may want to consider using
    FFTW++: https://github.com/dealias/fftwpp. It includes python
    wrappers for a pseudospectral convolution which will implicitly
    dealias your convolution without the need for additional padding.
    Note that one cannot use FFTW++'s convlution directly in this
    method as in handles the entire convolution process internally.
    Additionally, FFTW++ includes other useful pseudospectral methods to
    consider.

    Examples
    --------
    >>> convolve_fft([1, 0, 3], [1, 1, 1])
    array([0.33333333, 1.33333333, 1.        ])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])
    array([0.5, 2. , 1.5])

    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP
    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])

    >>> convolve_fft([1, 2, 3], [1])
    array([1., 2., 3.])

    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment='interpolate')
    array([1., 0., 3.])

    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment='interpolate',
    ...              min_wt=1e-8)
    array([ 1., nan,  3.])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate')
    array([0.5, 2. , 1.5])

    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',
    ...               normalize_kernel=True)
    array([0.5, 2. , 1.5])

    >>> import scipy.fft  # optional - requires scipy
    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',
    ...               normalize_kernel=True,
    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)
    array([0.5, 2. , 1.5])

    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores
    >>...b'Can't convolve two kernels with convolve_fft.  Use convolve instead.'u'Can't convolve two kernels with convolve_fft.  Use convolve instead.'b'Image and kernel must have same number of dimensions'u'Image and kernel must have same number of dimensions'b'Size Error: Arrays will be 'u'Size Error: Arrays will be 'b'.  Use allow_huge=True to override this exception.'u'.  Use allow_huge=True to override this exception.'b'Cannot interpolate NaNs with an unnormalizable kernel'u'Cannot interpolate NaNs with an unnormalizable kernel'b'The convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary'u'The convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary'b'psf_pad was set to 'u'psf_pad was set to 'b', which overrides the boundary='fill' setting.'u', which overrides the boundary='fill' setting.'b'With boundary='wrap', psf_pad cannot be enabled.'u'With boundary='wrap', psf_pad cannot be enabled.'b'With boundary='wrap', fft_pad cannot be enabled.'u'With boundary='wrap', fft_pad cannot be enabled.'b'With boundary='wrap', dealias cannot be enabled.'u'With boundary='wrap', dealias cannot be enabled.'b'The 'extend' option is not implemented for fft-based convolution'u'The 'extend' option is not implemented for fft-based convolution'b'Encountered NaNs in convolve.  This is disallowed.'u'Encountered NaNs in convolve.  This is disallowed.'b'
    Given a data set containing NaNs, replace the NaNs by interpolating from
    neighboring data points with a given kernel.

    Parameters
    ----------
    array : `numpy.ndarray`
        Array to be convolved with ``kernel``.  It can be of any
        dimensionality, though only 1, 2, and 3d arrays have been tested.
    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those
        for the array.  The dimensions *do not* have to be odd in all directions,
        unlike in the non-fft `convolve` function.  The kernel will be
        normalized if ``normalize_kernel`` is set.  It is assumed to be centered
        (i.e., shifts may result if your kernel is asymmetric).  The kernel
        *must be normalizable* (i.e., its sum cannot be zero).
    convolve : `convolve` or `convolve_fft`
        One of the two convolution functions defined in this package.

    Returns
    -------
    newarray : `numpy.ndarray`
        A copy of the original array with NaN pixels replaced with their
        interpolated counterparts
    'u'
    Given a data set containing NaNs, replace the NaNs by interpolating from
    neighboring data points with a given kernel.

    Parameters
    ----------
    array : `numpy.ndarray`
        Array to be convolved with ``kernel``.  It can be of any
        dimensionality, though only 1, 2, and 3d arrays have been tested.
    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`
        The convolution kernel. The number of dimensions should match those
        for the array.  The dimensions *do not* have to be odd in all directions,
        unlike in the non-fft `convolve` function.  The kernel will be
        normalized if ``normalize_kernel`` is set.  It is assumed to be centered
        (i.e., shifts may result if your kernel is asymmetric).  The kernel
        *must be normalizable* (i.e., its sum cannot be zero).
    convolve : `convolve` or `convolve_fft`
        One of the two convolution functions defined in this package.

    Returns
    -------
    newarray : `numpy.ndarray`
        A copy of the original array with NaN pixels replaced with their
        interpolated counterparts
    'b'
    Convolve two models using `~astropy.convolution.convolve_fft`.

    Parameters
    ----------
    model : `~astropy.modeling.core.Model`
        Functional model
    kernel : `~astropy.modeling.core.Model`
        Convolution kernel
    mode : str
        Keyword representing which function to use for convolution.
            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.
            * 'convolve' : use `~astropy.convolution.convolve`.
    **kwargs : dict
        Keyword arguments to me passed either to `~astropy.convolution.convolve`
        or `~astropy.convolution.convolve_fft` depending on ``mode``.

    Returns
    -------
    default : `~astropy.modeling.core.CompoundModel`
        Convolved model
    'u'
    Convolve two models using `~astropy.convolution.convolve_fft`.

    Parameters
    ----------
    model : `~astropy.modeling.core.Model`
        Functional model
    kernel : `~astropy.modeling.core.Model`
        Convolution kernel
    mode : str
        Keyword representing which function to use for convolution.
            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.
            * 'convolve' : use `~astropy.convolution.convolve`.
    **kwargs : dict
        Keyword arguments to me passed either to `~astropy.convolution.convolve`
        or `~astropy.convolution.convolve_fft` depending on ``mode``.

    Returns
    -------
    default : `~astropy.modeling.core.CompoundModel`
        Convolved model
    'b'convolve'u'convolve'b'Mode 'u'Mode 'b' is not supported.'u' is not supported.'b'
    Convolve two models using `~astropy.convolution.convolve_fft`.

    Parameters
    ----------
    model : `~astropy.modeling.core.Model`
        Functional model
    kernel : `~astropy.modeling.core.Model`
        Convolution kernel
    bounding_box : tuple
        The bounding box which encompasses enough of the support of both
        the ``model`` and ``kernel`` so that an accurate convolution can be
        computed.
    resolution : float
        The resolution that one wishes to approximate the convolution
        integral at.
    cache : optional, bool
        Default value True. Allow for the storage of the convolution
        computation for later reuse.
    **kwargs : dict
        Keyword arguments to be passed either to `~astropy.convolution.convolve`
        or `~astropy.convolution.convolve_fft` depending on ``mode``.

    Returns
    -------
    default : `~astropy.modeling.core.CompoundModel`
        Convolved model
    'u'
    Convolve two models using `~astropy.convolution.convolve_fft`.

    Parameters
    ----------
    model : `~astropy.modeling.core.Model`
        Functional model
    kernel : `~astropy.modeling.core.Model`
        Convolution kernel
    bounding_box : tuple
        The bounding box which encompasses enough of the support of both
        the ``model`` and ``kernel`` so that an accurate convolution can be
        computed.
    resolution : float
        The resolution that one wishes to approximate the convolution
        integral at.
    cache : optional, bool
        Default value True. Allow for the storage of the convolution
        computation for later reuse.
    **kwargs : dict
        Keyword arguments to be passed either to `~astropy.convolution.convolve`
        or `~astropy.convolution.convolve_fft` depending on ``mode``.

    Returns
    -------
    default : `~astropy.modeling.core.CompoundModel`
        Convolved model
    'u'astropy.convolution.convolve'u'convolution.convolve'
This file defines the classes used to represent a 'coordinate', which includes
axes, ticks, tick labels, and grid lines.
matplotlib.patchesPathPatchmatplotlib.pathAffine2DScaledTranslationaxislabelsformatter_locatorAngleFormatterLocatorScalarFormatterLocatorEllipticalFrameRectangularFrame1Dgrid_pathsget_gridline_pathget_lon_lat_pathticklabelsTickLabelsTicksMATPLOTLIB_LT_3_8soliddashed--dashdot-.dottedLINES_TO_PATCHES_LINESTYLEwrap_angle_atcoord_wrap
    Helper class to control one of the coordinates in the
    :class:`~astropy.visualization.wcsaxes.WCSAxes`.

    Parameters
    ----------
    parent_axes : :class:`~astropy.visualization.wcsaxes.WCSAxes`
        The axes the coordinate helper belongs to.
    parent_map : :class:`~astropy.visualization.wcsaxes.CoordinatesMap`
        The :class:`~astropy.visualization.wcsaxes.CoordinatesMap` object this
        coordinate belongs to.
    transform : `~matplotlib.transforms.Transform`
        The transform corresponding to this coordinate system.
    coord_index : int
        The index of this coordinate in the
        :class:`~astropy.visualization.wcsaxes.CoordinatesMap`.
    coord_type : {'longitude', 'latitude', 'scalar'}
        The type of this coordinate, which is used to determine the wrapping and
        boundary behavior of coordinates. Longitudes wrap at ``coord_wrap``,
        latitudes have to be in the range -90 to 90, and scalars are unbounded
        and do not wrap.
    coord_unit : `~astropy.units.Unit`
        The unit that this coordinate is in given the output of transform.
    format_unit : `~astropy.units.Unit`, optional
        The unit to use to display the coordinates.
    coord_wrap : `astropy.units.Quantity`
        The angle at which the longitude wraps (defaults to 360 degrees).
    frame : `~astropy.visualization.wcsaxes.frame.BaseFrame`
        The frame of the :class:`~astropy.visualization.wcsaxes.WCSAxes`.
    default_label : str, optional
        The axis label to show by default if none is set later.
    parent_axesparent_mapcoord_indexformat_unitdefault_label_parent_axes_parent_map_transform_coord_index_coord_unit_format_unit_default_label_auto_axislabel_axislabel_set_custom_formatterframe_classset_coord_typedpi_transformoffset_transformtransDataget_figure_ticklabelsdisplay_minor_ticksxtick.minor.visible_minor_frequency_axislabels_grid_linesfacecolorgrid.coloredgecolorgrid.linestylelinestylegrid.linewidthlinewidthgrid.alpha_grid_lines_kwargs
        The axes the coordinate helper belongs to.
        Setting CoordinateHelper.parent_axes directly is deprecated
        The :class:`~astropy.visualization.wcsaxes.CoordinatesMap` object this
        coordinate belongs to.
        Setting CoordinateHelper.parent_map directly is deprecated
        The transform corresponding to this coordinate system.
        Setting CoordinateHelper.transform directly is deprecated
        The index of this coordinate in the
        :class:`~astropy.visualization.wcsaxes.CoordinatesMap`.
        Setting CoordinateHelper.coord_index directly is deprecated
        The type of this coordinate (e.g., ``'longitude'``)
        _coord_typeSetting CoordinateHelper.coord_type directly is deprecated, use CoordinateHelper.set_coord_type instead
        The unit that this coordinate is in given the output of transform.
        Setting CoordinateHelper.coord_unit directly is deprecated
        The angle at which the longitude wraps (defaults to 360 degrees).
        _coord_wrapSetting CoordinateHelper.coord_wrap directly is deprecated, use CoordinateHelper.set_coord_type instead
        The frame of the :class:`~astropy.visualization.wcsaxes.WCSAxes`.
        Setting CoordinateHelper.frame directly is deprecated
        The axis label to show by default if none is set later.
        Setting CoordinateHelper.default_label directly is deprecatedCoordinateHelper.ticks should not be accessed directly and is deprecatedSetting CoordinateHelper.ticks directly is deprecatedCoordinateHelper.ticklabels should not be accessed directly and is deprecatedSetting CoordinateHelper.ticklabels directly is deprecatedCoordinateHelper.axislabels should not be accessed directly and is deprecatedSetting CoordinateHelper.axislabels directly is deprecatedgriddraw_gridgrid_type
        Plot grid lines for this coordinate.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments.

        Parameters
        ----------
        draw_grid : bool
            Whether to show the gridlines
        grid_type : {'lines', 'contours'}
            Whether to plot the contours by determining the grid lines in
            world coordinates and then plotting them in world coordinates
            (``'lines'``) or by determining the world coordinates at many
            positions in the image and then drawing contours
            (``'contours'``). The first is recommended for 2-d images, while
            for 3-d (or higher dimensional) cubes, the ``'contours'`` option
            is recommended. By default, 'lines' is used if the transform has
            an inverse, otherwise 'contours' is used.
        has_inverseThe specified transform has no inverse, so the grid cannot be drawn using grid_type='lines'"The specified transform has no inverse, so the ""grid cannot be drawn using grid_type='lines'"contours_grid_typegrid_type should be 'lines' or 'contours'
        Set the coordinate type for the axis.

        Parameters
        ----------
        coord_type : str
            One of 'longitude', 'latitude' or 'scalar'
        coord_wrap : `~astropy.units.Quantity`, optional
            The value to wrap at for angular coordinates.
        Passing 'coord_wrap' as a number is deprecated. Use a Quantity with units convertible to angular degrees instead.coord_wrap is not yet supported for non-longitude coordinates_coord_scale_to_deg_formatter_locatorcoord_type should be one of 'scalar', 'longitude', or 'latitude'set_major_formatter
        Set the format string to use for the major tick labels.

        See :ref:`tick_label_format` for accepted format strings and examples.

        Parameters
        ----------
        formatter : str or callable
            The format string to use, or a callable (for advanced use cases).
            If specified as a callable, this should take a
            `~astropy.units.Quantity` (which could be scalar or array) of tick
            world coordinates as well as an optional ``spacing`` keyword
            argument, which gives (also as a `~astropy.units.Quantity`) the
            spacing between ticks, and returns an iterable of strings
            containing the labels.
        formatter should be a stringformat_coord
        Given the value of a coordinate, will format it according to the
        format of the formatter_locator.

        Parameters
        ----------
        value : float
            The value to format
        format : {'auto', 'ascii', 'latex'}, optional
            The format to use - by default the formatting will be adjusted
            depending on whether Matplotlib is using LaTeX or MathTex. To
            get plain ASCII strings, use format='ascii'.
        _fl_spacingflspacingset_separator
        Set the separator to use for the angle major tick labels.

        Parameters
        ----------
        separator : str or tuple or None
            The separator between numbers in sexagesimal representation. Can be
            either a string or a tuple (or `None` for default).
        Separator can only be specified for angle coordinatesseparator should be a string, a tuple, or Noneset_format_unitdecimalshow_decimal_unit
        Set the unit for the major tick labels.

        Parameters
        ----------
        unit : class:`~astropy.units.Unit`
            The unit to which the tick labels should be converted to.
        decimal : bool, optional
            Whether to use decimal formatting. By default this is `False`
            for degrees or hours (which therefore use sexagesimal formatting)
            and `True` for all other units.
        show_decimal_unit : bool, optional
            Whether to include units when in decimal mode.
        get_format_unit
        Get the unit for the major tick labels.
        set_ticksdirectionexclude_overlapping
        Set the location and properties of the ticks.

        At most one of the options from ``values``, ``spacing``, or
        ``number`` can be specified.

        Parameters
        ----------
        values : iterable, optional
            The coordinate values at which to show the ticks.
        spacing : float, optional
            The spacing between ticks.
        number : float, optional
            The approximate number of ticks shown.
        size : float, optional
            The length of the ticks in points
        color : str or tuple, optional
            A valid Matplotlib color for the ticks
        alpha : float, optional
            The alpha value (transparency) for the ticks.
        direction : {'in','out'}, optional
            Whether the ticks should point inwards or outwards.
        At most one of values, spacing, or number should be specifiedset_ticksizeset_linewidthset_colorset_alphainset_tick_outdirection should be 'in' or 'out'exclude_overlapping= should be passed to set_ticklabel instead of set_ticks"exclude_overlapping= should be passed to ""set_ticklabel instead of set_ticks"set_exclude_overlappingposition
        Set where ticks should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the ticks for this coordinate should appear.
            Should be a sequence containing zero or more of ``'b'``, ``'t'``,
            ``'l'``, ``'r'``. For example, ``'lb'`` will lead the ticks to be
            shown on the left and bottom axis. In addition, if ``'#'`` is
            included in the sequence, the position will be considered dynamic and
            will be updated at draw-time in order to show the ticks on the same
            axes as the tick labels are shown.
        
        Get where tick labels will appear.
        set_ticks_visible
        Set whether ticks are visible or not.

        Parameters
        ----------
        visible : bool
            The visibility of ticks. Setting as ``False`` will hide ticks
            along this coordinate.
        set_visibleset_ticklabelsimplify
        Set the visual properties for the tick labels.

        Parameters
        ----------
        size : float, optional
            The size of the ticks labels in points
        color : str or tuple, optional
            A valid Matplotlib color for the tick labels
        pad : float, optional
            Distance in points between tick and label.
        exclude_overlapping : bool, optional
            Whether to exclude tick labels that overlap over each other.
        simplify : bool, optional
            Whether to remove repeated parts of tick labels.
        **kwargs
            Other keyword arguments are passed to :class:`matplotlib.text.Text`.
        set_sizeset_padset_simplify
        Set where tick labels should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the tick labels for this coordinate should
            appear. Should be a sequence containing zero or more of ``'b'``,
            ``'t'``, ``'l'``, ``'r'``. For example, ``'lb'`` will lead the
            tick labels to be shown on the left and bottom axis. In addition,
            if ``'#'`` is included in the sequence, the position will be
            considered dynamic and will be updated at draw-time in order to
            attempt to optimize the layout of all the coordinates.
        set_ticklabel_visible
        Set whether the tick labels are visible or not.

        Parameters
        ----------
        visible : bool
            The visibility of ticks. Setting as ``False`` will hide this
            coordinate's tick labels.
        set_axislabel
        Set the text and optionally visual properties for the axis label.

        Parameters
        ----------
        text : str
            The axis label text.
        minpad : float, optional
            The padding for the label in terms of axis label font size.
        **kwargs
            Keywords are passed to :class:`matplotlib.text.Text`. These
            can include keywords to set the ``color``, ``size``, ``weight``, and
            other text properties.
        fontdictset_textget_axislabel
        Get the text for the axis label.

        Returns
        -------
        label : str
            The axis label
        _get_default_axislabelget_textset_auto_axislabelauto_label
        Render default axis labels if no explicit label is provided.

        Parameters
        ----------
        auto_label : `bool`
            `True` if default labels will be rendered.
        get_auto_axislabel
        Render default axis labels if no explicit label is provided.

        Returns
        -------
        auto_axislabel : `bool`
            `True` if default labels will be rendered.
         [
        Set where axis labels should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the axis label for this coordinate should
            appear. Should be a sequence containing zero or more of ``'b'``,
            ``'t'``, ``'l'``, ``'r'``. For example, ``'lb'`` will lead the
            axis label to be shown on the left and bottom axis. In addition, if
            ``'#'`` is included in the sequence, the position will be considered
            dynamic and will be updated at draw-time in order to show the axis
            label on the same axes as the tick labels are shown.
        
        Get where axis labels will appear.
        set_axislabel_visibility_rulerule
        Set the rule used to determine when the axis label is drawn.

        Parameters
        ----------
        rule : str
            If the rule is 'always' axis labels will always be drawn on the
            axis. If the rule is 'ticks' the label will only be drawn if ticks
            were drawn on that axis. If the rule is 'labels' the axis label
            will only be drawn if tick labels were drawn on that axis.
        get_axislabel_visibility_rule
        Get the rule used to determine when the axis label is drawn.
        locator_draw_gridopen_groupgrid lines_update_grid_lines_1d_update_grid_lines_update_grid_contourpatchframe_patchset_clip_path_gridclose_group_draw_ticksexisting_bboxes
        Draw all ticks and ticklabels.

        Parameters
        ----------
        existing_bboxes : list[Bbox]
            All bboxes for ticks that have already been drawn by other
            coordinates.
        out_size_tick_out_size_set_existing_bboxes_draw_axislabelsaxis labels_update_ticks_coord_rangecoord_rangetick_world_coordinatesget_display_minor_ticksminor_locatorget_minor_frequencyminor_ticks_w_coordinatessample_lblinfo_lbl_worldinvertedinvertedTransLimitspixel0world0axes0pixel1world1pixel2world2dxdegreestick_anglenormal_angle_fullrotationw1w2_compute_tickstxttick_world_coordinates_valuesintersectionsiminimaxallclose1e-131.0e-13rtolx_data_iy_data_idelta_angleangle_iaxis_displacementadd_minorminor_axisminor_pixelminor_worldminor_angleminor_axis_displacement
        Display minor ticks for this coordinate.

        Parameters
        ----------
        display_minor_ticks : bool
            Whether or not to display minor ticks.
        set_minor_frequency
        Set the frequency of minor ticks per major ticks.

        Parameters
        ----------
        frequency : int
            The number of minor ticks per major ticks.
        x_ticks_posget_ylimymaxx_coordn_coordn_samplesxy_worldsubsetlinspacexy_world_round_get_gridlineadd_tickable_gridline
        Define a gridline that can be used for ticks and labels.

        This gridline is not itself drawn, but instead can be specified in calls to
        methods such as
        :meth:`~astropy.visualization.wcsaxes.coordinate_helpers.CoordinateHelper.set_ticklabel_position`
        for drawing ticks and labels.  Since the gridline has a constant value in this
        coordinate, and thus would not have any ticks or labels for the same coordinate,
        the call to
        :meth:`~astropy.visualization.wcsaxes.coordinate_helpers.CoordinateHelper.set_ticklabel_position`
        would typically be made on the complementary coordinate.

        Parameters
        ----------
        name : str
            The name for the gridline, usually a single character, but can be longer
        constant : `~astropy.units.Quantity`
            The constant coordinate value of the gridline

        Notes
        -----
        A limitation is that the tickable part of the gridline must be contiguous.  If
        the gridline consists of more than one disconnected segment within the plot
        extent, only one of those segments will be made tickable.
        The frame already has a spine with the name 'get_coord_rangegridlinedata_for_spineverticescodesget_xlimxmaxMOVETOflatnonzeroLINETOlinetolast_segmentmovetospine_classdata_func_clear_grid_contourmidcontourtick_paramsboth
        Method to set the tick and tick label parameters in the same way as the
        :meth:`~matplotlib.axes.Axes.tick_params` method in Matplotlib.

        This is provided for convenience, but the recommended API is to use
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks_position`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel_position`,
        and :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.grid`.

        Parameters
        ----------
        which : {'both', 'major', 'minor'}, optional
            Which ticks to apply the settings to. By default, setting are
            applied to both major and minor ticks. Note that if ``'minor'`` is
            specified, only the length of the ticks can be set currently.
        direction : {'in', 'out'}, optional
            Puts ticks inside the axes, or outside the axes.
        length : float, optional
            Tick length in points.
        width : float, optional
            Tick width in points.
        color : color, optional
            Tick color (accepts any valid Matplotlib color)
        pad : float, optional
            Distance in points between tick and label.
        labelsize : float or str, optional
            Tick label font size in points or as a string (e.g., 'large').
        labelcolor : color, optional
            Tick label color (accepts any valid Matplotlib color)
        colors : color, optional
            Changes the tick color and the label color to the same value
             (accepts any valid Matplotlib color).
        bottom, top, left, right : bool, optional
            Where to draw the ticks. Note that this will not work correctly if
            the frame is not rectangular.
        labelbottom, labeltop, labelleft, labelright : bool, optional
            Where to draw the tick labels. Note that this will not work
            correctly if the frame is not rectangular.
        grid_color : color, optional
            The color of the grid lines (accepts any valid Matplotlib color).
        grid_alpha : float, optional
            Transparency of grid lines: 0 (transparent) to 1 (opaque).
        grid_linewidth : float, optional
            Width of grid lines in points.
        grid_linestyle : str, optional
            The style of the grid lines (accepts any valid Matplotlib line
            style).
        colorslabelcolorWhen setting which='minor', the only property that can be set at the moment is 'length' (the minor tick length)"When setting which='minor', the only ""property that can be set at the moment is ""'length' (the minor tick length)"set_minor_ticksizebottomtoplabelsizegrid_colorgrid_alphagrid_linewidthgrid_linestyle# Matplotlib's gridlines use Line2D, but ours use PathPatch.# Patches take a slightly different format of linestyle argument.# On ARM processors, np.mod emits warnings if there are NaN values in the# array, although this doesn't seem to happen on other processors.# Keep a reference to the parent axes and the transform# Disable auto label for elliptical frames as it puts labels in# annoying places.# Initialize ticks# Initialize tick labels# display coordinates# Initialize axis labels# Initialize container for the grid lines# Initialize grid style. Take defaults from matplotlib.rcParams.# Based on matplotlib.axis.YTick._get_gridline.# Initialize tick formatter/locator# _update_ticks has not been called yet# Convert to degrees if needed# NOTE: When using plt.xlabel/plt.ylabel, minpad can get set explicitly# to None so we need to make sure that in that case we change to a# default numerical value.# Render the default axis label if no axis label is set.# TODO: this method should be optimized for speed# Here we determine the location and rotation of all the ticks. For# each axis, we can check the intersections for the specific# coordinate and once we have the tick positions, we can use the WCS# to determine the rotations.# First find the ticks we want to show# We want to allow non-standard rectangular frames, so we just rely on# the parent axes to tell us what the bounding frame is.# Look up parent axes' transform from data to figure coordinates.# See:# https://matplotlib.org/stable/tutorials/advanced/transforms_tutorial.html#the-transformation-pipeline# Determine tick rotation in display coordinates and compare to# the normal angle in display coordinates.# Advance 2 pixels in figure coordinates# Rotate by 90 degrees# Here we wrap at 180 not self.coord_wrap since we want to# always ensure abs(dx) < 180 and abs(dy) < 180# We find for each interval the starting and ending coordinate,# ensuring that we take wrapping into account correctly for# longitudes.# For longitudes, we need to check ticks as well as ticks + 360,# since the above can produce pairs such as 359 to 361 or 0.5 to# 1.5, both of which would match a tick at 0.75. Otherwise we just# check the ticks determined above.# format tick labels, add to scene# Find steps where a tick is present. We have to check# separately for the case where the tick falls exactly on the# frame points, otherwise we'll get two matches, one for w1 and# one for w2.# But we also need to check for intersection with the last w2# Loop over ticks, and find exact pixel coordinates by linear# interpolation# tick is exactly aligned with frame# store information to pass to ticklabels.add# it's faster to format many ticklabels at once outside# of the loop# For 3-d WCS with a correlated third axis, the *proper* way of# drawing a grid should be to find the world coordinates of all pixels# and drawing contours. What we are doing here assumes that we can# define the grid lines with just two of the coordinates (and# therefore assumes that the other coordinates are fixed and set to# the value in the slice). Here we basically assume that if the WCS# had a third axis, it has been abstracted away in the transformation.# We now convert all the world coordinates to pixel coordinates in a# single go rather than doing this in the gridline to path conversion# to fully benefit from vectorized coordinate transformations.# Transform line to pixel coordinates# Create round-tripped values for checking# See comment in _update_grid_lines() about a WCS with more than 2 axes# If the complementary coordinate is longitude, we attempt to close the gridline# If such closure is a discontinuity, it will be filtered out later# Get the path of the gridline, which masks hidden parts# Retain the parts of the gridline within the rectangular plot bounds.# We ought to use the potentially non-rectangular plot frame, but# calculating that patch requires updating all spines first, which is a# catch-22.# We isolate the last segment (the last run of LINETOs), which must be preceded# by at least one MOVETO and may be succeeded by MOVETOs.# We have to account for longitude wrapping as well.# Bail out if there is no visible segment# Find the start of the last segment (the last MOVETO before the LINETOs)# Double the gridline if it is closed (i.e., spans all longitudes)# Stop the last segment before any trailing MOVETOs# tick_world_coordinates is a Quantities array and we only needs its values# Find biggest gap in tick_world_coordinates and wrap in middle# For now just assume spacing is equal, so any mid-point will do# Replace wraps by NaN# First do some sanity checking on the keyword arguments# colors= is a fallback default for color and labelcolor# The only property that can be set *specifically* for minor ticks is# the length. In future we could consider having a separate Ticks instance# for minor ticks so that e.g. the color can be set separately.# At this point, we can now ignore the 'which' argument.# Set the tick arguments# Set the tick position# Set the tick label arguments.# Set the tick label position# And the grid settingsb'
This file defines the classes used to represent a 'coordinate', which includes
axes, ticks, tick labels, and grid lines.
'u'
This file defines the classes used to represent a 'coordinate', which includes
axes, ticks, tick labels, and grid lines.
'b'CoordinateHelper'u'CoordinateHelper'b'solid'u'solid'b'dashed'u'dashed'b'--'u'--'b'dashdot'u'dashdot'b'-.'u'-.'b'dotted'u'dotted'b'
    Helper class to control one of the coordinates in the
    :class:`~astropy.visualization.wcsaxes.WCSAxes`.

    Parameters
    ----------
    parent_axes : :class:`~astropy.visualization.wcsaxes.WCSAxes`
        The axes the coordinate helper belongs to.
    parent_map : :class:`~astropy.visualization.wcsaxes.CoordinatesMap`
        The :class:`~astropy.visualization.wcsaxes.CoordinatesMap` object this
        coordinate belongs to.
    transform : `~matplotlib.transforms.Transform`
        The transform corresponding to this coordinate system.
    coord_index : int
        The index of this coordinate in the
        :class:`~astropy.visualization.wcsaxes.CoordinatesMap`.
    coord_type : {'longitude', 'latitude', 'scalar'}
        The type of this coordinate, which is used to determine the wrapping and
        boundary behavior of coordinates. Longitudes wrap at ``coord_wrap``,
        latitudes have to be in the range -90 to 90, and scalars are unbounded
        and do not wrap.
    coord_unit : `~astropy.units.Unit`
        The unit that this coordinate is in given the output of transform.
    format_unit : `~astropy.units.Unit`, optional
        The unit to use to display the coordinates.
    coord_wrap : `astropy.units.Quantity`
        The angle at which the longitude wraps (defaults to 360 degrees).
    frame : `~astropy.visualization.wcsaxes.frame.BaseFrame`
        The frame of the :class:`~astropy.visualization.wcsaxes.WCSAxes`.
    default_label : str, optional
        The axis label to show by default if none is set later.
    'u'
    Helper class to control one of the coordinates in the
    :class:`~astropy.visualization.wcsaxes.WCSAxes`.

    Parameters
    ----------
    parent_axes : :class:`~astropy.visualization.wcsaxes.WCSAxes`
        The axes the coordinate helper belongs to.
    parent_map : :class:`~astropy.visualization.wcsaxes.CoordinatesMap`
        The :class:`~astropy.visualization.wcsaxes.CoordinatesMap` object this
        coordinate belongs to.
    transform : `~matplotlib.transforms.Transform`
        The transform corresponding to this coordinate system.
    coord_index : int
        The index of this coordinate in the
        :class:`~astropy.visualization.wcsaxes.CoordinatesMap`.
    coord_type : {'longitude', 'latitude', 'scalar'}
        The type of this coordinate, which is used to determine the wrapping and
        boundary behavior of coordinates. Longitudes wrap at ``coord_wrap``,
        latitudes have to be in the range -90 to 90, and scalars are unbounded
        and do not wrap.
    coord_unit : `~astropy.units.Unit`
        The unit that this coordinate is in given the output of transform.
    format_unit : `~astropy.units.Unit`, optional
        The unit to use to display the coordinates.
    coord_wrap : `astropy.units.Quantity`
        The angle at which the longitude wraps (defaults to 360 degrees).
    frame : `~astropy.visualization.wcsaxes.frame.BaseFrame`
        The frame of the :class:`~astropy.visualization.wcsaxes.WCSAxes`.
    default_label : str, optional
        The axis label to show by default if none is set later.
    'b'xtick.minor.visible'u'xtick.minor.visible'b'visible'u'visible'b'facecolor'u'facecolor'b'grid.color'u'grid.color'b'edgecolor'u'edgecolor'b'grid.linestyle'u'grid.linestyle'b'linestyle'u'linestyle'b'grid.linewidth'u'grid.linewidth'b'linewidth'u'linewidth'b'grid.alpha'u'grid.alpha'b'transform'u'transform'b'
        The axes the coordinate helper belongs to.
        'u'
        The axes the coordinate helper belongs to.
        'b'Setting CoordinateHelper.parent_axes directly is deprecated'u'Setting CoordinateHelper.parent_axes directly is deprecated'b'
        The :class:`~astropy.visualization.wcsaxes.CoordinatesMap` object this
        coordinate belongs to.
        'u'
        The :class:`~astropy.visualization.wcsaxes.CoordinatesMap` object this
        coordinate belongs to.
        'b'Setting CoordinateHelper.parent_map directly is deprecated'u'Setting CoordinateHelper.parent_map directly is deprecated'b'
        The transform corresponding to this coordinate system.
        'u'
        The transform corresponding to this coordinate system.
        'b'Setting CoordinateHelper.transform directly is deprecated'u'Setting CoordinateHelper.transform directly is deprecated'b'
        The index of this coordinate in the
        :class:`~astropy.visualization.wcsaxes.CoordinatesMap`.
        'u'
        The index of this coordinate in the
        :class:`~astropy.visualization.wcsaxes.CoordinatesMap`.
        'b'Setting CoordinateHelper.coord_index directly is deprecated'u'Setting CoordinateHelper.coord_index directly is deprecated'b'
        The type of this coordinate (e.g., ``'longitude'``)
        'u'
        The type of this coordinate (e.g., ``'longitude'``)
        'b'Setting CoordinateHelper.coord_type directly is deprecated, use CoordinateHelper.set_coord_type instead'u'Setting CoordinateHelper.coord_type directly is deprecated, use CoordinateHelper.set_coord_type instead'b'
        The unit that this coordinate is in given the output of transform.
        'u'
        The unit that this coordinate is in given the output of transform.
        'b'Setting CoordinateHelper.coord_unit directly is deprecated'u'Setting CoordinateHelper.coord_unit directly is deprecated'b'
        The angle at which the longitude wraps (defaults to 360 degrees).
        'u'
        The angle at which the longitude wraps (defaults to 360 degrees).
        'b'Setting CoordinateHelper.coord_wrap directly is deprecated, use CoordinateHelper.set_coord_type instead'u'Setting CoordinateHelper.coord_wrap directly is deprecated, use CoordinateHelper.set_coord_type instead'b'
        The frame of the :class:`~astropy.visualization.wcsaxes.WCSAxes`.
        'u'
        The frame of the :class:`~astropy.visualization.wcsaxes.WCSAxes`.
        'b'Setting CoordinateHelper.frame directly is deprecated'u'Setting CoordinateHelper.frame directly is deprecated'b'
        The axis label to show by default if none is set later.
        'u'
        The axis label to show by default if none is set later.
        'b'Setting CoordinateHelper.default_label directly is deprecated'u'Setting CoordinateHelper.default_label directly is deprecated'b'CoordinateHelper.ticks should not be accessed directly and is deprecated'u'CoordinateHelper.ticks should not be accessed directly and is deprecated'b'Setting CoordinateHelper.ticks directly is deprecated'u'Setting CoordinateHelper.ticks directly is deprecated'b'CoordinateHelper.ticklabels should not be accessed directly and is deprecated'u'CoordinateHelper.ticklabels should not be accessed directly and is deprecated'b'Setting CoordinateHelper.ticklabels directly is deprecated'u'Setting CoordinateHelper.ticklabels directly is deprecated'b'CoordinateHelper.axislabels should not be accessed directly and is deprecated'u'CoordinateHelper.axislabels should not be accessed directly and is deprecated'b'Setting CoordinateHelper.axislabels directly is deprecated'u'Setting CoordinateHelper.axislabels directly is deprecated'b'
        Plot grid lines for this coordinate.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments.

        Parameters
        ----------
        draw_grid : bool
            Whether to show the gridlines
        grid_type : {'lines', 'contours'}
            Whether to plot the contours by determining the grid lines in
            world coordinates and then plotting them in world coordinates
            (``'lines'``) or by determining the world coordinates at many
            positions in the image and then drawing contours
            (``'contours'``). The first is recommended for 2-d images, while
            for 3-d (or higher dimensional) cubes, the ``'contours'`` option
            is recommended. By default, 'lines' is used if the transform has
            an inverse, otherwise 'contours' is used.
        'u'
        Plot grid lines for this coordinate.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments.

        Parameters
        ----------
        draw_grid : bool
            Whether to show the gridlines
        grid_type : {'lines', 'contours'}
            Whether to plot the contours by determining the grid lines in
            world coordinates and then plotting them in world coordinates
            (``'lines'``) or by determining the world coordinates at many
            positions in the image and then drawing contours
            (``'contours'``). The first is recommended for 2-d images, while
            for 3-d (or higher dimensional) cubes, the ``'contours'`` option
            is recommended. By default, 'lines' is used if the transform has
            an inverse, otherwise 'contours' is used.
        'b'lines'u'lines'b'The specified transform has no inverse, so the grid cannot be drawn using grid_type='lines''u'The specified transform has no inverse, so the grid cannot be drawn using grid_type='lines''b'contours'u'contours'b'grid_type should be 'lines' or 'contours''u'grid_type should be 'lines' or 'contours''b'
        Set the coordinate type for the axis.

        Parameters
        ----------
        coord_type : str
            One of 'longitude', 'latitude' or 'scalar'
        coord_wrap : `~astropy.units.Quantity`, optional
            The value to wrap at for angular coordinates.
        'u'
        Set the coordinate type for the axis.

        Parameters
        ----------
        coord_type : str
            One of 'longitude', 'latitude' or 'scalar'
        coord_wrap : `~astropy.units.Quantity`, optional
            The value to wrap at for angular coordinates.
        'b'Passing 'coord_wrap' as a number is deprecated. Use a Quantity with units convertible to angular degrees instead.'u'Passing 'coord_wrap' as a number is deprecated. Use a Quantity with units convertible to angular degrees instead.'b'coord_wrap is not yet supported for non-longitude coordinates'u'coord_wrap is not yet supported for non-longitude coordinates'b'coord_type should be one of 'scalar', 'longitude', or 'latitude''u'coord_type should be one of 'scalar', 'longitude', or 'latitude''b'
        Set the format string to use for the major tick labels.

        See :ref:`tick_label_format` for accepted format strings and examples.

        Parameters
        ----------
        formatter : str or callable
            The format string to use, or a callable (for advanced use cases).
            If specified as a callable, this should take a
            `~astropy.units.Quantity` (which could be scalar or array) of tick
            world coordinates as well as an optional ``spacing`` keyword
            argument, which gives (also as a `~astropy.units.Quantity`) the
            spacing between ticks, and returns an iterable of strings
            containing the labels.
        'u'
        Set the format string to use for the major tick labels.

        See :ref:`tick_label_format` for accepted format strings and examples.

        Parameters
        ----------
        formatter : str or callable
            The format string to use, or a callable (for advanced use cases).
            If specified as a callable, this should take a
            `~astropy.units.Quantity` (which could be scalar or array) of tick
            world coordinates as well as an optional ``spacing`` keyword
            argument, which gives (also as a `~astropy.units.Quantity`) the
            spacing between ticks, and returns an iterable of strings
            containing the labels.
        'b'formatter should be a string'u'formatter should be a string'b'
        Given the value of a coordinate, will format it according to the
        format of the formatter_locator.

        Parameters
        ----------
        value : float
            The value to format
        format : {'auto', 'ascii', 'latex'}, optional
            The format to use - by default the formatting will be adjusted
            depending on whether Matplotlib is using LaTeX or MathTex. To
            get plain ASCII strings, use format='ascii'.
        'u'
        Given the value of a coordinate, will format it according to the
        format of the formatter_locator.

        Parameters
        ----------
        value : float
            The value to format
        format : {'auto', 'ascii', 'latex'}, optional
            The format to use - by default the formatting will be adjusted
            depending on whether Matplotlib is using LaTeX or MathTex. To
            get plain ASCII strings, use format='ascii'.
        'b'_fl_spacing'u'_fl_spacing'b'
        Set the separator to use for the angle major tick labels.

        Parameters
        ----------
        separator : str or tuple or None
            The separator between numbers in sexagesimal representation. Can be
            either a string or a tuple (or `None` for default).
        'u'
        Set the separator to use for the angle major tick labels.

        Parameters
        ----------
        separator : str or tuple or None
            The separator between numbers in sexagesimal representation. Can be
            either a string or a tuple (or `None` for default).
        'b'Separator can only be specified for angle coordinates'u'Separator can only be specified for angle coordinates'b'separator should be a string, a tuple, or None'u'separator should be a string, a tuple, or None'b'
        Set the unit for the major tick labels.

        Parameters
        ----------
        unit : class:`~astropy.units.Unit`
            The unit to which the tick labels should be converted to.
        decimal : bool, optional
            Whether to use decimal formatting. By default this is `False`
            for degrees or hours (which therefore use sexagesimal formatting)
            and `True` for all other units.
        show_decimal_unit : bool, optional
            Whether to include units when in decimal mode.
        'u'
        Set the unit for the major tick labels.

        Parameters
        ----------
        unit : class:`~astropy.units.Unit`
            The unit to which the tick labels should be converted to.
        decimal : bool, optional
            Whether to use decimal formatting. By default this is `False`
            for degrees or hours (which therefore use sexagesimal formatting)
            and `True` for all other units.
        show_decimal_unit : bool, optional
            Whether to include units when in decimal mode.
        'b'
        Get the unit for the major tick labels.
        'u'
        Get the unit for the major tick labels.
        'b'
        Set the location and properties of the ticks.

        At most one of the options from ``values``, ``spacing``, or
        ``number`` can be specified.

        Parameters
        ----------
        values : iterable, optional
            The coordinate values at which to show the ticks.
        spacing : float, optional
            The spacing between ticks.
        number : float, optional
            The approximate number of ticks shown.
        size : float, optional
            The length of the ticks in points
        color : str or tuple, optional
            A valid Matplotlib color for the ticks
        alpha : float, optional
            The alpha value (transparency) for the ticks.
        direction : {'in','out'}, optional
            Whether the ticks should point inwards or outwards.
        'u'
        Set the location and properties of the ticks.

        At most one of the options from ``values``, ``spacing``, or
        ``number`` can be specified.

        Parameters
        ----------
        values : iterable, optional
            The coordinate values at which to show the ticks.
        spacing : float, optional
            The spacing between ticks.
        number : float, optional
            The approximate number of ticks shown.
        size : float, optional
            The length of the ticks in points
        color : str or tuple, optional
            A valid Matplotlib color for the ticks
        alpha : float, optional
            The alpha value (transparency) for the ticks.
        direction : {'in','out'}, optional
            Whether the ticks should point inwards or outwards.
        'b'At most one of values, spacing, or number should be specified'u'At most one of values, spacing, or number should be specified'b'in'u'in'b'out'u'out'b'direction should be 'in' or 'out''u'direction should be 'in' or 'out''b'exclude_overlapping= should be passed to set_ticklabel instead of set_ticks'u'exclude_overlapping= should be passed to set_ticklabel instead of set_ticks'b'
        Set where ticks should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the ticks for this coordinate should appear.
            Should be a sequence containing zero or more of ``'b'``, ``'t'``,
            ``'l'``, ``'r'``. For example, ``'lb'`` will lead the ticks to be
            shown on the left and bottom axis. In addition, if ``'#'`` is
            included in the sequence, the position will be considered dynamic and
            will be updated at draw-time in order to show the ticks on the same
            axes as the tick labels are shown.
        'u'
        Set where ticks should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the ticks for this coordinate should appear.
            Should be a sequence containing zero or more of ``'b'``, ``'t'``,
            ``'l'``, ``'r'``. For example, ``'lb'`` will lead the ticks to be
            shown on the left and bottom axis. In addition, if ``'#'`` is
            included in the sequence, the position will be considered dynamic and
            will be updated at draw-time in order to show the ticks on the same
            axes as the tick labels are shown.
        'b'
        Get where tick labels will appear.
        'u'
        Get where tick labels will appear.
        'b'
        Set whether ticks are visible or not.

        Parameters
        ----------
        visible : bool
            The visibility of ticks. Setting as ``False`` will hide ticks
            along this coordinate.
        'u'
        Set whether ticks are visible or not.

        Parameters
        ----------
        visible : bool
            The visibility of ticks. Setting as ``False`` will hide ticks
            along this coordinate.
        'b'
        Set the visual properties for the tick labels.

        Parameters
        ----------
        size : float, optional
            The size of the ticks labels in points
        color : str or tuple, optional
            A valid Matplotlib color for the tick labels
        pad : float, optional
            Distance in points between tick and label.
        exclude_overlapping : bool, optional
            Whether to exclude tick labels that overlap over each other.
        simplify : bool, optional
            Whether to remove repeated parts of tick labels.
        **kwargs
            Other keyword arguments are passed to :class:`matplotlib.text.Text`.
        'u'
        Set the visual properties for the tick labels.

        Parameters
        ----------
        size : float, optional
            The size of the ticks labels in points
        color : str or tuple, optional
            A valid Matplotlib color for the tick labels
        pad : float, optional
            Distance in points between tick and label.
        exclude_overlapping : bool, optional
            Whether to exclude tick labels that overlap over each other.
        simplify : bool, optional
            Whether to remove repeated parts of tick labels.
        **kwargs
            Other keyword arguments are passed to :class:`matplotlib.text.Text`.
        'b'
        Set where tick labels should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the tick labels for this coordinate should
            appear. Should be a sequence containing zero or more of ``'b'``,
            ``'t'``, ``'l'``, ``'r'``. For example, ``'lb'`` will lead the
            tick labels to be shown on the left and bottom axis. In addition,
            if ``'#'`` is included in the sequence, the position will be
            considered dynamic and will be updated at draw-time in order to
            attempt to optimize the layout of all the coordinates.
        'u'
        Set where tick labels should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the tick labels for this coordinate should
            appear. Should be a sequence containing zero or more of ``'b'``,
            ``'t'``, ``'l'``, ``'r'``. For example, ``'lb'`` will lead the
            tick labels to be shown on the left and bottom axis. In addition,
            if ``'#'`` is included in the sequence, the position will be
            considered dynamic and will be updated at draw-time in order to
            attempt to optimize the layout of all the coordinates.
        'b'
        Set whether the tick labels are visible or not.

        Parameters
        ----------
        visible : bool
            The visibility of ticks. Setting as ``False`` will hide this
            coordinate's tick labels.
        'u'
        Set whether the tick labels are visible or not.

        Parameters
        ----------
        visible : bool
            The visibility of ticks. Setting as ``False`` will hide this
            coordinate's tick labels.
        'b'
        Set the text and optionally visual properties for the axis label.

        Parameters
        ----------
        text : str
            The axis label text.
        minpad : float, optional
            The padding for the label in terms of axis label font size.
        **kwargs
            Keywords are passed to :class:`matplotlib.text.Text`. These
            can include keywords to set the ``color``, ``size``, ``weight``, and
            other text properties.
        'u'
        Set the text and optionally visual properties for the axis label.

        Parameters
        ----------
        text : str
            The axis label text.
        minpad : float, optional
            The padding for the label in terms of axis label font size.
        **kwargs
            Keywords are passed to :class:`matplotlib.text.Text`. These
            can include keywords to set the ``color``, ``size``, ``weight``, and
            other text properties.
        'b'fontdict'u'fontdict'b'
        Get the text for the axis label.

        Returns
        -------
        label : str
            The axis label
        'u'
        Get the text for the axis label.

        Returns
        -------
        label : str
            The axis label
        'b'
        Render default axis labels if no explicit label is provided.

        Parameters
        ----------
        auto_label : `bool`
            `True` if default labels will be rendered.
        'u'
        Render default axis labels if no explicit label is provided.

        Parameters
        ----------
        auto_label : `bool`
            `True` if default labels will be rendered.
        'b'
        Render default axis labels if no explicit label is provided.

        Returns
        -------
        auto_axislabel : `bool`
            `True` if default labels will be rendered.
        'u'
        Render default axis labels if no explicit label is provided.

        Returns
        -------
        auto_axislabel : `bool`
            `True` if default labels will be rendered.
        'b' ['u' ['b'
        Set where axis labels should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the axis label for this coordinate should
            appear. Should be a sequence containing zero or more of ``'b'``,
            ``'t'``, ``'l'``, ``'r'``. For example, ``'lb'`` will lead the
            axis label to be shown on the left and bottom axis. In addition, if
            ``'#'`` is included in the sequence, the position will be considered
            dynamic and will be updated at draw-time in order to show the axis
            label on the same axes as the tick labels are shown.
        'u'
        Set where axis labels should appear.

        Parameters
        ----------
        position : str or list
            The axes on which the axis label for this coordinate should
            appear. Should be a sequence containing zero or more of ``'b'``,
            ``'t'``, ``'l'``, ``'r'``. For example, ``'lb'`` will lead the
            axis label to be shown on the left and bottom axis. In addition, if
            ``'#'`` is included in the sequence, the position will be considered
            dynamic and will be updated at draw-time in order to show the axis
            label on the same axes as the tick labels are shown.
        'b'
        Get where axis labels will appear.
        'u'
        Get where axis labels will appear.
        'b'
        Set the rule used to determine when the axis label is drawn.

        Parameters
        ----------
        rule : str
            If the rule is 'always' axis labels will always be drawn on the
            axis. If the rule is 'ticks' the label will only be drawn if ticks
            were drawn on that axis. If the rule is 'labels' the axis label
            will only be drawn if tick labels were drawn on that axis.
        'u'
        Set the rule used to determine when the axis label is drawn.

        Parameters
        ----------
        rule : str
            If the rule is 'always' axis labels will always be drawn on the
            axis. If the rule is 'ticks' the label will only be drawn if ticks
            were drawn on that axis. If the rule is 'labels' the axis label
            will only be drawn if tick labels were drawn on that axis.
        'b'
        Get the rule used to determine when the axis label is drawn.
        'u'
        Get the rule used to determine when the axis label is drawn.
        'b'grid lines'u'grid lines'b'
        Draw all ticks and ticklabels.

        Parameters
        ----------
        existing_bboxes : list[Bbox]
            All bboxes for ticks that have already been drawn by other
            coordinates.
        'u'
        Draw all ticks and ticklabels.

        Parameters
        ----------
        existing_bboxes : list[Bbox]
            All bboxes for ticks that have already been drawn by other
            coordinates.
        'b'axis labels'u'axis labels'b'minor'b'major'b'
        Display minor ticks for this coordinate.

        Parameters
        ----------
        display_minor_ticks : bool
            Whether or not to display minor ticks.
        'u'
        Display minor ticks for this coordinate.

        Parameters
        ----------
        display_minor_ticks : bool
            Whether or not to display minor ticks.
        'b'
        Set the frequency of minor ticks per major ticks.

        Parameters
        ----------
        frequency : int
            The number of minor ticks per major ticks.
        'u'
        Set the frequency of minor ticks per major ticks.

        Parameters
        ----------
        frequency : int
            The number of minor ticks per major ticks.
        'b'
        Define a gridline that can be used for ticks and labels.

        This gridline is not itself drawn, but instead can be specified in calls to
        methods such as
        :meth:`~astropy.visualization.wcsaxes.coordinate_helpers.CoordinateHelper.set_ticklabel_position`
        for drawing ticks and labels.  Since the gridline has a constant value in this
        coordinate, and thus would not have any ticks or labels for the same coordinate,
        the call to
        :meth:`~astropy.visualization.wcsaxes.coordinate_helpers.CoordinateHelper.set_ticklabel_position`
        would typically be made on the complementary coordinate.

        Parameters
        ----------
        name : str
            The name for the gridline, usually a single character, but can be longer
        constant : `~astropy.units.Quantity`
            The constant coordinate value of the gridline

        Notes
        -----
        A limitation is that the tickable part of the gridline must be contiguous.  If
        the gridline consists of more than one disconnected segment within the plot
        extent, only one of those segments will be made tickable.
        'u'
        Define a gridline that can be used for ticks and labels.

        This gridline is not itself drawn, but instead can be specified in calls to
        methods such as
        :meth:`~astropy.visualization.wcsaxes.coordinate_helpers.CoordinateHelper.set_ticklabel_position`
        for drawing ticks and labels.  Since the gridline has a constant value in this
        coordinate, and thus would not have any ticks or labels for the same coordinate,
        the call to
        :meth:`~astropy.visualization.wcsaxes.coordinate_helpers.CoordinateHelper.set_ticklabel_position`
        would typically be made on the complementary coordinate.

        Parameters
        ----------
        name : str
            The name for the gridline, usually a single character, but can be longer
        constant : `~astropy.units.Quantity`
            The constant coordinate value of the gridline

        Notes
        -----
        A limitation is that the tickable part of the gridline must be contiguous.  If
        the gridline consists of more than one disconnected segment within the plot
        extent, only one of those segments will be made tickable.
        'b'The frame already has a spine with the name ''u'The frame already has a spine with the name ''b'_grid'u'_grid'b'both'u'both'b'
        Method to set the tick and tick label parameters in the same way as the
        :meth:`~matplotlib.axes.Axes.tick_params` method in Matplotlib.

        This is provided for convenience, but the recommended API is to use
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks_position`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel_position`,
        and :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.grid`.

        Parameters
        ----------
        which : {'both', 'major', 'minor'}, optional
            Which ticks to apply the settings to. By default, setting are
            applied to both major and minor ticks. Note that if ``'minor'`` is
            specified, only the length of the ticks can be set currently.
        direction : {'in', 'out'}, optional
            Puts ticks inside the axes, or outside the axes.
        length : float, optional
            Tick length in points.
        width : float, optional
            Tick width in points.
        color : color, optional
            Tick color (accepts any valid Matplotlib color)
        pad : float, optional
            Distance in points between tick and label.
        labelsize : float or str, optional
            Tick label font size in points or as a string (e.g., 'large').
        labelcolor : color, optional
            Tick label color (accepts any valid Matplotlib color)
        colors : color, optional
            Changes the tick color and the label color to the same value
             (accepts any valid Matplotlib color).
        bottom, top, left, right : bool, optional
            Where to draw the ticks. Note that this will not work correctly if
            the frame is not rectangular.
        labelbottom, labeltop, labelleft, labelright : bool, optional
            Where to draw the tick labels. Note that this will not work
            correctly if the frame is not rectangular.
        grid_color : color, optional
            The color of the grid lines (accepts any valid Matplotlib color).
        grid_alpha : float, optional
            Transparency of grid lines: 0 (transparent) to 1 (opaque).
        grid_linewidth : float, optional
            Width of grid lines in points.
        grid_linestyle : str, optional
            The style of the grid lines (accepts any valid Matplotlib line
            style).
        'u'
        Method to set the tick and tick label parameters in the same way as the
        :meth:`~matplotlib.axes.Axes.tick_params` method in Matplotlib.

        This is provided for convenience, but the recommended API is to use
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks_position`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel_position`,
        and :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.grid`.

        Parameters
        ----------
        which : {'both', 'major', 'minor'}, optional
            Which ticks to apply the settings to. By default, setting are
            applied to both major and minor ticks. Note that if ``'minor'`` is
            specified, only the length of the ticks can be set currently.
        direction : {'in', 'out'}, optional
            Puts ticks inside the axes, or outside the axes.
        length : float, optional
            Tick length in points.
        width : float, optional
            Tick width in points.
        color : color, optional
            Tick color (accepts any valid Matplotlib color)
        pad : float, optional
            Distance in points between tick and label.
        labelsize : float or str, optional
            Tick label font size in points or as a string (e.g., 'large').
        labelcolor : color, optional
            Tick label color (accepts any valid Matplotlib color)
        colors : color, optional
            Changes the tick color and the label color to the same value
             (accepts any valid Matplotlib color).
        bottom, top, left, right : bool, optional
            Where to draw the ticks. Note that this will not work correctly if
            the frame is not rectangular.
        labelbottom, labeltop, labelleft, labelright : bool, optional
            Where to draw the tick labels. Note that this will not work
            correctly if the frame is not rectangular.
        grid_color : color, optional
            The color of the grid lines (accepts any valid Matplotlib color).
        grid_alpha : float, optional
            Transparency of grid lines: 0 (transparent) to 1 (opaque).
        grid_linewidth : float, optional
            Width of grid lines in points.
        grid_linestyle : str, optional
            The style of the grid lines (accepts any valid Matplotlib line
            style).
        'b'colors'u'colors'b'labelcolor'u'labelcolor'b'When setting which='minor', the only property that can be set at the moment is 'length' (the minor tick length)'u'When setting which='minor', the only property that can be set at the moment is 'length' (the minor tick length)'b'direction'u'direction'b'bottom'u'bottom'b'top'u'top'b'labelsize'u'labelsize'b'pad'u'pad'b'grid_color'u'grid_color'b'grid_alpha'u'grid_alpha'b'grid_linewidth'u'grid_linewidth'b'grid_linestyle'u'grid_linestyle'u'astropy.visualization.wcsaxes.coordinate_helpers'u'visualization.wcsaxes.coordinate_helpers'u'wcsaxes.coordinate_helpers'u'coordinate_helpers'LONLATwrap_180values_newfind_coordinate_rangeextentcoord_typescoord_unitscoord_wraps
    Find the range of coordinates to use for ticks/grids.

    Parameters
    ----------
    transform : func
        Function to transform pixel to world coordinates. Should take two
        values (the pixel coordinates) and return two values (the world
        coordinates).
    extent : iterable
        The range of the image viewport in pixel coordinates, given as [xmin,
        xmax, ymin, ymax].
    coord_types : list of str
        Whether each coordinate is a ``'longitude'``, ``'latitude'``, or
        ``'scalar'`` value.
    coord_units : list of `astropy.units.Unit`
        The units for each coordinate.
    coord_wraps : list of `astropy.units.Quantity`
        The wrap angles for longitudes.
    xpypxwwjumptruncxw_minnanmaxxw_maxxw_min_checkxw_max_checkx_range300.0Passing 'coord_wraps' as numbers is deprecated. Use a Quantity with units convertible to angular degrees instead.# Algorithm inspired by PGSBOX from WCSLIB by M. Calabretta# Sample coordinates on a NX x NY grid.# Iron out coordinates along first row# Now iron out coordinates along all columns, starting with first row.# Check if range is smaller when normalizing to the range 0 to 360# Check if range is smaller when normalizing to the range -180 to 180b'
    Find the range of coordinates to use for ticks/grids.

    Parameters
    ----------
    transform : func
        Function to transform pixel to world coordinates. Should take two
        values (the pixel coordinates) and return two values (the world
        coordinates).
    extent : iterable
        The range of the image viewport in pixel coordinates, given as [xmin,
        xmax, ymin, ymax].
    coord_types : list of str
        Whether each coordinate is a ``'longitude'``, ``'latitude'``, or
        ``'scalar'`` value.
    coord_units : list of `astropy.units.Unit`
        The units for each coordinate.
    coord_wraps : list of `astropy.units.Quantity`
        The wrap angles for longitudes.
    'u'
    Find the range of coordinates to use for ticks/grids.

    Parameters
    ----------
    transform : func
        Function to transform pixel to world coordinates. Should take two
        values (the pixel coordinates) and return two values (the world
        coordinates).
    extent : iterable
        The range of the image viewport in pixel coordinates, given as [xmin,
        xmax, ymin, ymax].
    coord_types : list of str
        Whether each coordinate is a ``'longitude'``, ``'latitude'``, or
        ``'scalar'`` value.
    coord_units : list of `astropy.units.Unit`
        The units for each coordinate.
    coord_wraps : list of `astropy.units.Quantity`
        The wrap angles for longitudes.
    'b'Passing 'coord_wraps' as numbers is deprecated. Use a Quantity with units convertible to angular degrees instead.'u'Passing 'coord_wraps' as numbers is deprecated. Use a Quantity with units convertible to angular degrees instead.'u'astropy.visualization.wcsaxes.coordinate_range'u'visualization.wcsaxes.coordinate_range'u'wcsaxes.coordinate_range'u'coordinate_range'coordinate_range
    A container for coordinate helpers that represents a coordinate system.

    This object can be used to access coordinate helpers by index (like a list)
    or by name (like a dictionary).

    Parameters
    ----------
    axes : :class:`~astropy.visualization.wcsaxes.WCSAxes`
        The axes the coordinate map belongs to.
    transform : `~matplotlib.transforms.Transform`, optional
        The transform for the data.
    coord_meta : dict, optional
        A dictionary providing additional metadata. This should include the keys
        ``type``, ``wrap``, and ``unit``. Each of these should be a list with as
        many items as the dimension of the coordinate system. The ``type``
        entries should be one of ``longitude``, ``latitude``, or ``scalar``, the
        ``wrap`` entries should give, for the longitude, the angle at which the
        coordinate wraps (and `None` otherwise), and the ``unit`` should give
        the unit of the coordinates as :class:`~astropy.units.Unit` instances.
        This can optionally also include a ``format_unit`` entry giving the
        units to use for the tick labels (if not specified, this defaults to
        ``unit``).
    frame_class : type, optional
        The class for the frame, which should be a subclass of
        :class:`~astropy.visualization.wcsaxes.frame.BaseFrame`. The default is to use a
        :class:`~astropy.visualization.wcsaxes.frame.RectangularFrame`
    previous_frame_path : `~matplotlib.path.Path`, optional
        When changing the WCS of the axes, the frame instance will change but
        we might want to keep reusing the same underlying matplotlib
        `~matplotlib.path.Path` - in that case, this can be passed to this
        keyword argument.
    previous_frame_path_coords_aliasesvisible_countdefault_axis_labelnmvisibility
        Plot gridlines for both coordinates.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments.

        Parameters
        ----------
        draw_grid : bool
            Whether to show the gridlines
        grid_type : { 'lines' | 'contours' }
            Whether to plot the contours by determining the grid lines in
            world coordinates and then plotting them in world coordinates
            (``'lines'``) or by determining the world coordinates at many
            positions in the image and then drawing contours
            (``'contours'``). The first is recommended for 2-d images, while
            for 3-d (or higher dimensional) cubes, the ``'contours'`` option
            is recommended. By default, 'lines' is used if the transform has
            an inverse, otherwise 'contours' is used.
        _as_tableicoord<CoordinatesMap with  world coordinates:

  

># Set up coordinates# Extract coordinate metadata# Set up aliases for coordinates# Do not replace an alias already in the map if we have# more than one alias for this axis.# Import Table here to avoid importing the astropy.table package# every time astropy.visualization.wcsaxes is imported.b'
    A container for coordinate helpers that represents a coordinate system.

    This object can be used to access coordinate helpers by index (like a list)
    or by name (like a dictionary).

    Parameters
    ----------
    axes : :class:`~astropy.visualization.wcsaxes.WCSAxes`
        The axes the coordinate map belongs to.
    transform : `~matplotlib.transforms.Transform`, optional
        The transform for the data.
    coord_meta : dict, optional
        A dictionary providing additional metadata. This should include the keys
        ``type``, ``wrap``, and ``unit``. Each of these should be a list with as
        many items as the dimension of the coordinate system. The ``type``
        entries should be one of ``longitude``, ``latitude``, or ``scalar``, the
        ``wrap`` entries should give, for the longitude, the angle at which the
        coordinate wraps (and `None` otherwise), and the ``unit`` should give
        the unit of the coordinates as :class:`~astropy.units.Unit` instances.
        This can optionally also include a ``format_unit`` entry giving the
        units to use for the tick labels (if not specified, this defaults to
        ``unit``).
    frame_class : type, optional
        The class for the frame, which should be a subclass of
        :class:`~astropy.visualization.wcsaxes.frame.BaseFrame`. The default is to use a
        :class:`~astropy.visualization.wcsaxes.frame.RectangularFrame`
    previous_frame_path : `~matplotlib.path.Path`, optional
        When changing the WCS of the axes, the frame instance will change but
        we might want to keep reusing the same underlying matplotlib
        `~matplotlib.path.Path` - in that case, this can be passed to this
        keyword argument.
    'u'
    A container for coordinate helpers that represents a coordinate system.

    This object can be used to access coordinate helpers by index (like a list)
    or by name (like a dictionary).

    Parameters
    ----------
    axes : :class:`~astropy.visualization.wcsaxes.WCSAxes`
        The axes the coordinate map belongs to.
    transform : `~matplotlib.transforms.Transform`, optional
        The transform for the data.
    coord_meta : dict, optional
        A dictionary providing additional metadata. This should include the keys
        ``type``, ``wrap``, and ``unit``. Each of these should be a list with as
        many items as the dimension of the coordinate system. The ``type``
        entries should be one of ``longitude``, ``latitude``, or ``scalar``, the
        ``wrap`` entries should give, for the longitude, the angle at which the
        coordinate wraps (and `None` otherwise), and the ``unit`` should give
        the unit of the coordinates as :class:`~astropy.units.Unit` instances.
        This can optionally also include a ``format_unit`` entry giving the
        units to use for the tick labels (if not specified, this defaults to
        ``unit``).
    frame_class : type, optional
        The class for the frame, which should be a subclass of
        :class:`~astropy.visualization.wcsaxes.frame.BaseFrame`. The default is to use a
        :class:`~astropy.visualization.wcsaxes.frame.RectangularFrame`
    previous_frame_path : `~matplotlib.path.Path`, optional
        When changing the WCS of the axes, the frame instance will change but
        we might want to keep reusing the same underlying matplotlib
        `~matplotlib.path.Path` - in that case, this can be passed to this
        keyword argument.
    'b'type'u'type'b'format_unit'u'format_unit'b'default_axis_label'u'default_axis_label'b'
        Plot gridlines for both coordinates.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments.

        Parameters
        ----------
        draw_grid : bool
            Whether to show the gridlines
        grid_type : { 'lines' | 'contours' }
            Whether to plot the contours by determining the grid lines in
            world coordinates and then plotting them in world coordinates
            (``'lines'``) or by determining the world coordinates at many
            positions in the image and then drawing contours
            (``'contours'``). The first is recommended for 2-d images, while
            for 3-d (or higher dimensional) cubes, the ``'contours'`` option
            is recommended. By default, 'lines' is used if the transform has
            an inverse, otherwise 'contours' is used.
        'u'
        Plot gridlines for both coordinates.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments.

        Parameters
        ----------
        draw_grid : bool
            Whether to show the gridlines
        grid_type : { 'lines' | 'contours' }
            Whether to plot the contours by determining the grid lines in
            world coordinates and then plotting them in world coordinates
            (``'lines'``) or by determining the world coordinates at many
            positions in the image and then drawing contours
            (``'contours'``). The first is recommended for 2-d images, while
            for 3-d (or higher dimensional) cubes, the ``'contours'`` option
            is recommended. By default, 'lines' is used if the transform has
            an inverse, otherwise 'contours' is used.
        'b'aliases'u'aliases'b'<CoordinatesMap with 'u'<CoordinatesMap with 'b' world coordinates:

'u' world coordinates:

'b'  'u'  'b'

>'u'

>'u'astropy.visualization.wcsaxes.coordinates_map'u'visualization.wcsaxes.coordinates_map'u'wcsaxes.coordinates_map'u'coordinates_map'
Core units classes and functions.
unicodedataUnitParserWarningresolve_fractionssanitize_powersanitize_scaleCollectionMutableMappingTracebackTypePhysicalTypeIDUnitLikeUnitPowerLikeUnitScaleLikeIrreducibleUnitPrefixUnitUnitPrefixadd_enabled_aliasesset_enabled_aliasesset_enabled_equivalenciesUNITY_WARNING_LOCKraise_WARNING_ACTIONS_flatten_units_collection
    Given a list of sequences, modules or dictionaries of units, or
    single units, return a flat set of all the units found.
    ismodule_normalize_equivalenciesNormalizes equivalencies ensuring each is a 4-tuple.

    The resulting tuple is of the form::

        (from_unit, to_unit, forward_func, backward_func)

    Parameters
    ----------
    equivalencies : list of equivalency pairs

    Raises
    ------
    ValueError if an equivalency cannot be interpreted
    normalizedequivfunittunitInvalid equivalence entry _UnitRegistry
    Manages a registry of the enabled units.
    _equivalencies_all_units_non_prefix_units_by_physical_type_reset_units_reset_equivalencies_reset_aliasesall_unitsnon_prefix_units
        Sets the units enabled in the unit registry.

        These units are searched when using
        `UnitBase.find_equivalent_units`, for example.

        Parameters
        ----------
        units : list of sequence, dict, or module
            This is a list of things in which units may be found
            (sequences, dicts or modules), or units themselves.  The
            entire set will be "enabled" for searching through by
            methods like `UnitBase.find_equivalent_units` and
            `UnitBase.compose`.
        
        Adds to the set of units enabled in the unit registry.

        These units are searched when using
        `UnitBase.find_equivalent_units`, for example.

        Parameters
        ----------
        units : list of sequence, dict, or module
            This is a list of things in which units may be found
            (sequences, dicts or modules), or units themselves.  The
            entire set will be added to the "enabled" set for
            searching through by methods like
            `UnitBase.find_equivalent_units` and `UnitBase.compose`.
        st_namesObject with name  already exists in namespace. Filter the set of units to avoid name clashes before enabling them." already exists in namespace. ""Filter the set of units to avoid name clashes before ""enabling them."_physical_type_idget_units_with_physical_type
        Get all units in the registry with the same physical type as
        the given unit.

        Parameters
        ----------
        unit : UnitBase instance
        
        Sets the equivalencies enabled in the unit registry.

        These equivalencies are used if no explicit equivalencies are given,
        both in unit conversion and in finding equivalent units.

        This is meant in particular for allowing angles to be dimensionless.
        Use with care.

        Parameters
        ----------
        equivalencies : list of tuple
            List of equivalent pairs, e.g., as returned by
            `~astropy.units.dimensionless_angles`.
        
        Adds to the set of equivalencies enabled in the unit registry.

        These equivalencies are used if no explicit equivalencies are given,
        both in unit conversion and in finding equivalent units.

        This is meant in particular for allowing angles to be dimensionless.
        Use with care.

        Parameters
        ----------
        equivalencies : list of tuple
            List of equivalent pairs, e.g., as returned by
            `~astropy.units.dimensionless_angles`.
        
        Set aliases for units.

        Parameters
        ----------
        aliases : dict of str, Unit
            The aliases to set. The keys must be the string aliases, and values
            must be the `astropy.units.Unit` that the alias will be mapped to.

        Raises
        ------
        ValueError
            If the alias already defines a different unit.

        
        Add aliases for units.

        Parameters
        ----------
        aliases : dict of str, Unit
            The aliases to add. The keys must be the string aliases, and values
            must be the `astropy.units.Unit` that the alias will be mapped to.

        Raises
        ------
        ValueError
            If the alias already defines a different unit.

         already means , so cannot be used as an alias for ", so ""cannot be used as an alias for " already is an alias for _UnitContext_unit_registriestb
    Sets the units enabled in the unit registry.

    These units are searched when using
    `UnitBase.find_equivalent_units`, for example.

    This may be used either permanently, or as a context manager using
    the ``with`` statement (see example below).

    Parameters
    ----------
    units : list of sequence, dict, or module
        This is a list of things in which units may be found
        (sequences, dicts or modules), or units themselves.  The
        entire set will be "enabled" for searching through by methods
        like `UnitBase.find_equivalent_units` and `UnitBase.compose`.

    Examples
    --------
    >>> from astropy import units as u
    >>> with u.set_enabled_units([u.pc]):
    ...     u.m.find_equivalent_units()
    ...
      Primary name | Unit definition | Aliases
    [
      pc           | 3.08568e+16 m   | parsec  ,
    ]
    >>> u.m.find_equivalent_units()
      Primary name | Unit definition | Aliases
    [
      AU           | 1.49598e+11 m   | au, astronomical_unit            ,
      Angstrom     | 1e-10 m         | AA, angstrom,                   ,
      cm           | 0.01 m          | centimeter                       ,
      earthRad     | 6.3781e+06 m    | R_earth, Rearth                  ,
      jupiterRad   | 7.1492e+07 m    | R_jup, Rjup, R_jupiter, Rjupiter ,
      lsec         | 2.99792e+08 m   | lightsecond                      ,
      lyr          | 9.46073e+15 m   | lightyear                        ,
      m            | irreducible     | meter                            ,
      micron       | 1e-06 m         |                                  ,
      pc           | 3.08568e+16 m   | parsec                           ,
      solRad       | 6.957e+08 m     | R_sun, Rsun                      ,
    ]
    
    Adds to the set of units enabled in the unit registry.

    These units are searched when using
    `UnitBase.find_equivalent_units`, for example.

    This may be used either permanently, or as a context manager using
    the ``with`` statement (see example below).

    Parameters
    ----------
    units : list of sequence, dict, or module
        This is a list of things in which units may be found
        (sequences, dicts or modules), or units themselves.  The
        entire set will be added to the "enabled" set for searching
        through by methods like `UnitBase.find_equivalent_units` and
        `UnitBase.compose`.

    Examples
    --------
    >>> from astropy import units as u
    >>> from astropy.units import imperial
    >>> with u.add_enabled_units(imperial):
    ...     u.m.find_equivalent_units()
    ...
      Primary name | Unit definition | Aliases
    [
      AU           | 1.49598e+11 m   | au, astronomical_unit            ,
      Angstrom     | 1e-10 m         | AA, angstrom,                   ,
      cm           | 0.01 m          | centimeter                       ,
      earthRad     | 6.3781e+06 m    | R_earth, Rearth                  ,
      ft           | 0.3048 m        | foot                             ,
      fur          | 201.168 m       | furlong                          ,
      inch         | 0.0254 m        |                                  ,
      jupiterRad   | 7.1492e+07 m    | R_jup, Rjup, R_jupiter, Rjupiter ,
      lsec         | 2.99792e+08 m   | lightsecond                      ,
      lyr          | 9.46073e+15 m   | lightyear                        ,
      m            | irreducible     | meter                            ,
      mi           | 1609.34 m       | mile                             ,
      micron       | 1e-06 m         |                                  ,
      mil          | 2.54e-05 m      | thou                             ,
      nmi          | 1852 m          | nauticalmile, NM                 ,
      pc           | 3.08568e+16 m   | parsec                           ,
      solRad       | 6.957e+08 m     | R_sun, Rsun                      ,
      yd           | 0.9144 m        | yard                             ,
    ]
    
    Sets the equivalencies enabled in the unit registry.

    These equivalencies are used if no explicit equivalencies are given,
    both in unit conversion and in finding equivalent units.

    This is meant in particular for allowing angles to be dimensionless.
    Use with care.

    Parameters
    ----------
    equivalencies : list of tuple
        list of equivalent pairs, e.g., as returned by
        `~astropy.units.dimensionless_angles`.

    Examples
    --------
    Exponentiation normally requires dimensionless quantities.  To avoid
    problems with complex phases::

        >>> from astropy import units as u
        >>> with u.set_enabled_equivalencies(u.dimensionless_angles()):
        ...     phase = 0.5 * u.cycle
        ...     np.exp(1j*phase)  # doctest: +FLOAT_CMP
        <Quantity -1.+1.2246468e-16j>
    
    Adds to the equivalencies enabled in the unit registry.

    These equivalencies are used if no explicit equivalencies are given,
    both in unit conversion and in finding equivalent units.

    This is meant in particular for allowing angles to be dimensionless.
    Since no equivalencies are enabled by default, generally it is recommended
    to use `set_enabled_equivalencies`.

    Parameters
    ----------
    equivalencies : list of tuple
        list of equivalent pairs, e.g., as returned by
        `~astropy.units.dimensionless_angles`.
    
    Set aliases for units.

    This is useful for handling alternate spellings for units, or
    misspelled units in files one is trying to read.

    Parameters
    ----------
    aliases : dict of str, Unit
        The aliases to set. The keys must be the string aliases, and values
        must be the `astropy.units.Unit` that the alias will be mapped to.

    Raises
    ------
    ValueError
        If the alias already defines a different unit.

    Examples
    --------
    To temporarily allow for a misspelled 'Angstroem' unit::

        >>> from astropy import units as u
        >>> with u.set_enabled_aliases({'Angstroem': u.Angstrom}):
        ...     print(u.Unit("Angstroem", parse_strict="raise") == u.Angstrom)
        True

    
    Add aliases for units.

    This is useful for handling alternate spellings for units, or
    misspelled units in files one is trying to read.

    Since no aliases are enabled by default, generally it is recommended
    to use `set_enabled_aliases`.

    Parameters
    ----------
    aliases : dict of str, Unit
        The aliases to add. The keys must be the string aliases, and values
        must be the `astropy.units.Unit` that the alias will be mapped to.

    Raises
    ------
    ValueError
        If the alias already defines a different unit.

    Examples
    --------
    To temporarily allow for a misspelled 'Angstroem' unit::

        >>> from astropy import units as u
        >>> with u.add_enabled_aliases({'Angstroem': u.Angstrom}):
        ...     print(u.Unit("Angstroem", parse_strict="raise") == u.Angstrom)
        True

    
    Abstract base class for units.

    Most of the arithmetic operations on units are defined in this
    base class.

    Should not be instantiated by users directly.
    _repr_latex_
        Generate latex representation of unit name.  This is used by
        the IPython notebook to print a unit with a nice layout.

        Returns
        -------
        Latex string
        unicode_escapeUnit("")
        Returns an identifier that uniquely identifies the physical
        type of this unit.  It is comprised of the bases and powers of
        this unit, without the scale.  Since it is hashable, it is
        useful as a dictionary key.
        The scale of the unit.The bases of the unit.The powers of the bases of the unit.Output the unit in the given format as a string.

        Parameters
        ----------
        format : `astropy.units.format.Base` subclass or str or None
            The name of a format or a formatter class.  If not
            provided (or `None`), defaults to the generic format.

        **kwargs
            Further options forwarded to the formatter. Currently
            recognized is ``fraction``, which can take the following values:

            - `False` : display unit bases with negative powers as they are;
            - 'inline' or `True` : use a single-line fraction;
            - 'multiline' : use a multiline fraction (available for the
              'latex', 'console' and 'unicode' formats only; for others,
              an 'inline' fraction is used).

        Raises
        ------
        TypeError
            If ``format`` is of the wrong type.
        ValueError
            If ``format`` or ``fraction`` are not recognized.

        Examples
        --------
        >>> import astropy.units as u
        >>> kms = u.Unit('km / s')
        >>> kms.to_string()  # Generic uses fraction='inline' by default
        'km / s'
        >>> kms.to_string('latex')  # Latex uses fraction='multiline' by default
        '$\\mathrm{\\frac{km}{s}}$'
        >>> print(kms.to_string('unicode', fraction=False))
        km s
        >>> print(kms.to_string('unicode', fraction='inline'))
        km / s
        >>> print(kms.to_string('unicode', fraction='multiline'))
        km
        
        s
        Normalizes equivalencies, ensuring each is a 4-tuple.

        The resulting tuple is of the form::

            (from_unit, to_unit, forward_func, backward_func)

        Parameters
        ----------
        equivalencies : list of equivalency pairs, or None

        Returns
        -------
        A normalized list, including possible global defaults set by, e.g.,
        `set_enabled_equivalencies`, except when `equivalencies`=`None`,
        in which case the returned list is always empty.

        Raises
        ------
        ValueError if an equivalency cannot be interpreted
        Quantities and Units may only be raised to a scalar power_warn_about_operation_with_deprecated_type involving a unit and a '' instance are deprecated since v7.1. Convert "' instance are ""deprecated since v7.1. Convert " to a unit explicitly.is_unitydivisionsproducts>> is not implemented. Did you mean to convert to a Quantity with unit ">> is not implemented. Did you mean to convert ""to a Quantity with unit " using '<<'?_hash__getstate___toCheck whether this unit is equivalent to ``other``.

        Parameters
        ----------
        other : `~astropy.units.Unit`, str, or tuple
            The unit to convert to. If a tuple of units is specified, this
            method returns true if the unit matches any of those in the tuple.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        bool
        _is_equivalentReturns `True` if this unit is equivalent to `other`.
        See `is_equivalent`, except that a proper Unit object should be
        given (i.e., no string) and that the equivalency list should be
        normalized using `_normalize_equivalencies`.
        _apply_equivalencies
        Internal function (used from `get_converter`) to apply
        equivalence pairs.
        make_converterscale1scale2convert_condition_argratioratio_in_funitget_err_strunit_strunknown' (other_str are not convertible
        Create a function that converts values from this unit to another.

        Parameters
        ----------
        other : unit-like
            The unit to convert to.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        func : callable
            A callable that takes an array-like argument and returns
            it converted from units of self to units of other.

        Raises
        ------
        UnitsError
            If the units cannot be converted to each other.

        Notes
        -----
        This method is used internally in `Quantity` to convert to
        different units. Note that the function returned takes
        and returns values, not quantities.
        unit_scale_converter
        Returns the scale to the specified unit.

        See `to`, except that a Unit object should be given (i.e., no
        string), and that all defaults are used, i.e., no
        equivalencies and value=1.
        self_decomposedother_decomposedself_baseother_base' is not a scaled version of '
        Return the converted values in the specified unit.

        Parameters
        ----------
        other : unit-like
            The unit to convert to.

        value : int, float, or scalar array-like, optional
            Value(s) in the current unit to be converted to the
            specified unit.  If not provided, defaults to 1.0

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        values : scalar or array
            Converted value(s). Input value sequences are returned as
            numpy arrays.

        Raises
        ------
        UnitsError
            If units are inconsistent
        to()in_units
        Alias for `to` for backward compatibility with pynbody.
        
        Return a unit object composed of only irreducible units.

        Parameters
        ----------
        bases : sequence of UnitBase, optional
            The bases to decompose into.  When not provided,
            decomposes down to any irreducible units.  When provided,
            the decomposed result will only contain the given units.
            This will raises a `UnitsError` if it's not possible
            to do so.

        Returns
        -------
        unit : `~astropy.units.CompositeUnit`
            New object containing only irreducible unit objects.
        _composemax_depthcached_resultsis_final_resultpartial_resultsfinal_resultstunit_decomposedcomposedfactoredlen_basesfinal_resultcomposed_listsubcomposedmin_lengthsubresultsCannot represent unit  in terms of the given unitscomposeinclude_prefix_units
        Return the simplest possible composite unit(s) that represent
        the given unit.  Since there may be multiple equally simple
        compositions of the unit, a list of units is always returned.

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also list.  See
            :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        units : set of `~astropy.units.Unit`, optional
            If not provided, any known units may be used to compose
            into.  Otherwise, ``units`` is a dict, module or sequence
            containing the units to compose into.

        max_depth : int, optional
            The maximum recursion depth to use when composing into
            composite units.

        include_prefix_units : bool, optional
            When `True`, include prefixed units in the result.
            Default is `True` if a sequence is passed in to ``units``,
            `False` otherwise.

        Returns
        -------
        units : list of `CompositeUnit`
            A list of candidate compositions.  These will all be
            equally simple, but it may not be possible to
            automatically determine which of the candidates are
            better.
        has_bases_in_commonabhas_bases_in_common_with_equivfilter_unitsdecomposed_get_units_with_same_physical_typeto_systemConvert this unit into ones belonging to the given system.

        Since more than one result may be possible, a list is always
        returned.

        Parameters
        ----------
        system : module
            The module that defines the unit system.  Commonly used
            ones include `astropy.units.si` and `astropy.units.cgs`.

            To use your own module it must contain unit objects and a
            sequence member named ``bases`` containing the base units of
            the system.

        Returns
        -------
        units : list of `CompositeUnit`
            With an attempt to sort simpler units to the start (see examples).

        Examples
        --------
        >>> import astropy.units as u
        >>> (u.N / u.m**2).to_system(u.si)  # preference for simpler units
        [Unit("Pa"), Unit("N / m2"), Unit("J / m3")]
        >>> u.Pa.to_system(u.cgs)
        [Unit("10 Ba"), Unit("10 P / s")]
        >>> u.Ba.to_system(u.si)
        [Unit("0.1 Pa"), Unit("0.1 N / m2"), Unit("0.1 J / m3")]
        >>> (u.AU/u.yr).to_system(u.cgs)  # preference for base units
        [Unit("474047 cm / s"), Unit("474047 Gal s")]
        >>> (u.m / u.s**2).to_system(u.cgs)
        [Unit("100 cm / s2"), Unit("100 Gal")]

        The unit expressed in terms of SI units.The unit expressed in terms of CGS units.
        Physical type(s) dimensionally compatible with the unit.

        Returns
        -------
        `~astropy.units.physical.PhysicalType`
            A representation of the physical type(s) of a unit.

        Examples
        --------
        >>> from astropy import units as u
        >>> u.m.physical_type
        PhysicalType('length')
        >>> (u.m ** 2 / u.s).physical_type
        PhysicalType({'diffusivity', 'kinematic viscosity'})

        Physical types can be compared to other physical types
        (recommended in packages) or to strings.

        >>> area = (u.m ** 2).physical_type
        >>> area == u.m.physical_type ** 2
        True
        >>> area == "area"
        True

        `~astropy.units.physical.PhysicalType` objects can be used for
        dimensional analysis.

        >>> number_density = u.m.physical_type ** -3
        >>> velocity = (u.m / u.s).physical_type
        >>> number_density * velocity
        PhysicalType('particle flux')
        get_physical_type
        Return a list of registered units with the same physical type
        as this unit.

        This function is used by Quantity to add its built-in
        conversions to equivalent units.

        This is a private method, since end users should be encouraged
        to use the more powerful `compose` and `find_equivalent_units`
        methods (which use this under the hood).

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also pull options from.
            See :ref:`astropy:unit_equivalencies`.  It must already be
            normalized using `_normalize_equivalencies`.
        unit_registryEquivalentUnitsList
        A class to handle pretty-printing the result of
        `find_equivalent_units`.
        Primary nameUnit definitionAliasesHEADING_NAMESThere are no equivalent unitsNO_EQUIV_UNITS_MSG_process_units  {{0:<{}s}} | {{1:<{}s}} | {{2:<{}s}}row_template ,
            Outputs a HTML table representation within Jupyter notebooks.
            <p></p><th></th>heading<tr>elem<td></td></tr><table style="width:50%"><tr></table>
            Extract attributes, and sort, the equivalent units pre-formatting.
            irreduciblefind_equivalent_units
        Return a list of all the units that are the same type as ``self``.

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also list.  See
            :ref:`astropy:unit_equivalencies`.
            Any list given, including an empty one, supersedes global defaults
            that may be in effect (as set by `set_enabled_equivalencies`)

        units : set of `~astropy.units.Unit`, optional
            If not provided, all defined units will be searched for
            equivalencies.  Otherwise, may be a dict, module or
            sequence containing the units to search for equivalencies.

        include_prefix_units : bool, optional
            When `True`, include prefixed units in the result.
            Default is `False`.

        Returns
        -------
        units : list of `UnitBase`
            A list of unit objects that match ``u``.  A subclass of
            `list` (``EquivalentUnitsList``) is returned that
            pretty-prints the list of units when output.
        Check whether the unit is unscaled and dimensionless.
    The base class of units that have a name.

    Parameters
    ----------
    st : str, list of str, 2-tuple
        The name of the unit.  If a list of strings, the first element
        is the canonical (short) name, and the rest of the elements
        are aliases.  If a tuple of lists, the first element is a list
        of short names, and the second element is a list of long
        names; all but the first short name are considered "aliases".
        Each name *should* be a valid Python identifier to make it
        easy to access, but this is not required.

    namespace : dict, optional
        When provided, inject the unit, and all of its aliases, in the
        given namespace dictionary.  If a unit by the same name is
        already in the namespace, a ValueError is raised.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to have it
        displayed as ``\Omega`` by the ``latex`` formatter.  In that
        case, `format` argument should be set to::

            {'latex': r'\Omega'}

    Raises
    ------
    ValueError
        If any of the given unit names are already in the registry.

    ValueError
        If any of the given unit names are not valid Python tokens.
    _short_names_long_namesst must be string, list or 2-tuplemust provide at least one namest list must have at least one entry_generate_doc_inject
        Generate a docstring for the unit if the user didn't supply
        one.  This is only used from the constructor and may be
        overridden in subclasses.
        to_string()get_format_name
        Get a name for this unit that is specific to a particular
        format.

        Uses the dictionary passed into the `format` kwarg in the
        constructor.

        Parameters
        ----------
        format : str
            The name of the format

        Returns
        -------
        name : str
            The name of the unit for the given format.
        All the names associated with the unit.The canonical (short) name associated with the unit.The aliases (long) names for the unit.short_namesAll the short names associated with the unit.long_namesAll the long names associated with the unit.
        Injects the unit, and all of its aliases, in the given
        namespace dictionary.
        normalizeNFKCObject with NFKC normalized name  already exists in given namespace (" already exists in ""given namespace ("_recreate_irreducible_unitregistered
    This is used to reconstruct units when passed around by
    multiprocessing.
    
    Irreducible units are the units that all other units are defined
    in terms of.

    Examples are meters, seconds, kilograms, amperes, etc.  There is
    only once instance of such a unit per type.
    representsThe unit that this named unit represents.

        For an irreducible unit, that is always itself.
        Unit  can not be decomposed into the requested bases
    A unit that did not parse correctly.  This allows for
    round-tripping it as a string, but no unit operations actually work
    on it.

    Parameters
    ----------
    st : str
        The name of the unit.
    UnrecognizedUnit(_unrecognized_operatorThe unit  is unrecognized, so all arithmetic operations with it are invalid." is unrecognized, so all arithmetic operations ""with it are invalid." is unrecognized.  It can not be converted to other units." is unrecognized.  It can not be converted ""to other units."_UnitMetaClass
    This metaclass exists because the Unit constructor should
    sometimes return instances that already exist.  This "overrides"
    the constructor before the new instance is actually created, so we
    can return an existing one.
    new_errIf you cannot change the unit string then try specifying the 'parse_strict' argument."If you cannot change the unit string then try specifying the ""'parse_strict' argument."'parse_strict' must be 'warn', 'raise' or 'silent'format_clause' did not parse as unit:  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html"If this is meant to be a custom unit, ""define it with 'u.def_unit'. To have it ""recognized inside a file reader or other code, ""enable it with 'u.add_enabled_units'. ""For details, see ""https://docs.astropy.org/en/latest/units/combining_and_defining.html" cannot be converted to a Unit
    The main unit class.

    There are a number of different ways to construct a Unit, but
    always returns a `UnitBase` instance.  If the arguments refer to
    an already-existing unit, that existing unit instance is returned,
    rather than a new one.

    - From a string::

        Unit(s, format=None, parse_strict='silent')

      Construct from a string representing a (possibly compound) unit.

      The optional `format` keyword argument specifies the format the
      string is in, by default ``"generic"``.  For a description of
      the available formats, see `astropy.units.format`.

      The optional ``parse_strict`` keyword argument controls what happens
      when the string does not comply with the specified format. It may be
      one of the following:

         - ``'raise'``: (default) raise a `ValueError` exception.

         - ``'warn'``: emit a `UnitParserWarning`, and return a unit.

         - ``'silent'``: return a unit silently.

      With ``'warn'`` or ``'silent'`` the parser might be able to parse the
      string and return a normal unit, but if it fails then an
      `UnrecognizedUnit` instance is returned.

    - From a number::

        Unit(number)

      Creates a dimensionless unit.

    - From a `UnitBase` instance::

        Unit(unit)

      Returns the given unit unchanged.

    - From no arguments::

        Unit()

      Returns the dimensionless unit.

    - The last form, which creates a new `Unit` is described in detail
      below.

    See also: https://docs.astropy.org/en/stable/units/

    Parameters
    ----------
    st : str or list of str
        The name of the unit.  If a list, the first element is the
        canonical (short) name, and the rest of the elements are
        aliases.

    represents : unit-like, optional
        The unit that this named unit represents.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to have it
        displayed as ``\Omega`` by the ``latex`` formatter.  In that
        case, `format` argument should be set to::

            {'latex': r'\Omega'}

    namespace : dict, optional
        When provided, inject the unit (and all of its aliases) into
        the given namespace.

    Raises
    ------
    ValueError
        If any of the given unit names are already in the registry.

    ValueError
        If any of the given unit names are not valid Python tokens.

    ValueError
        If ``represents`` cannot be parsed as a unit, e.g., because it is
        a malformed string or a |Quantity| that is not a scalar.

    The unit that this named unit represents._from_physical_type_idphysical_type_id
    A unit that is simply a SI-prefixed version of another unit.

    For example, ``mm`` is a `PrefixUnit` of ``.001 * m``.

    The constructor is the same as for `Unit`.
    
    Create a composite unit using expressions of previously defined
    units.

    Direct use of this class is not recommended. Instead use the
    factory function `Unit` and arithmetic operators to compose
    units.

    Parameters
    ----------
    scale : number
        A scaling factor for the unit.

    bases : sequence of `UnitBase`
        A sequence of units this unit is composed of.

    powers : sequence of numbers
        A sequence of powers (in parallel with ``bases``) for each
        of the base units.

    Raises
    ------
    UnitScaleError
        If the scale is zero.
    _decomposed_cachedecompose_basesbases must be sequence of UnitBase instances_bases_powers_expand_and_gatherUnit(dimensionless with a scale of Unit(dimensionless)The scale of the composite unit.The bases of the composite unit.The powers of the bases of the composite unit.add_unitnew_partsb_subp_subPrefix for representing multiples or sub-multiples of units.

    Parameters
    ----------
    symbols : tuple of str
        The symbols of the prefix, to be combined with symbols of units.
        If multiple are specified then they will be treated as aliases.
    names : tuple of str
        The names of the prefix, to be combined with names of units.
        If multiple are specified then they will be treated as aliases.
    factor : `~astropy.units.typing.UnitScale`
        The multiplicative factor represented by the prefix.

    Examples
    --------
    >>> UnitPrefix(("k",), ("kilo",), 1e3)  # Simple prefix
    UnitPrefix(symbols=('k',), names=('kilo',), factor=1000.0)
    >>> UnitPrefix(("da",), ("deca", "deka"), 1e1)  # Multiple names
    UnitPrefix(symbols=('da',), names=('deca', 'deka'), factor=10.0)
    >>> UnitPrefix(("u", ""), ("micro",), 1e-6)  # Multiple symbols
    UnitPrefix(symbols=('u', ''), names=('micro',), factor=1e-06)
    symbolsThe symbols of the prefix, to be combined with symbols of units.The names of the prefix, to be combined with names of units.The multiplicative factor represented by the prefix.quetta1e+301e30ronna1e+271e27yotta1e+241e24zetta1e+211e21exa1e+181e18peta1000000000000000.01e15tera1000000000000.01e12giga1000000000.01e9mega1000000.01e6kilohecto1e2dekadeca1e1deci1e-1centi0.011e-2milli0.0011e-3nano1e-091e-9pico1e-12femto1e-15atto1e-18zepto1e-21yocto1e-24ronto1e-27quecto1e-30KikibiMimebiGigibiTitebiPipebiEiexbiZizebiYiyobi_add_prefixes
    Set up all of the standard metric prefixes for a unit.  This
    function should not be used directly, but instead use the
    `prefixes` kwarg on `def_unit` See the documentation of that function
    for the description of the parameters.
    \mu Define a new unit.

    This function differs from creating units directly with `Unit` or
    `IrreducibleUnit` because it can also automatically generate prefixed
    units in the given namespace.

    Parameters
    ----------
    s : str or list of str
        The name of the unit.  If a list, the first element is the
        canonical (short) name, and the rest of the elements are
        aliases.

    represents : unit-like, optional
        The unit that this named unit represents.  If not provided,
        a new `IrreducibleUnit` is created.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to
        have it displayed as ``\Omega`` by the ``latex``
        formatter.  In that case, `format` argument should be set
        to::

            {'latex': r'\Omega'}

    prefixes : bool or iterable of UnitPrefix, optional
        When `True`, generate all of the SI prefixed versions of the
        unit as well.  For example, for a given unit ``m``, will
        generate ``mm``, ``cm``, ``km``, etc.  If only a few prefixed
        versions should be created then an iterable of `UnitPrefix`
        instances can be specified instead. Default is `False`, which
        means no prefixed versions will be generated.

        This function always returns the base unit object, even if
        multiple scaled versions of the unit were created.

    exclude_prefixes : `~collections.abc.Collection` of str, optional
        If any of the SI prefixes need to be excluded, they may be
        listed here.  For example, when defining the prefixes for ``a``,
        ``exclude_prefixes`` should be set to ``["P"]`` so that ``Pa``
        would still refer to the pascal.

        If a bare `str` is used then the prefixes that will be excluded are
        the substrings of the `str`, not just its individual characters.

    namespace : dict, optional
        When provided, inject the unit (and all of its aliases and
        prefixes), into the given namespace dictionary.

    Returns
    -------
    unit : `~astropy.units.NamedUnit`
        The newly-defined unit, or a matching unit that was already
        defined.

    Raises
    ------
    ValueError
        If ``represents`` cannot be parsed as a unit, e.g., because it is
        a malformed string or a |Quantity| that is not a scalar.

    KNOWN_GOODValidate value is acceptable for conversion purposes.

    Will convert into an array if not a scalar or array-like, where scalars
    and arrays can be python and numpy types, anything that defines
    ``__array_namespace__`` or anything that has a ``.dtype`` attribute.

    Parameters
    ----------
    value : scalar or array-like

    Returns
    -------
    Scalar value or array

    Raises
    ------
    ValueError
        If value is not as expected

    __array_namespace__ifcValue not scalar compatible or convertible to an int, float, or complex array"Value not scalar compatible or convertible to ""an int, float, or complex array"Function that just multiplies the value by unity.

    This is a separate function so it can be recognized and
    discarded in unit conversion.
    # If passed another registry we don't need to rebuild everything.# but because these are mutable types we don't want to create# conflicts so everything needs to be copied.# The physical type is a dictionary containing sets as values.# All of these must be copied otherwise we could alter the old# registry.# Loop through all of the names first, to ensure all of them# are new, then add them all as a single "transaction" below.# pre-normalize list to help catch mistakes# get a context with a new registry, using equivalencies of the current one# in this new current registry, enable the units requested# get a context with a new registry, which is a copy of the current one# in this new current registry, enable the further units requested# get a context with a new registry, using all units of the current one# in this new current registry, enable the equivalencies requested# in this new current registry, enable the further equivalencies requested# Make sure that __rmul__ of units gets called over the __mul__ of Numpy# arrays to avoid element-wise multiplication.# This may look odd, but the units conversion will be very# broken after deep-copying if we don't guarantee that a given# physical unit corresponds to only one instance# Handling scalars should be as quick as possible# Cannot handle this as Unit, re-try as Quantity# Cannot handle this as Unit.  Here, m cannot be a Quantity,# so we make it into one, fasttracking when it does not have a# unit, for the common case of <array> / <unit>.# Cannot handle this as Unit, re-try as Quantity.# so we make it into one, fasttracking when it does not have a unit# for the common case of <array> * <unit>.# If we get pickled, we should *not* store the memoized members since# hashes of strings vary between sessions.# Other is unit-like, but the test below requires it is a UnitBase# instance; if it is not, give up (so that other can try).# after canceling, is what's left convertible# to dimensionless (according to the equivalency)?# First see if it is just a scaling.# If no conversion is necessary, returns ``unit_scale_converter``# (which is used as a check in quantity helpers).# if that doesn't work, maybe we can do it with equivalencies?# Last hope: maybe other knows how to do it?# We assume the equivalencies have the unit itself as first item.# TODO: maybe better for other to have a `_back_converter` method?# There are many cases where we just want to ensure a Quantity is# of a particular unit, without checking whether it's already in# a particular unit.  If we're being asked to convert from a unit# to itself, we can short-circuit all of this.# Don't presume decomposition is possible; e.g.,# conversion to function units is through equivalencies.# Check quickly whether equivalent.  This is faster than# `is_equivalent`, because it doesn't generate the entire# physical type list of both units.  In other words it "fails# fast".# Returns True if this result contains only the expected# units# Prevent too many levels of recursion# And special case for dimensionless unit# Make a list including all of the equivalent units# Store partial results# Store final results that reduce to a single unit or pair of# If the unit is a base unit, look for an exact match# to one of the bases of the target unit.  If found,# factor by the same power as the target unit's base.# This allows us to factor out fractional powers# without needing to do an exhaustive search.# Do we have any minimal results?# ...we have to recurse and try to further compose# if units parameter is specified and is a sequence (list|tuple),# include_prefix_units is turned on by default.  Ex: units=[u.kpc]# Pre-normalize the equivalencies list# The namespace of units to compose into should be filtered to# only include units with bases in common with self, otherwise# they can't possibly provide useful results.  Having too many# destination units greatly increases the search space.# Sort the results so the simplest ones appear first.# Simplest is defined as "the minimum sum of absolute# powers" (i.e. the fewest bases), and preference should# be given to results where the sum of powers is positive# and the scale is exactly equal to 1.0# The HTML will be rendered & the table is simple, so don't# bother to include newlines & indentation for the HTML code.# If in local registry return that object.# otherwise, recreate the unit.# If not in local registry but registered in origin registry,# enable unit in local registry.# When IrreducibleUnit objects are passed to other processes# over multiprocessing, they need to be recreated to be the# ones already in the subprocesses' namespace, not new# objects, or they will be considered "unconvertible".# Therefore, we have a custom pickler/unpickler that# understands how to recreate the Unit on the other side.# For UnrecognizedUnits, we want to use "standard" Python# pickling, not the special case that is used for# IrreducibleUnits.# Short-circuit if we're already a unit# This has the effect of calling the real __new__ and# __init__ on the Unit class.# Return the NULL unit# Try a shortcut# No `f._validate_unit()` (AttributeError)# or `s` was a composite unit (ValueError).# Deliberately not issubclass here. Subclasses# should use their name.# get string bases and powers from the ID tuple# _error_check can switch off runtime validation of scale, bases and powers.# These overloads enable type checkers to validate statically.# There are many cases internal to astropy.units where we# already know that all the bases are Unit objects, and the# powers have been validated.  In those cases, we can skip the# error checking for performance reasons.  When the private# kwarg `_error_check` is False, the error checking is turned# off.# Short-cut; with one unit there's nothing to expand and gather,# as that has happened already when creating the unit.  But do only# positive powers, since for negative powers we need to re-sort.# Regular case: use inputs as preliminary scale, bases, and powers,# then "expand and gather" identical bases, sanitize the scale, &c.# This is a hack to use Greek mu as a prefix# for some formatters.# Abbreviation of the above, see #1980b'
Core units classes and functions.
'u'
Core units classes and functions.
'b'CompositeUnit'u'CompositeUnit'b'IrreducibleUnit'u'IrreducibleUnit'b'NamedUnit'u'NamedUnit'b'PrefixUnit'u'PrefixUnit'b'UnitBase'u'UnitBase'b'UnitPrefix'u'UnitPrefix'b'UnrecognizedUnit'u'UnrecognizedUnit'b'add_enabled_aliases'u'add_enabled_aliases'b'add_enabled_equivalencies'u'add_enabled_equivalencies'b'add_enabled_units'u'add_enabled_units'b'def_unit'u'def_unit'b'dimensionless_unscaled'u'dimensionless_unscaled'b'get_current_unit_registry'u'get_current_unit_registry'b'one'u'one'b'set_enabled_aliases'u'set_enabled_aliases'b'set_enabled_equivalencies'u'set_enabled_equivalencies'b'set_enabled_units'u'set_enabled_units'b'raise'u'raise'b'
    Given a list of sequences, modules or dictionaries of units, or
    single units, return a flat set of all the units found.
    'u'
    Given a list of sequences, modules or dictionaries of units, or
    single units, return a flat set of all the units found.
    'b'Normalizes equivalencies ensuring each is a 4-tuple.

    The resulting tuple is of the form::

        (from_unit, to_unit, forward_func, backward_func)

    Parameters
    ----------
    equivalencies : list of equivalency pairs

    Raises
    ------
    ValueError if an equivalency cannot be interpreted
    'u'Normalizes equivalencies ensuring each is a 4-tuple.

    The resulting tuple is of the form::

        (from_unit, to_unit, forward_func, backward_func)

    Parameters
    ----------
    equivalencies : list of equivalency pairs

    Raises
    ------
    ValueError if an equivalency cannot be interpreted
    'b'Invalid equivalence entry 'u'Invalid equivalence entry 'b'
    Manages a registry of the enabled units.
    'u'
    Manages a registry of the enabled units.
    'b'
        Sets the units enabled in the unit registry.

        These units are searched when using
        `UnitBase.find_equivalent_units`, for example.

        Parameters
        ----------
        units : list of sequence, dict, or module
            This is a list of things in which units may be found
            (sequences, dicts or modules), or units themselves.  The
            entire set will be "enabled" for searching through by
            methods like `UnitBase.find_equivalent_units` and
            `UnitBase.compose`.
        'u'
        Sets the units enabled in the unit registry.

        These units are searched when using
        `UnitBase.find_equivalent_units`, for example.

        Parameters
        ----------
        units : list of sequence, dict, or module
            This is a list of things in which units may be found
            (sequences, dicts or modules), or units themselves.  The
            entire set will be "enabled" for searching through by
            methods like `UnitBase.find_equivalent_units` and
            `UnitBase.compose`.
        'b'
        Adds to the set of units enabled in the unit registry.

        These units are searched when using
        `UnitBase.find_equivalent_units`, for example.

        Parameters
        ----------
        units : list of sequence, dict, or module
            This is a list of things in which units may be found
            (sequences, dicts or modules), or units themselves.  The
            entire set will be added to the "enabled" set for
            searching through by methods like
            `UnitBase.find_equivalent_units` and `UnitBase.compose`.
        'u'
        Adds to the set of units enabled in the unit registry.

        These units are searched when using
        `UnitBase.find_equivalent_units`, for example.

        Parameters
        ----------
        units : list of sequence, dict, or module
            This is a list of things in which units may be found
            (sequences, dicts or modules), or units themselves.  The
            entire set will be added to the "enabled" set for
            searching through by methods like
            `UnitBase.find_equivalent_units` and `UnitBase.compose`.
        'b'Object with name 'u'Object with name 'b' already exists in namespace. Filter the set of units to avoid name clashes before enabling them.'u' already exists in namespace. Filter the set of units to avoid name clashes before enabling them.'b'
        Get all units in the registry with the same physical type as
        the given unit.

        Parameters
        ----------
        unit : UnitBase instance
        'u'
        Get all units in the registry with the same physical type as
        the given unit.

        Parameters
        ----------
        unit : UnitBase instance
        'b'
        Sets the equivalencies enabled in the unit registry.

        These equivalencies are used if no explicit equivalencies are given,
        both in unit conversion and in finding equivalent units.

        This is meant in particular for allowing angles to be dimensionless.
        Use with care.

        Parameters
        ----------
        equivalencies : list of tuple
            List of equivalent pairs, e.g., as returned by
            `~astropy.units.dimensionless_angles`.
        'u'
        Sets the equivalencies enabled in the unit registry.

        These equivalencies are used if no explicit equivalencies are given,
        both in unit conversion and in finding equivalent units.

        This is meant in particular for allowing angles to be dimensionless.
        Use with care.

        Parameters
        ----------
        equivalencies : list of tuple
            List of equivalent pairs, e.g., as returned by
            `~astropy.units.dimensionless_angles`.
        'b'
        Adds to the set of equivalencies enabled in the unit registry.

        These equivalencies are used if no explicit equivalencies are given,
        both in unit conversion and in finding equivalent units.

        This is meant in particular for allowing angles to be dimensionless.
        Use with care.

        Parameters
        ----------
        equivalencies : list of tuple
            List of equivalent pairs, e.g., as returned by
            `~astropy.units.dimensionless_angles`.
        'u'
        Adds to the set of equivalencies enabled in the unit registry.

        These equivalencies are used if no explicit equivalencies are given,
        both in unit conversion and in finding equivalent units.

        This is meant in particular for allowing angles to be dimensionless.
        Use with care.

        Parameters
        ----------
        equivalencies : list of tuple
            List of equivalent pairs, e.g., as returned by
            `~astropy.units.dimensionless_angles`.
        'b'
        Set aliases for units.

        Parameters
        ----------
        aliases : dict of str, Unit
            The aliases to set. The keys must be the string aliases, and values
            must be the `astropy.units.Unit` that the alias will be mapped to.

        Raises
        ------
        ValueError
            If the alias already defines a different unit.

        'u'
        Set aliases for units.

        Parameters
        ----------
        aliases : dict of str, Unit
            The aliases to set. The keys must be the string aliases, and values
            must be the `astropy.units.Unit` that the alias will be mapped to.

        Raises
        ------
        ValueError
            If the alias already defines a different unit.

        'b'
        Add aliases for units.

        Parameters
        ----------
        aliases : dict of str, Unit
            The aliases to add. The keys must be the string aliases, and values
            must be the `astropy.units.Unit` that the alias will be mapped to.

        Raises
        ------
        ValueError
            If the alias already defines a different unit.

        'u'
        Add aliases for units.

        Parameters
        ----------
        aliases : dict of str, Unit
            The aliases to add. The keys must be the string aliases, and values
            must be the `astropy.units.Unit` that the alias will be mapped to.

        Raises
        ------
        ValueError
            If the alias already defines a different unit.

        'b' already means 'u' already means 'b', so cannot be used as an alias for 'u', so cannot be used as an alias for 'b' already is an alias for 'u' already is an alias for 'b'
    Sets the units enabled in the unit registry.

    These units are searched when using
    `UnitBase.find_equivalent_units`, for example.

    This may be used either permanently, or as a context manager using
    the ``with`` statement (see example below).

    Parameters
    ----------
    units : list of sequence, dict, or module
        This is a list of things in which units may be found
        (sequences, dicts or modules), or units themselves.  The
        entire set will be "enabled" for searching through by methods
        like `UnitBase.find_equivalent_units` and `UnitBase.compose`.

    Examples
    --------
    >>> from astropy import units as u
    >>> with u.set_enabled_units([u.pc]):
    ...     u.m.find_equivalent_units()
    ...
      Primary name | Unit definition | Aliases
    [
      pc           | 3.08568e+16 m   | parsec  ,
    ]
    >>> u.m.find_equivalent_units()
      Primary name | Unit definition | Aliases
    [
      AU           | 1.49598e+11 m   | au, astronomical_unit            ,
      Angstrom     | 1e-10 m         | AA, angstrom,                   ,
      cm           | 0.01 m          | centimeter                       ,
      earthRad     | 6.3781e+06 m    | R_earth, Rearth                  ,
      jupiterRad   | 7.1492e+07 m    | R_jup, Rjup, R_jupiter, Rjupiter ,
      lsec         | 2.99792e+08 m   | lightsecond                      ,
      lyr          | 9.46073e+15 m   | lightyear                        ,
      m            | irreducible     | meter                            ,
      micron       | 1e-06 m         |                                  ,
      pc           | 3.08568e+16 m   | parsec                           ,
      solRad       | 6.957e+08 m     | R_sun, Rsun                      ,
    ]
    'u'
    Sets the units enabled in the unit registry.

    These units are searched when using
    `UnitBase.find_equivalent_units`, for example.

    This may be used either permanently, or as a context manager using
    the ``with`` statement (see example below).

    Parameters
    ----------
    units : list of sequence, dict, or module
        This is a list of things in which units may be found
        (sequences, dicts or modules), or units themselves.  The
        entire set will be "enabled" for searching through by methods
        like `UnitBase.find_equivalent_units` and `UnitBase.compose`.

    Examples
    --------
    >>> from astropy import units as u
    >>> with u.set_enabled_units([u.pc]):
    ...     u.m.find_equivalent_units()
    ...
      Primary name | Unit definition | Aliases
    [
      pc           | 3.08568e+16 m   | parsec  ,
    ]
    >>> u.m.find_equivalent_units()
      Primary name | Unit definition | Aliases
    [
      AU           | 1.49598e+11 m   | au, astronomical_unit            ,
      Angstrom     | 1e-10 m         | AA, angstrom,                   ,
      cm           | 0.01 m          | centimeter                       ,
      earthRad     | 6.3781e+06 m    | R_earth, Rearth                  ,
      jupiterRad   | 7.1492e+07 m    | R_jup, Rjup, R_jupiter, Rjupiter ,
      lsec         | 2.99792e+08 m   | lightsecond                      ,
      lyr          | 9.46073e+15 m   | lightyear                        ,
      m            | irreducible     | meter                            ,
      micron       | 1e-06 m         |                                  ,
      pc           | 3.08568e+16 m   | parsec                           ,
      solRad       | 6.957e+08 m     | R_sun, Rsun                      ,
    ]
    'b'
    Adds to the set of units enabled in the unit registry.

    These units are searched when using
    `UnitBase.find_equivalent_units`, for example.

    This may be used either permanently, or as a context manager using
    the ``with`` statement (see example below).

    Parameters
    ----------
    units : list of sequence, dict, or module
        This is a list of things in which units may be found
        (sequences, dicts or modules), or units themselves.  The
        entire set will be added to the "enabled" set for searching
        through by methods like `UnitBase.find_equivalent_units` and
        `UnitBase.compose`.

    Examples
    --------
    >>> from astropy import units as u
    >>> from astropy.units import imperial
    >>> with u.add_enabled_units(imperial):
    ...     u.m.find_equivalent_units()
    ...
      Primary name | Unit definition | Aliases
    [
      AU           | 1.49598e+11 m   | au, astronomical_unit            ,
      Angstrom     | 1e-10 m         | AA, angstrom,                   ,
      cm           | 0.01 m          | centimeter                       ,
      earthRad     | 6.3781e+06 m    | R_earth, Rearth                  ,
      ft           | 0.3048 m        | foot                             ,
      fur          | 201.168 m       | furlong                          ,
      inch         | 0.0254 m        |                                  ,
      jupiterRad   | 7.1492e+07 m    | R_jup, Rjup, R_jupiter, Rjupiter ,
      lsec         | 2.99792e+08 m   | lightsecond                      ,
      lyr          | 9.46073e+15 m   | lightyear                        ,
      m            | irreducible     | meter                            ,
      mi           | 1609.34 m       | mile                             ,
      micron       | 1e-06 m         |                                  ,
      mil          | 2.54e-05 m      | thou                             ,
      nmi          | 1852 m          | nauticalmile, NM                 ,
      pc           | 3.08568e+16 m   | parsec                           ,
      solRad       | 6.957e+08 m     | R_sun, Rsun                      ,
      yd           | 0.9144 m        | yard                             ,
    ]
    'u'
    Adds to the set of units enabled in the unit registry.

    These units are searched when using
    `UnitBase.find_equivalent_units`, for example.

    This may be used either permanently, or as a context manager using
    the ``with`` statement (see example below).

    Parameters
    ----------
    units : list of sequence, dict, or module
        This is a list of things in which units may be found
        (sequences, dicts or modules), or units themselves.  The
        entire set will be added to the "enabled" set for searching
        through by methods like `UnitBase.find_equivalent_units` and
        `UnitBase.compose`.

    Examples
    --------
    >>> from astropy import units as u
    >>> from astropy.units import imperial
    >>> with u.add_enabled_units(imperial):
    ...     u.m.find_equivalent_units()
    ...
      Primary name | Unit definition | Aliases
    [
      AU           | 1.49598e+11 m   | au, astronomical_unit            ,
      Angstrom     | 1e-10 m         | AA, angstrom,                   ,
      cm           | 0.01 m          | centimeter                       ,
      earthRad     | 6.3781e+06 m    | R_earth, Rearth                  ,
      ft           | 0.3048 m        | foot                             ,
      fur          | 201.168 m       | furlong                          ,
      inch         | 0.0254 m        |                                  ,
      jupiterRad   | 7.1492e+07 m    | R_jup, Rjup, R_jupiter, Rjupiter ,
      lsec         | 2.99792e+08 m   | lightsecond                      ,
      lyr          | 9.46073e+15 m   | lightyear                        ,
      m            | irreducible     | meter                            ,
      mi           | 1609.34 m       | mile                             ,
      micron       | 1e-06 m         |                                  ,
      mil          | 2.54e-05 m      | thou                             ,
      nmi          | 1852 m          | nauticalmile, NM                 ,
      pc           | 3.08568e+16 m   | parsec                           ,
      solRad       | 6.957e+08 m     | R_sun, Rsun                      ,
      yd           | 0.9144 m        | yard                             ,
    ]
    'b'
    Sets the equivalencies enabled in the unit registry.

    These equivalencies are used if no explicit equivalencies are given,
    both in unit conversion and in finding equivalent units.

    This is meant in particular for allowing angles to be dimensionless.
    Use with care.

    Parameters
    ----------
    equivalencies : list of tuple
        list of equivalent pairs, e.g., as returned by
        `~astropy.units.dimensionless_angles`.

    Examples
    --------
    Exponentiation normally requires dimensionless quantities.  To avoid
    problems with complex phases::

        >>> from astropy import units as u
        >>> with u.set_enabled_equivalencies(u.dimensionless_angles()):
        ...     phase = 0.5 * u.cycle
        ...     np.exp(1j*phase)  # doctest: +FLOAT_CMP
        <Quantity -1.+1.2246468e-16j>
    'u'
    Sets the equivalencies enabled in the unit registry.

    These equivalencies are used if no explicit equivalencies are given,
    both in unit conversion and in finding equivalent units.

    This is meant in particular for allowing angles to be dimensionless.
    Use with care.

    Parameters
    ----------
    equivalencies : list of tuple
        list of equivalent pairs, e.g., as returned by
        `~astropy.units.dimensionless_angles`.

    Examples
    --------
    Exponentiation normally requires dimensionless quantities.  To avoid
    problems with complex phases::

        >>> from astropy import units as u
        >>> with u.set_enabled_equivalencies(u.dimensionless_angles()):
        ...     phase = 0.5 * u.cycle
        ...     np.exp(1j*phase)  # doctest: +FLOAT_CMP
        <Quantity -1.+1.2246468e-16j>
    'b'
    Adds to the equivalencies enabled in the unit registry.

    These equivalencies are used if no explicit equivalencies are given,
    both in unit conversion and in finding equivalent units.

    This is meant in particular for allowing angles to be dimensionless.
    Since no equivalencies are enabled by default, generally it is recommended
    to use `set_enabled_equivalencies`.

    Parameters
    ----------
    equivalencies : list of tuple
        list of equivalent pairs, e.g., as returned by
        `~astropy.units.dimensionless_angles`.
    'u'
    Adds to the equivalencies enabled in the unit registry.

    These equivalencies are used if no explicit equivalencies are given,
    both in unit conversion and in finding equivalent units.

    This is meant in particular for allowing angles to be dimensionless.
    Since no equivalencies are enabled by default, generally it is recommended
    to use `set_enabled_equivalencies`.

    Parameters
    ----------
    equivalencies : list of tuple
        list of equivalent pairs, e.g., as returned by
        `~astropy.units.dimensionless_angles`.
    'b'
    Set aliases for units.

    This is useful for handling alternate spellings for units, or
    misspelled units in files one is trying to read.

    Parameters
    ----------
    aliases : dict of str, Unit
        The aliases to set. The keys must be the string aliases, and values
        must be the `astropy.units.Unit` that the alias will be mapped to.

    Raises
    ------
    ValueError
        If the alias already defines a different unit.

    Examples
    --------
    To temporarily allow for a misspelled 'Angstroem' unit::

        >>> from astropy import units as u
        >>> with u.set_enabled_aliases({'Angstroem': u.Angstrom}):
        ...     print(u.Unit("Angstroem", parse_strict="raise") == u.Angstrom)
        True

    'u'
    Set aliases for units.

    This is useful for handling alternate spellings for units, or
    misspelled units in files one is trying to read.

    Parameters
    ----------
    aliases : dict of str, Unit
        The aliases to set. The keys must be the string aliases, and values
        must be the `astropy.units.Unit` that the alias will be mapped to.

    Raises
    ------
    ValueError
        If the alias already defines a different unit.

    Examples
    --------
    To temporarily allow for a misspelled 'Angstroem' unit::

        >>> from astropy import units as u
        >>> with u.set_enabled_aliases({'Angstroem': u.Angstrom}):
        ...     print(u.Unit("Angstroem", parse_strict="raise") == u.Angstrom)
        True

    'b'
    Add aliases for units.

    This is useful for handling alternate spellings for units, or
    misspelled units in files one is trying to read.

    Since no aliases are enabled by default, generally it is recommended
    to use `set_enabled_aliases`.

    Parameters
    ----------
    aliases : dict of str, Unit
        The aliases to add. The keys must be the string aliases, and values
        must be the `astropy.units.Unit` that the alias will be mapped to.

    Raises
    ------
    ValueError
        If the alias already defines a different unit.

    Examples
    --------
    To temporarily allow for a misspelled 'Angstroem' unit::

        >>> from astropy import units as u
        >>> with u.add_enabled_aliases({'Angstroem': u.Angstrom}):
        ...     print(u.Unit("Angstroem", parse_strict="raise") == u.Angstrom)
        True

    'u'
    Add aliases for units.

    This is useful for handling alternate spellings for units, or
    misspelled units in files one is trying to read.

    Since no aliases are enabled by default, generally it is recommended
    to use `set_enabled_aliases`.

    Parameters
    ----------
    aliases : dict of str, Unit
        The aliases to add. The keys must be the string aliases, and values
        must be the `astropy.units.Unit` that the alias will be mapped to.

    Raises
    ------
    ValueError
        If the alias already defines a different unit.

    Examples
    --------
    To temporarily allow for a misspelled 'Angstroem' unit::

        >>> from astropy import units as u
        >>> with u.add_enabled_aliases({'Angstroem': u.Angstrom}):
        ...     print(u.Unit("Angstroem", parse_strict="raise") == u.Angstrom)
        True

    'b'
    Abstract base class for units.

    Most of the arithmetic operations on units are defined in this
    base class.

    Should not be instantiated by users directly.
    'u'
    Abstract base class for units.

    Most of the arithmetic operations on units are defined in this
    base class.

    Should not be instantiated by users directly.
    'b'
        Generate latex representation of unit name.  This is used by
        the IPython notebook to print a unit with a nice layout.

        Returns
        -------
        Latex string
        'u'
        Generate latex representation of unit name.  This is used by
        the IPython notebook to print a unit with a nice layout.

        Returns
        -------
        Latex string
        'b'unicode_escape'u'unicode_escape'b'Unit("'u'Unit("'b'")'u'")'b'
        Returns an identifier that uniquely identifies the physical
        type of this unit.  It is comprised of the bases and powers of
        this unit, without the scale.  Since it is hashable, it is
        useful as a dictionary key.
        'u'
        Returns an identifier that uniquely identifies the physical
        type of this unit.  It is comprised of the bases and powers of
        this unit, without the scale.  Since it is hashable, it is
        useful as a dictionary key.
        'b'The scale of the unit.'u'The scale of the unit.'b'The bases of the unit.'u'The bases of the unit.'b'The powers of the bases of the unit.'u'The powers of the bases of the unit.'u'Output the unit in the given format as a string.

        Parameters
        ----------
        format : `astropy.units.format.Base` subclass or str or None
            The name of a format or a formatter class.  If not
            provided (or `None`), defaults to the generic format.

        **kwargs
            Further options forwarded to the formatter. Currently
            recognized is ``fraction``, which can take the following values:

            - `False` : display unit bases with negative powers as they are;
            - 'inline' or `True` : use a single-line fraction;
            - 'multiline' : use a multiline fraction (available for the
              'latex', 'console' and 'unicode' formats only; for others,
              an 'inline' fraction is used).

        Raises
        ------
        TypeError
            If ``format`` is of the wrong type.
        ValueError
            If ``format`` or ``fraction`` are not recognized.

        Examples
        --------
        >>> import astropy.units as u
        >>> kms = u.Unit('km / s')
        >>> kms.to_string()  # Generic uses fraction='inline' by default
        'km / s'
        >>> kms.to_string('latex')  # Latex uses fraction='multiline' by default
        '$\\mathrm{\\frac{km}{s}}$'
        >>> print(kms.to_string('unicode', fraction=False))
        km s
        >>> print(kms.to_string('unicode', fraction='inline'))
        km / s
        >>> print(kms.to_string('unicode', fraction='multiline'))
        km
        
        s
        'b'Normalizes equivalencies, ensuring each is a 4-tuple.

        The resulting tuple is of the form::

            (from_unit, to_unit, forward_func, backward_func)

        Parameters
        ----------
        equivalencies : list of equivalency pairs, or None

        Returns
        -------
        A normalized list, including possible global defaults set by, e.g.,
        `set_enabled_equivalencies`, except when `equivalencies`=`None`,
        in which case the returned list is always empty.

        Raises
        ------
        ValueError if an equivalency cannot be interpreted
        'u'Normalizes equivalencies, ensuring each is a 4-tuple.

        The resulting tuple is of the form::

            (from_unit, to_unit, forward_func, backward_func)

        Parameters
        ----------
        equivalencies : list of equivalency pairs, or None

        Returns
        -------
        A normalized list, including possible global defaults set by, e.g.,
        `set_enabled_equivalencies`, except when `equivalencies`=`None`,
        in which case the returned list is always empty.

        Raises
        ------
        ValueError if an equivalency cannot be interpreted
        'b'Quantities and Units may only be raised to a scalar power'u'Quantities and Units may only be raised to a scalar power'b' involving a unit and a ''u' involving a unit and a ''b'' instance are deprecated since v7.1. Convert 'u'' instance are deprecated since v7.1. Convert 'b' to a unit explicitly.'u' to a unit explicitly.'b'divisions'u'divisions'b'products'u'products'b'>> is not implemented. Did you mean to convert to a Quantity with unit 'u'>> is not implemented. Did you mean to convert to a Quantity with unit 'b' using '<<'?'u' using '<<'?'b'_hash'u'_hash'b'_physical_type_id'u'_physical_type_id'b'Check whether this unit is equivalent to ``other``.

        Parameters
        ----------
        other : `~astropy.units.Unit`, str, or tuple
            The unit to convert to. If a tuple of units is specified, this
            method returns true if the unit matches any of those in the tuple.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        bool
        'u'Check whether this unit is equivalent to ``other``.

        Parameters
        ----------
        other : `~astropy.units.Unit`, str, or tuple
            The unit to convert to. If a tuple of units is specified, this
            method returns true if the unit matches any of those in the tuple.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        bool
        'b'Returns `True` if this unit is equivalent to `other`.
        See `is_equivalent`, except that a proper Unit object should be
        given (i.e., no string) and that the equivalency list should be
        normalized using `_normalize_equivalencies`.
        'u'Returns `True` if this unit is equivalent to `other`.
        See `is_equivalent`, except that a proper Unit object should be
        given (i.e., no string) and that the equivalency list should be
        normalized using `_normalize_equivalencies`.
        'b'
        Internal function (used from `get_converter`) to apply
        equivalence pairs.
        'u'
        Internal function (used from `get_converter`) to apply
        equivalence pairs.
        'b'unknown'u'unknown'b'' ('u'' ('b' are not convertible'u' are not convertible'b'
        Create a function that converts values from this unit to another.

        Parameters
        ----------
        other : unit-like
            The unit to convert to.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        func : callable
            A callable that takes an array-like argument and returns
            it converted from units of self to units of other.

        Raises
        ------
        UnitsError
            If the units cannot be converted to each other.

        Notes
        -----
        This method is used internally in `Quantity` to convert to
        different units. Note that the function returned takes
        and returns values, not quantities.
        'u'
        Create a function that converts values from this unit to another.

        Parameters
        ----------
        other : unit-like
            The unit to convert to.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        func : callable
            A callable that takes an array-like argument and returns
            it converted from units of self to units of other.

        Raises
        ------
        UnitsError
            If the units cannot be converted to each other.

        Notes
        -----
        This method is used internally in `Quantity` to convert to
        different units. Note that the function returned takes
        and returns values, not quantities.
        'b'equivalencies'u'equivalencies'b'
        Returns the scale to the specified unit.

        See `to`, except that a Unit object should be given (i.e., no
        string), and that all defaults are used, i.e., no
        equivalencies and value=1.
        'u'
        Returns the scale to the specified unit.

        See `to`, except that a Unit object should be given (i.e., no
        string), and that all defaults are used, i.e., no
        equivalencies and value=1.
        'b'' is not a scaled version of ''u'' is not a scaled version of ''b'
        Return the converted values in the specified unit.

        Parameters
        ----------
        other : unit-like
            The unit to convert to.

        value : int, float, or scalar array-like, optional
            Value(s) in the current unit to be converted to the
            specified unit.  If not provided, defaults to 1.0

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        values : scalar or array
            Converted value(s). Input value sequences are returned as
            numpy arrays.

        Raises
        ------
        UnitsError
            If units are inconsistent
        'u'
        Return the converted values in the specified unit.

        Parameters
        ----------
        other : unit-like
            The unit to convert to.

        value : int, float, or scalar array-like, optional
            Value(s) in the current unit to be converted to the
            specified unit.  If not provided, defaults to 1.0

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        Returns
        -------
        values : scalar or array
            Converted value(s). Input value sequences are returned as
            numpy arrays.

        Raises
        ------
        UnitsError
            If units are inconsistent
        'b'to()'u'to()'b'
        Alias for `to` for backward compatibility with pynbody.
        'u'
        Alias for `to` for backward compatibility with pynbody.
        'b'
        Return a unit object composed of only irreducible units.

        Parameters
        ----------
        bases : sequence of UnitBase, optional
            The bases to decompose into.  When not provided,
            decomposes down to any irreducible units.  When provided,
            the decomposed result will only contain the given units.
            This will raises a `UnitsError` if it's not possible
            to do so.

        Returns
        -------
        unit : `~astropy.units.CompositeUnit`
            New object containing only irreducible unit objects.
        'u'
        Return a unit object composed of only irreducible units.

        Parameters
        ----------
        bases : sequence of UnitBase, optional
            The bases to decompose into.  When not provided,
            decomposes down to any irreducible units.  When provided,
            the decomposed result will only contain the given units.
            This will raises a `UnitsError` if it's not possible
            to do so.

        Returns
        -------
        unit : `~astropy.units.CompositeUnit`
            New object containing only irreducible unit objects.
        'b'Cannot represent unit 'u'Cannot represent unit 'b' in terms of the given units'u' in terms of the given units'b'
        Return the simplest possible composite unit(s) that represent
        the given unit.  Since there may be multiple equally simple
        compositions of the unit, a list of units is always returned.

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also list.  See
            :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        units : set of `~astropy.units.Unit`, optional
            If not provided, any known units may be used to compose
            into.  Otherwise, ``units`` is a dict, module or sequence
            containing the units to compose into.

        max_depth : int, optional
            The maximum recursion depth to use when composing into
            composite units.

        include_prefix_units : bool, optional
            When `True`, include prefixed units in the result.
            Default is `True` if a sequence is passed in to ``units``,
            `False` otherwise.

        Returns
        -------
        units : list of `CompositeUnit`
            A list of candidate compositions.  These will all be
            equally simple, but it may not be possible to
            automatically determine which of the candidates are
            better.
        'u'
        Return the simplest possible composite unit(s) that represent
        the given unit.  Since there may be multiple equally simple
        compositions of the unit, a list of units is always returned.

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also list.  See
            :ref:`astropy:unit_equivalencies`.
            This list is in addition to possible global defaults set by, e.g.,
            `set_enabled_equivalencies`.
            Use `None` to turn off all equivalencies.

        units : set of `~astropy.units.Unit`, optional
            If not provided, any known units may be used to compose
            into.  Otherwise, ``units`` is a dict, module or sequence
            containing the units to compose into.

        max_depth : int, optional
            The maximum recursion depth to use when composing into
            composite units.

        include_prefix_units : bool, optional
            When `True`, include prefixed units in the result.
            Default is `True` if a sequence is passed in to ``units``,
            `False` otherwise.

        Returns
        -------
        units : list of `CompositeUnit`
            A list of candidate compositions.  These will all be
            equally simple, but it may not be possible to
            automatically determine which of the candidates are
            better.
        'b'Convert this unit into ones belonging to the given system.

        Since more than one result may be possible, a list is always
        returned.

        Parameters
        ----------
        system : module
            The module that defines the unit system.  Commonly used
            ones include `astropy.units.si` and `astropy.units.cgs`.

            To use your own module it must contain unit objects and a
            sequence member named ``bases`` containing the base units of
            the system.

        Returns
        -------
        units : list of `CompositeUnit`
            With an attempt to sort simpler units to the start (see examples).

        Examples
        --------
        >>> import astropy.units as u
        >>> (u.N / u.m**2).to_system(u.si)  # preference for simpler units
        [Unit("Pa"), Unit("N / m2"), Unit("J / m3")]
        >>> u.Pa.to_system(u.cgs)
        [Unit("10 Ba"), Unit("10 P / s")]
        >>> u.Ba.to_system(u.si)
        [Unit("0.1 Pa"), Unit("0.1 N / m2"), Unit("0.1 J / m3")]
        >>> (u.AU/u.yr).to_system(u.cgs)  # preference for base units
        [Unit("474047 cm / s"), Unit("474047 Gal s")]
        >>> (u.m / u.s**2).to_system(u.cgs)
        [Unit("100 cm / s2"), Unit("100 Gal")]

        'u'Convert this unit into ones belonging to the given system.

        Since more than one result may be possible, a list is always
        returned.

        Parameters
        ----------
        system : module
            The module that defines the unit system.  Commonly used
            ones include `astropy.units.si` and `astropy.units.cgs`.

            To use your own module it must contain unit objects and a
            sequence member named ``bases`` containing the base units of
            the system.

        Returns
        -------
        units : list of `CompositeUnit`
            With an attempt to sort simpler units to the start (see examples).

        Examples
        --------
        >>> import astropy.units as u
        >>> (u.N / u.m**2).to_system(u.si)  # preference for simpler units
        [Unit("Pa"), Unit("N / m2"), Unit("J / m3")]
        >>> u.Pa.to_system(u.cgs)
        [Unit("10 Ba"), Unit("10 P / s")]
        >>> u.Ba.to_system(u.si)
        [Unit("0.1 Pa"), Unit("0.1 N / m2"), Unit("0.1 J / m3")]
        >>> (u.AU/u.yr).to_system(u.cgs)  # preference for base units
        [Unit("474047 cm / s"), Unit("474047 Gal s")]
        >>> (u.m / u.s**2).to_system(u.cgs)
        [Unit("100 cm / s2"), Unit("100 Gal")]

        'b'The unit expressed in terms of SI units.'u'The unit expressed in terms of SI units.'b'The unit expressed in terms of CGS units.'u'The unit expressed in terms of CGS units.'b'
        Physical type(s) dimensionally compatible with the unit.

        Returns
        -------
        `~astropy.units.physical.PhysicalType`
            A representation of the physical type(s) of a unit.

        Examples
        --------
        >>> from astropy import units as u
        >>> u.m.physical_type
        PhysicalType('length')
        >>> (u.m ** 2 / u.s).physical_type
        PhysicalType({'diffusivity', 'kinematic viscosity'})

        Physical types can be compared to other physical types
        (recommended in packages) or to strings.

        >>> area = (u.m ** 2).physical_type
        >>> area == u.m.physical_type ** 2
        True
        >>> area == "area"
        True

        `~astropy.units.physical.PhysicalType` objects can be used for
        dimensional analysis.

        >>> number_density = u.m.physical_type ** -3
        >>> velocity = (u.m / u.s).physical_type
        >>> number_density * velocity
        PhysicalType('particle flux')
        'u'
        Physical type(s) dimensionally compatible with the unit.

        Returns
        -------
        `~astropy.units.physical.PhysicalType`
            A representation of the physical type(s) of a unit.

        Examples
        --------
        >>> from astropy import units as u
        >>> u.m.physical_type
        PhysicalType('length')
        >>> (u.m ** 2 / u.s).physical_type
        PhysicalType({'diffusivity', 'kinematic viscosity'})

        Physical types can be compared to other physical types
        (recommended in packages) or to strings.

        >>> area = (u.m ** 2).physical_type
        >>> area == u.m.physical_type ** 2
        True
        >>> area == "area"
        True

        `~astropy.units.physical.PhysicalType` objects can be used for
        dimensional analysis.

        >>> number_density = u.m.physical_type ** -3
        >>> velocity = (u.m / u.s).physical_type
        >>> number_density * velocity
        PhysicalType('particle flux')
        'b'
        Return a list of registered units with the same physical type
        as this unit.

        This function is used by Quantity to add its built-in
        conversions to equivalent units.

        This is a private method, since end users should be encouraged
        to use the more powerful `compose` and `find_equivalent_units`
        methods (which use this under the hood).

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also pull options from.
            See :ref:`astropy:unit_equivalencies`.  It must already be
            normalized using `_normalize_equivalencies`.
        'u'
        Return a list of registered units with the same physical type
        as this unit.

        This function is used by Quantity to add its built-in
        conversions to equivalent units.

        This is a private method, since end users should be encouraged
        to use the more powerful `compose` and `find_equivalent_units`
        methods (which use this under the hood).

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also pull options from.
            See :ref:`astropy:unit_equivalencies`.  It must already be
            normalized using `_normalize_equivalencies`.
        'b'
        A class to handle pretty-printing the result of
        `find_equivalent_units`.
        'u'
        A class to handle pretty-printing the result of
        `find_equivalent_units`.
        'b'Primary name'u'Primary name'b'Unit definition'u'Unit definition'b'Aliases'u'Aliases'b'There are no equivalent units'u'There are no equivalent units'b'  {{0:<{}s}} | {{1:<{}s}} | {{2:<{}s}}'u'  {{0:<{}s}} | {{1:<{}s}} | {{2:<{}s}}'b' ,'u' ,'b'
            Outputs a HTML table representation within Jupyter notebooks.
            'u'
            Outputs a HTML table representation within Jupyter notebooks.
            'b'<p>'u'<p>'b'</p>'u'</p>'b'<th>'u'<th>'b'</th>'u'</th>'b'<tr>'u'<tr>'b'<td>'u'<td>'b'</td>'u'</td>'b'</tr>'u'</tr>'b'<table style="width:50%"><tr>'u'<table style="width:50%"><tr>'b'</table>'u'</table>'b'
            Extract attributes, and sort, the equivalent units pre-formatting.
            'u'
            Extract attributes, and sort, the equivalent units pre-formatting.
            'b'irreducible'u'irreducible'b'
        Return a list of all the units that are the same type as ``self``.

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also list.  See
            :ref:`astropy:unit_equivalencies`.
            Any list given, including an empty one, supersedes global defaults
            that may be in effect (as set by `set_enabled_equivalencies`)

        units : set of `~astropy.units.Unit`, optional
            If not provided, all defined units will be searched for
            equivalencies.  Otherwise, may be a dict, module or
            sequence containing the units to search for equivalencies.

        include_prefix_units : bool, optional
            When `True`, include prefixed units in the result.
            Default is `False`.

        Returns
        -------
        units : list of `UnitBase`
            A list of unit objects that match ``u``.  A subclass of
            `list` (``EquivalentUnitsList``) is returned that
            pretty-prints the list of units when output.
        'u'
        Return a list of all the units that are the same type as ``self``.

        Parameters
        ----------
        equivalencies : list of tuple
            A list of equivalence pairs to also list.  See
            :ref:`astropy:unit_equivalencies`.
            Any list given, including an empty one, supersedes global defaults
            that may be in effect (as set by `set_enabled_equivalencies`)

        units : set of `~astropy.units.Unit`, optional
            If not provided, all defined units will be searched for
            equivalencies.  Otherwise, may be a dict, module or
            sequence containing the units to search for equivalencies.

        include_prefix_units : bool, optional
            When `True`, include prefixed units in the result.
            Default is `False`.

        Returns
        -------
        units : list of `UnitBase`
            A list of unit objects that match ``u``.  A subclass of
            `list` (``EquivalentUnitsList``) is returned that
            pretty-prints the list of units when output.
        'b'Check whether the unit is unscaled and dimensionless.'u'Check whether the unit is unscaled and dimensionless.'b'
    The base class of units that have a name.

    Parameters
    ----------
    st : str, list of str, 2-tuple
        The name of the unit.  If a list of strings, the first element
        is the canonical (short) name, and the rest of the elements
        are aliases.  If a tuple of lists, the first element is a list
        of short names, and the second element is a list of long
        names; all but the first short name are considered "aliases".
        Each name *should* be a valid Python identifier to make it
        easy to access, but this is not required.

    namespace : dict, optional
        When provided, inject the unit, and all of its aliases, in the
        given namespace dictionary.  If a unit by the same name is
        already in the namespace, a ValueError is raised.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to have it
        displayed as ``\Omega`` by the ``latex`` formatter.  In that
        case, `format` argument should be set to::

            {'latex': r'\Omega'}

    Raises
    ------
    ValueError
        If any of the given unit names are already in the registry.

    ValueError
        If any of the given unit names are not valid Python tokens.
    'u'
    The base class of units that have a name.

    Parameters
    ----------
    st : str, list of str, 2-tuple
        The name of the unit.  If a list of strings, the first element
        is the canonical (short) name, and the rest of the elements
        are aliases.  If a tuple of lists, the first element is a list
        of short names, and the second element is a list of long
        names; all but the first short name are considered "aliases".
        Each name *should* be a valid Python identifier to make it
        easy to access, but this is not required.

    namespace : dict, optional
        When provided, inject the unit, and all of its aliases, in the
        given namespace dictionary.  If a unit by the same name is
        already in the namespace, a ValueError is raised.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to have it
        displayed as ``\Omega`` by the ``latex`` formatter.  In that
        case, `format` argument should be set to::

            {'latex': r'\Omega'}

    Raises
    ------
    ValueError
        If any of the given unit names are already in the registry.

    ValueError
        If any of the given unit names are not valid Python tokens.
    'b'st must be string, list or 2-tuple'u'st must be string, list or 2-tuple'b'must provide at least one name'u'must provide at least one name'b'st list must have at least one entry'u'st list must have at least one entry'b'
        Generate a docstring for the unit if the user didn't supply
        one.  This is only used from the constructor and may be
        overridden in subclasses.
        'u'
        Generate a docstring for the unit if the user didn't supply
        one.  This is only used from the constructor and may be
        overridden in subclasses.
        'b'to_string()'u'to_string()'b'
        Get a name for this unit that is specific to a particular
        format.

        Uses the dictionary passed into the `format` kwarg in the
        constructor.

        Parameters
        ----------
        format : str
            The name of the format

        Returns
        -------
        name : str
            The name of the unit for the given format.
        'u'
        Get a name for this unit that is specific to a particular
        format.

        Uses the dictionary passed into the `format` kwarg in the
        constructor.

        Parameters
        ----------
        format : str
            The name of the format

        Returns
        -------
        name : str
            The name of the unit for the given format.
        'b'All the names associated with the unit.'u'All the names associated with the unit.'b'The canonical (short) name associated with the unit.'u'The canonical (short) name associated with the unit.'b'The aliases (long) names for the unit.'u'The aliases (long) names for the unit.'b'All the short names associated with the unit.'u'All the short names associated with the unit.'b'All the long names associated with the unit.'u'All the long names associated with the unit.'b'
        Injects the unit, and all of its aliases, in the given
        namespace dictionary.
        'u'
        Injects the unit, and all of its aliases, in the given
        namespace dictionary.
        'b'NFKC'u'NFKC'b'Object with NFKC normalized name 'u'Object with NFKC normalized name 'b' already exists in given namespace ('u' already exists in given namespace ('b'
    This is used to reconstruct units when passed around by
    multiprocessing.
    'u'
    This is used to reconstruct units when passed around by
    multiprocessing.
    'b'
    Irreducible units are the units that all other units are defined
    in terms of.

    Examples are meters, seconds, kilograms, amperes, etc.  There is
    only once instance of such a unit per type.
    'u'
    Irreducible units are the units that all other units are defined
    in terms of.

    Examples are meters, seconds, kilograms, amperes, etc.  There is
    only once instance of such a unit per type.
    'b'The unit that this named unit represents.

        For an irreducible unit, that is always itself.
        'u'The unit that this named unit represents.

        For an irreducible unit, that is always itself.
        'b'Unit 'u'Unit 'b' can not be decomposed into the requested bases'u' can not be decomposed into the requested bases'b'
    A unit that did not parse correctly.  This allows for
    round-tripping it as a string, but no unit operations actually work
    on it.

    Parameters
    ----------
    st : str
        The name of the unit.
    'u'
    A unit that did not parse correctly.  This allows for
    round-tripping it as a string, but no unit operations actually work
    on it.

    Parameters
    ----------
    st : str
        The name of the unit.
    'b'UnrecognizedUnit('u'UnrecognizedUnit('b'replace'u'replace'b'The unit 'u'The unit 'b' is unrecognized, so all arithmetic operations with it are invalid.'u' is unrecognized, so all arithmetic operations with it are invalid.'b' is unrecognized.  It can not be converted to other units.'u' is unrecognized.  It can not be converted to other units.'b'
    This metaclass exists because the Unit constructor should
    sometimes return instances that already exist.  This "overrides"
    the constructor before the new instance is actually created, so we
    can return an existing one.
    'u'
    This metaclass exists because the Unit constructor should
    sometimes return instances that already exist.  This "overrides"
    the constructor before the new instance is actually created, so we
    can return an existing one.
    'b'If you cannot change the unit string then try specifying the 'parse_strict' argument.'u'If you cannot change the unit string then try specifying the 'parse_strict' argument.'b''parse_strict' must be 'warn', 'raise' or 'silent''u''parse_strict' must be 'warn', 'raise' or 'silent''b'' did not parse as 'u'' did not parse as 'b'unit: 'u'unit: 'b' If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html'u' If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html'b' cannot be converted to a Unit'u' cannot be converted to a Unit'b'
    The main unit class.

    There are a number of different ways to construct a Unit, but
    always returns a `UnitBase` instance.  If the arguments refer to
    an already-existing unit, that existing unit instance is returned,
    rather than a new one.

    - From a string::

        Unit(s, format=None, parse_strict='silent')

      Construct from a string representing a (possibly compound) unit.

      The optional `format` keyword argument specifies the format the
      string is in, by default ``"generic"``.  For a description of
      the available formats, see `astropy.units.format`.

      The optional ``parse_strict`` keyword argument controls what happens
      when the string does not comply with the specified format. It may be
      one of the following:

         - ``'raise'``: (default) raise a `ValueError` exception.

         - ``'warn'``: emit a `UnitParserWarning`, and return a unit.

         - ``'silent'``: return a unit silently.

      With ``'warn'`` or ``'silent'`` the parser might be able to parse the
      string and return a normal unit, but if it fails then an
      `UnrecognizedUnit` instance is returned.

    - From a number::

        Unit(number)

      Creates a dimensionless unit.

    - From a `UnitBase` instance::

        Unit(unit)

      Returns the given unit unchanged.

    - From no arguments::

        Unit()

      Returns the dimensionless unit.

    - The last form, which creates a new `Unit` is described in detail
      below.

    See also: https://docs.astropy.org/en/stable/units/

    Parameters
    ----------
    st : str or list of str
        The name of the unit.  If a list, the first element is the
        canonical (short) name, and the rest of the elements are
        aliases.

    represents : unit-like, optional
        The unit that this named unit represents.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to have it
        displayed as ``\Omega`` by the ``latex`` formatter.  In that
        case, `format` argument should be set to::

            {'latex': r'\Omega'}

    namespace : dict, optional
        When provided, inject the unit (and all of its aliases) into
        the given namespace.

    Raises
    ------
    ValueError
        If any of the given unit names are already in the registry.

    ValueError
        If any of the given unit names are not valid Python tokens.

    ValueError
        If ``represents`` cannot be parsed as a unit, e.g., because it is
        a malformed string or a |Quantity| that is not a scalar.

    'u'
    The main unit class.

    There are a number of different ways to construct a Unit, but
    always returns a `UnitBase` instance.  If the arguments refer to
    an already-existing unit, that existing unit instance is returned,
    rather than a new one.

    - From a string::

        Unit(s, format=None, parse_strict='silent')

      Construct from a string representing a (possibly compound) unit.

      The optional `format` keyword argument specifies the format the
      string is in, by default ``"generic"``.  For a description of
      the available formats, see `astropy.units.format`.

      The optional ``parse_strict`` keyword argument controls what happens
      when the string does not comply with the specified format. It may be
      one of the following:

         - ``'raise'``: (default) raise a `ValueError` exception.

         - ``'warn'``: emit a `UnitParserWarning`, and return a unit.

         - ``'silent'``: return a unit silently.

      With ``'warn'`` or ``'silent'`` the parser might be able to parse the
      string and return a normal unit, but if it fails then an
      `UnrecognizedUnit` instance is returned.

    - From a number::

        Unit(number)

      Creates a dimensionless unit.

    - From a `UnitBase` instance::

        Unit(unit)

      Returns the given unit unchanged.

    - From no arguments::

        Unit()

      Returns the dimensionless unit.

    - The last form, which creates a new `Unit` is described in detail
      below.

    See also: https://docs.astropy.org/en/stable/units/

    Parameters
    ----------
    st : str or list of str
        The name of the unit.  If a list, the first element is the
        canonical (short) name, and the rest of the elements are
        aliases.

    represents : unit-like, optional
        The unit that this named unit represents.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to have it
        displayed as ``\Omega`` by the ``latex`` formatter.  In that
        case, `format` argument should be set to::

            {'latex': r'\Omega'}

    namespace : dict, optional
        When provided, inject the unit (and all of its aliases) into
        the given namespace.

    Raises
    ------
    ValueError
        If any of the given unit names are already in the registry.

    ValueError
        If any of the given unit names are not valid Python tokens.

    ValueError
        If ``represents`` cannot be parsed as a unit, e.g., because it is
        a malformed string or a |Quantity| that is not a scalar.

    'b'The unit that this named unit represents.'u'The unit that this named unit represents.'b'
    A unit that is simply a SI-prefixed version of another unit.

    For example, ``mm`` is a `PrefixUnit` of ``.001 * m``.

    The constructor is the same as for `Unit`.
    'u'
    A unit that is simply a SI-prefixed version of another unit.

    For example, ``mm`` is a `PrefixUnit` of ``.001 * m``.

    The constructor is the same as for `Unit`.
    'b'
    Create a composite unit using expressions of previously defined
    units.

    Direct use of this class is not recommended. Instead use the
    factory function `Unit` and arithmetic operators to compose
    units.

    Parameters
    ----------
    scale : number
        A scaling factor for the unit.

    bases : sequence of `UnitBase`
        A sequence of units this unit is composed of.

    powers : sequence of numbers
        A sequence of powers (in parallel with ``bases``) for each
        of the base units.

    Raises
    ------
    UnitScaleError
        If the scale is zero.
    'u'
    Create a composite unit using expressions of previously defined
    units.

    Direct use of this class is not recommended. Instead use the
    factory function `Unit` and arithmetic operators to compose
    units.

    Parameters
    ----------
    scale : number
        A scaling factor for the unit.

    bases : sequence of `UnitBase`
        A sequence of units this unit is composed of.

    powers : sequence of numbers
        A sequence of powers (in parallel with ``bases``) for each
        of the base units.

    Raises
    ------
    UnitScaleError
        If the scale is zero.
    'b'bases must be sequence of UnitBase instances'u'bases must be sequence of UnitBase instances'b'Unit(dimensionless with a scale of 'u'Unit(dimensionless with a scale of 'b'Unit(dimensionless)'u'Unit(dimensionless)'b'The scale of the composite unit.'u'The scale of the composite unit.'b'The bases of the composite unit.'u'The bases of the composite unit.'b'The powers of the bases of the composite unit.'u'The powers of the bases of the composite unit.'b'Prefix for representing multiples or sub-multiples of units.

    Parameters
    ----------
    symbols : tuple of str
        The symbols of the prefix, to be combined with symbols of units.
        If multiple are specified then they will be treated as aliases.
    names : tuple of str
        The names of the prefix, to be combined with names of units.
        If multiple are specified then they will be treated as aliases.
    factor : `~astropy.units.typing.UnitScale`
        The multiplicative factor represented by the prefix.

    Examples
    --------
    >>> UnitPrefix(("k",), ("kilo",), 1e3)  # Simple prefix
    UnitPrefix(symbols=('k',), names=('kilo',), factor=1000.0)
    >>> UnitPrefix(("da",), ("deca", "deka"), 1e1)  # Multiple names
    UnitPrefix(symbols=('da',), names=('deca', 'deka'), factor=10.0)
    >>> UnitPrefix(("u", ""), ("micro",), 1e-6)  # Multiple symbols
    UnitPrefix(symbols=('u', ''), names=('micro',), factor=1e-06)
    'u'Prefix for representing multiples or sub-multiples of units.

    Parameters
    ----------
    symbols : tuple of str
        The symbols of the prefix, to be combined with symbols of units.
        If multiple are specified then they will be treated as aliases.
    names : tuple of str
        The names of the prefix, to be combined with names of units.
        If multiple are specified then they will be treated as aliases.
    factor : `~astropy.units.typing.UnitScale`
        The multiplicative factor represented by the prefix.

    Examples
    --------
    >>> UnitPrefix(("k",), ("kilo",), 1e3)  # Simple prefix
    UnitPrefix(symbols=('k',), names=('kilo',), factor=1000.0)
    >>> UnitPrefix(("da",), ("deca", "deka"), 1e1)  # Multiple names
    UnitPrefix(symbols=('da',), names=('deca', 'deka'), factor=10.0)
    >>> UnitPrefix(("u", ""), ("micro",), 1e-6)  # Multiple symbols
    UnitPrefix(symbols=('u', ''), names=('micro',), factor=1e-06)
    'b'The symbols of the prefix, to be combined with symbols of units.'u'The symbols of the prefix, to be combined with symbols of units.'b'The names of the prefix, to be combined with names of units.'u'The names of the prefix, to be combined with names of units.'b'The multiplicative factor represented by the prefix.'u'The multiplicative factor represented by the prefix.'b'quetta'u'quetta'b'ronna'u'ronna'b'yotta'u'yotta'b'zetta'u'zetta'b'exa'u'exa'b'peta'u'peta'b'tera'u'tera'b'giga'u'giga'b'mega'u'mega'b'kilo'u'kilo'b'hecto'u'hecto'b'deka'u'deka'b'deca'u'deca'b'deci'u'deci'b'centi'u'centi'b'milli'u'milli'b''u''u''b'micro'b'nano'u'nano'b'pico'u'pico'b'femto'u'femto'b'atto'u'atto'b'zepto'u'zepto'b'yocto'u'yocto'b'ronto'u'ronto'b'quecto'u'quecto'b'Ki'u'Ki'b'kibi'u'kibi'b'Mi'u'Mi'b'mebi'u'mebi'b'Gi'u'Gi'b'gibi'u'gibi'b'Ti'u'Ti'b'tebi'u'tebi'b'Pi'u'Pi'b'pebi'u'pebi'b'Ei'u'Ei'b'exbi'u'exbi'b'Zi'u'Zi'b'zebi'u'zebi'b'Yi'u'Yi'b'yobi'u'yobi'b'
    Set up all of the standard metric prefixes for a unit.  This
    function should not be used directly, but instead use the
    `prefixes` kwarg on `def_unit` See the documentation of that function
    for the description of the parameters.
    'u'
    Set up all of the standard metric prefixes for a unit.  This
    function should not be used directly, but instead use the
    `prefixes` kwarg on `def_unit` See the documentation of that function
    for the description of the parameters.
    'b'\mu 'u'\mu 'b'Define a new unit.

    This function differs from creating units directly with `Unit` or
    `IrreducibleUnit` because it can also automatically generate prefixed
    units in the given namespace.

    Parameters
    ----------
    s : str or list of str
        The name of the unit.  If a list, the first element is the
        canonical (short) name, and the rest of the elements are
        aliases.

    represents : unit-like, optional
        The unit that this named unit represents.  If not provided,
        a new `IrreducibleUnit` is created.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to
        have it displayed as ``\Omega`` by the ``latex``
        formatter.  In that case, `format` argument should be set
        to::

            {'latex': r'\Omega'}

    prefixes : bool or iterable of UnitPrefix, optional
        When `True`, generate all of the SI prefixed versions of the
        unit as well.  For example, for a given unit ``m``, will
        generate ``mm``, ``cm``, ``km``, etc.  If only a few prefixed
        versions should be created then an iterable of `UnitPrefix`
        instances can be specified instead. Default is `False`, which
        means no prefixed versions will be generated.

        This function always returns the base unit object, even if
        multiple scaled versions of the unit were created.

    exclude_prefixes : `~collections.abc.Collection` of str, optional
        If any of the SI prefixes need to be excluded, they may be
        listed here.  For example, when defining the prefixes for ``a``,
        ``exclude_prefixes`` should be set to ``["P"]`` so that ``Pa``
        would still refer to the pascal.

        If a bare `str` is used then the prefixes that will be excluded are
        the substrings of the `str`, not just its individual characters.

    namespace : dict, optional
        When provided, inject the unit (and all of its aliases and
        prefixes), into the given namespace dictionary.

    Returns
    -------
    unit : `~astropy.units.NamedUnit`
        The newly-defined unit, or a matching unit that was already
        defined.

    Raises
    ------
    ValueError
        If ``represents`` cannot be parsed as a unit, e.g., because it is
        a malformed string or a |Quantity| that is not a scalar.

    'u'Define a new unit.

    This function differs from creating units directly with `Unit` or
    `IrreducibleUnit` because it can also automatically generate prefixed
    units in the given namespace.

    Parameters
    ----------
    s : str or list of str
        The name of the unit.  If a list, the first element is the
        canonical (short) name, and the rest of the elements are
        aliases.

    represents : unit-like, optional
        The unit that this named unit represents.  If not provided,
        a new `IrreducibleUnit` is created.

    doc : str, optional
        A docstring describing the unit.

    format : dict, optional
        A mapping to format-specific representations of this unit.
        For example, for the ``Ohm`` unit, it might be nice to
        have it displayed as ``\Omega`` by the ``latex``
        formatter.  In that case, `format` argument should be set
        to::

            {'latex': r'\Omega'}

    prefixes : bool or iterable of UnitPrefix, optional
        When `True`, generate all of the SI prefixed versions of the
        unit as well.  For example, for a given unit ``m``, will
        generate ``mm``, ``cm``, ``km``, etc.  If only a few prefixed
        versions should be created then an iterable of `UnitPrefix`
        instances can be specified instead. Default is `False`, which
        means no prefixed versions will be generated.

        This function always returns the base unit object, even if
        multiple scaled versions of the unit were created.

    exclude_prefixes : `~collections.abc.Collection` of str, optional
        If any of the SI prefixes need to be excluded, they may be
        listed here.  For example, when defining the prefixes for ``a``,
        ``exclude_prefixes`` should be set to ``["P"]`` so that ``Pa``
        would still refer to the pascal.

        If a bare `str` is used then the prefixes that will be excluded are
        the substrings of the `str`, not just its individual characters.

    namespace : dict, optional
        When provided, inject the unit (and all of its aliases and
        prefixes), into the given namespace dictionary.

    Returns
    -------
    unit : `~astropy.units.NamedUnit`
        The newly-defined unit, or a matching unit that was already
        defined.

    Raises
    ------
    ValueError
        If ``represents`` cannot be parsed as a unit, e.g., because it is
        a malformed string or a |Quantity| that is not a scalar.

    'b'Validate value is acceptable for conversion purposes.

    Will convert into an array if not a scalar or array-like, where scalars
    and arrays can be python and numpy types, anything that defines
    ``__array_namespace__`` or anything that has a ``.dtype`` attribute.

    Parameters
    ----------
    value : scalar or array-like

    Returns
    -------
    Scalar value or array

    Raises
    ------
    ValueError
        If value is not as expected

    'u'Validate value is acceptable for conversion purposes.

    Will convert into an array if not a scalar or array-like, where scalars
    and arrays can be python and numpy types, anything that defines
    ``__array_namespace__`` or anything that has a ``.dtype`` attribute.

    Parameters
    ----------
    value : scalar or array-like

    Returns
    -------
    Scalar value or array

    Raises
    ------
    ValueError
        If value is not as expected

    'b'__array_namespace__'u'__array_namespace__'b'ifc'u'ifc'b'Value not scalar compatible or convertible to an int, float, or complex array'u'Value not scalar compatible or convertible to an int, float, or complex array'b'Function that just multiplies the value by unity.

    This is a separate function so it can be recognized and
    discarded in unit conversion.
    'u'Function that just multiplies the value by unity.

    This is a separate function so it can be recognized and
    discarded in unit conversion.
    'u'astropy.units.core'u'units.core'u'core'
This module contains the fundamental classes used for representing
coordinates in astropy.
SpecificTypeQuantityhms_tupleA named tuple of (hour, minute, second) values.The hour value.The minute value.The second value.dms_tupleA named tuple of (degree, minute, second) values.The degree value.signed_dms_tupleA named tuple of (sign, degree, minute, second) values.The sign of the angle, either -1 or +1.
    One or more angular value(s) with units equivalent to radians or degrees.

    An angle can be specified either as an array, scalar, tuple (see
    below), string, `~astropy.units.Quantity` or another
    :class:`~astropy.coordinates.Angle`.

    The input parser is flexible and supports a variety of formats.
    The examples below illustrate common ways of initializing an
    `~astropy.coordinates.Angle` object. First some imports::

      >>> from astropy.coordinates import Angle
      >>> from astropy import units as u

    The angle values can now be provided::

      >>> Angle('10.2345d')
      <Angle 10.2345 deg>
      >>> Angle(['10.2345d', '-20d'])
      <Angle [ 10.2345, -20.    ] deg>
      >>> Angle('1:2:30.43 degrees')
      <Angle 1.04178611 deg>
      >>> Angle('1 2 0 hours')
      <Angle 1.03333333 hourangle>
      >>> Angle(np.arange(1, 8), unit=u.deg)
      <Angle [1., 2., 3., 4., 5., 6., 7.] deg>
      >>> Angle('123')
      <Angle 1.03416667 deg>
      >>> Angle('123N')
      <Angle 1.03416667 deg>
      >>> Angle('1d2m3.4s')
      <Angle 1.03427778 deg>
      >>> Angle('1d2m3.4sS')
      <Angle -1.03427778 deg>
      >>> Angle('-1h2m3s')
      <Angle -1.03416667 hourangle>
      >>> Angle('-1h2m3sE')
      <Angle -1.03416667 hourangle>
      >>> Angle('-1h2.5m')
      <Angle -1.04166667 hourangle>
      >>> Angle('-1h2.5mW')
      <Angle 1.04166667 hourangle>
      >>> Angle('-1:2.5', unit=u.deg)
      <Angle -1.04166667 deg>
      >>> Angle(10.2345 * u.deg)
      <Angle 10.2345 deg>
      >>> Angle(Angle(10.2345 * u.deg))
      <Angle 10.2345 deg>

    Parameters
    ----------
    angle : `~numpy.array`, scalar, `~astropy.units.Quantity`, `~astropy.coordinates.Angle`
        The angle value. If a tuple, will be interpreted as ``(h, m,
        s)`` or ``(d, m, s)`` depending on ``unit``. If a string, it
        will be interpreted following the rules described above.

        If ``angle`` is a sequence or array of strings, the resulting
        values will be in the given ``unit``, or if `None` is provided,
        the unit will be taken from the first given value.

    unit : unit-like, optional
        The unit of the value specified for the angle.  This may be
        any string that `~astropy.units.Unit` understands, but it is
        better to give an actual unit object.  Must be an angular
        unit.

    dtype : `~numpy.dtype`, optional
        See `~astropy.units.Quantity`.

    copy : bool, optional
        See `~astropy.units.Quantity`.

    Raises
    ------
    `~astropy.units.UnitsError`
        If a unit is not provided or it is not an angular unit.
    _equivalent_unit_include_easy_conversion_members_convert_unit_to_angle_unitCreating an Angle with a tuple of degrees (or hours), minutes, and seconds is no longer supported, as it has ambiguous behavior when the degree value is 0. Use another way of creating angles instead (e.g., a less ambiguous string like '-0d1m2.3s'). In a future version of astropy, a tuple will be interpreted simply as a sequence with the given unit."Creating an Angle with a tuple of degrees (or hours), minutes, and seconds ""is no longer supported, as it has ambiguous behavior when the degree ""value is 0. Use another way of creating angles instead (e.g., a less ""ambiguous string like '-0d1m2.3s'). In a future version of astropy, a tuple ""will be interpreted simply as a sequence with the given unit."parse_angleangle_unithourangle_check_hour_range_check_minute_range60.0_check_second_range3600.0copysignSUVO_set_unit
        The angle's value in hours (read-only property).
        The angle's value in hours, as a named tuple with ``(h, m, s)`` members._decimal_to_sexagesimalThe angle's value in degrees, as a ``(d, m, s)`` named tuple.signed_dmsThe angle's value in degrees, as a ``(sign, d, m, s)`` named tuple.

        The ``d``, ``m``, ``s`` are thus always positive, and the sign of
        the angle is given by ``sign``.

        This is primarily intended for use with `dms` to generate string
        representations of coordinates that are correct for negative angles.
        fromunitalwayssignA string representation of the angle.

        Parameters
        ----------
        unit : `~astropy.units.UnitBase`, optional
            Specifies the unit.  Must be an angular unit.  If not
            provided, the unit used to initialize the angle will be
            used.

        decimal : bool, optional
            If `False`, the returned string will be in sexagesimal form
            if possible (for units of degrees or hourangle).  If `True`,
            a decimal representation will be used. In that case, no unit
            will be appended if ``format`` is not explicitly given.

        sep : str, optional
            The separator between numbers in a sexagesimal
            representation.  E.g., if it is ':', the result is
            ``'12:41:11.1241'``. Also accepts 2 or 3 separators. E.g.,
            ``sep='hms'`` would give the result ``'12h41m11.1241s'``, or
            sep='-:' would yield ``'11-21:17.124'``.  Alternatively, the
            special string 'fromunit' means 'dms' if the unit is
            degrees, or 'hms' if the unit is hours.

        precision : int, optional
            The level of decimal precision.  If ``decimal`` is `True`,
            this is the raw precision, otherwise it gives the
            precision of the last place of the sexagesimal
            representation (seconds).  If `None`, or not provided, the
            number of decimal places is determined by the value, and
            will be between 0-8 decimal places as required.

        alwayssign : bool, optional
            If `True`, include the sign no matter what.  If `False`,
            only include the sign if it is negative.

        pad : bool, optional
            If `True`, include leading zeros when needed to ensure a
            fixed number of characters for sexagesimal representation.

        fields : int, optional
            Specifies the number of fields to display when outputting
            sexagesimal notation.  For example:

                - fields == 1: ``'5d'``
                - fields == 2: ``'5d45m'``
                - fields == 3: ``'5d45m32.5s'``

            By default, all fields are displayed.

        format : str, optional
            The format of the result.  If not provided, an unadorned
            string is returned.  Supported values are:

            - 'latex': Return a LaTeX-formatted string

            - 'latex_inline': Return a LaTeX-formatted string which is the
              same as with ``format='latex'`` for |Angle| instances

            - 'unicode': Return a string containing non-ASCII unicode
              characters, such as the degree symbol

        Returns
        -------
        strrepr : str or array
            A string representation of the angle. If the angle is an array, this
            will be an array with a unicode dtype.

        With decimal=True, separator cannot be used (got ^\circ{}^\prime{}^{\prime\prime}^{\mathrm{h}}^{\mathrm{m}}^{\mathrm{s}}separatorslatex_inlineUnknown format '_decimal_to_sexagesimal_string{:g}{{0:0.f}}unit_string\;format_funcdo_formatvectorizeotypesformat_ufunc_wrap_at
        Implementation that assumes ``angle`` is already validated
        and that wrapping is inplace.
        a360self_anglewrap_angle_floorout_of_rangewrap_at
        Wrap the `~astropy.coordinates.Angle` object at the given ``wrap_angle``.

        This method forces all the angle values to be within a contiguous
        360 degree range so that ``wrap_angle - 360d <= angle <
        wrap_angle``. By default a new Angle object is returned, but if the
        ``inplace`` argument is `True` then the `~astropy.coordinates.Angle`
        object is wrapped in place and nothing is returned.

        For instance::

          >>> from astropy.coordinates import Angle
          >>> import astropy.units as u
          >>> a = Angle([-20.0, 150.0, 350.0] * u.deg)

          >>> a.wrap_at(360 * u.deg).degree  # Wrap into range 0 to 360 degrees  # doctest: +FLOAT_CMP
          array([340., 150., 350.])

          >>> a.wrap_at('180d', inplace=True)  # Wrap into range -180 to 180 degrees  # doctest: +FLOAT_CMP
          >>> a.degree  # doctest: +FLOAT_CMP
          array([-20., 150., -10.])

        Parameters
        ----------
        wrap_angle : angle-like
            Specifies a single value for the wrap angle.  This can be any
            object that can initialize an `~astropy.coordinates.Angle` object,
            e.g. ``'180d'``, ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.

        inplace : bool
            If `True` then wrap the object in place instead of returning
            a new `~astropy.coordinates.Angle`

        Returns
        -------
        out : Angle or None
            If ``inplace is False`` (default), return new
            `~astropy.coordinates.Angle` object with angles wrapped accordingly.
            Otherwise wrap in place and return `None`.
        is_within_bounds
        Check if all angle(s) satisfy ``lower <= angle < upper``.

        If ``lower`` is not specified (or `None`) then no lower bounds check is
        performed.  Likewise ``upper`` can be left unspecified.  For example::

          >>> from astropy.coordinates import Angle
          >>> import astropy.units as u
          >>> a = Angle([-20, 150, 350] * u.deg)
          >>> a.is_within_bounds('0d', '360d')
          False
          >>> a.is_within_bounds(None, '360d')
          True
          >>> a.is_within_bounds(-30 * u.deg, None)
          True

        Parameters
        ----------
        lower : angle-like or None
            Specifies lower bound for checking.  This can be any object
            that can initialize an `~astropy.coordinates.Angle` object, e.g. ``'180d'``,
            ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.
        upper : angle-like or None
            Specifies upper bound for checking.  This can be any object
            that can initialize an `~astropy.coordinates.Angle` object, e.g. ``'180d'``,
            ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.

        Returns
        -------
        is_within_bounds : bool
            `True` if all angles satisfy ``lower <= angle < upper``
        _str_helper_no_angle_subclassReturn any Angle subclass objects as an Angle objects.

    This is used to ensure that Latitude and Longitude change to Angle
    objects when they are used in calculations (such as lon/2.)
    
    Latitude-like angle(s) which must be in the range -90 to +90 deg.

    A Latitude object is distinguished from a pure
    :class:`~astropy.coordinates.Angle` by virtue of being constrained
    so that::

      -90.0 * u.deg <= angle(s) <= +90.0 * u.deg

    Any attempt to set a value outside that range will result in a
    `ValueError`.

    The input angle(s) can be specified either as an array, list,
    scalar, tuple (see below), string,
    :class:`~astropy.units.Quantity` or another
    :class:`~astropy.coordinates.Angle`.

    The input parser is flexible and supports all of the input formats
    supported by :class:`~astropy.coordinates.Angle`.

    Parameters
    ----------
    angle : array, list, scalar, `~astropy.units.Quantity`, `~astropy.coordinates.Angle`
        The angle value(s). If a tuple, will be interpreted as ``(h, m, s)``
        or ``(d, m, s)`` depending on ``unit``. If a string, it will be
        interpreted following the rules described for
        :class:`~astropy.coordinates.Angle`.

        If ``angle`` is a sequence or array of strings, the resulting
        values will be in the given ``unit``, or if `None` is provided,
        the unit will be taken from the first given value.

    unit : unit-like, optional
        The unit of the value specified for the angle.  This may be
        any string that `~astropy.units.Unit` understands, but it is
        better to give an actual unit object.  Must be an angular
        unit.

    Raises
    ------
    `~astropy.units.UnitsError`
        If a unit is not provided or it is not an angular unit.
    `TypeError`
        If the angle parameter is an instance of :class:`~astropy.coordinates.Longitude`.
    A Latitude angle cannot be created from a Longitude angle_validate_anglesCheck that angles are between -90 and 90 degrees.
        If not given, the check is done on the object itself.
        limitangles_viewLatitude angle(s) must be within -90 deg <= angle <= 90 deg, got "Latitude angle(s) must be within -90 deg <= angle ""<= 90 deg, got " <= angle <= " <= ""angle <= "A Longitude angle cannot be assigned to a Latitude angle__array_ufunc__LongitudeInfoQuantityInfo
    Longitude-like angle(s) which are wrapped within a contiguous 360 degree range.

    A ``Longitude`` object is distinguished from a pure
    :class:`~astropy.coordinates.Angle` by virtue of a ``wrap_angle``
    property.  The ``wrap_angle`` specifies that all angle values
    represented by the object will be in the range::

      wrap_angle - 360 * u.deg <= angle(s) < wrap_angle

    The default ``wrap_angle`` is 360 deg.  Setting ``wrap_angle=180 *
    u.deg`` would instead result in values between -180 and +180 deg.
    Setting the ``wrap_angle`` attribute of an existing ``Longitude``
    object will result in re-wrapping the angle values in-place.

    The input angle(s) can be specified either as an array, list,
    scalar, tuple, string, :class:`~astropy.units.Quantity`
    or another :class:`~astropy.coordinates.Angle`.

    The input parser is flexible and supports all of the input formats
    supported by :class:`~astropy.coordinates.Angle`.

    Parameters
    ----------
    angle : tuple or angle-like
        The angle value(s). If a tuple, will be interpreted as ``(h, m s)`` or
        ``(d, m, s)`` depending on ``unit``. If a string, it will be interpreted
        following the rules described for :class:`~astropy.coordinates.Angle`.

        If ``angle`` is a sequence or array of strings, the resulting
        values will be in the given ``unit``, or if `None` is provided,
        the unit will be taken from the first given value.

    unit : unit-like ['angle'], optional
        The unit of the value specified for the angle.  This may be
        any string that `~astropy.units.Unit` understands, but it is
        better to give an actual unit object.  Must be an angular
        unit.

    wrap_angle : angle-like or None, optional
        Angle at which to wrap back to ``wrap_angle - 360 deg``.
        If ``None`` (default), it will be taken to be 360 deg unless ``angle``
        has a ``wrap_angle`` attribute already (i.e., is a ``Longitude``),
        in which case it will be taken from there.

    Raises
    ------
    `~astropy.units.UnitsError`
        If a unit is not provided or it is not an angular unit.
    `TypeError`
        If the angle parameter is an instance of :class:`~astropy.coordinates.Latitude`.
    _wrap_angle_default_wrap_angleA Longitude angle cannot be created from a Latitude angle.A Latitude angle cannot be assigned to a Longitude angle# these are used by the `hms` and `dms` attributes# Possible conversion to `unit` will be done below.# using caching to return early when possible (unit comparison is expensive)# Default separators are as for generic.# For Angle "latex_inline" is the same as "latex"# Create an iterator so we can format each element of what# might be an array.# Sexagesimal.# Don't add unit by default for decimal.# TODO: could we use Quantity.to_string() here?# Remove $ and add space in front if unit is not a superscript.# Length one for angular units can only happen for# superscript degree, arcmin, arcsec, hour, minute, second,# and those should not get an extra space.# Check if value is not nan to avoid ValueErrors when turning it into# a hexagesimal string.# Convert the wrap angle and 360 degrees to the native unit of# this Angle, then do all the math on raw Numpy arrays rather# than Quantity objects for speed.# Ensure ndim>=1 so that comparison is done using the angle dtype.# Use explicit float to ensure casting to self_angle.dtype (NEP 50).# Do the wrapping, but only if any angles need to be wrapped# Catch any invalid warnings from the floor division.# See if any wrapping is necessary and return early otherwise.# It is useful to avoid this since the array may be read-only# (e.g. due to broadcasting).# Note that since comparisons with NaN always return False,# this also ensures that no adjustments are made for a# read-only array with some NaN but otherwise OK elements.# Rounding errors can cause problems.# Convert to an Angle# Forbid creating a Lat from a Long.# Convert the lower and upper bounds to the "native" unit of# this angle.  This limits multiplication to two values,# rather than the N values in `self.value`.  Also, the# comparison is performed on raw arrays, rather than Quantity# objects, for speed.# For speed, compare using "is", which is not strictly guaranteed to hold,# but if it doesn't we'll just convert correctly in the 'else' clause.# Otherwise, e.g., np.array(np.pi/2, 'f4') > np.pi/2 will yield True.# Forbid assigning a Long to a Lat.# first check bounds# Any calculation should drop to Angle# Forbid creating a Long from a Lat.# angle-like b/c property setter# Forbid assigning a Lat to a Long.b'
This module contains the fundamental classes used for representing
coordinates in astropy.
'u'
This module contains the fundamental classes used for representing
coordinates in astropy.
'b'A named tuple of (hour, minute, second) values.'u'A named tuple of (hour, minute, second) values.'b'The hour value.'u'The hour value.'b'The minute value.'u'The minute value.'b'The second value.'u'The second value.'b'A named tuple of (degree, minute, second) values.'u'A named tuple of (degree, minute, second) values.'b'The degree value.'u'The degree value.'b'A named tuple of (sign, degree, minute, second) values.'u'A named tuple of (sign, degree, minute, second) values.'b'The sign of the angle, either -1 or +1.'u'The sign of the angle, either -1 or +1.'u'
    One or more angular value(s) with units equivalent to radians or degrees.

    An angle can be specified either as an array, scalar, tuple (see
    below), string, `~astropy.units.Quantity` or another
    :class:`~astropy.coordinates.Angle`.

    The input parser is flexible and supports a variety of formats.
    The examples below illustrate common ways of initializing an
    `~astropy.coordinates.Angle` object. First some imports::

      >>> from astropy.coordinates import Angle
      >>> from astropy import units as u

    The angle values can now be provided::

      >>> Angle('10.2345d')
      <Angle 10.2345 deg>
      >>> Angle(['10.2345d', '-20d'])
      <Angle [ 10.2345, -20.    ] deg>
      >>> Angle('1:2:30.43 degrees')
      <Angle 1.04178611 deg>
      >>> Angle('1 2 0 hours')
      <Angle 1.03333333 hourangle>
      >>> Angle(np.arange(1, 8), unit=u.deg)
      <Angle [1., 2., 3., 4., 5., 6., 7.] deg>
      >>> Angle('123')
      <Angle 1.03416667 deg>
      >>> Angle('123N')
      <Angle 1.03416667 deg>
      >>> Angle('1d2m3.4s')
      <Angle 1.03427778 deg>
      >>> Angle('1d2m3.4sS')
      <Angle -1.03427778 deg>
      >>> Angle('-1h2m3s')
      <Angle -1.03416667 hourangle>
      >>> Angle('-1h2m3sE')
      <Angle -1.03416667 hourangle>
      >>> Angle('-1h2.5m')
      <Angle -1.04166667 hourangle>
      >>> Angle('-1h2.5mW')
      <Angle 1.04166667 hourangle>
      >>> Angle('-1:2.5', unit=u.deg)
      <Angle -1.04166667 deg>
      >>> Angle(10.2345 * u.deg)
      <Angle 10.2345 deg>
      >>> Angle(Angle(10.2345 * u.deg))
      <Angle 10.2345 deg>

    Parameters
    ----------
    angle : `~numpy.array`, scalar, `~astropy.units.Quantity`, `~astropy.coordinates.Angle`
        The angle value. If a tuple, will be interpreted as ``(h, m,
        s)`` or ``(d, m, s)`` depending on ``unit``. If a string, it
        will be interpreted following the rules described above.

        If ``angle`` is a sequence or array of strings, the resulting
        values will be in the given ``unit``, or if `None` is provided,
        the unit will be taken from the first given value.

    unit : unit-like, optional
        The unit of the value specified for the angle.  This may be
        any string that `~astropy.units.Unit` understands, but it is
        better to give an actual unit object.  Must be an angular
        unit.

    dtype : `~numpy.dtype`, optional
        See `~astropy.units.Quantity`.

    copy : bool, optional
        See `~astropy.units.Quantity`.

    Raises
    ------
    `~astropy.units.UnitsError`
        If a unit is not provided or it is not an angular unit.
    'b'Creating an Angle with a tuple of degrees (or hours), minutes, and seconds is no longer supported, as it has ambiguous behavior when the degree value is 0. Use another way of creating angles instead (e.g., a less ambiguous string like '-0d1m2.3s'). In a future version of astropy, a tuple will be interpreted simply as a sequence with the given unit.'u'Creating an Angle with a tuple of degrees (or hours), minutes, and seconds is no longer supported, as it has ambiguous behavior when the degree value is 0. Use another way of creating angles instead (e.g., a less ambiguous string like '-0d1m2.3s'). In a future version of astropy, a tuple will be interpreted simply as a sequence with the given unit.'b'SUVO'u'SUVO'b'__array__'u'__array__'b'
        The angle's value in hours (read-only property).
        'u'
        The angle's value in hours (read-only property).
        'b'The angle's value in hours, as a named tuple with ``(h, m, s)`` members.'u'The angle's value in hours, as a named tuple with ``(h, m, s)`` members.'b'The angle's value in degrees, as a ``(d, m, s)`` named tuple.'u'The angle's value in degrees, as a ``(d, m, s)`` named tuple.'b'The angle's value in degrees, as a ``(sign, d, m, s)`` named tuple.

        The ``d``, ``m``, ``s`` are thus always positive, and the sign of
        the angle is given by ``sign``.

        This is primarily intended for use with `dms` to generate string
        representations of coordinates that are correct for negative angles.
        'u'The angle's value in degrees, as a ``(sign, d, m, s)`` named tuple.

        The ``d``, ``m``, ``s`` are thus always positive, and the sign of
        the angle is given by ``sign``.

        This is primarily intended for use with `dms` to generate string
        representations of coordinates that are correct for negative angles.
        'b'fromunit'u'fromunit'b'A string representation of the angle.

        Parameters
        ----------
        unit : `~astropy.units.UnitBase`, optional
            Specifies the unit.  Must be an angular unit.  If not
            provided, the unit used to initialize the angle will be
            used.

        decimal : bool, optional
            If `False`, the returned string will be in sexagesimal form
            if possible (for units of degrees or hourangle).  If `True`,
            a decimal representation will be used. In that case, no unit
            will be appended if ``format`` is not explicitly given.

        sep : str, optional
            The separator between numbers in a sexagesimal
            representation.  E.g., if it is ':', the result is
            ``'12:41:11.1241'``. Also accepts 2 or 3 separators. E.g.,
            ``sep='hms'`` would give the result ``'12h41m11.1241s'``, or
            sep='-:' would yield ``'11-21:17.124'``.  Alternatively, the
            special string 'fromunit' means 'dms' if the unit is
            degrees, or 'hms' if the unit is hours.

        precision : int, optional
            The level of decimal precision.  If ``decimal`` is `True`,
            this is the raw precision, otherwise it gives the
            precision of the last place of the sexagesimal
            representation (seconds).  If `None`, or not provided, the
            number of decimal places is determined by the value, and
            will be between 0-8 decimal places as required.

        alwayssign : bool, optional
            If `True`, include the sign no matter what.  If `False`,
            only include the sign if it is negative.

        pad : bool, optional
            If `True`, include leading zeros when needed to ensure a
            fixed number of characters for sexagesimal representation.

        fields : int, optional
            Specifies the number of fields to display when outputting
            sexagesimal notation.  For example:

                - fields == 1: ``'5d'``
                - fields == 2: ``'5d45m'``
                - fields == 3: ``'5d45m32.5s'``

            By default, all fields are displayed.

        format : str, optional
            The format of the result.  If not provided, an unadorned
            string is returned.  Supported values are:

            - 'latex': Return a LaTeX-formatted string

            - 'latex_inline': Return a LaTeX-formatted string which is the
              same as with ``format='latex'`` for |Angle| instances

            - 'unicode': Return a string containing non-ASCII unicode
              characters, such as the degree symbol

        Returns
        -------
        strrepr : str or array
            A string representation of the angle. If the angle is an array, this
            will be an array with a unicode dtype.

        'u'A string representation of the angle.

        Parameters
        ----------
        unit : `~astropy.units.UnitBase`, optional
            Specifies the unit.  Must be an angular unit.  If not
            provided, the unit used to initialize the angle will be
            used.

        decimal : bool, optional
            If `False`, the returned string will be in sexagesimal form
            if possible (for units of degrees or hourangle).  If `True`,
            a decimal representation will be used. In that case, no unit
            will be appended if ``format`` is not explicitly given.

        sep : str, optional
            The separator between numbers in a sexagesimal
            representation.  E.g., if it is ':', the result is
            ``'12:41:11.1241'``. Also accepts 2 or 3 separators. E.g.,
            ``sep='hms'`` would give the result ``'12h41m11.1241s'``, or
            sep='-:' would yield ``'11-21:17.124'``.  Alternatively, the
            special string 'fromunit' means 'dms' if the unit is
            degrees, or 'hms' if the unit is hours.

        precision : int, optional
            The level of decimal precision.  If ``decimal`` is `True`,
            this is the raw precision, otherwise it gives the
            precision of the last place of the sexagesimal
            representation (seconds).  If `None`, or not provided, the
            number of decimal places is determined by the value, and
            will be between 0-8 decimal places as required.

        alwayssign : bool, optional
            If `True`, include the sign no matter what.  If `False`,
            only include the sign if it is negative.

        pad : bool, optional
            If `True`, include leading zeros when needed to ensure a
            fixed number of characters for sexagesimal representation.

        fields : int, optional
            Specifies the number of fields to display when outputting
            sexagesimal notation.  For example:

                - fields == 1: ``'5d'``
                - fields == 2: ``'5d45m'``
                - fields == 3: ``'5d45m32.5s'``

            By default, all fields are displayed.

        format : str, optional
            The format of the result.  If not provided, an unadorned
            string is returned.  Supported values are:

            - 'latex': Return a LaTeX-formatted string

            - 'latex_inline': Return a LaTeX-formatted string which is the
              same as with ``format='latex'`` for |Angle| instances

            - 'unicode': Return a string containing non-ASCII unicode
              characters, such as the degree symbol

        Returns
        -------
        strrepr : str or array
            A string representation of the angle. If the angle is an array, this
            will be an array with a unicode dtype.

        'b'With decimal=True, separator cannot be used (got 'u'With decimal=True, separator cannot be used (got 'b'^\circ'u'^\circ'b'{}^\prime'u'{}^\prime'b'{}^{\prime\prime}'u'{}^{\prime\prime}'b'^{\mathrm{h}}'u'^{\mathrm{h}}'b'^{\mathrm{m}}'u'^{\mathrm{m}}'b'^{\mathrm{s}}'u'^{\mathrm{s}}'u''u''b'latex_inline'u'latex_inline'b'Unknown format ''u'Unknown format ''b'{:g}'u'{:g}'b'{{0:0.'u'{{0:0.'b'f}}'u'f}}'b'\;'u'\;'b'
        Implementation that assumes ``angle`` is already validated
        and that wrapping is inplace.
        'u'
        Implementation that assumes ``angle`` is already validated
        and that wrapping is inplace.
        'b'
        Wrap the `~astropy.coordinates.Angle` object at the given ``wrap_angle``.

        This method forces all the angle values to be within a contiguous
        360 degree range so that ``wrap_angle - 360d <= angle <
        wrap_angle``. By default a new Angle object is returned, but if the
        ``inplace`` argument is `True` then the `~astropy.coordinates.Angle`
        object is wrapped in place and nothing is returned.

        For instance::

          >>> from astropy.coordinates import Angle
          >>> import astropy.units as u
          >>> a = Angle([-20.0, 150.0, 350.0] * u.deg)

          >>> a.wrap_at(360 * u.deg).degree  # Wrap into range 0 to 360 degrees  # doctest: +FLOAT_CMP
          array([340., 150., 350.])

          >>> a.wrap_at('180d', inplace=True)  # Wrap into range -180 to 180 degrees  # doctest: +FLOAT_CMP
          >>> a.degree  # doctest: +FLOAT_CMP
          array([-20., 150., -10.])

        Parameters
        ----------
        wrap_angle : angle-like
            Specifies a single value for the wrap angle.  This can be any
            object that can initialize an `~astropy.coordinates.Angle` object,
            e.g. ``'180d'``, ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.

        inplace : bool
            If `True` then wrap the object in place instead of returning
            a new `~astropy.coordinates.Angle`

        Returns
        -------
        out : Angle or None
            If ``inplace is False`` (default), return new
            `~astropy.coordinates.Angle` object with angles wrapped accordingly.
            Otherwise wrap in place and return `None`.
        'u'
        Wrap the `~astropy.coordinates.Angle` object at the given ``wrap_angle``.

        This method forces all the angle values to be within a contiguous
        360 degree range so that ``wrap_angle - 360d <= angle <
        wrap_angle``. By default a new Angle object is returned, but if the
        ``inplace`` argument is `True` then the `~astropy.coordinates.Angle`
        object is wrapped in place and nothing is returned.

        For instance::

          >>> from astropy.coordinates import Angle
          >>> import astropy.units as u
          >>> a = Angle([-20.0, 150.0, 350.0] * u.deg)

          >>> a.wrap_at(360 * u.deg).degree  # Wrap into range 0 to 360 degrees  # doctest: +FLOAT_CMP
          array([340., 150., 350.])

          >>> a.wrap_at('180d', inplace=True)  # Wrap into range -180 to 180 degrees  # doctest: +FLOAT_CMP
          >>> a.degree  # doctest: +FLOAT_CMP
          array([-20., 150., -10.])

        Parameters
        ----------
        wrap_angle : angle-like
            Specifies a single value for the wrap angle.  This can be any
            object that can initialize an `~astropy.coordinates.Angle` object,
            e.g. ``'180d'``, ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.

        inplace : bool
            If `True` then wrap the object in place instead of returning
            a new `~astropy.coordinates.Angle`

        Returns
        -------
        out : Angle or None
            If ``inplace is False`` (default), return new
            `~astropy.coordinates.Angle` object with angles wrapped accordingly.
            Otherwise wrap in place and return `None`.
        'b'
        Check if all angle(s) satisfy ``lower <= angle < upper``.

        If ``lower`` is not specified (or `None`) then no lower bounds check is
        performed.  Likewise ``upper`` can be left unspecified.  For example::

          >>> from astropy.coordinates import Angle
          >>> import astropy.units as u
          >>> a = Angle([-20, 150, 350] * u.deg)
          >>> a.is_within_bounds('0d', '360d')
          False
          >>> a.is_within_bounds(None, '360d')
          True
          >>> a.is_within_bounds(-30 * u.deg, None)
          True

        Parameters
        ----------
        lower : angle-like or None
            Specifies lower bound for checking.  This can be any object
            that can initialize an `~astropy.coordinates.Angle` object, e.g. ``'180d'``,
            ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.
        upper : angle-like or None
            Specifies upper bound for checking.  This can be any object
            that can initialize an `~astropy.coordinates.Angle` object, e.g. ``'180d'``,
            ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.

        Returns
        -------
        is_within_bounds : bool
            `True` if all angles satisfy ``lower <= angle < upper``
        'u'
        Check if all angle(s) satisfy ``lower <= angle < upper``.

        If ``lower`` is not specified (or `None`) then no lower bounds check is
        performed.  Likewise ``upper`` can be left unspecified.  For example::

          >>> from astropy.coordinates import Angle
          >>> import astropy.units as u
          >>> a = Angle([-20, 150, 350] * u.deg)
          >>> a.is_within_bounds('0d', '360d')
          False
          >>> a.is_within_bounds(None, '360d')
          True
          >>> a.is_within_bounds(-30 * u.deg, None)
          True

        Parameters
        ----------
        lower : angle-like or None
            Specifies lower bound for checking.  This can be any object
            that can initialize an `~astropy.coordinates.Angle` object, e.g. ``'180d'``,
            ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.
        upper : angle-like or None
            Specifies upper bound for checking.  This can be any object
            that can initialize an `~astropy.coordinates.Angle` object, e.g. ``'180d'``,
            ``180 * u.deg``, or ``Angle(180, unit=u.deg)``.

        Returns
        -------
        is_within_bounds : bool
            `True` if all angles satisfy ``lower <= angle < upper``
        'b'Return any Angle subclass objects as an Angle objects.

    This is used to ensure that Latitude and Longitude change to Angle
    objects when they are used in calculations (such as lon/2.)
    'u'Return any Angle subclass objects as an Angle objects.

    This is used to ensure that Latitude and Longitude change to Angle
    objects when they are used in calculations (such as lon/2.)
    'b'
    Latitude-like angle(s) which must be in the range -90 to +90 deg.

    A Latitude object is distinguished from a pure
    :class:`~astropy.coordinates.Angle` by virtue of being constrained
    so that::

      -90.0 * u.deg <= angle(s) <= +90.0 * u.deg

    Any attempt to set a value outside that range will result in a
    `ValueError`.

    The input angle(s) can be specified either as an array, list,
    scalar, tuple (see below), string,
    :class:`~astropy.units.Quantity` or another
    :class:`~astropy.coordinates.Angle`.

    The input parser is flexible and supports all of the input formats
    supported by :class:`~astropy.coordinates.Angle`.

    Parameters
    ----------
    angle : array, list, scalar, `~astropy.units.Quantity`, `~astropy.coordinates.Angle`
        The angle value(s). If a tuple, will be interpreted as ``(h, m, s)``
        or ``(d, m, s)`` depending on ``unit``. If a string, it will be
        interpreted following the rules described for
        :class:`~astropy.coordinates.Angle`.

        If ``angle`` is a sequence or array of strings, the resulting
        values will be in the given ``unit``, or if `None` is provided,
        the unit will be taken from the first given value.

    unit : unit-like, optional
        The unit of the value specified for the angle.  This may be
        any string that `~astropy.units.Unit` understands, but it is
        better to give an actual unit object.  Must be an angular
        unit.

    Raises
    ------
    `~astropy.units.UnitsError`
        If a unit is not provided or it is not an angular unit.
    `TypeError`
        If the angle parameter is an instance of :class:`~astropy.coordinates.Longitude`.
    'u'
    Latitude-like angle(s) which must be in the range -90 to +90 deg.

    A Latitude object is distinguished from a pure
    :class:`~astropy.coordinates.Angle` by virtue of being constrained
    so that::

      -90.0 * u.deg <= angle(s) <= +90.0 * u.deg

    Any attempt to set a value outside that range will result in a
    `ValueError`.

    The input angle(s) can be specified either as an array, list,
    scalar, tuple (see below), string,
    :class:`~astropy.units.Quantity` or another
    :class:`~astropy.coordinates.Angle`.

    The input parser is flexible and supports all of the input formats
    supported by :class:`~astropy.coordinates.Angle`.

    Parameters
    ----------
    angle : array, list, scalar, `~astropy.units.Quantity`, `~astropy.coordinates.Angle`
        The angle value(s). If a tuple, will be interpreted as ``(h, m, s)``
        or ``(d, m, s)`` depending on ``unit``. If a string, it will be
        interpreted following the rules described for
        :class:`~astropy.coordinates.Angle`.

        If ``angle`` is a sequence or array of strings, the resulting
        values will be in the given ``unit``, or if `None` is provided,
        the unit will be taken from the first given value.

    unit : unit-like, optional
        The unit of the value specified for the angle.  This may be
        any string that `~astropy.units.Unit` understands, but it is
        better to give an actual unit object.  Must be an angular
        unit.

    Raises
    ------
    `~astropy.units.UnitsError`
        If a unit is not provided or it is not an angular unit.
    `TypeError`
        If the angle parameter is an instance of :class:`~astropy.coordinates.Longitude`.
    'b'A Latitude angle cannot be created from a Longitude angle'u'A Latitude angle cannot be created from a Longitude angle'b'Check that angles are between -90 and 90 degrees.
        If not given, the check is done on the object itself.
        'u'Check that angles are between -90 and 90 degrees.
        If not given, the check is done on the object itself.
        'b'Latitude angle(s) must be within -90 deg <= angle <= 90 deg, got 'u'Latitude angle(s) must be within -90 deg <= angle <= 90 deg, got 'b' <= angle <= 'u' <= angle <= 'b'A Longitude angle cannot be assigned to a Latitude angle'u'A Longitude angle cannot be assigned to a Latitude angle'b'wrap_angle'u'wrap_angle'b'
    Longitude-like angle(s) which are wrapped within a contiguous 360 degree range.

    A ``Longitude`` object is distinguished from a pure
    :class:`~astropy.coordinates.Angle` by virtue of a ``wrap_angle``
    property.  The ``wrap_angle`` specifies that all angle values
    represented by the object will be in the range::

      wrap_angle - 360 * u.deg <= angle(s) < wrap_angle

    The default ``wrap_angle`` is 360 deg.  Setting ``wrap_angle=180 *
    u.deg`` would instead result in values between -180 and +180 deg.
    Setting the ``wrap_angle`` attribute of an existing ``Longitude``
    object will result in re-wrapping the angle values in-place.

    The input angle(s) can be specified either as an array, list,
    scalar, tuple, string, :class:`~astropy.units.Quantity`
    or another :class:`~astropy.coordinates.Angle`.

    The input parser is flexible and supports all of the input formats
    supported by :class:`~astropy.coordinates.Angle`.

    Parameters
    ----------
    angle : tuple or angle-like
        The angle value(s). If a tuple, will be interpreted as ``(h, m s)`` or
        ``(d, m, s)`` depending on ``unit``. If a string, it will be interpreted
        following the rules described for :class:`~astropy.coordinates.Angle`.

        If ``angle`` is a sequence or array of strings, the resulting
        values will be in the given ``unit``, or if `None` is provided,
        the unit will be taken from the first given value.

    unit : unit-like ['angle'], optional
        The unit of the value specified for the angle.  This may be
        any string that `~astropy.units.Unit` understands, but it is
        better to give an actual unit object.  Must be an angular
        unit.

    wrap_angle : angle-like or None, optional
        Angle at which to wrap back to ``wrap_angle - 360 deg``.
        If ``None`` (default), it will be taken to be 360 deg unless ``angle``
        has a ``wrap_angle`` attribute already (i.e., is a ``Longitude``),
        in which case it will be taken from there.

    Raises
    ------
    `~astropy.units.UnitsError`
        If a unit is not provided or it is not an angular unit.
    `TypeError`
        If the angle parameter is an instance of :class:`~astropy.coordinates.Latitude`.
    'u'
    Longitude-like angle(s) which are wrapped within a contiguous 360 degree range.

    A ``Longitude`` object is distinguished from a pure
    :class:`~astropy.coordinates.Angle` by virtue of a ``wrap_angle``
    property.  The ``wrap_angle`` specifies that all angle values
    represented by the object will be in the range::

      wrap_angle - 360 * u.deg <= angle(s) < wrap_angle

    The default ``wrap_angle`` is 360 deg.  Setting ``wrap_angle=180 *
    u.deg`` would instead result in values between -180 and +180 deg.
    Setting the ``wrap_angle`` attribute of an existing ``Longitude``
    object will result in re-wrapping the angle values in-place.

    The input angle(s) can be specified either as an array, list,
    scalar, tuple, string, :class:`~astropy.units.Quantity`
    or another :class:`~astropy.coordinates.Angle`.

    The input parser is flexible and supports all of the input formats
    supported by :class:`~astropy.coordinates.Angle`.

    Parameters
    ----------
    angle : tuple or angle-like
        The angle value(s). If a tuple, will be interpreted as ``(h, m s)`` or
        ``(d, m, s)`` depending on ``unit``. If a string, it will be interpreted
        following the rules described for :class:`~astropy.coordinates.Angle`.

        If ``angle`` is a sequence or array of strings, the resulting
        values will be in the given ``unit``, or if `None` is provided,
        the unit will be taken from the first given value.

    unit : unit-like ['angle'], optional
        The unit of the value specified for the angle.  This may be
        any string that `~astropy.units.Unit` understands, but it is
        better to give an actual unit object.  Must be an angular
        unit.

    wrap_angle : angle-like or None, optional
        Angle at which to wrap back to ``wrap_angle - 360 deg``.
        If ``None`` (default), it will be taken to be 360 deg unless ``angle``
        has a ``wrap_angle`` attribute already (i.e., is a ``Longitude``),
        in which case it will be taken from there.

    Raises
    ------
    `~astropy.units.UnitsError`
        If a unit is not provided or it is not an angular unit.
    `TypeError`
        If the angle parameter is an instance of :class:`~astropy.coordinates.Latitude`.
    'b'A Longitude angle cannot be created from a Latitude angle.'u'A Longitude angle cannot be created from a Latitude angle.'b'A Latitude angle cannot be assigned to a Longitude angle'u'A Latitude angle cannot be assigned to a Longitude angle'b'_wrap_angle'u'_wrap_angle'u'astropy.coordinates.angles.core'u'coordinates.angles.core'u'angles.core'matplotlib.artistArtistmatplotlib.axesAxessubplot_class_factoryTransformHAS_PIL_autoget_coord_metatransform_contour_set_inplaceIDENTITYtransform_coord_meta_from_wcsWCSAxesWCSAxesSubplotVISUAL_PROPERTIESPIL.ImageImageTranspose_WCSAxesArtistThis is a dummy artist to enforce the correct z-order of axis ticks,
    tick labels, and gridlines.

    FIXME: This is a bit of a hack. ``Axes.draw`` sorts the artists by zorder
    and then renders them in sequence. For normal Matplotlib axes, the ticks,
    tick labels, and gridlines are included in this list of artists and hence
    are automatically drawn in the correct order. However, ``WCSAxes`` disables
    the native ticks, labels, and gridlines. Instead, ``WCSAxes.draw`` renders
    ersatz ticks, labels, and gridlines by explicitly calling the functions
    ``CoordinateHelper._draw_ticks``, ``CoordinateHelper._draw_grid``, etc.
    This hack would not be necessary if ``WCSAxes`` drew ticks, tick labels,
    and gridlines in the standary way.
    draw_wcsaxes
    The main axes class that can be used to show world coordinates from a WCS.

    Parameters
    ----------
    fig : `~matplotlib.figure.Figure`
        The figure to add the axes to
    *args
        ``*args`` can be a single ``(left, bottom, width, height)``
        rectangle or a single `matplotlib.transforms.Bbox`.  This specifies
        the rectangle (in figure coordinates) where the Axes is positioned.
        ``*args`` can also consist of three numbers or a single three-digit
        number; in the latter case, the digits are considered as
        independent numbers.  The numbers are interpreted as ``(nrows,
        ncols, index)``: ``(nrows, ncols)`` specifies the size of an array
        of subplots, and ``index`` is the 1-based index of the subplot
        being created.  Finally, ``*args`` can also directly be a
        `matplotlib.gridspec.SubplotSpec` instance.
    wcs : :class:`~astropy.wcs.WCS`, optional
        The WCS for the data. If this is specified, ``transform`` cannot be
        specified.
    transform : `~matplotlib.transforms.Transform`, optional
        The transform for the data. If this is specified, ``wcs`` cannot be
        specified.
    coord_meta : dict, optional
        A dictionary providing additional metadata when ``transform`` is
        specified. This should include the keys ``type``, ``wrap``, and
        ``unit``. Each of these should be a list with as many items as the
        dimension of the WCS. The ``type`` entries should be one of
        ``longitude``, ``latitude``, or ``scalar``, the ``wrap`` entries should
        give, for the longitude, the angle at which the coordinate wraps (and
        `None` otherwise), and the ``unit`` should give the unit of the
        coordinates as :class:`~astropy.units.Unit` instances. This can
        optionally also include a ``format_unit`` entry giving the units to use
        for the tick labels (if not specified, this defaults to ``unit``).
    transData : `~matplotlib.transforms.Transform`, optional
        Can be used to override the default data -> pixel mapping.
    slices : tuple, optional
        For WCS transformations with more than two dimensions, we need to
        choose which dimensions are being shown in the 2D image. The slice
        should contain one ``x`` entry, one ``y`` entry, and the rest of the
        values should be integers indicating the slice through the data. The
        order of the items in the slice should be the same as the order of the
        dimensions in the :class:`~astropy.wcs.WCS`, and the opposite of the
        order of the dimensions in Numpy. For example, ``(50, 'x', 'y')`` means
        that the first WCS dimension (last Numpy dimension) will be sliced at
        an index of 50, the second WCS and Numpy dimension will be shown on the
        x axis, and the final WCS dimension (first Numpy dimension) will be
        shown on the y-axis (and therefore the data will be plotted using
        ``data[:, :, 50].transpose()``)
    frame_class : type, optional
        The class for the frame, which should be a subclass of
        :class:`~astropy.visualization.wcsaxes.frame.BaseFrame`. The default is to use a
        :class:`~astropy.visualization.wcsaxes.frame.RectangularFrame`

    Attributes
    ----------
    coords : :class:`~astropy.visualization.wcsaxes.CoordinatesMap`
        Container for coordinate information.
    figslices_bboxesreset_wcs_hide_parent_artists_display_world_coords_display_coords_indexcanvasmpl_connectkey_press_event_set_cursor_prefs_wcsaxesartistadd_artist_drawn (pixel)coord_stringscoord_stringworld, overlay eventxaxisyaxisimshow
        Wrapper to Matplotlib's :meth:`~matplotlib.axes.Axes.imshow`.

        If an RGB image is passed as a PIL object, it will be flipped
        vertically and ``origin`` will be set to ``lower``, since WCS
        transformations - like FITS files - assume that the origin is the lower
        left pixel of the image (whereas RGB images have the origin in the top
        left).

        All arguments are passed to :meth:`~matplotlib.axes.Axes.imshow`.
        Cannot use images with origin='upper' in WCSAxes.getpixelFLIP_TOP_BOTTOM
        Plot contours.

        This is a custom implementation of :meth:`~matplotlib.axes.Axes.contour`
        which applies the transform (if specified) to all contours in one go for
        performance rather than to each contour line individually. All
        positional and keyword arguments are the same as for
        :meth:`~matplotlib.axes.Axes.contour`.
        csetcontourf
        Plot filled contours.

        This is a custom implementation of :meth:`~matplotlib.axes.Axes.contourf`
        which applies the transform (if specified) to all contours in one go for
        performance rather than to each contour line individually. All
        positional and keyword arguments are the same as for
        :meth:`~matplotlib.axes.Axes.contourf`.
        _transform_plot_args
        Apply transformations to arguments to ``plot_coord`` and
        ``scatter_coord``.
        frame0_transform_pixel2worldframe_outnative_frameplot_dataCoordinates cannot be plotted with this method because the WCS does not represent longitude/latitude."Coordinates cannot be plotted with this ""method because the WCS does not represent longitude/latitude."The 'transform' keyword argument is not allowed, as it is automatically determined by the input coordinate frame."The 'transform' keyword argument is not allowed,"" as it is automatically determined by the input coordinate frame."plot_coord
        Plot `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.plot_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.plot`. All other arguments are the same as
        `matplotlib.axes.Axes.plot`. If not specified a ``transform`` keyword
        argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to plot on the axes. This is converted to the
            first two arguments to `matplotlib.axes.Axes.plot`.

        See Also
        --------
        matplotlib.axes.Axes.plot :
            This method is called from this function with all arguments passed to it.

        plottext_coord
        Print a text string using `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.text_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.text`. All other arguments are the same as
        `matplotlib.axes.Axes.text`. If not specified a ``transform`` keyword
        argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to plot on the axes. This is converted to the
            first two arguments to `matplotlib.axes.Axes.text`.

        See Also
        --------
        matplotlib.axes.Axes.text :
            This method is called from this function with all arguments passed to it.

        scatter_coord
        Scatter `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.scatter_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.scatter`. All other arguments are the same as
        `matplotlib.axes.Axes.scatter`. If not specified a ``transform``
        keyword argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to scatter on the axes. This is converted to
            the first two arguments to `matplotlib.axes.Axes.scatter`.

        See Also
        --------
        matplotlib.axes.Axes.scatter : This method is called from this function with all arguments passed to it.
        scatter
        Reset the current Axes, to use a new WCS object.
        _pathget_colorget_linewidthprevious_framedefault_axislabel_positiondefault_ticklabel_positiondefault_ticks_positionbltraxes.grid_update_tick_and_label_positionskeep_coord_range
        This method will update the tick positions and will then optionally
        decide on which axes to show ticks/tick labels/axis labels on if in
        automatic mode.

        The ``keep_coord_range`` argument is used to indicate whether to keep
        coords._coord_range at the end of the method or whether to clean it
        up.
        axison_axis_bboxes_all_bboxesDraw the axes.get_axes_locatorapply_aspect_axisbelowset_zorder_update_patch_pathset_xlabelxlabellabelpadSet x-label.set_xlabel() missing 1 required positional argument: 'xlabel'set_ylabelylabelSet y-label.set_ylabel() missing 1 required positional argument: 'ylabel'get_xlabelget_ylabelget_coords_overlayGet coordinates overlay on given frame.

        Parameters
        ----------
        frame : str, `~astropy.coordinates.BaseCoordinateFrame`
            Frame to get overlay for. If a string must correspond to
            one of the coordinate frames registered in the astropy
            frame transform graph.

        coord_meta : dict
            Metadata for the coordinates overlay.

        Returns
        -------
        overlay : `~astropy.visualization.wcsaxes.CoordinatesMap`
            Coordinates overlay.
        _get_transform_no_transdataoverlay_coords
        Return a transform from the specified frame to display coordinates.

        This does not include the transData transformation

        Parameters
        ----------
        frame : :class:`~astropy.wcs.WCS` or :class:`~matplotlib.transforms.Transform` or str
            The ``frame`` parameter can have several possible types:
                * :class:`~astropy.wcs.WCS` instance: assumed to be a
                  transformation from pixel to world coordinates, where the
                  world coordinates are the same as those in the WCS
                  transformation used for this ``WCSAxes`` instance. This is
                  used for example to show contours, since this involves
                  plotting an array in pixel coordinates that are not the
                  final data coordinate and have to be transformed to the
                  common world coordinate system first.
                * :class:`~matplotlib.transforms.Transform` instance: it is
                  assumed to be a transform to the world coordinates that are
                  part of the WCS used to instantiate this ``WCSAxes``
                  instance.
                * ``'pixel'`` or ``'world'``: return a transformation that
                  allows users to plot in pixel/data coordinates (essentially
                  an identity transform) and ``world`` (the default
                  world-to-pixel transformation used to instantiate the
                  ``WCSAxes`` instance).
                * ``'fk5'`` or ``'galactic'``: return a transformation from
                  the specified frame to the pixel/data coordinates.
                * :class:`~astropy.coordinates.BaseCoordinateFrame` instance.
        
        Return a transform from data to the specified frame.
        transform_world2pixelframe_incoordinate_transformsame_framesget_tightbbox_bbox
        Plot gridlines for both coordinates.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments. This behaves like `matplotlib.axes.Axes`
        except that if no arguments are specified, the grid is shown rather
        than toggled.

        Parameters
        ----------
        b : bool
            Whether to show the gridlines.
        axis : 'both', 'x', 'y'
            Which axis to turn the gridlines on/off for.
        which : str
            Currently only ``'major'`` is supported.
        Plotting the grid for the minor ticks is not supported.axis should be one of x/y/both
        Method to set the tick and tick label parameters in the same way as the
        :meth:`~matplotlib.axes.Axes.tick_params` method in Matplotlib.

        This is provided for convenience, but the recommended API is to use
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks_position`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel_position`,
        and :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.grid`.

        Parameters
        ----------
        axis : int or str, optional
            Which axis to apply the parameters to. This defaults to 'both'
            but this can also be set to an `int` or `str` that refers to the
            axis to apply it to, following the valid values that can index
            ``ax.coords``. Note that ``'x'`` and ``'y``' are also accepted in
            the case of rectangular axes.
        which : {'both', 'major', 'minor'}, optional
            Which ticks to apply the settings to. By default, setting are
            applied to both major and minor ticks. Note that if ``'minor'`` is
            specified, only the length of the ticks can be set currently.
        direction : {'in', 'out'}, optional
            Puts ticks inside the axes, or outside the axes.
        length : float, optional
            Tick length in points.
        width : float, optional
            Tick width in points.
        color : color, optional
            Tick color (accepts any valid Matplotlib color)
        pad : float, optional
            Distance in points between tick and label.
        labelsize : float or str, optional
            Tick label font size in points or as a string (e.g., 'large').
        labelcolor : color, optional
            Tick label color (accepts any valid Matplotlib color)
        colors : color, optional
            Changes the tick color and the label color to the same value
             (accepts any valid Matplotlib color).
        bottom, top, left, right : bool, optional
            Where to draw the ticks. Note that this can only be given if a
            specific coordinate is specified via the ``axis`` argument, and it
            will not work correctly if the frame is not rectangular.
        labelbottom, labeltop, labelleft, labelright : bool, optional
            Where to draw the tick labels. Note that this can only be given if a
            specific coordinate is specified via the ``axis`` argument, and it
            will not work correctly if the frame is not rectangular.
        grid_color : color, optional
            The color of the grid lines (accepts any valid Matplotlib color).
        grid_alpha : float, optional
            Transparency of grid lines: 0 (transparent) to 1 (opaque).
        grid_linewidth : float, optional
            Width of grid lines in points.
        grid_linestyle : str, optional
            The style of the grid lines (accepts any valid Matplotlib line
            style).
        Cannot specify = when axis='both'Cannot specify label
    A subclass class for WCSAxes.
    # User wants to override the transform for the final# data->pixel mapping# Turn off spines and current axes# We now overload ``imshow`` because we need to make sure that origin is# set to ``lower`` for all images, which means that we need to flip RGB# images.# plt.imshow passes origin as None, which we should default to lower.# In Matplotlib, when calling contour() with a transform, each# individual path in the contour map is transformed separately. However,# this is much too slow for us since each call to the transforms results# in an Astropy coordinate transformation, which has a non-negligible# overhead - therefore a better approach is to override contour(), call# the Matplotlib one with no transform, then apply the transform in one# go to all the segments that make up the contour map.# The transform passed to self.contour will normally include# a transData component at the end, but we can remove that since# we are already working in data space.# See notes for contour above.# Extract the frame from the first argument.# Transform to the native frame of the plot# Here determine all the coordinate axes that should be shown.# We now force call 'set', which ensures the WCS object is# consistent, which will only be important if the WCS has been set# by hand. For example if the user sets a celestial WCS by hand and# forgets to set the units, WCS.wcs.set() will do this.# Check if the WCS object is an instance of `astropy.wcs.WCS`# This check is necessary as only `astropy.wcs.WCS` supports# wcs.set() method# If we are making a new WCS, we need to preserve the path object since# it may already be used by objects that have been plotted, and we need# to continue updating it. CoordinatesMap will create a new frame# instance, but we can tell that instance to keep using the old path.# Common default settings for Rectangular Frame# Start off by updating the frame, pre-computing the coordinate range# in the figure, and updating the tick positions.# At this point, if any of the tick/ticklabel/axislabel positions are# set to be automatic, we need to determine the optimal positions.# Here need to find out range of all coordinates, and update range for# each coordinate axis. For now, just assume it covers the whole sky.# This generates a structure like [coords][axis] = [...]# Delete the computation to protect from accidental use of a stale range# Draw tick labels# Save ticklabel bboxes# Draw axis labels# Before we do any drawing, we need to remove any existing grid lines# drawn with contours, otherwise if we try and remove the contours# part way through drawing, we end up with the issue mentioned in# https://github.com/astropy/astropy/issues/12446# In Axes.draw, the following code can result in the xlim and ylim# values changing, so we need to force call this here to make sure that# the limits are correct before we update the patch.# 'line': above patches, below lines# We need to make sure that that frame path is up to date# Matplotlib internally sometimes calls set_xlabel(label=...).# Here we can't use get_transform because that deals with# pixel-to-pixel transformations when passing a WCS object.# Common settings for overlay# FIXME: we should determine what to do with the extra arguments here.# Note that the expected signature of this method is different in# Matplotlib 3.x compared to 2.x, but we only support 3.x now.# Do a draw to populate the self._bboxes list# Axes haven't been fully initialized yet, so just ignore, as# Axes.__init__ calls this method# In the following, we put the generated subplot class in a temporary class and# we then inherit it - if we don't do this, the generated class appears to# belong in matplotlib, not in WCSAxes, from the API's point of view.b'WCSAxes'u'WCSAxes'b'WCSAxesSubplot'u'WCSAxesSubplot'b'This is a dummy artist to enforce the correct z-order of axis ticks,
    tick labels, and gridlines.

    FIXME: This is a bit of a hack. ``Axes.draw`` sorts the artists by zorder
    and then renders them in sequence. For normal Matplotlib axes, the ticks,
    tick labels, and gridlines are included in this list of artists and hence
    are automatically drawn in the correct order. However, ``WCSAxes`` disables
    the native ticks, labels, and gridlines. Instead, ``WCSAxes.draw`` renders
    ersatz ticks, labels, and gridlines by explicitly calling the functions
    ``CoordinateHelper._draw_ticks``, ``CoordinateHelper._draw_grid``, etc.
    This hack would not be necessary if ``WCSAxes`` drew ticks, tick labels,
    and gridlines in the standary way.
    'u'This is a dummy artist to enforce the correct z-order of axis ticks,
    tick labels, and gridlines.

    FIXME: This is a bit of a hack. ``Axes.draw`` sorts the artists by zorder
    and then renders them in sequence. For normal Matplotlib axes, the ticks,
    tick labels, and gridlines are included in this list of artists and hence
    are automatically drawn in the correct order. However, ``WCSAxes`` disables
    the native ticks, labels, and gridlines. Instead, ``WCSAxes.draw`` renders
    ersatz ticks, labels, and gridlines by explicitly calling the functions
    ``CoordinateHelper._draw_ticks``, ``CoordinateHelper._draw_grid``, etc.
    This hack would not be necessary if ``WCSAxes`` drew ticks, tick labels,
    and gridlines in the standary way.
    'b'
    The main axes class that can be used to show world coordinates from a WCS.

    Parameters
    ----------
    fig : `~matplotlib.figure.Figure`
        The figure to add the axes to
    *args
        ``*args`` can be a single ``(left, bottom, width, height)``
        rectangle or a single `matplotlib.transforms.Bbox`.  This specifies
        the rectangle (in figure coordinates) where the Axes is positioned.
        ``*args`` can also consist of three numbers or a single three-digit
        number; in the latter case, the digits are considered as
        independent numbers.  The numbers are interpreted as ``(nrows,
        ncols, index)``: ``(nrows, ncols)`` specifies the size of an array
        of subplots, and ``index`` is the 1-based index of the subplot
        being created.  Finally, ``*args`` can also directly be a
        `matplotlib.gridspec.SubplotSpec` instance.
    wcs : :class:`~astropy.wcs.WCS`, optional
        The WCS for the data. If this is specified, ``transform`` cannot be
        specified.
    transform : `~matplotlib.transforms.Transform`, optional
        The transform for the data. If this is specified, ``wcs`` cannot be
        specified.
    coord_meta : dict, optional
        A dictionary providing additional metadata when ``transform`` is
        specified. This should include the keys ``type``, ``wrap``, and
        ``unit``. Each of these should be a list with as many items as the
        dimension of the WCS. The ``type`` entries should be one of
        ``longitude``, ``latitude``, or ``scalar``, the ``wrap`` entries should
        give, for the longitude, the angle at which the coordinate wraps (and
        `None` otherwise), and the ``unit`` should give the unit of the
        coordinates as :class:`~astropy.units.Unit` instances. This can
        optionally also include a ``format_unit`` entry giving the units to use
        for the tick labels (if not specified, this defaults to ``unit``).
    transData : `~matplotlib.transforms.Transform`, optional
        Can be used to override the default data -> pixel mapping.
    slices : tuple, optional
        For WCS transformations with more than two dimensions, we need to
        choose which dimensions are being shown in the 2D image. The slice
        should contain one ``x`` entry, one ``y`` entry, and the rest of the
        values should be integers indicating the slice through the data. The
        order of the items in the slice should be the same as the order of the
        dimensions in the :class:`~astropy.wcs.WCS`, and the opposite of the
        order of the dimensions in Numpy. For example, ``(50, 'x', 'y')`` means
        that the first WCS dimension (last Numpy dimension) will be sliced at
        an index of 50, the second WCS and Numpy dimension will be shown on the
        x axis, and the final WCS dimension (first Numpy dimension) will be
        shown on the y-axis (and therefore the data will be plotted using
        ``data[:, :, 50].transpose()``)
    frame_class : type, optional
        The class for the frame, which should be a subclass of
        :class:`~astropy.visualization.wcsaxes.frame.BaseFrame`. The default is to use a
        :class:`~astropy.visualization.wcsaxes.frame.RectangularFrame`

    Attributes
    ----------
    coords : :class:`~astropy.visualization.wcsaxes.CoordinatesMap`
        Container for coordinate information.
    'u'
    The main axes class that can be used to show world coordinates from a WCS.

    Parameters
    ----------
    fig : `~matplotlib.figure.Figure`
        The figure to add the axes to
    *args
        ``*args`` can be a single ``(left, bottom, width, height)``
        rectangle or a single `matplotlib.transforms.Bbox`.  This specifies
        the rectangle (in figure coordinates) where the Axes is positioned.
        ``*args`` can also consist of three numbers or a single three-digit
        number; in the latter case, the digits are considered as
        independent numbers.  The numbers are interpreted as ``(nrows,
        ncols, index)``: ``(nrows, ncols)`` specifies the size of an array
        of subplots, and ``index`` is the 1-based index of the subplot
        being created.  Finally, ``*args`` can also directly be a
        `matplotlib.gridspec.SubplotSpec` instance.
    wcs : :class:`~astropy.wcs.WCS`, optional
        The WCS for the data. If this is specified, ``transform`` cannot be
        specified.
    transform : `~matplotlib.transforms.Transform`, optional
        The transform for the data. If this is specified, ``wcs`` cannot be
        specified.
    coord_meta : dict, optional
        A dictionary providing additional metadata when ``transform`` is
        specified. This should include the keys ``type``, ``wrap``, and
        ``unit``. Each of these should be a list with as many items as the
        dimension of the WCS. The ``type`` entries should be one of
        ``longitude``, ``latitude``, or ``scalar``, the ``wrap`` entries should
        give, for the longitude, the angle at which the coordinate wraps (and
        `None` otherwise), and the ``unit`` should give the unit of the
        coordinates as :class:`~astropy.units.Unit` instances. This can
        optionally also include a ``format_unit`` entry giving the units to use
        for the tick labels (if not specified, this defaults to ``unit``).
    transData : `~matplotlib.transforms.Transform`, optional
        Can be used to override the default data -> pixel mapping.
    slices : tuple, optional
        For WCS transformations with more than two dimensions, we need to
        choose which dimensions are being shown in the 2D image. The slice
        should contain one ``x`` entry, one ``y`` entry, and the rest of the
        values should be integers indicating the slice through the data. The
        order of the items in the slice should be the same as the order of the
        dimensions in the :class:`~astropy.wcs.WCS`, and the opposite of the
        order of the dimensions in Numpy. For example, ``(50, 'x', 'y')`` means
        that the first WCS dimension (last Numpy dimension) will be sliced at
        an index of 50, the second WCS and Numpy dimension will be shown on the
        x axis, and the final WCS dimension (first Numpy dimension) will be
        shown on the y-axis (and therefore the data will be plotted using
        ``data[:, :, 50].transpose()``)
    frame_class : type, optional
        The class for the frame, which should be a subclass of
        :class:`~astropy.visualization.wcsaxes.frame.BaseFrame`. The default is to use a
        :class:`~astropy.visualization.wcsaxes.frame.RectangularFrame`

    Attributes
    ----------
    coords : :class:`~astropy.visualization.wcsaxes.CoordinatesMap`
        Container for coordinate information.
    'b'key_press_event'u'key_press_event'b' (pixel)'u' (pixel)'b'world, overlay 'u'world, overlay 'b'
        Wrapper to Matplotlib's :meth:`~matplotlib.axes.Axes.imshow`.

        If an RGB image is passed as a PIL object, it will be flipped
        vertically and ``origin`` will be set to ``lower``, since WCS
        transformations - like FITS files - assume that the origin is the lower
        left pixel of the image (whereas RGB images have the origin in the top
        left).

        All arguments are passed to :meth:`~matplotlib.axes.Axes.imshow`.
        'u'
        Wrapper to Matplotlib's :meth:`~matplotlib.axes.Axes.imshow`.

        If an RGB image is passed as a PIL object, it will be flipped
        vertically and ``origin`` will be set to ``lower``, since WCS
        transformations - like FITS files - assume that the origin is the lower
        left pixel of the image (whereas RGB images have the origin in the top
        left).

        All arguments are passed to :meth:`~matplotlib.axes.Axes.imshow`.
        'b'origin'u'origin'b'Cannot use images with origin='upper' in WCSAxes.'u'Cannot use images with origin='upper' in WCSAxes.'b'getpixel'u'getpixel'b'
        Plot contours.

        This is a custom implementation of :meth:`~matplotlib.axes.Axes.contour`
        which applies the transform (if specified) to all contours in one go for
        performance rather than to each contour line individually. All
        positional and keyword arguments are the same as for
        :meth:`~matplotlib.axes.Axes.contour`.
        'u'
        Plot contours.

        This is a custom implementation of :meth:`~matplotlib.axes.Axes.contour`
        which applies the transform (if specified) to all contours in one go for
        performance rather than to each contour line individually. All
        positional and keyword arguments are the same as for
        :meth:`~matplotlib.axes.Axes.contour`.
        'b'
        Plot filled contours.

        This is a custom implementation of :meth:`~matplotlib.axes.Axes.contourf`
        which applies the transform (if specified) to all contours in one go for
        performance rather than to each contour line individually. All
        positional and keyword arguments are the same as for
        :meth:`~matplotlib.axes.Axes.contourf`.
        'u'
        Plot filled contours.

        This is a custom implementation of :meth:`~matplotlib.axes.Axes.contourf`
        which applies the transform (if specified) to all contours in one go for
        performance rather than to each contour line individually. All
        positional and keyword arguments are the same as for
        :meth:`~matplotlib.axes.Axes.contourf`.
        'b'
        Apply transformations to arguments to ``plot_coord`` and
        ``scatter_coord``.
        'u'
        Apply transformations to arguments to ``plot_coord`` and
        ``scatter_coord``.
        'b'Coordinates cannot be plotted with this method because the WCS does not represent longitude/latitude.'u'Coordinates cannot be plotted with this method because the WCS does not represent longitude/latitude.'b'The 'transform' keyword argument is not allowed, as it is automatically determined by the input coordinate frame.'u'The 'transform' keyword argument is not allowed, as it is automatically determined by the input coordinate frame.'b'
        Plot `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.plot_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.plot`. All other arguments are the same as
        `matplotlib.axes.Axes.plot`. If not specified a ``transform`` keyword
        argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to plot on the axes. This is converted to the
            first two arguments to `matplotlib.axes.Axes.plot`.

        See Also
        --------
        matplotlib.axes.Axes.plot :
            This method is called from this function with all arguments passed to it.

        'u'
        Plot `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.plot_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.plot`. All other arguments are the same as
        `matplotlib.axes.Axes.plot`. If not specified a ``transform`` keyword
        argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to plot on the axes. This is converted to the
            first two arguments to `matplotlib.axes.Axes.plot`.

        See Also
        --------
        matplotlib.axes.Axes.plot :
            This method is called from this function with all arguments passed to it.

        'b'
        Print a text string using `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.text_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.text`. All other arguments are the same as
        `matplotlib.axes.Axes.text`. If not specified a ``transform`` keyword
        argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to plot on the axes. This is converted to the
            first two arguments to `matplotlib.axes.Axes.text`.

        See Also
        --------
        matplotlib.axes.Axes.text :
            This method is called from this function with all arguments passed to it.

        'u'
        Print a text string using `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.text_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.text`. All other arguments are the same as
        `matplotlib.axes.Axes.text`. If not specified a ``transform`` keyword
        argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to plot on the axes. This is converted to the
            first two arguments to `matplotlib.axes.Axes.text`.

        See Also
        --------
        matplotlib.axes.Axes.text :
            This method is called from this function with all arguments passed to it.

        'b'
        Scatter `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.scatter_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.scatter`. All other arguments are the same as
        `matplotlib.axes.Axes.scatter`. If not specified a ``transform``
        keyword argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to scatter on the axes. This is converted to
            the first two arguments to `matplotlib.axes.Axes.scatter`.

        See Also
        --------
        matplotlib.axes.Axes.scatter : This method is called from this function with all arguments passed to it.
        'u'
        Scatter `~astropy.coordinates.SkyCoord` or
        `~astropy.coordinates.BaseCoordinateFrame` objects onto the axes.

        The first argument to
        :meth:`~astropy.visualization.wcsaxes.WCSAxes.scatter_coord` should be a
        coordinate, which will then be converted to the first two parameters to
        `matplotlib.axes.Axes.scatter`. All other arguments are the same as
        `matplotlib.axes.Axes.scatter`. If not specified a ``transform``
        keyword argument will be created based on the coordinate.

        Parameters
        ----------
        coordinate : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`
            The coordinate object to scatter on the axes. This is converted to
            the first two arguments to `matplotlib.axes.Axes.scatter`.

        See Also
        --------
        matplotlib.axes.Axes.scatter : This method is called from this function with all arguments passed to it.
        'b'
        Reset the current Axes, to use a new WCS object.
        'u'
        Reset the current Axes, to use a new WCS object.
        'b'coords'u'coords'b'path'u'path'b'default_axislabel_position'u'default_axislabel_position'b'default_ticklabel_position'u'default_ticklabel_position'b'default_ticks_position'u'default_ticks_position'b'bltr'u'bltr'b'axes.grid'u'axes.grid'b'
        This method will update the tick positions and will then optionally
        decide on which axes to show ticks/tick labels/axis labels on if in
        automatic mode.

        The ``keep_coord_range`` argument is used to indicate whether to keep
        coords._coord_range at the end of the method or whether to clean it
        up.
        'u'
        This method will update the tick positions and will then optionally
        decide on which axes to show ticks/tick labels/axis labels on if in
        automatic mode.

        The ``keep_coord_range`` argument is used to indicate whether to keep
        coords._coord_range at the end of the method or whether to clean it
        up.
        'b'Draw the axes.'u'Draw the axes.'b'Set x-label.'u'Set x-label.'b'set_xlabel() missing 1 required positional argument: 'xlabel''u'set_xlabel() missing 1 required positional argument: 'xlabel''b'Set y-label.'u'Set y-label.'b'set_ylabel() missing 1 required positional argument: 'ylabel''u'set_ylabel() missing 1 required positional argument: 'ylabel''b'Get coordinates overlay on given frame.

        Parameters
        ----------
        frame : str, `~astropy.coordinates.BaseCoordinateFrame`
            Frame to get overlay for. If a string must correspond to
            one of the coordinate frames registered in the astropy
            frame transform graph.

        coord_meta : dict
            Metadata for the coordinates overlay.

        Returns
        -------
        overlay : `~astropy.visualization.wcsaxes.CoordinatesMap`
            Coordinates overlay.
        'u'Get coordinates overlay on given frame.

        Parameters
        ----------
        frame : str, `~astropy.coordinates.BaseCoordinateFrame`
            Frame to get overlay for. If a string must correspond to
            one of the coordinate frames registered in the astropy
            frame transform graph.

        coord_meta : dict
            Metadata for the coordinates overlay.

        Returns
        -------
        overlay : `~astropy.visualization.wcsaxes.CoordinatesMap`
            Coordinates overlay.
        'b'
        Return a transform from the specified frame to display coordinates.

        This does not include the transData transformation

        Parameters
        ----------
        frame : :class:`~astropy.wcs.WCS` or :class:`~matplotlib.transforms.Transform` or str
            The ``frame`` parameter can have several possible types:
                * :class:`~astropy.wcs.WCS` instance: assumed to be a
                  transformation from pixel to world coordinates, where the
                  world coordinates are the same as those in the WCS
                  transformation used for this ``WCSAxes`` instance. This is
                  used for example to show contours, since this involves
                  plotting an array in pixel coordinates that are not the
                  final data coordinate and have to be transformed to the
                  common world coordinate system first.
                * :class:`~matplotlib.transforms.Transform` instance: it is
                  assumed to be a transform to the world coordinates that are
                  part of the WCS used to instantiate this ``WCSAxes``
                  instance.
                * ``'pixel'`` or ``'world'``: return a transformation that
                  allows users to plot in pixel/data coordinates (essentially
                  an identity transform) and ``world`` (the default
                  world-to-pixel transformation used to instantiate the
                  ``WCSAxes`` instance).
                * ``'fk5'`` or ``'galactic'``: return a transformation from
                  the specified frame to the pixel/data coordinates.
                * :class:`~astropy.coordinates.BaseCoordinateFrame` instance.
        'u'
        Return a transform from the specified frame to display coordinates.

        This does not include the transData transformation

        Parameters
        ----------
        frame : :class:`~astropy.wcs.WCS` or :class:`~matplotlib.transforms.Transform` or str
            The ``frame`` parameter can have several possible types:
                * :class:`~astropy.wcs.WCS` instance: assumed to be a
                  transformation from pixel to world coordinates, where the
                  world coordinates are the same as those in the WCS
                  transformation used for this ``WCSAxes`` instance. This is
                  used for example to show contours, since this involves
                  plotting an array in pixel coordinates that are not the
                  final data coordinate and have to be transformed to the
                  common world coordinate system first.
                * :class:`~matplotlib.transforms.Transform` instance: it is
                  assumed to be a transform to the world coordinates that are
                  part of the WCS used to instantiate this ``WCSAxes``
                  instance.
                * ``'pixel'`` or ``'world'``: return a transformation that
                  allows users to plot in pixel/data coordinates (essentially
                  an identity transform) and ``world`` (the default
                  world-to-pixel transformation used to instantiate the
                  ``WCSAxes`` instance).
                * ``'fk5'`` or ``'galactic'``: return a transformation from
                  the specified frame to the pixel/data coordinates.
                * :class:`~astropy.coordinates.BaseCoordinateFrame` instance.
        'b'
        Return a transform from data to the specified frame.
        'u'
        Return a transform from data to the specified frame.
        'b'
        Plot gridlines for both coordinates.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments. This behaves like `matplotlib.axes.Axes`
        except that if no arguments are specified, the grid is shown rather
        than toggled.

        Parameters
        ----------
        b : bool
            Whether to show the gridlines.
        axis : 'both', 'x', 'y'
            Which axis to turn the gridlines on/off for.
        which : str
            Currently only ``'major'`` is supported.
        'u'
        Plot gridlines for both coordinates.

        Standard matplotlib appearance options (color, alpha, etc.) can be
        passed as keyword arguments. This behaves like `matplotlib.axes.Axes`
        except that if no arguments are specified, the grid is shown rather
        than toggled.

        Parameters
        ----------
        b : bool
            Whether to show the gridlines.
        axis : 'both', 'x', 'y'
            Which axis to turn the gridlines on/off for.
        which : str
            Currently only ``'major'`` is supported.
        'b'Plotting the grid for the minor ticks is not supported.'u'Plotting the grid for the minor ticks is not supported.'b'axis should be one of x/y/both'u'axis should be one of x/y/both'b'
        Method to set the tick and tick label parameters in the same way as the
        :meth:`~matplotlib.axes.Axes.tick_params` method in Matplotlib.

        This is provided for convenience, but the recommended API is to use
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks_position`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel_position`,
        and :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.grid`.

        Parameters
        ----------
        axis : int or str, optional
            Which axis to apply the parameters to. This defaults to 'both'
            but this can also be set to an `int` or `str` that refers to the
            axis to apply it to, following the valid values that can index
            ``ax.coords``. Note that ``'x'`` and ``'y``' are also accepted in
            the case of rectangular axes.
        which : {'both', 'major', 'minor'}, optional
            Which ticks to apply the settings to. By default, setting are
            applied to both major and minor ticks. Note that if ``'minor'`` is
            specified, only the length of the ticks can be set currently.
        direction : {'in', 'out'}, optional
            Puts ticks inside the axes, or outside the axes.
        length : float, optional
            Tick length in points.
        width : float, optional
            Tick width in points.
        color : color, optional
            Tick color (accepts any valid Matplotlib color)
        pad : float, optional
            Distance in points between tick and label.
        labelsize : float or str, optional
            Tick label font size in points or as a string (e.g., 'large').
        labelcolor : color, optional
            Tick label color (accepts any valid Matplotlib color)
        colors : color, optional
            Changes the tick color and the label color to the same value
             (accepts any valid Matplotlib color).
        bottom, top, left, right : bool, optional
            Where to draw the ticks. Note that this can only be given if a
            specific coordinate is specified via the ``axis`` argument, and it
            will not work correctly if the frame is not rectangular.
        labelbottom, labeltop, labelleft, labelright : bool, optional
            Where to draw the tick labels. Note that this can only be given if a
            specific coordinate is specified via the ``axis`` argument, and it
            will not work correctly if the frame is not rectangular.
        grid_color : color, optional
            The color of the grid lines (accepts any valid Matplotlib color).
        grid_alpha : float, optional
            Transparency of grid lines: 0 (transparent) to 1 (opaque).
        grid_linewidth : float, optional
            Width of grid lines in points.
        grid_linestyle : str, optional
            The style of the grid lines (accepts any valid Matplotlib line
            style).
        'u'
        Method to set the tick and tick label parameters in the same way as the
        :meth:`~matplotlib.axes.Axes.tick_params` method in Matplotlib.

        This is provided for convenience, but the recommended API is to use
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticks_position`,
        :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.set_ticklabel_position`,
        and :meth:`~astropy.visualization.wcsaxes.CoordinateHelper.grid`.

        Parameters
        ----------
        axis : int or str, optional
            Which axis to apply the parameters to. This defaults to 'both'
            but this can also be set to an `int` or `str` that refers to the
            axis to apply it to, following the valid values that can index
            ``ax.coords``. Note that ``'x'`` and ``'y``' are also accepted in
            the case of rectangular axes.
        which : {'both', 'major', 'minor'}, optional
            Which ticks to apply the settings to. By default, setting are
            applied to both major and minor ticks. Note that if ``'minor'`` is
            specified, only the length of the ticks can be set currently.
        direction : {'in', 'out'}, optional
            Puts ticks inside the axes, or outside the axes.
        length : float, optional
            Tick length in points.
        width : float, optional
            Tick width in points.
        color : color, optional
            Tick color (accepts any valid Matplotlib color)
        pad : float, optional
            Distance in points between tick and label.
        labelsize : float or str, optional
            Tick label font size in points or as a string (e.g., 'large').
        labelcolor : color, optional
            Tick label color (accepts any valid Matplotlib color)
        colors : color, optional
            Changes the tick color and the label color to the same value
             (accepts any valid Matplotlib color).
        bottom, top, left, right : bool, optional
            Where to draw the ticks. Note that this can only be given if a
            specific coordinate is specified via the ``axis`` argument, and it
            will not work correctly if the frame is not rectangular.
        labelbottom, labeltop, labelleft, labelright : bool, optional
            Where to draw the tick labels. Note that this can only be given if a
            specific coordinate is specified via the ``axis`` argument, and it
            will not work correctly if the frame is not rectangular.
        grid_color : color, optional
            The color of the grid lines (accepts any valid Matplotlib color).
        grid_alpha : float, optional
            Transparency of grid lines: 0 (transparent) to 1 (opaque).
        grid_linewidth : float, optional
            Width of grid lines in points.
        grid_linestyle : str, optional
            The style of the grid lines (accepts any valid Matplotlib line
            style).
        'b'Cannot specify 'u'Cannot specify 'b'= when axis='both''u'= when axis='both''b'Cannot specify label'u'Cannot specify label'b'
    A subclass class for WCSAxes.
    'u'
    A subclass class for WCSAxes.
    'u'astropy.visualization.wcsaxes.core'u'visualization.wcsaxes.core'u'wcsaxes.core'An extensible ASCII table reader and writer.

core.py:
  Core base classes and functions for reading and writing tables.

:Copyright: Smithsonian Astrophysical Observatory (2010)
:Author: Tom Aldcroft (aldcroft@head.cfa.harvard.edu)
get_readable_fileobjREAD_DOCSTRINGWRITE_DOCSTRINGSupportsFloatTypeGuardMetaBaseReaderFAST_CLASSES_check_multidim_tablemax_ndimCheck that ``table`` has only columns with ndim <= ``max_ndim``.

    Currently ECSV is the only built-in format that supports output of arbitrary
    N-d columns, but HTML supports 2-d.
    nd_namescolumn(s) with dimension >  cannot be be written with this format, try using 'ecsv' (Enhanced CSV) format"cannot be be written with this format, try using 'ecsv' ""(Enhanced CSV) format"CsvWriter
    Internal class to replace the csv writer ``writerow`` and ``writerows``
    functions so that in the case of ``delimiter=' '`` and
    ``quoting=csv.QUOTE_MINIMAL``, the output field value is quoted for empty
    fields (when value == '').

    This changes the API slightly in that the writerow() and writerows()
    methods return the output written string instead of the length of
    that string.

    Examples
    --------
    >>> from astropy.io.ascii.core import CsvWriter
    >>> writer = CsvWriter(delimiter=' ')
    >>> print(writer.writerow(['hello', '', 'world']))
    hello "" world
    2b=48Av%0-V3p>bXreplace_sentinelcsvfiletemp_outdialectquotecharquotechar2quotingQUOTE_MINIMALquote_emptywriterow
        Similar to csv.writer.writerow but with the custom quoting behavior.
        Returns the written string instead of the length of that string.
        has_empty_writerowwriterowsvalues_list
        Similar to csv.writer.writerows but with the custom quoting behavior.
        Returns the written string instead of the length of that string.
        writerow_func
        Call ``writerow_func`` (either writerow or writerows) with ``values``.
        If it has empty fields that have been replaced then change those
        sentinel strings back to quoted empty strings, e.g. ``""``.
        getvaluerow_stringMaskedConstantA trivial extension of numpy.ma.masked.

    We want to be able to put the generic term ``masked`` into a dictionary.
    The constant ``numpy.ma.masked`` is not hashable (see
    https://github.com/numpy/numpy/issues/4660), so we need to extend it
    here with a hash value.

    See https://github.com/numpy/numpy/issues/11021 for rationale for
    __copy__ and __deepcopy__ methods.
    All instances of this class shall have the same hash.1234567890This is a singleton so just return self.
    Indicates that an input table is inconsistent in some way.

    The default behavior of ``BaseReader`` is to throw an instance of
    this class if a data row doesn't match the header.
    OptionalTableImportError
    Indicates that a dependency for table reading is not present.

    An instance of this class is raised whenever an optional reader
    with certain required dependencies cannot operate because of
    an ImportError.
    
    Indicates that a reader cannot handle a passed parameter.

    The C-based fast readers in ``io.ascii`` raise an instance of
    this error class upon encountering a parameter that the
    C engine cannot handle.
    FastOptionsError
    Indicates that one of the specified options for fast
    reading is invalid.
    
    Superclass for ``StrType`` and ``NumType`` classes.

    This class is the default type of ``Column`` and provides a base
    class for other data types.
    
    Indicates that a column consists of text data.
    
    Indicates that a column consists of numerical data.
    
    Describes floating-point data.
    BoolType
    Describes boolean data.
    
    Describes integer data.
    
    Subclass of all other data types.

    This type is returned by ``convert_numpy`` if the given numpy
    type does not match ``StrType``, ``FloatType``, or ``IntType``.
    Table column.

    The key attributes of a Column object are:

    * **name** : column name
    * **type** : column type (NoType, StrType, NumType, FloatType, IntType)
    * **dtype** : numpy dtype (optional, overrides **type** if set)
    * **str_vals** : list of column values as strings
    * **fill_values** : dict of fill values
    * **shape** : list of element shape (default [] => scalar)
    * **data** : list of converted column values
    * **subtype** : actual datatype for columns serialized with JSON
    subtype
    Get the lines from the table input and return a list of lines.

    Encoding used to read the fileGet the lines from the ``table`` input.

        The input table can be one of:

        * File name (str or pathlike)
        * String (newline separated) with all header and data lines (must have at least 2 lines)
        * File-like object with read() method
        * List of strings

        Parameters
        ----------
        table : str, file-like, list
            Can be either a file name, string (newline separated) with all header and data
            lines (must have at least 2 lines), a file-like object with a
            ``read()`` method, or a list of strings.
        newline :
            Line separator. If `None` use OS default from ``splitlines()``.

        Returns
        -------
        lines : list
            List of lines
        Input "table" must be a string (filename or data) or an iterableProcess lines for subsequent use.  In the default case do nothing.
        This routine is not generally intended for removing comment lines or
        stripping whitespace.  These are done (if needed) in the header and
        data line processing.

        Override this method if something more has to be done to convert raw
        input lines to the table rows.  For example the
        ContinuationLinesInputter derived class accounts for continuation
        characters if a row is split into lines.
        
    Base splitter that uses python's split method to do the work.

    This does not handle quoted values.  A key feature is the formulation of
    __call__ as a generator that returns a list of the split line values at
    each iteration.

    There are two methods that are intended to be overridden, first
    ``process_line()`` to do pre-processing on each input line before splitting
    and ``process_val()`` to do post-processing on each split string value.  By
    default these apply the string ``strip()`` function.  These can be set to
    another function via the instance attribute or be disabled entirely, for
    example::

      reader.header.splitter.process_val = lambda x: x.lstrip()
      reader.data.splitter.process_val = None

     one-character string used to separate fields Remove whitespace at the beginning or end of line.  This is especially useful for
        whitespace-delimited files to prevent spurious columns at the beginning or end.
        Remove whitespace at the beginning or end of value.valsDefault class to split strings into columns using python csv.  The class
    attributes are taken from the csv Dialect class.

    Typical usage::

      # lines = ..
      splitter = ascii.DefaultSplitter()
      for col_vals in splitter(lines):
          for col_val in col_vals:
               ...

     one-character string used to separate fields.  control how instances of *quotechar* in a field are quoted doublequote character to remove special meaning from following character escapechar one-character stringto quote fields containing special characters  control when quotes are recognized by the reader  ignore whitespace immediately following the delimiter csv_writercsv_writer_outRemove whitespace at the beginning or end of line.  This is especially useful for
        whitespace-delimited files to prevent spurious columns at the beginning or end.
        If splitting on whitespace then replace unquoted tabs with space first.
        _replace_tab_with_space 	Return an iterator over the table ``lines``, where each iterator output
        is a list of the split line values.

        Parameters
        ----------
        lines : list
            List of table lines

        Yields
        ------
        line : list of str
            Each line's split values.

        csv_readerReplace tabs with spaces in given string, preserving quoted substrings.

    Parameters
    ----------
    line : str
        String containing tabs to be replaced with spaces.
    escapechar : str
        Character in ``line`` used to escape special characters.
    quotechar : str
        Character in ``line`` indicating the start/end of a substring.

    Returns
    -------
    line : str
        A copy of ``line`` with tabs replaced by spaces, preserving quoted substrings.
    in_quotelastchar_get_line_indexline_or_funcReturn the appropriate line index, depending on ``line_or_func`` which
    can be either a function, a positive or negative int, or None.
    n_lines
    Base table header reader.
    col{}auto_format format string for auto-generating column names  None, int, or a function of ``lines`` that returns None or int  regular expression for comment lines  Splitter class for splitting data lines into columns  list of names corresponding to each data column ASCII_TABLE_WRITE_SPACER_LINEwrite_spacer_linesupdate_meta
        Extract any table-level metadata, e.g. keywords, comments, column metadata, from
        the table ``lines`` and update the OrderedDict ``meta`` in place.  This base
        method extracts comment lines and stores them in ``meta`` for output.
        Initialize the header Column objects from the table ``lines``.

        Based on the previously set Header attributes find or create the column names.
        Sets ``self.cols`` with the list of Columns.

        Parameters
        ----------
        lines : list
            List of table lines

        get_str_valsfirst_data_valsNo data lines found so cannot autogenerate column namesn_data_colsNo header line found in tableGenerator to yield non-blank and non-comment lines.spacer_linecycleReturn the column names of the table.remove_columns
        Remove several columns from the table.

        Parameters
        ----------
        names : list
            A list containing the names of the columns to remove
         does not existrename_column
        Rename a column.

        Parameters
        ----------
        name : str
            The current name of the column.
        new_name : str
            The new name for the column
        got column type  instead of required type_map_keyUnknown data type """" for column "check_column_namesstrict_namesguessing
        Check column names.

        This must be done before applying the names transformation
        so that guessing will fail appropriately if ``names`` is supplied.
        For instance if the basic reader is given a table with no column header
        row.

        Parameters
        ----------
        names : list
            User-supplied list of column names
        strict_names : bool
            Whether to impose extra requirements on names
        guessing : bool
            True if this method is being called while guessing the table format
        bads_is_numberColumn name  does not meet strict name requirementsEcsvHeaderTable format guessing requires at least two columns, got "Table format guessing requires at least two columns, ""got "Length of names argument () does not match number of table columns (") does not match number ""of table columns ("
    Base table data reader.
    end_line Regular expression for comment lines fill_include_namesfill_exclude_names
        READ: Strip out comment lines and blank lines from list of ``lines``.

        Parameters
        ----------
        lines : list
            All lines in table

        Returns
        -------
        lines : list
            List of lines

        nonblank_linesget_data_lines
        READ: Set ``data_lines`` attribute to lines slice comprising table data values.
        Return a generator that returns a list of column values (as strings)
        for each data line.
        READ: Set fill value for each column and then apply that fill value.

        In the first step it is evaluated with value from ``fill_values`` applies to
        which column using ``fill_include_names`` and ``fill_exclude_names``.
        In the second step all replacements are done for the appropriate columns.
        _set_fill_values_set_masksREAD, WRITE: Set fill values of individual cols based on fill_values of BaseData.

        fill values has the following form:
        <fill_spec> = (<bad_value>, <fill_value>, <optional col_name>...)
        fill_values = <fill_spec> or list of <fill_spec>'s

        Format of fill_values must be (<bad>, <fill>, <optional col1>, ...)"Format of fill_values must be ""(<bad>, <fill>, <optional col1>, ...)"affect_colsREAD: Replace string values in col.str_vals and set masks.str_val_replace_valsWRITE: replace string values in col.str_vals.WRITE: convert all values in table to a list of lists of strings.

        This sets the fill values and possibly column formats from the input
        formats={} keyword, then ends up calling table.pprint._pformat_col_iter()
        by a circuitous path. That function does the real work of formatting.
        Finally replace anything matching the fill_values.

        Returns
        -------
        values : list of list of str
        _set_col_formatsWrite ``self.cols`` in place to ``lines``.

        Parameters
        ----------
        lines : list
            List for collecting output of writing self.cols.
        Start_line attribute cannot be callable for write()data_start_linecol_str_itersWRITE: set column formats.numpy_typeReturn a tuple containing a function which converts a list into a numpy
    array and the type produced by the converter function.

    Parameters
    ----------
    numpy_type : numpy data-type
        The numpy type required of an array returned by ``converter``. Must be a
        valid `numpy type <https://numpy.org/doc/stable/user/basics.types.html>`_
        (e.g., numpy.uint, numpy.int8, numpy.int64, numpy.float64) or a python
        type covered by a numpy type (e.g., int, float, str, bool).

    Returns
    -------
    converter : callable
        ``converter`` is a function which accepts a list and converts it to a
        numpy array of type ``numpy_type``.
    converter_type : type
        ``converter_type`` tracks the generic data type produced by the
        converter function.

    Raises
    ------
    ValueError
        Raised by ``converter`` if the list elements could not be converted to
        the required type.
    type_nameconverter_typebool_converter
        Convert values "False" and "True" to bools.  Raise an exception
        for any other string values.
        svalsbool input strings must be False, True, 0, 1, or ""truesfalsesbool input strings must be only False, True, 0, 1, or ""generic_converterOutput table as a dict of column objects keyed on column name.  The
    table data are stored as plain python lists within the column objects.
    _validate_and_copyValidate the format for the type converters and then copy those
        which are valid converters for this column (i.e. converter type is
        a subclass of col.type).
        converters_outconverter_funccannot unpackconverter_type must be a subclass of NoTypeError: invalid format for converters, see documentation
"Error: invalid format for converters, see ""documentation\n"_convert_valsdefault_convertersno converters definedlast_err failed to convert: converter type  does not match column type " does not match"" column type "Exceeds the limitOverflowError converting to  in column " in"" column ", reverting to String._deduplicate_namesEnsure there are no duplicates in ``names``.

    This is done by iteratively adding ``_<N>`` to the name for increasing N
    until the name is unique.
    new_namesexisting_namesbase_name
    Output the table as an astropy.table.Table object.
    t_colsout_col_fastfastio_formatsASCII reader '' details
cleandocASCII writer '_apply_include_exclude_namesinclude_namesexclude_names
    Apply names, include_names and exclude_names to a table or BaseHeader.

    For the latter this relies on BaseHeader implementing ``colnames``,
    ``rename_column``, and ``remove_columns``.

    Parameters
    ----------
    table : `~astropy.table.Table`, `~astropy.io.ascii.BaseHeader`
        Input table or BaseHeader subclass instance
    names : list
        List of names to override those in table (set to None to use existing names)
    include_names : list
        List of names to include in output
    exclude_names : list
        List of names to exclude from output (applied after ``include_names``)

    rename_columnsxxxscolnames_uniqnames_setremove_namesClass providing methods to read and write an ASCII table using the specified
    header, data, inputter, and outputter instances.

    Typical usage is to instantiate a Reader() object and customize the
    ``header``, ``data``, ``inputter``, and ``outputter`` attributes.  Each
    of these is an object of the corresponding class.

    There is one method ``inconsistent_handler`` that can be used to customize the
    behavior of ``read()`` in the event that a data row doesn't match the header.
    The default behavior is to raise an InconsistentTableError.

    inputter_classoutputter_classoutputterCheck that the dimensions of columns in ``table`` are acceptable.

        The reader class attribute ``max_ndim`` defines the maximum dimension of
        columns that can be written using this format. The base value is ``1``,
        corresponding to normal scalar columns with just a length.

        Parameters
        ----------
        table : `~astropy.table.Table`
            Input table.

        Raises
        ------
        ValueError
            If any column exceeds the number of allowed dimensions
        Read the ``table`` and return the results in a format determined by
        the ``outputter`` attribute.

        The ``table`` parameter is any string or object that can be processed
        by the instance ``inputter``.  For the base Inputter class ``table`` can be
        one of:

        * File name
        * File-like object
        * String (newline separated) with all header and data lines (must have at least 2 lines)
        * List of strings

        Parameters
        ----------
        table : str, file-like, list
            Input table.

        Returns
        -------
        table : `~astropy.table.Table`
            Output table

        Number of header columns () inconsistent with data columns (") inconsistent with ""data columns (") at data line 
Header values: "Header values: "
Data values: "Data values: "errmsgtable_meta
        Adjust or skip data entries if a row is inconsistent with the header.

        The default implementation does no adjustment, and hence will always trigger
        an exception in read() any time the number of data entries does not match
        the header.

        Note that this will *not* be called if the row already matches the header.

        Parameters
        ----------
        str_vals : list
            A list of value strings from the current row of the table.
        ncols : int
            The expected number of entries from the table header.

        Returns
        -------
        str_vals : list
            List of strings to be parsed into data entries in the output table. If
            the length of this list does not match ``ncols``, an exception will be
            raised in read().  Can also be None, in which case the row will be
            skipped.
        Return lines in the table that match header.comment regexp.Table must be read prior to accessing the header comment linesupdate_table_data
        Update table columns in place if needed.

        This is a hook to allow updating the table columns after name
        filtering but before setting up to write the data.  This is currently
        only used by ECSV and is otherwise just a pass-through.

        Parameters
        ----------
        table : `astropy.table.Table`
            Input table for writing

        Returns
        -------
        table : `astropy.table.Table`
            Output table for writing
        
        Write ``table`` as list of strings.

        Parameters
        ----------
        table : `~astropy.table.Table`
            Input table data.

        Returns
        -------
        lines : list
            List of strings corresponding to ASCII table

        new_colsInputter where lines ending in ``continuation_char`` are joined with the subsequent line.

    Example::

      col1 col2 col3
      1       2 3
      4 5       6
    continuation_charreplace_charno_continuere_no_continueoutlinesReplace tab with space within ``line`` while respecting quoted substrings.header_startdata_enddata_splitter_clsheader_splitter_clsextra_reader_pars_get_readerreader_clsinputter_clsoutputter_clsInitialize a table reader allowing for common customizations.  See ui.get_reader()
    for param docs.  This routine is for internal (package) use only and is useful
    because it depends only on the "core" module.
    fast_readerfast_reader required with {}, but this is not a fast C reader: {}"fast_reader required with ""{}, but this is not a fast C reader: {}"reader_kwargsdefault_header_lengthfixed_width_two_lineheader_start cannot be modified for this ReaderCannot have None for column nameDuplicate column namesstrip_whitespaceextra_writer_pars_get_writerwriter_clsfast_writerInitialize a table writer allowing for common customizations. This
    routine is for internal (package) use only and is useful because it depends
    only on the "core" module.
    fast_writer_kwargs# Global dictionary mapping format arg to the corresponding Reader class# Similar dictionary for fast readers# No limit?# Check for N-d columns# Random 16-character string that gets injected instead of any# empty fields and is then replaced post-write with doubled-quotechar.# Created with:# ''.join(random.choice(string.printable[:90]) for _ in range(16))# Temporary StringIO for catching the real csv.writer() object output# If QUOTE_MINIMAL and space-delimited then replace empty fields with# the sentinel value.# Clear the temporary StringIO buffer that self.writer writes into and# then call the real csv.writer().writerow or writerows with values.# self.csvfile is defined then write the output.  In practice the pure# Python writer calls with csvfile=None, while the fast writer calls with# a file-like object.# Any large number will do.# Generic type (Int, Float, Str etc)# Numpy dtype if available# See if table supports indexing, slicing, and iteration# treat single entry as if string had been passed directly# No header line so auto-generate names from n_data_cols# Get the data values from the first line of table data to determine n_data_cols# No header line matching# Yield non-comment lines# For writing self.cols can contain cols that are not Column.  Raise# exception in that case.# Impose strict requirements on column names (normally used in guessing)# When guessing require at least two columns, except for ECSV which can# reliably be guessed from the header requirements.# Need to make sure fill_values list is instance attribute, not class attribute.# On read, this will be overwritten by the default in the ui.read (thus, in# the current implementation there can be no different default for different# Readers). On write, ui.py does not specify a default, so this line here matters.# Don't copy entire data lines unless necessary# when we write tables the columns may be astropy.table.Columns# which don't carry a fill_values by default# if input is only one <fill_spec>, then make it a list# Step 1: Set the default list of columns which are affected by# fill_values# Step 2a: Find out which columns are affected by this tuple# iterate over reversed order, so last condition is set first and# overwritten by earlier conditions# Infer converter type from an instance of numpy_type.# Try a smaller subset first for a long array# User-defined converters which gets set in ascii.ui if a `converter` kwarg# is supplied.# Derived classes must define default_converters and __call__# Allow specifying a single converter instead of a list of converters.# The input `converters` must be a ``type`` value that can init np.dtype.# Don't allow list-like things that dtype accepts# Catch the last error in order to provide additional information# in case all attempts at column conversion fail.  The initial# value of of last_error will apply if no converters are defined# and the first col.converters[0] access raises IndexError.# Try converters, popping the unsuccessful ones from the list.# If there are no converters left here then fail.# Overflow during conversion (most likely an int that# doesn't fit in native C long). Put string at the top of# the converters list for the next while iteration.# With python/cpython#95778 this has been supplemented with a# "ValueError: Exceeds the limit (4300) for integer string conversion"# so need to catch that as well.# Iterate until a unique name is found# Use `np.int64` to ensure large integers can be read as ints# on platforms such as Windows# https://github.com/astropy/astropy/issues/5744# Sets col.data to numpy array and col.type to io.ascii Type class (e.g.# FloatType) for each col.# Rename table column names to those passed by user# Temporarily rename with names that are not in `names` or `table.colnames`.# This ensures that rename succeeds regardless of existing names.# Max column dimension that writer supports for this format. Exceptions# include ECSV (no limit) and HTML (max_ndim=2).# Data and Header instances benefit from a little cross-coupling.  Header may need to# know about number of data columns for auto-column name generation and Data may# need to know about header (e.g. for fixed-width tables where widths are spec'd in header.# Metadata, consisting of table-level meta and column-level meta.  The latter# could include information about column type, description, formatting, etc,# depending on the table meta format.# If ``table`` is a file then store the name in the ``data``# attribute. The ``table`` is a "file" if it is a string# without the new line specific to the OS.# Strings only# If one of the newline chars is set as field delimiter, only# accept the other one as line splitter# Set self.data.data_lines to a slice of lines contain the data rows# Extract table meta values (e.g. keywords, comments, etc).  Updates self.meta.# Get the table column definitions# Make sure columns are valid# if str_vals is None, we skip this row# otherwise, we raise an error only if it is still inconsistent# an empty list will always trigger an InconsistentTableError in read()# Check column names before altering# In-place update of columns in input ``table`` to reflect column# filtering.  Note that ``table`` is guaranteed to be a copy of the# original user-supplied table.# This is a hook to allow updating the table columns after name# filtering but before setting up to write the data.  This is currently# only used by ECSV and is otherwise just a pass-through.# Check that table column dimensions are supported by this format class.# Most formats support only 1-d columns, but some like ECSV support N-d.# Now use altered columns# link information about the columns to the writer object (i.e. self)# Write header and data to lines list# If no_continue is not None then lines matching this regex are not subject# to line continuation.  The initial use case here is Daophot.  In this# case the continuation character is just replaced with replace_char.# Fast readers handle args separately# If user explicitly passed a fast reader with enable='force'# (e.g. by passing non-default options), raise an error for slow readers# Otherwise ignore fast_reader parameter# Issue #855 suggested to set data_start to header_start + default_header_length# Thus, we need to retrieve this from the class definition before resetting these numbers.# Start line could be None or an instancemethod# csv.reader is hard-coded to recognise either '\r' or '\n' as end-of-line,# therefore DefaultSplitter cannot handle these as delimiters.# For FixedWidthTwoLine the data_start is calculated relative to the position line.# However, position_line is given as absolute number and not relative to header_start.# So, ignore this Reader here.# User trying to set a None header start to some value other than None# Strict names is normally set only within the guessing process to# indicate that column names cannot be numeric or have certain# characters at the beginning or end.  It gets used in# BaseHeader.check_column_names().# A value of None for fill_values imply getting the default string# representation of masked values (depending on the writer class), but the# machinery expects a list.  The easiest here is to just pop the value off,# i.e. fill_values=None is the same as not providing it at all.# Fast writers handle args separately# Switch to fast writer# Restore the default SplitterClass process_val method which strips# whitespace.  This may have been changed in the Writer# initialization (e.g. Rdb and Tab)# Prepend user-specified values to the class default.# Test if it looks like (match, replace_string, optional_colname),# in which case make it a listb'An extensible ASCII table reader and writer.

core.py:
  Core base classes and functions for reading and writing tables.

:Copyright: Smithsonian Astrophysical Observatory (2010)
:Author: Tom Aldcroft (aldcroft@head.cfa.harvard.edu)
'u'An extensible ASCII table reader and writer.

core.py:
  Core base classes and functions for reading and writing tables.

:Copyright: Smithsonian Astrophysical Observatory (2010)
:Author: Tom Aldcroft (aldcroft@head.cfa.harvard.edu)
'b'Check that ``table`` has only columns with ndim <= ``max_ndim``.

    Currently ECSV is the only built-in format that supports output of arbitrary
    N-d columns, but HTML supports 2-d.
    'u'Check that ``table`` has only columns with ndim <= ``max_ndim``.

    Currently ECSV is the only built-in format that supports output of arbitrary
    N-d columns, but HTML supports 2-d.
    'b'column(s) with dimension > 'u'column(s) with dimension > 'b' cannot be be written with this format, try using 'ecsv' (Enhanced CSV) format'u' cannot be be written with this format, try using 'ecsv' (Enhanced CSV) format'b'
    Internal class to replace the csv writer ``writerow`` and ``writerows``
    functions so that in the case of ``delimiter=' '`` and
    ``quoting=csv.QUOTE_MINIMAL``, the output field value is quoted for empty
    fields (when value == '').

    This changes the API slightly in that the writerow() and writerows()
    methods return the output written string instead of the length of
    that string.

    Examples
    --------
    >>> from astropy.io.ascii.core import CsvWriter
    >>> writer = CsvWriter(delimiter=' ')
    >>> print(writer.writerow(['hello', '', 'world']))
    hello "" world
    'u'
    Internal class to replace the csv writer ``writerow`` and ``writerows``
    functions so that in the case of ``delimiter=' '`` and
    ``quoting=csv.QUOTE_MINIMAL``, the output field value is quoted for empty
    fields (when value == '').

    This changes the API slightly in that the writerow() and writerows()
    methods return the output written string instead of the length of
    that string.

    Examples
    --------
    >>> from astropy.io.ascii.core import CsvWriter
    >>> writer = CsvWriter(delimiter=' ')
    >>> print(writer.writerow(['hello', '', 'world']))
    hello "" world
    'b'2b=48Av%0-V3p>bX'u'2b=48Av%0-V3p>bX'b'
        Similar to csv.writer.writerow but with the custom quoting behavior.
        Returns the written string instead of the length of that string.
        'u'
        Similar to csv.writer.writerow but with the custom quoting behavior.
        Returns the written string instead of the length of that string.
        'b'
        Similar to csv.writer.writerows but with the custom quoting behavior.
        Returns the written string instead of the length of that string.
        'u'
        Similar to csv.writer.writerows but with the custom quoting behavior.
        Returns the written string instead of the length of that string.
        'b'
        Call ``writerow_func`` (either writerow or writerows) with ``values``.
        If it has empty fields that have been replaced then change those
        sentinel strings back to quoted empty strings, e.g. ``""``.
        'u'
        Call ``writerow_func`` (either writerow or writerows) with ``values``.
        If it has empty fields that have been replaced then change those
        sentinel strings back to quoted empty strings, e.g. ``""``.
        'b'A trivial extension of numpy.ma.masked.

    We want to be able to put the generic term ``masked`` into a dictionary.
    The constant ``numpy.ma.masked`` is not hashable (see
    https://github.com/numpy/numpy/issues/4660), so we need to extend it
    here with a hash value.

    See https://github.com/numpy/numpy/issues/11021 for rationale for
    __copy__ and __deepcopy__ methods.
    'u'A trivial extension of numpy.ma.masked.

    We want to be able to put the generic term ``masked`` into a dictionary.
    The constant ``numpy.ma.masked`` is not hashable (see
    https://github.com/numpy/numpy/issues/4660), so we need to extend it
    here with a hash value.

    See https://github.com/numpy/numpy/issues/11021 for rationale for
    __copy__ and __deepcopy__ methods.
    'b'All instances of this class shall have the same hash.'u'All instances of this class shall have the same hash.'b'This is a singleton so just return self.'u'This is a singleton so just return self.'b'
    Indicates that an input table is inconsistent in some way.

    The default behavior of ``BaseReader`` is to throw an instance of
    this class if a data row doesn't match the header.
    'u'
    Indicates that an input table is inconsistent in some way.

    The default behavior of ``BaseReader`` is to throw an instance of
    this class if a data row doesn't match the header.
    'b'
    Indicates that a dependency for table reading is not present.

    An instance of this class is raised whenever an optional reader
    with certain required dependencies cannot operate because of
    an ImportError.
    'u'
    Indicates that a dependency for table reading is not present.

    An instance of this class is raised whenever an optional reader
    with certain required dependencies cannot operate because of
    an ImportError.
    'b'
    Indicates that a reader cannot handle a passed parameter.

    The C-based fast readers in ``io.ascii`` raise an instance of
    this error class upon encountering a parameter that the
    C engine cannot handle.
    'u'
    Indicates that a reader cannot handle a passed parameter.

    The C-based fast readers in ``io.ascii`` raise an instance of
    this error class upon encountering a parameter that the
    C engine cannot handle.
    'b'
    Indicates that one of the specified options for fast
    reading is invalid.
    'u'
    Indicates that one of the specified options for fast
    reading is invalid.
    'b'
    Superclass for ``StrType`` and ``NumType`` classes.

    This class is the default type of ``Column`` and provides a base
    class for other data types.
    'u'
    Superclass for ``StrType`` and ``NumType`` classes.

    This class is the default type of ``Column`` and provides a base
    class for other data types.
    'b'
    Indicates that a column consists of text data.
    'u'
    Indicates that a column consists of text data.
    'b'
    Indicates that a column consists of numerical data.
    'u'
    Indicates that a column consists of numerical data.
    'b'
    Describes floating-point data.
    'u'
    Describes floating-point data.
    'b'
    Describes boolean data.
    'u'
    Describes boolean data.
    'b'
    Describes integer data.
    'u'
    Describes integer data.
    'b'
    Subclass of all other data types.

    This type is returned by ``convert_numpy`` if the given numpy
    type does not match ``StrType``, ``FloatType``, or ``IntType``.
    'u'
    Subclass of all other data types.

    This type is returned by ``convert_numpy`` if the given numpy
    type does not match ``StrType``, ``FloatType``, or ``IntType``.
    'b'Table column.

    The key attributes of a Column object are:

    * **name** : column name
    * **type** : column type (NoType, StrType, NumType, FloatType, IntType)
    * **dtype** : numpy dtype (optional, overrides **type** if set)
    * **str_vals** : list of column values as strings
    * **fill_values** : dict of fill values
    * **shape** : list of element shape (default [] => scalar)
    * **data** : list of converted column values
    * **subtype** : actual datatype for columns serialized with JSON
    'u'Table column.

    The key attributes of a Column object are:

    * **name** : column name
    * **type** : column type (NoType, StrType, NumType, FloatType, IntType)
    * **dtype** : numpy dtype (optional, overrides **type** if set)
    * **str_vals** : list of column values as strings
    * **fill_values** : dict of fill values
    * **shape** : list of element shape (default [] => scalar)
    * **data** : list of converted column values
    * **subtype** : actual datatype for columns serialized with JSON
    'b'
    Get the lines from the table input and return a list of lines.

    'u'
    Get the lines from the table input and return a list of lines.

    'b'Encoding used to read the file'u'Encoding used to read the file'b'Get the lines from the ``table`` input.

        The input table can be one of:

        * File name (str or pathlike)
        * String (newline separated) with all header and data lines (must have at least 2 lines)
        * File-like object with read() method
        * List of strings

        Parameters
        ----------
        table : str, file-like, list
            Can be either a file name, string (newline separated) with all header and data
            lines (must have at least 2 lines), a file-like object with a
            ``read()`` method, or a list of strings.
        newline :
            Line separator. If `None` use OS default from ``splitlines()``.

        Returns
        -------
        lines : list
            List of lines
        'u'Get the lines from the ``table`` input.

        The input table can be one of:

        * File name (str or pathlike)
        * String (newline separated) with all header and data lines (must have at least 2 lines)
        * File-like object with read() method
        * List of strings

        Parameters
        ----------
        table : str, file-like, list
            Can be either a file name, string (newline separated) with all header and data
            lines (must have at least 2 lines), a file-like object with a
            ``read()`` method, or a list of strings.
        newline :
            Line separator. If `None` use OS default from ``splitlines()``.

        Returns
        -------
        lines : list
            List of lines
        'b'Input "table" must be a string (filename or data) or an iterable'u'Input "table" must be a string (filename or data) or an iterable'b'Process lines for subsequent use.  In the default case do nothing.
        This routine is not generally intended for removing comment lines or
        stripping whitespace.  These are done (if needed) in the header and
        data line processing.

        Override this method if something more has to be done to convert raw
        input lines to the table rows.  For example the
        ContinuationLinesInputter derived class accounts for continuation
        characters if a row is split into lines.
        'u'Process lines for subsequent use.  In the default case do nothing.
        This routine is not generally intended for removing comment lines or
        stripping whitespace.  These are done (if needed) in the header and
        data line processing.

        Override this method if something more has to be done to convert raw
        input lines to the table rows.  For example the
        ContinuationLinesInputter derived class accounts for continuation
        characters if a row is split into lines.
        'b'
    Base splitter that uses python's split method to do the work.

    This does not handle quoted values.  A key feature is the formulation of
    __call__ as a generator that returns a list of the split line values at
    each iteration.

    There are two methods that are intended to be overridden, first
    ``process_line()`` to do pre-processing on each input line before splitting
    and ``process_val()`` to do post-processing on each split string value.  By
    default these apply the string ``strip()`` function.  These can be set to
    another function via the instance attribute or be disabled entirely, for
    example::

      reader.header.splitter.process_val = lambda x: x.lstrip()
      reader.data.splitter.process_val = None

    'u'
    Base splitter that uses python's split method to do the work.

    This does not handle quoted values.  A key feature is the formulation of
    __call__ as a generator that returns a list of the split line values at
    each iteration.

    There are two methods that are intended to be overridden, first
    ``process_line()`` to do pre-processing on each input line before splitting
    and ``process_val()`` to do post-processing on each split string value.  By
    default these apply the string ``strip()`` function.  These can be set to
    another function via the instance attribute or be disabled entirely, for
    example::

      reader.header.splitter.process_val = lambda x: x.lstrip()
      reader.data.splitter.process_val = None

    'b' one-character string used to separate fields 'u' one-character string used to separate fields 'b'Remove whitespace at the beginning or end of line.  This is especially useful for
        whitespace-delimited files to prevent spurious columns at the beginning or end.
        'u'Remove whitespace at the beginning or end of line.  This is especially useful for
        whitespace-delimited files to prevent spurious columns at the beginning or end.
        'b'Remove whitespace at the beginning or end of value.'u'Remove whitespace at the beginning or end of value.'b'Default class to split strings into columns using python csv.  The class
    attributes are taken from the csv Dialect class.

    Typical usage::

      # lines = ..
      splitter = ascii.DefaultSplitter()
      for col_vals in splitter(lines):
          for col_val in col_vals:
               ...

    'u'Default class to split strings into columns using python csv.  The class
    attributes are taken from the csv Dialect class.

    Typical usage::

      # lines = ..
      splitter = ascii.DefaultSplitter()
      for col_vals in splitter(lines):
          for col_val in col_vals:
               ...

    'b' one-character string used to separate fields. 'u' one-character string used to separate fields. 'b' control how instances of *quotechar* in a field are quoted 'u' control how instances of *quotechar* in a field are quoted 'b' character to remove special meaning from following character 'u' character to remove special meaning from following character 'b' one-character stringto quote fields containing special characters 'u' one-character stringto quote fields containing special characters 'b' control when quotes are recognized by the reader 'u' control when quotes are recognized by the reader 'b' ignore whitespace immediately following the delimiter 'u' ignore whitespace immediately following the delimiter 'b'Remove whitespace at the beginning or end of line.  This is especially useful for
        whitespace-delimited files to prevent spurious columns at the beginning or end.
        If splitting on whitespace then replace unquoted tabs with space first.
        'u'Remove whitespace at the beginning or end of line.  This is especially useful for
        whitespace-delimited files to prevent spurious columns at the beginning or end.
        If splitting on whitespace then replace unquoted tabs with space first.
        'b' 	'u' 	'b'Return an iterator over the table ``lines``, where each iterator output
        is a list of the split line values.

        Parameters
        ----------
        lines : list
            List of table lines

        Yields
        ------
        line : list of str
            Each line's split values.

        'u'Return an iterator over the table ``lines``, where each iterator output
        is a list of the split line values.

        Parameters
        ----------
        lines : list
            List of table lines

        Yields
        ------
        line : list of str
            Each line's split values.

        'b'Replace tabs with spaces in given string, preserving quoted substrings.

    Parameters
    ----------
    line : str
        String containing tabs to be replaced with spaces.
    escapechar : str
        Character in ``line`` used to escape special characters.
    quotechar : str
        Character in ``line`` indicating the start/end of a substring.

    Returns
    -------
    line : str
        A copy of ``line`` with tabs replaced by spaces, preserving quoted substrings.
    'u'Replace tabs with spaces in given string, preserving quoted substrings.

    Parameters
    ----------
    line : str
        String containing tabs to be replaced with spaces.
    escapechar : str
        Character in ``line`` used to escape special characters.
    quotechar : str
        Character in ``line`` indicating the start/end of a substring.

    Returns
    -------
    line : str
        A copy of ``line`` with tabs replaced by spaces, preserving quoted substrings.
    'b'Return the appropriate line index, depending on ``line_or_func`` which
    can be either a function, a positive or negative int, or None.
    'u'Return the appropriate line index, depending on ``line_or_func`` which
    can be either a function, a positive or negative int, or None.
    'b'
    Base table header reader.
    'u'
    Base table header reader.
    'b'col{}'u'col{}'b' format string for auto-generating column names 'u' format string for auto-generating column names 'b' None, int, or a function of ``lines`` that returns None or int 'u' None, int, or a function of ``lines`` that returns None or int 'b' regular expression for comment lines 'u' regular expression for comment lines 'b' Splitter class for splitting data lines into columns 'u' Splitter class for splitting data lines into columns 'b' list of names corresponding to each data column 'u' list of names corresponding to each data column 'b'ASCII_TABLE_WRITE_SPACER_LINE'u'ASCII_TABLE_WRITE_SPACER_LINE'b'
        Extract any table-level metadata, e.g. keywords, comments, column metadata, from
        the table ``lines`` and update the OrderedDict ``meta`` in place.  This base
        method extracts comment lines and stores them in ``meta`` for output.
        'u'
        Extract any table-level metadata, e.g. keywords, comments, column metadata, from
        the table ``lines`` and update the OrderedDict ``meta`` in place.  This base
        method extracts comment lines and stores them in ``meta`` for output.
        'b'Initialize the header Column objects from the table ``lines``.

        Based on the previously set Header attributes find or create the column names.
        Sets ``self.cols`` with the list of Columns.

        Parameters
        ----------
        lines : list
            List of table lines

        'u'Initialize the header Column objects from the table ``lines``.

        Based on the previously set Header attributes find or create the column names.
        Sets ``self.cols`` with the list of Columns.

        Parameters
        ----------
        lines : list
            List of table lines

        'b'No data lines found so cannot autogenerate column names'u'No data lines found so cannot autogenerate column names'b'No header line found in table'u'No header line found in table'b'Generator to yield non-blank and non-comment lines.'u'Generator to yield non-blank and non-comment lines.'b'Return the column names of the table.'u'Return the column names of the table.'b'
        Remove several columns from the table.

        Parameters
        ----------
        names : list
            A list containing the names of the columns to remove
        'u'
        Remove several columns from the table.

        Parameters
        ----------
        names : list
            A list containing the names of the columns to remove
        'b' does not exist'u' does not exist'b'
        Rename a column.

        Parameters
        ----------
        name : str
            The current name of the column.
        new_name : str
            The new name for the column
        'u'
        Rename a column.

        Parameters
        ----------
        name : str
            The current name of the column.
        new_name : str
            The new name for the column
        'b'got column type 'u'got column type 'b' instead of required 'u' instead of required 'b'Unknown data type ""'u'Unknown data type ""'b'"" for column "'u'"" for column "'b'
        Check column names.

        This must be done before applying the names transformation
        so that guessing will fail appropriately if ``names`` is supplied.
        For instance if the basic reader is given a table with no column header
        row.

        Parameters
        ----------
        names : list
            User-supplied list of column names
        strict_names : bool
            Whether to impose extra requirements on names
        guessing : bool
            True if this method is being called while guessing the table format
        'u'
        Check column names.

        This must be done before applying the names transformation
        so that guessing will fail appropriately if ``names`` is supplied.
        For instance if the basic reader is given a table with no column header
        row.

        Parameters
        ----------
        names : list
            User-supplied list of column names
        strict_names : bool
            Whether to impose extra requirements on names
        guessing : bool
            True if this method is being called while guessing the table format
        'b'Column name 'u'Column name 'b' does not meet strict name requirements'u' does not meet strict name requirements'b'EcsvHeader'u'EcsvHeader'b'Table format guessing requires at least two columns, got 'u'Table format guessing requires at least two columns, got 'b'Length of names argument ('u'Length of names argument ('b') does not match number of table columns ('u') does not match number of table columns ('b'
    Base table data reader.
    'u'
    Base table data reader.
    'b' Regular expression for comment lines 'u' Regular expression for comment lines 'b'
        READ: Strip out comment lines and blank lines from list of ``lines``.

        Parameters
        ----------
        lines : list
            All lines in table

        Returns
        -------
        lines : list
            List of lines

        'u'
        READ: Strip out comment lines and blank lines from list of ``lines``.

        Parameters
        ----------
        lines : list
            All lines in table

        Returns
        -------
        lines : list
            List of lines

        'b'
        READ: Set ``data_lines`` attribute to lines slice comprising table data values.
        'u'
        READ: Set ``data_lines`` attribute to lines slice comprising table data values.
        'b'Return a generator that returns a list of column values (as strings)
        for each data line.
        'u'Return a generator that returns a list of column values (as strings)
        for each data line.
        'b'READ: Set fill value for each column and then apply that fill value.

        In the first step it is evaluated with value from ``fill_values`` applies to
        which column using ``fill_include_names`` and ``fill_exclude_names``.
        In the second step all replacements are done for the appropriate columns.
        'u'READ: Set fill value for each column and then apply that fill value.

        In the first step it is evaluated with value from ``fill_values`` applies to
        which column using ``fill_include_names`` and ``fill_exclude_names``.
        In the second step all replacements are done for the appropriate columns.
        'b'READ, WRITE: Set fill values of individual cols based on fill_values of BaseData.

        fill values has the following form:
        <fill_spec> = (<bad_value>, <fill_value>, <optional col_name>...)
        fill_values = <fill_spec> or list of <fill_spec>'s

        'u'READ, WRITE: Set fill values of individual cols based on fill_values of BaseData.

        fill values has the following form:
        <fill_spec> = (<bad_value>, <fill_value>, <optional col_name>...)
        fill_values = <fill_spec> or list of <fill_spec>'s

        'b'fill_values'u'fill_values'b'Format of fill_values must be (<bad>, <fill>, <optional col1>, ...)'u'Format of fill_values must be (<bad>, <fill>, <optional col1>, ...)'b'READ: Replace string values in col.str_vals and set masks.'u'READ: Replace string values in col.str_vals and set masks.'b'WRITE: replace string values in col.str_vals.'u'WRITE: replace string values in col.str_vals.'b'WRITE: convert all values in table to a list of lists of strings.

        This sets the fill values and possibly column formats from the input
        formats={} keyword, then ends up calling table.pprint._pformat_col_iter()
        by a circuitous path. That function does the real work of formatting.
        Finally replace anything matching the fill_values.

        Returns
        -------
        values : list of list of str
        'u'WRITE: convert all values in table to a list of lists of strings.

        This sets the fill values and possibly column formats from the input
        formats={} keyword, then ends up calling table.pprint._pformat_col_iter()
        by a circuitous path. That function does the real work of formatting.
        Finally replace anything matching the fill_values.

        Returns
        -------
        values : list of list of str
        'b'Write ``self.cols`` in place to ``lines``.

        Parameters
        ----------
        lines : list
            List for collecting output of writing self.cols.
        'u'Write ``self.cols`` in place to ``lines``.

        Parameters
        ----------
        lines : list
            List for collecting output of writing self.cols.
        'b'Start_line attribute cannot be callable for write()'u'Start_line attribute cannot be callable for write()'b'WRITE: set column formats.'u'WRITE: set column formats.'b'Return a tuple containing a function which converts a list into a numpy
    array and the type produced by the converter function.

    Parameters
    ----------
    numpy_type : numpy data-type
        The numpy type required of an array returned by ``converter``. Must be a
        valid `numpy type <https://numpy.org/doc/stable/user/basics.types.html>`_
        (e.g., numpy.uint, numpy.int8, numpy.int64, numpy.float64) or a python
        type covered by a numpy type (e.g., int, float, str, bool).

    Returns
    -------
    converter : callable
        ``converter`` is a function which accepts a list and converts it to a
        numpy array of type ``numpy_type``.
    converter_type : type
        ``converter_type`` tracks the generic data type produced by the
        converter function.

    Raises
    ------
    ValueError
        Raised by ``converter`` if the list elements could not be converted to
        the required type.
    'u'Return a tuple containing a function which converts a list into a numpy
    array and the type produced by the converter function.

    Parameters
    ----------
    numpy_type : numpy data-type
        The numpy type required of an array returned by ``converter``. Must be a
        valid `numpy type <https://numpy.org/doc/stable/user/basics.types.html>`_
        (e.g., numpy.uint, numpy.int8, numpy.int64, numpy.float64) or a python
        type covered by a numpy type (e.g., int, float, str, bool).

    Returns
    -------
    converter : callable
        ``converter`` is a function which accepts a list and converts it to a
        numpy array of type ``numpy_type``.
    converter_type : type
        ``converter_type`` tracks the generic data type produced by the
        converter function.

    Raises
    ------
    ValueError
        Raised by ``converter`` if the list elements could not be converted to
        the required type.
    'b'
        Convert values "False" and "True" to bools.  Raise an exception
        for any other string values.
        'u'
        Convert values "False" and "True" to bools.  Raise an exception
        for any other string values.
        'b'bool input strings must be False, True, 0, 1, or ""'u'bool input strings must be False, True, 0, 1, or ""'b'bool input strings must be only False, True, 0, 1, or ""'u'bool input strings must be only False, True, 0, 1, or ""'b'Output table as a dict of column objects keyed on column name.  The
    table data are stored as plain python lists within the column objects.
    'u'Output table as a dict of column objects keyed on column name.  The
    table data are stored as plain python lists within the column objects.
    'b'Validate the format for the type converters and then copy those
        which are valid converters for this column (i.e. converter type is
        a subclass of col.type).
        'u'Validate the format for the type converters and then copy those
        which are valid converters for this column (i.e. converter type is
        a subclass of col.type).
        'b'cannot unpack'u'cannot unpack'b'converter_type must be a subclass of NoType'u'converter_type must be a subclass of NoType'b'Error: invalid format for converters, see documentation
'u'Error: invalid format for converters, see documentation
'b'no converters defined'u'no converters defined'b' failed to convert: 'u' failed to convert: 'b'converter type 'u'converter type 'b' does not match column type 'u' does not match column type 'b'Exceeds the limit'u'Exceeds the limit'b'OverflowError converting to 'u'OverflowError converting to 'b' in column 'u' in column 'b', reverting to String.'u', reverting to String.'b'Ensure there are no duplicates in ``names``.

    This is done by iteratively adding ``_<N>`` to the name for increasing N
    until the name is unique.
    'u'Ensure there are no duplicates in ``names``.

    This is done by iteratively adding ``_<N>`` to the name for increasing N
    until the name is unique.
    'b'
    Output the table as an astropy.table.Table object.
    'u'
    Output the table as an astropy.table.Table object.
    'b'_format_name'u'_format_name'b'_fast'u'_fast'b'_io_registry_format_aliases'u'_io_registry_format_aliases'b'ASCII reader ''u'ASCII reader ''b'' details
'u'' details
'b'ASCII writer ''u'ASCII writer ''b'
    Apply names, include_names and exclude_names to a table or BaseHeader.

    For the latter this relies on BaseHeader implementing ``colnames``,
    ``rename_column``, and ``remove_columns``.

    Parameters
    ----------
    table : `~astropy.table.Table`, `~astropy.io.ascii.BaseHeader`
        Input table or BaseHeader subclass instance
    names : list
        List of names to override those in table (set to None to use existing names)
    include_names : list
        List of names to include in output
    exclude_names : list
        List of names to exclude from output (applied after ``include_names``)

    'u'
    Apply names, include_names and exclude_names to a table or BaseHeader.

    For the latter this relies on BaseHeader implementing ``colnames``,
    ``rename_column``, and ``remove_columns``.

    Parameters
    ----------
    table : `~astropy.table.Table`, `~astropy.io.ascii.BaseHeader`
        Input table or BaseHeader subclass instance
    names : list
        List of names to override those in table (set to None to use existing names)
    include_names : list
        List of names to include in output
    exclude_names : list
        List of names to exclude from output (applied after ``include_names``)

    'b'Class providing methods to read and write an ASCII table using the specified
    header, data, inputter, and outputter instances.

    Typical usage is to instantiate a Reader() object and customize the
    ``header``, ``data``, ``inputter``, and ``outputter`` attributes.  Each
    of these is an object of the corresponding class.

    There is one method ``inconsistent_handler`` that can be used to customize the
    behavior of ``read()`` in the event that a data row doesn't match the header.
    The default behavior is to raise an InconsistentTableError.

    'u'Class providing methods to read and write an ASCII table using the specified
    header, data, inputter, and outputter instances.

    Typical usage is to instantiate a Reader() object and customize the
    ``header``, ``data``, ``inputter``, and ``outputter`` attributes.  Each
    of these is an object of the corresponding class.

    There is one method ``inconsistent_handler`` that can be used to customize the
    behavior of ``read()`` in the event that a data row doesn't match the header.
    The default behavior is to raise an InconsistentTableError.

    'b'cols'u'cols'b'Check that the dimensions of columns in ``table`` are acceptable.

        The reader class attribute ``max_ndim`` defines the maximum dimension of
        columns that can be written using this format. The base value is ``1``,
        corresponding to normal scalar columns with just a length.

        Parameters
        ----------
        table : `~astropy.table.Table`
            Input table.

        Raises
        ------
        ValueError
            If any column exceeds the number of allowed dimensions
        'u'Check that the dimensions of columns in ``table`` are acceptable.

        The reader class attribute ``max_ndim`` defines the maximum dimension of
        columns that can be written using this format. The base value is ``1``,
        corresponding to normal scalar columns with just a length.

        Parameters
        ----------
        table : `~astropy.table.Table`
            Input table.

        Raises
        ------
        ValueError
            If any column exceeds the number of allowed dimensions
        'b'Read the ``table`` and return the results in a format determined by
        the ``outputter`` attribute.

        The ``table`` parameter is any string or object that can be processed
        by the instance ``inputter``.  For the base Inputter class ``table`` can be
        one of:

        * File name
        * File-like object
        * String (newline separated) with all header and data lines (must have at least 2 lines)
        * List of strings

        Parameters
        ----------
        table : str, file-like, list
            Input table.

        Returns
        -------
        table : `~astropy.table.Table`
            Output table

        'u'Read the ``table`` and return the results in a format determined by
        the ``outputter`` attribute.

        The ``table`` parameter is any string or object that can be processed
        by the instance ``inputter``.  For the base Inputter class ``table`` can be
        one of:

        * File name
        * File-like object
        * String (newline separated) with all header and data lines (must have at least 2 lines)
        * List of strings

        Parameters
        ----------
        table : str, file-like, list
            Input table.

        Returns
        -------
        table : `~astropy.table.Table`
            Output table

        'b'Number of header columns ('u'Number of header columns ('b') inconsistent with data columns ('u') inconsistent with data columns ('b') at data line 'u') at data line 'b'
Header values: 'u'
Header values: 'b'
Data values: 'u'
Data values: 'b'table_meta'u'table_meta'b'
        Adjust or skip data entries if a row is inconsistent with the header.

        The default implementation does no adjustment, and hence will always trigger
        an exception in read() any time the number of data entries does not match
        the header.

        Note that this will *not* be called if the row already matches the header.

        Parameters
        ----------
        str_vals : list
            A list of value strings from the current row of the table.
        ncols : int
            The expected number of entries from the table header.

        Returns
        -------
        str_vals : list
            List of strings to be parsed into data entries in the output table. If
            the length of this list does not match ``ncols``, an exception will be
            raised in read().  Can also be None, in which case the row will be
            skipped.
        'u'
        Adjust or skip data entries if a row is inconsistent with the header.

        The default implementation does no adjustment, and hence will always trigger
        an exception in read() any time the number of data entries does not match
        the header.

        Note that this will *not* be called if the row already matches the header.

        Parameters
        ----------
        str_vals : list
            A list of value strings from the current row of the table.
        ncols : int
            The expected number of entries from the table header.

        Returns
        -------
        str_vals : list
            List of strings to be parsed into data entries in the output table. If
            the length of this list does not match ``ncols``, an exception will be
            raised in read().  Can also be None, in which case the row will be
            skipped.
        'b'Return lines in the table that match header.comment regexp.'u'Return lines in the table that match header.comment regexp.'b'Table must be read prior to accessing the header comment lines'u'Table must be read prior to accessing the header comment lines'b'
        Update table columns in place if needed.

        This is a hook to allow updating the table columns after name
        filtering but before setting up to write the data.  This is currently
        only used by ECSV and is otherwise just a pass-through.

        Parameters
        ----------
        table : `astropy.table.Table`
            Input table for writing

        Returns
        -------
        table : `astropy.table.Table`
            Output table for writing
        'u'
        Update table columns in place if needed.

        This is a hook to allow updating the table columns after name
        filtering but before setting up to write the data.  This is currently
        only used by ECSV and is otherwise just a pass-through.

        Parameters
        ----------
        table : `astropy.table.Table`
            Input table for writing

        Returns
        -------
        table : `astropy.table.Table`
            Output table for writing
        'b'
        Write ``table`` as list of strings.

        Parameters
        ----------
        table : `~astropy.table.Table`
            Input table data.

        Returns
        -------
        lines : list
            List of strings corresponding to ASCII table

        'u'
        Write ``table`` as list of strings.

        Parameters
        ----------
        table : `~astropy.table.Table`
            Input table data.

        Returns
        -------
        lines : list
            List of strings corresponding to ASCII table

        'b'Inputter where lines ending in ``continuation_char`` are joined with the subsequent line.

    Example::

      col1 col2 col3
      1       2 3
      4 5       6
    'u'Inputter where lines ending in ``continuation_char`` are joined with the subsequent line.

    Example::

      col1 col2 col3
      1       2 3
      4 5       6
    'b'Replace tab with space within ``line`` while respecting quoted substrings.'u'Replace tab with space within ``line`` while respecting quoted substrings.'b'delimiter'u'delimiter'b'quotechar'u'quotechar'b'header_start'u'header_start'b'data_start'u'data_start'b'data_end'u'data_end'b'converters'b'data_splitter_cls'u'data_splitter_cls'b'header_splitter_cls'u'header_splitter_cls'b'include_names'u'include_names'b'exclude_names'u'exclude_names'b'strict_names'u'strict_names'b'fill_include_names'u'fill_include_names'b'fill_exclude_names'u'fill_exclude_names'b'Initialize a table reader allowing for common customizations.  See ui.get_reader()
    for param docs.  This routine is for internal (package) use only and is useful
    because it depends only on the "core" module.
    'u'Initialize a table reader allowing for common customizations.  See ui.get_reader()
    for param docs.  This routine is for internal (package) use only and is useful
    because it depends only on the "core" module.
    'b'inputter_cls'u'inputter_cls'b'fast_reader'u'fast_reader'b'fast_reader required with {}, but this is not a fast C reader: {}'u'fast_reader required with {}, but this is not a fast C reader: {}'b'fixed_width_two_line'u'fixed_width_two_line'b'header_start cannot be modified for this Reader'u'header_start cannot be modified for this Reader'b'Cannot have None for column name'u'Cannot have None for column name'b'Duplicate column names'u'Duplicate column names'b'strip_whitespace'u'strip_whitespace'b'Initialize a table writer allowing for common customizations. This
    routine is for internal (package) use only and is useful because it depends
    only on the "core" module.
    'u'Initialize a table writer allowing for common customizations. This
    routine is for internal (package) use only and is useful because it depends
    only on the "core" module.
    'b'fast_'u'fast_'b'fast_writer'u'fast_writer'b'strip'u'strip'u'astropy.io.ascii.core'u'io.ascii.core'u'ascii.core'add_columnskeep_columnsCOLUMN_RELATED_METHODS
    This is a decorator that ensures that the table contains specific
    methods indicated by the _required_columns attribute. The aim is to
    decorate all methods that might affect the columns in the table and check
    for consistency after the methods have been run.
    decorator_method_check_required_columns is not a valid method_required_columns_enabledas_scalar_or_list_strrequired_columnsplural object is invalid - expected '" object is invalid - expected"' as the first column but time series has no columns" but time"" series has no columns" object is invalid - expected  as the first column" as the first"" column" but found " but found"# If _required_column_relax is True, we don't require the columns to be# present but we do require them to be the correct ones IF present. Note# that this is a temporary state - as soon as the required columns# are all present, we toggle this to Falseb'BaseTimeSeries'u'BaseTimeSeries'b'autocheck_required_columns'u'autocheck_required_columns'b'add_column'u'add_column'b'add_columns'u'add_columns'b'keep_columns'u'keep_columns'b'remove_column'u'remove_column'b'remove_columns'u'remove_columns'b'rename_column'u'rename_column'b'
    This is a decorator that ensures that the table contains specific
    methods indicated by the _required_columns attribute. The aim is to
    decorate all methods that might affect the columns in the table and check
    for consistency after the methods have been run.
    'u'
    This is a decorator that ensures that the table contains specific
    methods indicated by the _required_columns attribute. The aim is to
    decorate all methods that might affect the columns in the table and check
    for consistency after the methods have been run.
    'b' is not a valid method'u' is not a valid method'b' object is invalid - expected ''u' object is invalid - expected ''b'' as the first column'u'' as the first column'b' but time series has no columns'u' but time series has no columns'b' object is invalid - expected 'u' object is invalid - expected 'b' as the first column'u' as the first column'b' but found 'u' but found 'u'astropy.timeseries.core'u'timeseries.core'Astropy cosmology core module.

.. deprecated:: 7.1

    This module is deprecated and will be removed in a future version. All the public
    classes and functions have been and will continue to be available in the
    :mod:`~astropy.cosmology` module.

_srcThe module `astropy.cosmology.core` is deprecated since v7.1 and will be removed in a future version. Import from `astropy.cosmology` instead."The module `astropy.cosmology.core` is deprecated since v7.1 and will be ""removed in a future version. Import from `astropy.cosmology` instead."b'Astropy cosmology core module.

.. deprecated:: 7.1

    This module is deprecated and will be removed in a future version. All the public
    classes and functions have been and will continue to be available in the
    :mod:`~astropy.cosmology` module.

'u'Astropy cosmology core module.

.. deprecated:: 7.1

    This module is deprecated and will be removed in a future version. All the public
    classes and functions have been and will continue to be available in the
    :mod:`~astropy.cosmology` module.

'b'_COSMOLOGY_CLASSES'u'_COSMOLOGY_CLASSES'b'dataclass_decorator'u'dataclass_decorator'b'The module `astropy.cosmology.core` is deprecated since v7.1 and will be removed in a future version. Import from `astropy.cosmology` instead.'u'The module `astropy.cosmology.core` is deprecated since v7.1 and will be removed in a future version. Import from `astropy.cosmology` instead.'u'astropy.cosmology.core'u'cosmology.core'
Built-in mask mixin class.

The design uses `Masked` as a factory class which automatically
generates new subclasses for any data class that is itself a
subclass of a predefined masked class, with `MaskedNDArray`
providing such a predefined class for `~numpy.ndarray`.

Generally, any new predefined class should override the
``from_unmasked(data, mask, copy=False)`` class method that
creates an instance from unmasked data and a mask, as well as
the ``unmasked`` property that returns just the data.
The `Masked` class itself provides a base ``mask`` property,
which can also be overridden if needed.

ParentDtypeInfoastropy.utils.shapesNDArrayShapeMethodsAPPLY_TO_BOTH_FUNCTIONSDISPATCHED_FUNCTIONSMASKED_SAFE_FUNCTIONSUNSUPPORTED_FUNCTIONSMaskedNDArrayget_data_and_maskMasked version of {0.__name__}.

Except for the ability to pass in a ``mask``, parameters are
as for `{0.__module__}.{0.__name__}`.
get__doc__Split possibly masked array into unmasked and mask.

    Parameters
    ----------
    array : array-like
        Possibly masked item, judged by whether it has a ``mask`` attribute.
        If so, checks for having an ``unmasked`` attribute (as expected for
        instances of `~astropy.utils.masked.Masked`), or uses the ``_data``
        attribute if the inpuit is an instance of `~numpy.ma.MaskedArray`.

    Returns
    -------
    unmasked, mask : array-like
        If the input array had no mask, this will be ``array, None``.

    Raises
    ------
    AttributeError
        If ``array`` has a ``mask`` but not an ``unmasked`` attribute, and
        is not an instance of `~numpy.ma.MaskedArray`.
    ValueError
        If ``array`` is ``np.ma.masked`` (since it has no data).

    ' object has a 'mask' attribute but not an 'unmasked' attribute (and is not an np.ma.MaskedArray instance)."' object has a 'mask' attribute but not an ""'unmasked' attribute (and is not an np.ma.MaskedArray instance)."cannot handle np.ma.masked.Combine masks, possibly storing it in some output.

    Parameters
    ----------
    masks : tuple of array of bool or False or None
        Input masks.  Any that are `None` or `False` are ignored.
        Should broadcast to each other.  For structured dtype,
        an element is considered masked if any of the fields is.
    out : array, optional
        Possible output array to hold the result.
    where : array of bool, optional
        Which elements of the output array to fill.
    copy : bool optional
        Whether to ensure a copy is made. Only relevant if just a
        single input mask is not `None`, and ``out`` is not given.

    Returns
    -------
    mask : array
        Combined mask.
    copytoA scalar value or array of values with associated mask.

    The resulting instance will take its exact type from whatever the
    contents are, with the type generated on the fly as needed.

    Parameters
    ----------
    data : array-like
        The data for which a mask is to be added.  The result will be a
        a subclass of the type of ``data``.
    mask : array-like of bool, optional
        The initial mask to assign.  If not given, taken from the data.
        If the data already has a mask, the masks are combined.
    copy : bool
        Whether the data and mask should be copied. Default: `False`.

    _base_classesExplicitly defined masked classes keyed by their unmasked counterparts.

    For subclasses of these unmasked classes, masked counterparts can be generated.
    _masked_classesMasked classes keyed by their unmasked data counterparts._get_masked_cls_get_masked_instancedata_clsRegister a Masked subclass.

        Parameters
        ----------
        base_cls : type, optional
            If given, it is taken to mean that ``cls`` can be used as
            a base for masked versions of all subclasses of ``base_cls``,
            so it is registered as such in ``_base_classes``.
        data_cls : type, optional
            If given, ``cls`` should will be registered as the masked version of
            ``data_cls``.  Will set the private ``cls._data_cls`` attribute,
            and auto-generate a docstring if not present already.
        **kwargs
            Passed on for possible further initialization by superclasses.

        _data_clsfrom_unmaskedCreate an instance from unmasked data and a mask.masked_clsGet the masked wrapper for a given data class.

        If the data class does not exist yet but is a subclass of any of the
        registered base data classes, it is automatically generated
        (except we skip `~numpy.ma.MaskedArray` subclasses, since then the
        masking mechanisms would interfere).
        mro_item_get_maskThe mask.

        If set, replace the original mask, with whatever it is set with,
        using a view if no broadcasting or type conversion is required.
        _set_maskself_dtypemake_mask_descrmask_dtypeThe unmasked values.

        See Also
        --------
        astropy.utils.masked.Masked.filled
        _unmaskedGet a copy of the underlying data, with masked values filled in.

        Parameters
        ----------
        fill_value : object
            Value to replace masked values with.

        See Also
        --------
        astropy.utils.masked.Masked.unmasked
        _recursive_filledLike ShapedLikeNDArray, but for classes that can work with masked data.

    Defines default unmasked property as well as a filled method, and inherits
    private class methods that help deal with masked inputs.

    Any class using this must provide a masked property, which tells whether
    the underlying data are Masked, as well as a mask property, which
    generally should provide a read-only copy of the underlying mask.

    Whether or not the instance uses masked values.The mask.Get an instance without the mask.

        Note that while one gets a new instance, the underlying data will be shared.

        See Also
        --------
        filled : get a copy of the underlying data, with masked values filled in.
        Get a copy of the underlying data, with masked values filled in.

        Parameters
        ----------
        fill_value : object
            Value to replace masked values with.

        Returns
        -------
        filled : instance
            Copy of ``self`` with masked items replaced by ``fill_value``.

        See Also
        --------
        unmasked : get an instance without the mask.
        MaskedInfoBaseMaskedNDArrayInfo
    Container for meta information like name, description, format.
    MaskedArraySubclassInfoMixin class to create a subclasses such as MaskedQuantityInfo._comparison_method
    Create a comparison operator for MaskedNDArray.

    Needed since for string dtypes the base operators bypass __array_ufunc__
    and hence return unmasked results.
    other_dataother_mask_masked_resultMaskedIterator
    Flat iterator object to iterate over Masked Arrays.

    A `~astropy.utils.masked.MaskedIterator` iterator is returned by ``m.flat``
    for any masked array ``m``.  It allows iterating over the array as if it
    were a 1-D array, either in a for-loop or by calling its `next` method.

    Iteration is done in C-contiguous style, with the last index varying the
    fastest. The iterator can also be indexed using basic slicing or
    advanced indexing.

    Notes
    -----
    The design of `~astropy.utils.masked.MaskedIterator` follows that of
    `~numpy.ma.core.MaskedIterator`.  It is not exported by the
    `~astropy.utils.masked` module.  Instead of instantiating directly,
    use the ``flat`` method in the masked array instance.
    _masked_dataiter_maskiter
        Return the next value, or raise StopIteration.
        Get data class instance from arguments and then set mask.newclsdata_infoInfonew_infoA 1-D iterator over the Masked array.

        This returns a ``MaskedIterator`` instance, which behaves the same
        as the `~numpy.flatiter` instance returned by `~numpy.ndarray.flat`,
        and is similar to Python's built-in iterator, except that it also
        allows assignment.
        Work-around for MaskedArray initialization.

        Allows the base class to be inferred correctly when a masked instance
        is used to initialize (or viewed as) a `~numpy.ma.MaskedArray`.

        New view of the masked array.

        Like `numpy.ndarray.view`, but always returning a masked array subclass.
         cannot be viewed with a dtype with a different number of fields or size." cannot be viewed with a dtype ""with a different number of fields or size."super_array_finalizeThe shape of the data and the mask.

        Usually used to get the current shape of an array, but may also be
        used to reshape the array in-place by assigning a tuple of array
        dimensions to it.  As with `numpy.reshape`, one of the new shape
        dimensions can be -1, in which case its value is inferred from the
        size of the array and the remaining dimensions.

        Raises
        ------
        AttributeError
            If a copy is required, of either the data or the mask.

        old_shapecould not broadcastIncompatible shape for in-place modification. Use `.reshape()` to make a copy with the desired shape."Incompatible shape for in-place modification. ""Use `.reshape()` to make a copy with the desired ""shape."_eq_simple_ne_simple_get_data_and_masksExtracts the data and masks from the given arrays.

        Parameters
        ----------
        arrays : iterable of array
            An iterable of arrays, possibly masked.

        Returns
        -------
        datas, masks: tuple of array
            Extracted data and mask arrays. For any input array without
            a mask, the corresponding entry in ``masks`` is `None`.
        data_masksout_maskout_masksout_unmaskedcannot write to unmasked outputwhere_unmaskedwhere_maskmatmulnan_masksfloat16m_kwargslibfunction_base_parse_gufunc_signaturein_sigout_sig_function_base_implnargskeepdimsin_masksresult_masksomaskm0m1masked instances cannot yet deal with 'reduceat' or 'at'.__array_function__helper_result_not_implemented_or_raisedata_argsmask_argsdispatched_functiondispatched_resultthe MaskedNDArray implementation cannot handle  with the given arguments."with the given arguments."result_mask_out___array_wrap__ should not be used with a context any more since all use should go through array_function. Please raise an issue on https://github.com/astropy/astropy"__array_wrap__ should not be used with a context any more since all use ""should go through array_function. Please raise an issue on "_reduce_defaultsinitial_funcGet default where and initial for masked reductions.

        Generally, the default should be to skip all masked elements.  For
        reductions such as np.minimum.reduce, we also need an initial value,
        which can be determined using ``initial_func``.

        initialtraceaxis1axis2diagonalptpunmasked_nonzeronot_maskedconditioncannot yet give outputrepeatschoosechoicesargminat_minat_maxargsortReturns the indices that would sort an array.

        Perform an indirect sort along the given axis on both the array
        and the mask, with masked items being sorted to the end.

        Parameters
        ----------
        axis : int or None, optional
            Axis along which to sort.  The default is -1 (the last axis).
            If None, the flattened array is used.
        kind : str or None, ignored.
            The kind of sort.  Present only to allow subclasses to work.
        order : str or list of str.
            For an array with fields defined, the fields to compare first,
            second, etc.  A single field can be specified as a string, and not
            all fields need be specified, but unspecified fields will still be
            used, in dtype order, to break ties.
        stable: bool, keyword-only, ignored
            Sort stability. Present only to allow subclasses to work.

        Returns
        -------
        index_array : ndarray, int
            Array of indices that sorts along the specified ``axis``.  Use
            ``np.take_along_axis(self, index_array, axis=axis)`` to obtain
            the sorted array.

        _internal_newnamesCannot specify order when the array has no fields.lexsortSort an array in-place. Refer to `numpy.sort` for full documentation.

        Notes
        -----
        Masked items will be sorted to the end. The implementation
        is via `numpy.lexsort` and thus ignores the ``kind`` and ``stable`` arguments;
        they are present only so that subclasses can pass them on.
        argsort_kwargstake_along_axisargpartitionintroselectkthcumprodReturn an array whose values are limited to ``[min, max]``.

        Like `~numpy.clip`, but any masked values in ``min`` and ``max``
        are ignored for clipping.  The mask of the input array is propagated.
        dminmmindmaxmmaxmasked_outis_float16_resultneq0varddofwhere_finalstdarray_strarray_reprMaskedRecarrayInfomasked_ndarrayMaskedRecarraygetfieldcan only get existing field from structured dtype.setfieldcan only set existing field from structured dtype.out0extra_spaceMake commonly used Masked subclasses importable for ASDF support.

    Registered types associated with ASDF converters must be importable by
    their fully qualified name. Masked classes are dynamically created and have
    apparent names like ``astropy.utils.masked.core.MaskedQuantity`` although
    they aren't actually attributes of this module. Customize module attribute
    lookup so that certain commonly used Masked classes are importable.

    See:
    - https://asdf.readthedocs.io/en/latest/asdf/extending/converters.html#entry-point-performance-considerations
    - https://github.com/astropy/asdf-astropy/pull/253
    astropy.table.serialize__construct_mixin_classesbase_class_namebase_class_qualnamebase_classmasked_classmodule '' has no attribute '# We use the private _data attribute here since MaskedColumn# overrides the normal ".data".# Simplify masks, by removing empty ones and combining possible fields.# Use copyto to deal with broadcasting with `where`.# Initializing with Masked itself means we're in "factory mode".# Create a new masked class.# Otherwise we're a subclass and should just pass information on.# This base implementation just uses the class initializer.# Subclasses can override this in case the class does not work# with this signature, or to provide a faster implementation.# Walk through MRO and find closest base data class.# Note: right now, will basically always be ndarray, but# one could imagine needing some special care for one subclass,# which would then get its own entry.  E.g., if MaskedAngle# defined something special, then MaskedLongitude should depend# on it.# Just hope that MaskedNDArray can handle it.# TODO: this covers the case where a user puts in a list or so,# but for those one could just explicitly do something like# _masked_classes[list] = MaskedNDArray.# Create (and therefore register) new Masked subclass for the# given data_cls.# This will fail (correctly) if not broadcastable.# Even if not copying use a view so that shape setting# does not propagate.# Note: subclass should generally override the unmasked property.# This one assumes the unmasked data is stored in a private attribute.# Required method for NDArrayShapeMethods, to help provide __getitem__# and shape-changing methods.# Add `serialize_method` attribute to the attrs that MaskedNDArrayInfo knows# are any masked values.  This is the same as for MaskedColumn.# Override usual handling, since MaskedNDArray takes shape and buffer# as input, which is less useful here.# The map can contain either a MaskedColumn or a Column and a mask.# Extract the mask for the former case.# This is used below in __init_subclass__, which also inserts a# 'serialize_method' attribute in attr_names.# Use the data_cls as the class name for serialization,# so that we do not have to store all possible masked classes# in astropy.table.serialize.__construct_mixin_classes.# For single elements, ndarray.flat.__getitem__ returns scalars; these# need a new view as a Masked array.# For all subclasses we should set a default __new__ that passes on# arguments other than mask to the data class, and then sets the mask.# Need to explicitly mention classes outside of class definition.# The two pieces typically overridden.# Note: have to override since __new__ would use ndarray.__new__# which expects the shape as its first argument, not an array.# Short-cuts# for .view()# Mask should be viewed in all but simplest case.# If we're a new object or viewing an ndarray, nothing has to be done.# Logically, this should come from ndarray and hence be None, but# just in case someone creates a new mixin, we check.# Got here after, e.g., a view of another masked class.# Get its mask, or initialize ours.# Redefinition to allow defining a setter and add a docstring.# Reshape array proper in try/except just in case some broadcasting# or so causes it to fail.# Given that the mask reshaping succeeded, the only logical# reason for an exception is something like a broadcast error in# in __array_finalize__, or a different memory ordering between# mask and data.  For those, give a more useful error message;# otherwise just raise the error.# For structured arrays, we treat this as a reduction over the fields,# where masked fields are skipped and thus do not influence the result.# Get inputs and there masks.# Deal with possible outputs and their masks.# TODO: allow writing to unmasked output if nothing is masked?# TODO: where is only needed for __call__ and reduce;# this is very fast, but still worth separating out?# First calculate the unmasked result. This will also verify kwargs.# It will raise if the arguments do not know how to deal with each other.# We're dealing with a gufunc. For now, only deal with# np.matmul and gufuncs for which the mask of any output always# depends on all core dimension values of all inputs.# TODO: in principle, it should be possible to generate the mask# purely based on the signature.# np.matmul is tricky and its signature cannot be parsed by# _parse_gufunc_signature.  But we can calculate the mask# with matmul by using that nan will propagate correctly.# We use float16 to minimize the memory requirements.# Parse signature with private numpy function. Note it# cannot handle spaces in tuples, so remove those.# Maybe axis was given? (Note: ufunc will not take both.)# All outputs have no core dimensions, which means axes# is not needed, but add None's for the zip below.# not inplace!# Input has core dimensions.  Assume that if any# value in those is masked, the output will be# masked too (TODO: for multiple core dimensions# this may be too strong).# Special-case where possible in-place is easy.# Here, some masks may need expansion, so we forego in-place.# Output has core dimensions.  Assume all those# get the same mask.# Regular ufunc call.# Combine the masks from the input, possibly selecting elements.# If relevant, also mask output elements for which where was masked.# Check for any additional explicitly given outputs.# Must have two inputs and one output, so also only one output mask.# Adjust masks as will be done for data.# Reductions like np.add.reduce (sum).# Treat any masked where as if the input element was masked.# This is too complicated, just fall through to below.# By default, we simply propagate masks, since for# things like np.sum, it makes no sense to do otherwise.# Individual methods need to override as needed.# Mask also whole rows in which no elements were selected;# those will have been left as unmasked above.# Accumulate# Can only get here if neither input nor output was masked, but# perhaps where was masked (possible in "not NUMPY_LT_1_25").# We don't support this.# This happens for the "at" method.# TODO: go through functions systematically to see which ones# work and/or can be supported.# By default, just pass it through for now.# Our function helper or dispatcher found that the function does not# work with Masked.  In principle, there may be another class that# knows what to do with us, for which we should return NotImplemented.# But if there is ndarray (or a non-Masked subclass of it) around,# it quite likely coerces, so we should just break.# Note that we cannot count on result being the same class as# 'self' (e.g., comparison of quantity results in an ndarray, most# operations on Longitude and Latitude result in Angle or# Quantity), so use Masked to determine the appropriate class.# TODO: remove this sanity check once test cases are more complete.# For inplace, the mask will have been set already.# Functions like np.ediff1d call __array_wrap__ to turn the array# into self's subclass.# Below are ndarray methods that need to be overridden as masked elements# need to be skipped and/or an initial value needs to be set.# Unfortunately, cannot override the call to diagonal inside trace, so# duplicate implementation in numpy/core/src/multiarray/calculation.c.# Let __array_function__ take care since choices can be masked too.# TODO: should this return a masked integer array, with masks# if all elements were masked?# As done inside the argsort implementation in multiarray/methods.c.# TODO: probably possible to do this faster than going through argsort!# TODO: should be possible to do this faster than with a full argsort!# TODO: implement this at the ufunc level.# Fast path for unmasked max, min.# Implementation based on that in numpy/core/_methods.py# Cast bool, unsigned int, and int to float64 by default,# and do float16 at higher precision.# catch the case when an axis is fully masked to prevent div by zero:# correct fully-masked slice results to what is expected for 0/0 division# Simplified implementation based on that in numpy/core/_methods.py# Cast bool, unsigned int, and int to float64 by default.# Conjugate just returns x if not complex.# First get result from array itself; this will error if not a scalar.# Following overrides needed since somehow the ndarray implementation# does not actually call these.# Try to be somewhat like a numpy array scalar if possible.# Will raise regular ndarray error.# Ensure that we output a plain MaskedArray, not a masked_recarray.# Explicit definition since we need to override some methods.# recarray.__array_finalize__ does not do super, so we do it# explicitly.# __getattribute__, __setattr__, and field use these somewhat# obscrure ndarray methods.  TODO: override in MaskedNDArray?# TODO: avoid using a private attribute from table.# Can we make this more beautiful?# Try creating the masked class# But only return it if it is a standard one, not one# where we just used the ndarray fallback.b'
Built-in mask mixin class.

The design uses `Masked` as a factory class which automatically
generates new subclasses for any data class that is itself a
subclass of a predefined masked class, with `MaskedNDArray`
providing such a predefined class for `~numpy.ndarray`.

Generally, any new predefined class should override the
``from_unmasked(data, mask, copy=False)`` class method that
creates an instance from unmasked data and a mask, as well as
the ``unmasked`` property that returns just the data.
The `Masked` class itself provides a base ``mask`` property,
which can also be overridden if needed.

'u'
Built-in mask mixin class.

The design uses `Masked` as a factory class which automatically
generates new subclasses for any data class that is itself a
subclass of a predefined masked class, with `MaskedNDArray`
providing such a predefined class for `~numpy.ndarray`.

Generally, any new predefined class should override the
``from_unmasked(data, mask, copy=False)`` class method that
creates an instance from unmasked data and a mask, as well as
the ``unmasked`` property that returns just the data.
The `Masked` class itself provides a base ``mask`` property,
which can also be overridden if needed.

'b'MaskableShapedLikeNDArray'u'MaskableShapedLikeNDArray'b'MaskedNDArray'u'MaskedNDArray'b'combine_masks'u'combine_masks'b'get_data_and_mask'u'get_data_and_mask'b'Masked version of {0.__name__}.

Except for the ability to pass in a ``mask``, parameters are
as for `{0.__module__}.{0.__name__}`.
'u'Masked version of {0.__name__}.

Except for the ability to pass in a ``mask``, parameters are
as for `{0.__module__}.{0.__name__}`.
'b'Split possibly masked array into unmasked and mask.

    Parameters
    ----------
    array : array-like
        Possibly masked item, judged by whether it has a ``mask`` attribute.
        If so, checks for having an ``unmasked`` attribute (as expected for
        instances of `~astropy.utils.masked.Masked`), or uses the ``_data``
        attribute if the inpuit is an instance of `~numpy.ma.MaskedArray`.

    Returns
    -------
    unmasked, mask : array-like
        If the input array had no mask, this will be ``array, None``.

    Raises
    ------
    AttributeError
        If ``array`` has a ``mask`` but not an ``unmasked`` attribute, and
        is not an instance of `~numpy.ma.MaskedArray`.
    ValueError
        If ``array`` is ``np.ma.masked`` (since it has no data).

    'u'Split possibly masked array into unmasked and mask.

    Parameters
    ----------
    array : array-like
        Possibly masked item, judged by whether it has a ``mask`` attribute.
        If so, checks for having an ``unmasked`` attribute (as expected for
        instances of `~astropy.utils.masked.Masked`), or uses the ``_data``
        attribute if the inpuit is an instance of `~numpy.ma.MaskedArray`.

    Returns
    -------
    unmasked, mask : array-like
        If the input array had no mask, this will be ``array, None``.

    Raises
    ------
    AttributeError
        If ``array`` has a ``mask`` but not an ``unmasked`` attribute, and
        is not an instance of `~numpy.ma.MaskedArray`.
    ValueError
        If ``array`` is ``np.ma.masked`` (since it has no data).

    'b'' object has a 'mask' attribute but not an 'unmasked' attribute (and is not an np.ma.MaskedArray instance).'u'' object has a 'mask' attribute but not an 'unmasked' attribute (and is not an np.ma.MaskedArray instance).'b'cannot handle np.ma.masked.'u'cannot handle np.ma.masked.'b'Combine masks, possibly storing it in some output.

    Parameters
    ----------
    masks : tuple of array of bool or False or None
        Input masks.  Any that are `None` or `False` are ignored.
        Should broadcast to each other.  For structured dtype,
        an element is considered masked if any of the fields is.
    out : array, optional
        Possible output array to hold the result.
    where : array of bool, optional
        Which elements of the output array to fill.
    copy : bool optional
        Whether to ensure a copy is made. Only relevant if just a
        single input mask is not `None`, and ``out`` is not given.

    Returns
    -------
    mask : array
        Combined mask.
    'u'Combine masks, possibly storing it in some output.

    Parameters
    ----------
    masks : tuple of array of bool or False or None
        Input masks.  Any that are `None` or `False` are ignored.
        Should broadcast to each other.  For structured dtype,
        an element is considered masked if any of the fields is.
    out : array, optional
        Possible output array to hold the result.
    where : array of bool, optional
        Which elements of the output array to fill.
    copy : bool optional
        Whether to ensure a copy is made. Only relevant if just a
        single input mask is not `None`, and ``out`` is not given.

    Returns
    -------
    mask : array
        Combined mask.
    'b'A scalar value or array of values with associated mask.

    The resulting instance will take its exact type from whatever the
    contents are, with the type generated on the fly as needed.

    Parameters
    ----------
    data : array-like
        The data for which a mask is to be added.  The result will be a
        a subclass of the type of ``data``.
    mask : array-like of bool, optional
        The initial mask to assign.  If not given, taken from the data.
        If the data already has a mask, the masks are combined.
    copy : bool
        Whether the data and mask should be copied. Default: `False`.

    'u'A scalar value or array of values with associated mask.

    The resulting instance will take its exact type from whatever the
    contents are, with the type generated on the fly as needed.

    Parameters
    ----------
    data : array-like
        The data for which a mask is to be added.  The result will be a
        a subclass of the type of ``data``.
    mask : array-like of bool, optional
        The initial mask to assign.  If not given, taken from the data.
        If the data already has a mask, the masks are combined.
    copy : bool
        Whether the data and mask should be copied. Default: `False`.

    'b'Explicitly defined masked classes keyed by their unmasked counterparts.

    For subclasses of these unmasked classes, masked counterparts can be generated.
    'u'Explicitly defined masked classes keyed by their unmasked counterparts.

    For subclasses of these unmasked classes, masked counterparts can be generated.
    'b'Masked classes keyed by their unmasked data counterparts.'u'Masked classes keyed by their unmasked data counterparts.'b'Register a Masked subclass.

        Parameters
        ----------
        base_cls : type, optional
            If given, it is taken to mean that ``cls`` can be used as
            a base for masked versions of all subclasses of ``base_cls``,
            so it is registered as such in ``_base_classes``.
        data_cls : type, optional
            If given, ``cls`` should will be registered as the masked version of
            ``data_cls``.  Will set the private ``cls._data_cls`` attribute,
            and auto-generate a docstring if not present already.
        **kwargs
            Passed on for possible further initialization by superclasses.

        'u'Register a Masked subclass.

        Parameters
        ----------
        base_cls : type, optional
            If given, it is taken to mean that ``cls`` can be used as
            a base for masked versions of all subclasses of ``base_cls``,
            so it is registered as such in ``_base_classes``.
        data_cls : type, optional
            If given, ``cls`` should will be registered as the masked version of
            ``data_cls``.  Will set the private ``cls._data_cls`` attribute,
            and auto-generate a docstring if not present already.
        **kwargs
            Passed on for possible further initialization by superclasses.

        'b'Create an instance from unmasked data and a mask.'u'Create an instance from unmasked data and a mask.'b'Get the masked wrapper for a given data class.

        If the data class does not exist yet but is a subclass of any of the
        registered base data classes, it is automatically generated
        (except we skip `~numpy.ma.MaskedArray` subclasses, since then the
        masking mechanisms would interfere).
        'u'Get the masked wrapper for a given data class.

        If the data class does not exist yet but is a subclass of any of the
        registered base data classes, it is automatically generated
        (except we skip `~numpy.ma.MaskedArray` subclasses, since then the
        masking mechanisms would interfere).
        'b'The mask.

        If set, replace the original mask, with whatever it is set with,
        using a view if no broadcasting or type conversion is required.
        'u'The mask.

        If set, replace the original mask, with whatever it is set with,
        using a view if no broadcasting or type conversion is required.
        'b'The unmasked values.

        See Also
        --------
        astropy.utils.masked.Masked.filled
        'u'The unmasked values.

        See Also
        --------
        astropy.utils.masked.Masked.filled
        'b'Get a copy of the underlying data, with masked values filled in.

        Parameters
        ----------
        fill_value : object
            Value to replace masked values with.

        See Also
        --------
        astropy.utils.masked.Masked.unmasked
        'u'Get a copy of the underlying data, with masked values filled in.

        Parameters
        ----------
        fill_value : object
            Value to replace masked values with.

        See Also
        --------
        astropy.utils.masked.Masked.unmasked
        'b'Like ShapedLikeNDArray, but for classes that can work with masked data.

    Defines default unmasked property as well as a filled method, and inherits
    private class methods that help deal with masked inputs.

    Any class using this must provide a masked property, which tells whether
    the underlying data are Masked, as well as a mask property, which
    generally should provide a read-only copy of the underlying mask.

    'u'Like ShapedLikeNDArray, but for classes that can work with masked data.

    Defines default unmasked property as well as a filled method, and inherits
    private class methods that help deal with masked inputs.

    Any class using this must provide a masked property, which tells whether
    the underlying data are Masked, as well as a mask property, which
    generally should provide a read-only copy of the underlying mask.

    'b'Whether or not the instance uses masked values.'u'Whether or not the instance uses masked values.'b'The mask.'u'The mask.'b'Get an instance without the mask.

        Note that while one gets a new instance, the underlying data will be shared.

        See Also
        --------
        filled : get a copy of the underlying data, with masked values filled in.
        'u'Get an instance without the mask.

        Note that while one gets a new instance, the underlying data will be shared.

        See Also
        --------
        filled : get a copy of the underlying data, with masked values filled in.
        'b'Get a copy of the underlying data, with masked values filled in.

        Parameters
        ----------
        fill_value : object
            Value to replace masked values with.

        Returns
        -------
        filled : instance
            Copy of ``self`` with masked items replaced by ``fill_value``.

        See Also
        --------
        unmasked : get an instance without the mask.
        'u'Get a copy of the underlying data, with masked values filled in.

        Parameters
        ----------
        fill_value : object
            Value to replace masked values with.

        Returns
        -------
        filled : instance
            Copy of ``self`` with masked items replaced by ``fill_value``.

        See Also
        --------
        unmasked : get an instance without the mask.
        'b'
    Container for meta information like name, description, format.
    'u'
    Container for meta information like name, description, format.
    'b'Mixin class to create a subclasses such as MaskedQuantityInfo.'u'Mixin class to create a subclasses such as MaskedQuantityInfo.'b'__class__'u'__class__'b'
    Create a comparison operator for MaskedNDArray.

    Needed since for string dtypes the base operators bypass __array_ufunc__
    and hence return unmasked results.
    'u'
    Create a comparison operator for MaskedNDArray.

    Needed since for string dtypes the base operators bypass __array_ufunc__
    and hence return unmasked results.
    'b'
    Flat iterator object to iterate over Masked Arrays.

    A `~astropy.utils.masked.MaskedIterator` iterator is returned by ``m.flat``
    for any masked array ``m``.  It allows iterating over the array as if it
    were a 1-D array, either in a for-loop or by calling its `next` method.

    Iteration is done in C-contiguous style, with the last index varying the
    fastest. The iterator can also be indexed using basic slicing or
    advanced indexing.

    Notes
    -----
    The design of `~astropy.utils.masked.MaskedIterator` follows that of
    `~numpy.ma.core.MaskedIterator`.  It is not exported by the
    `~astropy.utils.masked` module.  Instead of instantiating directly,
    use the ``flat`` method in the masked array instance.
    'u'
    Flat iterator object to iterate over Masked Arrays.

    A `~astropy.utils.masked.MaskedIterator` iterator is returned by ``m.flat``
    for any masked array ``m``.  It allows iterating over the array as if it
    were a 1-D array, either in a for-loop or by calling its `next` method.

    Iteration is done in C-contiguous style, with the last index varying the
    fastest. The iterator can also be indexed using basic slicing or
    advanced indexing.

    Notes
    -----
    The design of `~astropy.utils.masked.MaskedIterator` follows that of
    `~numpy.ma.core.MaskedIterator`.  It is not exported by the
    `~astropy.utils.masked` module.  Instead of instantiating directly,
    use the ``flat`` method in the masked array instance.
    'b'
        Return the next value, or raise StopIteration.
        'u'
        Return the next value, or raise StopIteration.
        'b'Get data class instance from arguments and then set mask.'u'Get data class instance from arguments and then set mask.'b'Info'u'Info'b'A 1-D iterator over the Masked array.

        This returns a ``MaskedIterator`` instance, which behaves the same
        as the `~numpy.flatiter` instance returned by `~numpy.ndarray.flat`,
        and is similar to Python's built-in iterator, except that it also
        allows assignment.
        'u'A 1-D iterator over the Masked array.

        This returns a ``MaskedIterator`` instance, which behaves the same
        as the `~numpy.flatiter` instance returned by `~numpy.ndarray.flat`,
        and is similar to Python's built-in iterator, except that it also
        allows assignment.
        'b'Work-around for MaskedArray initialization.

        Allows the base class to be inferred correctly when a masked instance
        is used to initialize (or viewed as) a `~numpy.ma.MaskedArray`.

        'u'Work-around for MaskedArray initialization.

        Allows the base class to be inferred correctly when a masked instance
        is used to initialize (or viewed as) a `~numpy.ma.MaskedArray`.

        'b'New view of the masked array.

        Like `numpy.ndarray.view`, but always returning a masked array subclass.
        'u'New view of the masked array.

        Like `numpy.ndarray.view`, but always returning a masked array subclass.
        'b' cannot be viewed with a dtype with a different number of fields or size.'u' cannot be viewed with a dtype with a different number of fields or size.'b'_mask'u'_mask'b'The shape of the data and the mask.

        Usually used to get the current shape of an array, but may also be
        used to reshape the array in-place by assigning a tuple of array
        dimensions to it.  As with `numpy.reshape`, one of the new shape
        dimensions can be -1, in which case its value is inferred from the
        size of the array and the remaining dimensions.

        Raises
        ------
        AttributeError
            If a copy is required, of either the data or the mask.

        'u'The shape of the data and the mask.

        Usually used to get the current shape of an array, but may also be
        used to reshape the array in-place by assigning a tuple of array
        dimensions to it.  As with `numpy.reshape`, one of the new shape
        dimensions can be -1, in which case its value is inferred from the
        size of the array and the remaining dimensions.

        Raises
        ------
        AttributeError
            If a copy is required, of either the data or the mask.

        'b'could not broadcast'u'could not broadcast'b'Incompatible shape for in-place modification. Use `.reshape()` to make a copy with the desired shape.'u'Incompatible shape for in-place modification. Use `.reshape()` to make a copy with the desired shape.'b'Extracts the data and masks from the given arrays.

        Parameters
        ----------
        arrays : iterable of array
            An iterable of arrays, possibly masked.

        Returns
        -------
        datas, masks: tuple of array
            Extracted data and mask arrays. For any input array without
            a mask, the corresponding entry in ``masks`` is `None`.
        'u'Extracts the data and masks from the given arrays.

        Parameters
        ----------
        arrays : iterable of array
            An iterable of arrays, possibly masked.

        Returns
        -------
        datas, masks: tuple of array
            Extracted data and mask arrays. For any input array without
            a mask, the corresponding entry in ``masks`` is `None`.
        'b'cannot write to unmasked output'u'cannot write to unmasked output'b'where'u'where'b'axes'u'axes'b'axis'u'axis'b'keepdims'u'keepdims'b'masked instances cannot yet deal with 'reduceat' or 'at'.'u'masked instances cannot yet deal with 'reduceat' or 'at'.'b'the MaskedNDArray implementation cannot handle 'u'the MaskedNDArray implementation cannot handle 'b' with the given arguments.'u' with the given arguments.'b'__array_wrap__ should not be used with a context any more since all use should go through array_function. Please raise an issue on https://github.com/astropy/astropy'u'__array_wrap__ should not be used with a context any more since all use should go through array_function. Please raise an issue on https://github.com/astropy/astropy'b'Get default where and initial for masked reductions.

        Generally, the default should be to skip all masked elements.  For
        reductions such as np.minimum.reduce, we also need an initial value,
        which can be determined using ``initial_func``.

        'u'Get default where and initial for masked reductions.

        Generally, the default should be to skip all masked elements.  For
        reductions such as np.minimum.reduce, we also need an initial value,
        which can be determined using ``initial_func``.

        'b'initial'u'initial'b'cannot yet give output'u'cannot yet give output'b'compress'u'compress'b'Returns the indices that would sort an array.

        Perform an indirect sort along the given axis on both the array
        and the mask, with masked items being sorted to the end.

        Parameters
        ----------
        axis : int or None, optional
            Axis along which to sort.  The default is -1 (the last axis).
            If None, the flattened array is used.
        kind : str or None, ignored.
            The kind of sort.  Present only to allow subclasses to work.
        order : str or list of str.
            For an array with fields defined, the fields to compare first,
            second, etc.  A single field can be specified as a string, and not
            all fields need be specified, but unspecified fields will still be
            used, in dtype order, to break ties.
        stable: bool, keyword-only, ignored
            Sort stability. Present only to allow subclasses to work.

        Returns
        -------
        index_array : ndarray, int
            Array of indices that sorts along the specified ``axis``.  Use
            ``np.take_along_axis(self, index_array, axis=axis)`` to obtain
            the sorted array.

        'u'Returns the indices that would sort an array.

        Perform an indirect sort along the given axis on both the array
        and the mask, with masked items being sorted to the end.

        Parameters
        ----------
        axis : int or None, optional
            Axis along which to sort.  The default is -1 (the last axis).
            If None, the flattened array is used.
        kind : str or None, ignored.
            The kind of sort.  Present only to allow subclasses to work.
        order : str or list of str.
            For an array with fields defined, the fields to compare first,
            second, etc.  A single field can be specified as a string, and not
            all fields need be specified, but unspecified fields will still be
            used, in dtype order, to break ties.
        stable: bool, keyword-only, ignored
            Sort stability. Present only to allow subclasses to work.

        Returns
        -------
        index_array : ndarray, int
            Array of indices that sorts along the specified ``axis``.  Use
            ``np.take_along_axis(self, index_array, axis=axis)`` to obtain
            the sorted array.

        'b'Cannot specify order when the array has no fields.'u'Cannot specify order when the array has no fields.'b'Sort an array in-place. Refer to `numpy.sort` for full documentation.

        Notes
        -----
        Masked items will be sorted to the end. The implementation
        is via `numpy.lexsort` and thus ignores the ``kind`` and ``stable`` arguments;
        they are present only so that subclasses can pass them on.
        'u'Sort an array in-place. Refer to `numpy.sort` for full documentation.

        Notes
        -----
        Masked items will be sorted to the end. The implementation
        is via `numpy.lexsort` and thus ignores the ``kind`` and ``stable`` arguments;
        they are present only so that subclasses can pass them on.
        'b'introselect'u'introselect'b'Return an array whose values are limited to ``[min, max]``.

        Like `~numpy.clip`, but any masked values in ``min`` and ``max``
        are ignored for clipping.  The mask of the input array is propagated.
        'u'Return an array whose values are limited to ``[min, max]``.

        Like `~numpy.clip`, but any masked values in ``min`` and ``max``
        are ignored for clipping.  The mask of the input array is propagated.
        'u''b'can only get existing field from structured dtype.'u'can only get existing field from structured dtype.'b'can only set existing field from structured dtype.'u'can only set existing field from structured dtype.'b'Make commonly used Masked subclasses importable for ASDF support.

    Registered types associated with ASDF converters must be importable by
    their fully qualified name. Masked classes are dynamically created and have
    apparent names like ``astropy.utils.masked.core.MaskedQuantity`` although
    they aren't actually attributes of this module. Customize module attribute
    lookup so that certain commonly used Masked classes are importable.

    See:
    - https://asdf.readthedocs.io/en/latest/asdf/extending/converters.html#entry-point-performance-considerations
    - https://github.com/astropy/asdf-astropy/pull/253
    'u'Make commonly used Masked subclasses importable for ASDF support.

    Registered types associated with ASDF converters must be importable by
    their fully qualified name. Masked classes are dynamically created and have
    apparent names like ``astropy.utils.masked.core.MaskedQuantity`` although
    they aren't actually attributes of this module. Customize module attribute
    lookup so that certain commonly used Masked classes are importable.

    See:
    - https://asdf.readthedocs.io/en/latest/asdf/extending/converters.html#entry-point-performance-considerations
    - https://github.com/astropy/asdf-astropy/pull/253
    'b'module ''u'module ''b'' has no attribute ''u'' has no attribute ''u'astropy.utils.masked.core'u'utils.masked.core'u'masked.core'Main Lomb-Scargle Implementation._statisticsimplementationsimplementations.mleperiodic_fithas_unitsget_unitstrip_unitsarrsCompute the Lomb-Scargle Periodogram.

    This implementations here are based on code presented in [1]_ and [2]_;
    if you use this functionality in an academic application, citation of
    those works would be appreciated.

    Parameters
    ----------
    t : array-like or `~astropy.units.Quantity` ['time']
        sequence of observation times
    y : array-like or `~astropy.units.Quantity`
        sequence of observations associated with times t
    dy : float, array-like, or `~astropy.units.Quantity`, optional
        error or sequence of observational errors associated with times t
    fit_mean : bool, optional
        if True, include a constant offset as part of the model at each
        frequency. This can lead to more accurate results, especially in the
        case of incomplete phase coverage.
    center_data : bool, optional
        if True, pre-center the data by subtracting the weighted mean
        of the input data. This is especially important if fit_mean = False
    nterms : int, optional
        number of terms to use in the Fourier fit
    normalization : {'standard', 'model', 'log', 'psd'}, optional
        Normalization to use for the periodogram.

    Examples
    --------
    Generate noisy periodic data:

    >>> rand = np.random.default_rng(42)
    >>> t = 100 * rand.random(100)
    >>> y = np.sin(2 * np.pi * t) + rand.standard_normal(100)

    Compute the Lomb-Scargle periodogram on an automatically-determined
    frequency grid & find the frequency of max power:

    >>> frequency, power = LombScargle(t, y).autopower()
    >>> frequency[np.argmax(power)]  # doctest: +FLOAT_CMP
    np.float64(1.0007641728995051)

    Compute the Lomb-Scargle periodogram at a user-specified frequency grid:

    >>> freq = np.arange(0.8, 1.3, 0.1)
    >>> LombScargle(t, y).power(freq)  # doctest: +FLOAT_CMP
    array([0.0792948 , 0.01778874, 0.25328167, 0.01064157, 0.01471387])

    If the inputs are astropy Quantities with units, the units will be
    validated and the outputs will also be Quantities with appropriate units:

    >>> from astropy import units as u
    >>> t = t * u.s
    >>> y = y * u.mag
    >>> frequency, power = LombScargle(t, y).autopower()
    >>> frequency.unit
    Unit("1 / s")
    >>> power.unit
    Unit(dimensionless)

    Note here that the Lomb-Scargle power is always a unitless quantity,
    because it is related to the :math:`\chi^2` of the best-fit periodic
    model at each frequency.

    References
    ----------
    .. [1] Vanderplas, J., Connolly, A. Ivezic, Z. & Gray, A. *Introduction to
        astroML: Machine learning for astrophysics*. Proceedings of the
        Conference on Intelligent Data Understanding (2012)
    .. [2] VanderPlas, J. & Ivezic, Z. *Periodograms for Multiband Astronomical
        Time Series*. ApJ 812.1:18 (2015)
    _tstarttrel_validate_inputs_trelInputs (t, y, dy) must be 1-dimensionalUnits of dy not equivalent to units of y_validate_frequencyUnits of frequency not equivalent to units of 1/tfrequency have units while 1/t doesn't._validate_tUnits of t not equivalent to units of input self.t_power_unitautofrequencysamples_per_peaknyquist_factorminimum_frequencyreturn_freq_limitsDetermine a suitable frequency grid for data.

        Note that this assumes the peak width is driven by the observational
        baseline, which is generally a good assumption when the baseline is
        much larger than the oscillation period.
        If you are searching for periods longer than the baseline of your
        observations, this may not perform well.

        Even with a large baseline, be aware that the maximum frequency
        returned is based on the concept of "average Nyquist frequency", which
        may not be useful for irregularly-sampled data. The maximum frequency
        can be adjusted via the nyquist_factor argument, or through the
        maximum_frequency argument.

        Parameters
        ----------
        samples_per_peak : float, optional
            The approximate number of desired samples across the typical peak
        nyquist_factor : float, optional
            The multiple of the average nyquist frequency used to choose the
            maximum frequency if maximum_frequency is not provided.
        minimum_frequency : float, optional
            If specified, then use this minimum frequency rather than one
            chosen based on the size of the baseline.
        maximum_frequency : float, optional
            If specified, then use this maximum frequency rather than one
            chosen based on the average nyquist frequency.
        return_freq_limits : bool, optional
            if True, return only the frequency limits rather than the full
            frequency grid.

        Returns
        -------
        frequency : ndarray or `~astropy.units.Quantity` ['frequency']
            The heuristically-determined optimal frequency bin
        baselineavg_nyquistNfCompute Lomb-Scargle power at automatically-determined frequencies.

        Parameters
        ----------
        method : str, optional
            specify the lomb scargle implementation to use. Options are:

            - 'auto': choose the best method based on the input
            - 'fast': use the O[N log N] fast method. Note that this requires
              evenly-spaced frequencies: by default this will be checked unless
              ``assume_regular_frequency`` is set to True.
            - 'slow': use the O[N^2] pure-python implementation
            - 'cython': use the O[N^2] cython implementation. This is slightly
              faster than method='slow', but much more memory efficient.
            - 'chi2': use the O[N^2] chi2/linear-fitting implementation
            - 'fastchi2': use the O[N log N] chi2 implementation. Note that this
              requires evenly-spaced frequencies: by default this will be checked
              unless ``assume_regular_frequency`` is set to True.
            - 'scipy': use ``scipy.signal.lombscargle``, which is an O[N^2]
              implementation written in C. Note that this does not support
              heteroskedastic errors.

        method_kwds : dict, optional
            additional keywords to pass to the lomb-scargle method
        normalization : {'standard', 'model', 'log', 'psd'}, optional
            If specified, override the normalization specified at instantiation.
        samples_per_peak : float, optional
            The approximate number of desired samples across the typical peak
        nyquist_factor : float, optional
            The multiple of the average nyquist frequency used to choose the
            maximum frequency if maximum_frequency is not provided.
        minimum_frequency : float or `~astropy.units.Quantity` ['frequency'], optional
            If specified, then use this minimum frequency rather than one
            chosen based on the size of the baseline. Should be `~astropy.units.Quantity`
            if inputs to LombScargle are `~astropy.units.Quantity`.
        maximum_frequency : float or `~astropy.units.Quantity` ['frequency'], optional
            If specified, then use this maximum frequency rather than one
            chosen based on the average nyquist frequency. Should be `~astropy.units.Quantity`
            if inputs to LombScargle are `~astropy.units.Quantity`.

        Returns
        -------
        frequency, power : ndarray
            The frequency and Lomb-Scargle power
        assume_regular_frequencyCompute the Lomb-Scargle power at the given frequencies.

        Parameters
        ----------
        frequency : array-like or `~astropy.units.Quantity` ['frequency']
            frequencies (not angular frequencies) at which to evaluate the
            periodogram. Note that in order to use method='fast', frequencies
            must be regularly-spaced.
        method : str, optional
            specify the lomb scargle implementation to use. Options are:

            - 'auto': choose the best method based on the input
            - 'fast': use the O[N log N] fast method. Note that this requires
              evenly-spaced frequencies: by default this will be checked unless
              ``assume_regular_frequency`` is set to True.
            - 'slow': use the O[N^2] pure-python implementation
            - 'cython': use the O[N^2] cython implementation. This is slightly
              faster than method='slow', but much more memory efficient.
            - 'chi2': use the O[N^2] chi2/linear-fitting implementation
            - 'fastchi2': use the O[N log N] chi2 implementation. Note that this
              requires evenly-spaced frequencies: by default this will be checked
              unless ``assume_regular_frequency`` is set to True.
            - 'scipy': use ``scipy.signal.lombscargle``, which is an O[N^2]
              implementation written in C. Note that this does not support
              heteroskedastic errors.

        assume_regular_frequency : bool, optional
            if True, assume that the input frequency is of the form
            freq = f0 + df * np.arange(N). Only referenced if method is 'auto'
            or 'fast'.
        normalization : {'standard', 'model', 'log', 'psd'}, optional
            If specified, override the normalization specified at instantiation.

        method_kwds : dict, optional
            additional keywords to pass to the lomb-scargle method

        Returns
        -------
        power : ndarray
            The Lomb-Scargle power at the specified frequency
        _as_relative_time
        Convert the provided times (if absolute) to relative times using the
        current _tstart value. If the times provided are relative, they are
        returned without conversion (though we still do some checks).
         was provided as an absolute time but the LombScargle class was initialized with relative times." was provided as an absolute time but ""the LombScargle class was initialized ""with relative times." was provided as a relative time but the LombScargle class was initialized with absolute times." was provided as a relative time but ""with absolute times."Compute the Lomb-Scargle model at the given frequency.

        The model at a particular frequency is a linear model:
        model = offset + dot(design_matrix, model_parameters)

        Parameters
        ----------
        t : array-like or `~astropy.units.Quantity` ['time']
            Times (length ``n_samples``) at which to compute the model.
        frequency : float
            the frequency for the model

        Returns
        -------
        y : np.ndarray
            The model fit corresponding to the input times
            (will have length ``n_samples``).

        See Also
        --------
        design_matrix
        offset
        model_parameters
        t_fity_fitReturn the offset of the model.

        The offset of the model is the (weighted) mean of the y values.
        Note that if self.center_data is False, the offset is 0 by definition.

        Returns
        -------
        offset : scalar

        See Also
        --------
        design_matrix
        model
        model_parameters
        y_meanmodel_parametersCompute the best-fit model parameters at the given frequency.

        The model described by these parameters is:

        .. math::

            y(t; f, \vec{\theta}) = \theta_0 + \sum_{n=1}^{\tt nterms} [\theta_{2n-1}\sin(2\pi n f t) + \theta_{2n}\cos(2\pi n f t)]

        where :math:`\vec{\theta}` is the array of parameters returned by this function.

        Parameters
        ----------
        frequency : float
            the frequency for the model
        units : bool
            If True (default), return design matrix with data units.

        Returns
        -------
        theta : np.ndarray (n_parameters,)
            The best-fit model parameters at the given frequency.

        See Also
        --------
        design_matrix
        model
        offset
        Compute the design matrix for a given frequency.

        Parameters
        ----------
        frequency : float
            the frequency for the model
        t : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time` (optional)
            Times (length ``n_samples``) at which to compute the model.
            If not specified, then the times and uncertainties of the input
            data are used.

        Returns
        -------
        X : array
            The design matrix for the model at the given frequency.
            This should have a shape of (``len(t)``, ``n_parameters``).

        See Also
        --------
        model
        model_parameters
        offset
        cumulativeExpected periodogram distribution under the null hypothesis.

        This computes the expected probability distribution or cumulative
        probability distribution of periodogram power, under the null
        hypothesis of a non-varying signal with Gaussian noise. Note that
        this is not the same as the expected distribution of peak values;
        for that see the ``false_alarm_probability()`` method.

        Parameters
        ----------
        power : array-like
            The periodogram power at which to compute the distribution.
        cumulative : bool, optional
            If True, then return the cumulative distribution.

        See Also
        --------
        false_alarm_probability
        false_alarm_level

        Returns
        -------
        dist : np.ndarray
            The probability density or cumulative probability associated with
            the provided powers.
        False alarm probability of periodogram maxima under the null hypothesis.

        This gives an estimate of the false alarm probability given the height
        of the largest peak in the periodogram, based on the null hypothesis
        of non-varying data with Gaussian noise.

        Parameters
        ----------
        power : array-like
            The periodogram value.
        method : {'baluev', 'davies', 'naive', 'bootstrap'}, optional
            The approximation method to use.
        maximum_frequency : float
            The maximum frequency of the periodogram.
        method_kwds : dict, optional
            Additional method-specific keywords.

        Returns
        -------
        false_alarm_probability : np.ndarray
            The false alarm probability

        Notes
        -----
        The true probability distribution for the largest peak cannot be
        determined analytically, so each method here provides an approximation
        to the value. The available methods are:

        - "baluev" (default): the upper-limit to the alias-free probability,
          using the approach of Baluev (2008) [1]_.
        - "davies" : the Davies upper bound from Baluev (2008) [1]_.
        - "naive" : the approximate probability based on an estimated
          effective number of independent frequencies.
        - "bootstrap" : the approximate probability based on bootstrap
          resamplings of the input data.

        Note also that for normalization='psd', the distribution can only be
        computed for periodograms constructed with errors specified.

        See Also
        --------
        distribution
        false_alarm_level

        References
        ----------
        .. [1] Baluev, R.V. MNRAS 385, 1279 (2008)
        false alarm probability is not implemented for multiterm periodograms.false alarm probability is implemented only for periodograms of centered data."false alarm probability is implemented ""only for periodograms of centered data."fminLevel of maximum at a given false alarm probability.

        This gives an estimate of the periodogram level corresponding to a
        specified false alarm probability for the largest peak, assuming a
        null hypothesis of non-varying data with Gaussian noise.

        Parameters
        ----------
        false_alarm_probability : array-like
            The false alarm probability (0 < fap < 1).
        maximum_frequency : float
            The maximum frequency of the periodogram.
        method : {'baluev', 'davies', 'naive', 'bootstrap'}, optional
            The approximation method to use; default='baluev'.
        method_kwds : dict, optional
            Additional method-specific keywords.

        Returns
        -------
        power : np.ndarray
            The periodogram peak height corresponding to the specified
            false alarm probability.

        Notes
        -----
        The true probability distribution for the largest peak cannot be
        determined analytically, so each method here provides an approximation
        to the value. The available methods are:

        - "baluev" (default): the upper-limit to the alias-free probability,
          using the approach of Baluev (2008) [1]_.
        - "davies" : the Davies upper bound from Baluev (2008) [1]_.
        - "naive" : the approximate probability based on an estimated
          effective number of independent frequencies.
        - "bootstrap" : the approximate probability based on bootstrap
          resamplings of the input data. The number of samples can
          be set with the method-specific keyword "n_bootstraps" (default=1000).

        Note also that for normalization='psd', the distribution can only be
        computed for periodograms constructed with errors specified.

        See Also
        --------
        distribution
        false_alarm_probability

        References
        ----------
        .. [1] Baluev, R.V. MNRAS 385, 1279 (2008)
        # If t is a TimeDelta, convert it to a quantity. The units we convert# to don't really matter since the user gets a Quantity back at the end# so can convert to any units they like.# We want to expose self.t as being the times the user passed in, but# if the times are absolute, we need to convert them to relative times# internally, so we use self._trel and self._tstart for this.# Validate shapes of inputs# validate units of inputs if any is a Quantityb'Main Lomb-Scargle Implementation.'u'Main Lomb-Scargle Implementation.'b'Compute the Lomb-Scargle Periodogram.

    This implementations here are based on code presented in [1]_ and [2]_;
    if you use this functionality in an academic application, citation of
    those works would be appreciated.

    Parameters
    ----------
    t : array-like or `~astropy.units.Quantity` ['time']
        sequence of observation times
    y : array-like or `~astropy.units.Quantity`
        sequence of observations associated with times t
    dy : float, array-like, or `~astropy.units.Quantity`, optional
        error or sequence of observational errors associated with times t
    fit_mean : bool, optional
        if True, include a constant offset as part of the model at each
        frequency. This can lead to more accurate results, especially in the
        case of incomplete phase coverage.
    center_data : bool, optional
        if True, pre-center the data by subtracting the weighted mean
        of the input data. This is especially important if fit_mean = False
    nterms : int, optional
        number of terms to use in the Fourier fit
    normalization : {'standard', 'model', 'log', 'psd'}, optional
        Normalization to use for the periodogram.

    Examples
    --------
    Generate noisy periodic data:

    >>> rand = np.random.default_rng(42)
    >>> t = 100 * rand.random(100)
    >>> y = np.sin(2 * np.pi * t) + rand.standard_normal(100)

    Compute the Lomb-Scargle periodogram on an automatically-determined
    frequency grid & find the frequency of max power:

    >>> frequency, power = LombScargle(t, y).autopower()
    >>> frequency[np.argmax(power)]  # doctest: +FLOAT_CMP
    np.float64(1.0007641728995051)

    Compute the Lomb-Scargle periodogram at a user-specified frequency grid:

    >>> freq = np.arange(0.8, 1.3, 0.1)
    >>> LombScargle(t, y).power(freq)  # doctest: +FLOAT_CMP
    array([0.0792948 , 0.01778874, 0.25328167, 0.01064157, 0.01471387])

    If the inputs are astropy Quantities with units, the units will be
    validated and the outputs will also be Quantities with appropriate units:

    >>> from astropy import units as u
    >>> t = t * u.s
    >>> y = y * u.mag
    >>> frequency, power = LombScargle(t, y).autopower()
    >>> frequency.unit
    Unit("1 / s")
    >>> power.unit
    Unit(dimensionless)

    Note here that the Lomb-Scargle power is always a unitless quantity,
    because it is related to the :math:`\chi^2` of the best-fit periodic
    model at each frequency.

    References
    ----------
    .. [1] Vanderplas, J., Connolly, A. Ivezic, Z. & Gray, A. *Introduction to
        astroML: Machine learning for astrophysics*. Proceedings of the
        Conference on Intelligent Data Understanding (2012)
    .. [2] VanderPlas, J. & Ivezic, Z. *Periodograms for Multiband Astronomical
        Time Series*. ApJ 812.1:18 (2015)
    'u'Compute the Lomb-Scargle Periodogram.

    This implementations here are based on code presented in [1]_ and [2]_;
    if you use this functionality in an academic application, citation of
    those works would be appreciated.

    Parameters
    ----------
    t : array-like or `~astropy.units.Quantity` ['time']
        sequence of observation times
    y : array-like or `~astropy.units.Quantity`
        sequence of observations associated with times t
    dy : float, array-like, or `~astropy.units.Quantity`, optional
        error or sequence of observational errors associated with times t
    fit_mean : bool, optional
        if True, include a constant offset as part of the model at each
        frequency. This can lead to more accurate results, especially in the
        case of incomplete phase coverage.
    center_data : bool, optional
        if True, pre-center the data by subtracting the weighted mean
        of the input data. This is especially important if fit_mean = False
    nterms : int, optional
        number of terms to use in the Fourier fit
    normalization : {'standard', 'model', 'log', 'psd'}, optional
        Normalization to use for the periodogram.

    Examples
    --------
    Generate noisy periodic data:

    >>> rand = np.random.default_rng(42)
    >>> t = 100 * rand.random(100)
    >>> y = np.sin(2 * np.pi * t) + rand.standard_normal(100)

    Compute the Lomb-Scargle periodogram on an automatically-determined
    frequency grid & find the frequency of max power:

    >>> frequency, power = LombScargle(t, y).autopower()
    >>> frequency[np.argmax(power)]  # doctest: +FLOAT_CMP
    np.float64(1.0007641728995051)

    Compute the Lomb-Scargle periodogram at a user-specified frequency grid:

    >>> freq = np.arange(0.8, 1.3, 0.1)
    >>> LombScargle(t, y).power(freq)  # doctest: +FLOAT_CMP
    array([0.0792948 , 0.01778874, 0.25328167, 0.01064157, 0.01471387])

    If the inputs are astropy Quantities with units, the units will be
    validated and the outputs will also be Quantities with appropriate units:

    >>> from astropy import units as u
    >>> t = t * u.s
    >>> y = y * u.mag
    >>> frequency, power = LombScargle(t, y).autopower()
    >>> frequency.unit
    Unit("1 / s")
    >>> power.unit
    Unit(dimensionless)

    Note here that the Lomb-Scargle power is always a unitless quantity,
    because it is related to the :math:`\chi^2` of the best-fit periodic
    model at each frequency.

    References
    ----------
    .. [1] Vanderplas, J., Connolly, A. Ivezic, Z. & Gray, A. *Introduction to
        astroML: Machine learning for astrophysics*. Proceedings of the
        Conference on Intelligent Data Understanding (2012)
    .. [2] VanderPlas, J. & Ivezic, Z. *Periodograms for Multiband Astronomical
        Time Series*. ApJ 812.1:18 (2015)
    'b'day'u'day'b'Inputs (t, y, dy) must be 1-dimensional'u'Inputs (t, y, dy) must be 1-dimensional'b'Units of dy not equivalent to units of y'u'Units of dy not equivalent to units of y'b'Units of frequency not equivalent to units of 1/t'u'Units of frequency not equivalent to units of 1/t'b'frequency have units while 1/t doesn't.'u'frequency have units while 1/t doesn't.'b'Units of t not equivalent to units of input self.t'u'Units of t not equivalent to units of input self.t'b'Determine a suitable frequency grid for data.

        Note that this assumes the peak width is driven by the observational
        baseline, which is generally a good assumption when the baseline is
        much larger than the oscillation period.
        If you are searching for periods longer than the baseline of your
        observations, this may not perform well.

        Even with a large baseline, be aware that the maximum frequency
        returned is based on the concept of "average Nyquist frequency", which
        may not be useful for irregularly-sampled data. The maximum frequency
        can be adjusted via the nyquist_factor argument, or through the
        maximum_frequency argument.

        Parameters
        ----------
        samples_per_peak : float, optional
            The approximate number of desired samples across the typical peak
        nyquist_factor : float, optional
            The multiple of the average nyquist frequency used to choose the
            maximum frequency if maximum_frequency is not provided.
        minimum_frequency : float, optional
            If specified, then use this minimum frequency rather than one
            chosen based on the size of the baseline.
        maximum_frequency : float, optional
            If specified, then use this maximum frequency rather than one
            chosen based on the average nyquist frequency.
        return_freq_limits : bool, optional
            if True, return only the frequency limits rather than the full
            frequency grid.

        Returns
        -------
        frequency : ndarray or `~astropy.units.Quantity` ['frequency']
            The heuristically-determined optimal frequency bin
        'u'Determine a suitable frequency grid for data.

        Note that this assumes the peak width is driven by the observational
        baseline, which is generally a good assumption when the baseline is
        much larger than the oscillation period.
        If you are searching for periods longer than the baseline of your
        observations, this may not perform well.

        Even with a large baseline, be aware that the maximum frequency
        returned is based on the concept of "average Nyquist frequency", which
        may not be useful for irregularly-sampled data. The maximum frequency
        can be adjusted via the nyquist_factor argument, or through the
        maximum_frequency argument.

        Parameters
        ----------
        samples_per_peak : float, optional
            The approximate number of desired samples across the typical peak
        nyquist_factor : float, optional
            The multiple of the average nyquist frequency used to choose the
            maximum frequency if maximum_frequency is not provided.
        minimum_frequency : float, optional
            If specified, then use this minimum frequency rather than one
            chosen based on the size of the baseline.
        maximum_frequency : float, optional
            If specified, then use this maximum frequency rather than one
            chosen based on the average nyquist frequency.
        return_freq_limits : bool, optional
            if True, return only the frequency limits rather than the full
            frequency grid.

        Returns
        -------
        frequency : ndarray or `~astropy.units.Quantity` ['frequency']
            The heuristically-determined optimal frequency bin
        'b'Compute Lomb-Scargle power at automatically-determined frequencies.

        Parameters
        ----------
        method : str, optional
            specify the lomb scargle implementation to use. Options are:

            - 'auto': choose the best method based on the input
            - 'fast': use the O[N log N] fast method. Note that this requires
              evenly-spaced frequencies: by default this will be checked unless
              ``assume_regular_frequency`` is set to True.
            - 'slow': use the O[N^2] pure-python implementation
            - 'cython': use the O[N^2] cython implementation. This is slightly
              faster than method='slow', but much more memory efficient.
            - 'chi2': use the O[N^2] chi2/linear-fitting implementation
            - 'fastchi2': use the O[N log N] chi2 implementation. Note that this
              requires evenly-spaced frequencies: by default this will be checked
              unless ``assume_regular_frequency`` is set to True.
            - 'scipy': use ``scipy.signal.lombscargle``, which is an O[N^2]
              implementation written in C. Note that this does not support
              heteroskedastic errors.

        method_kwds : dict, optional
            additional keywords to pass to the lomb-scargle method
        normalization : {'standard', 'model', 'log', 'psd'}, optional
            If specified, override the normalization specified at instantiation.
        samples_per_peak : float, optional
            The approximate number of desired samples across the typical peak
        nyquist_factor : float, optional
            The multiple of the average nyquist frequency used to choose the
            maximum frequency if maximum_frequency is not provided.
        minimum_frequency : float or `~astropy.units.Quantity` ['frequency'], optional
            If specified, then use this minimum frequency rather than one
            chosen based on the size of the baseline. Should be `~astropy.units.Quantity`
            if inputs to LombScargle are `~astropy.units.Quantity`.
        maximum_frequency : float or `~astropy.units.Quantity` ['frequency'], optional
            If specified, then use this maximum frequency rather than one
            chosen based on the average nyquist frequency. Should be `~astropy.units.Quantity`
            if inputs to LombScargle are `~astropy.units.Quantity`.

        Returns
        -------
        frequency, power : ndarray
            The frequency and Lomb-Scargle power
        'u'Compute Lomb-Scargle power at automatically-determined frequencies.

        Parameters
        ----------
        method : str, optional
            specify the lomb scargle implementation to use. Options are:

            - 'auto': choose the best method based on the input
            - 'fast': use the O[N log N] fast method. Note that this requires
              evenly-spaced frequencies: by default this will be checked unless
              ``assume_regular_frequency`` is set to True.
            - 'slow': use the O[N^2] pure-python implementation
            - 'cython': use the O[N^2] cython implementation. This is slightly
              faster than method='slow', but much more memory efficient.
            - 'chi2': use the O[N^2] chi2/linear-fitting implementation
            - 'fastchi2': use the O[N log N] chi2 implementation. Note that this
              requires evenly-spaced frequencies: by default this will be checked
              unless ``assume_regular_frequency`` is set to True.
            - 'scipy': use ``scipy.signal.lombscargle``, which is an O[N^2]
              implementation written in C. Note that this does not support
              heteroskedastic errors.

        method_kwds : dict, optional
            additional keywords to pass to the lomb-scargle method
        normalization : {'standard', 'model', 'log', 'psd'}, optional
            If specified, override the normalization specified at instantiation.
        samples_per_peak : float, optional
            The approximate number of desired samples across the typical peak
        nyquist_factor : float, optional
            The multiple of the average nyquist frequency used to choose the
            maximum frequency if maximum_frequency is not provided.
        minimum_frequency : float or `~astropy.units.Quantity` ['frequency'], optional
            If specified, then use this minimum frequency rather than one
            chosen based on the size of the baseline. Should be `~astropy.units.Quantity`
            if inputs to LombScargle are `~astropy.units.Quantity`.
        maximum_frequency : float or `~astropy.units.Quantity` ['frequency'], optional
            If specified, then use this maximum frequency rather than one
            chosen based on the average nyquist frequency. Should be `~astropy.units.Quantity`
            if inputs to LombScargle are `~astropy.units.Quantity`.

        Returns
        -------
        frequency, power : ndarray
            The frequency and Lomb-Scargle power
        'b'Compute the Lomb-Scargle power at the given frequencies.

        Parameters
        ----------
        frequency : array-like or `~astropy.units.Quantity` ['frequency']
            frequencies (not angular frequencies) at which to evaluate the
            periodogram. Note that in order to use method='fast', frequencies
            must be regularly-spaced.
        method : str, optional
            specify the lomb scargle implementation to use. Options are:

            - 'auto': choose the best method based on the input
            - 'fast': use the O[N log N] fast method. Note that this requires
              evenly-spaced frequencies: by default this will be checked unless
              ``assume_regular_frequency`` is set to True.
            - 'slow': use the O[N^2] pure-python implementation
            - 'cython': use the O[N^2] cython implementation. This is slightly
              faster than method='slow', but much more memory efficient.
            - 'chi2': use the O[N^2] chi2/linear-fitting implementation
            - 'fastchi2': use the O[N log N] chi2 implementation. Note that this
              requires evenly-spaced frequencies: by default this will be checked
              unless ``assume_regular_frequency`` is set to True.
            - 'scipy': use ``scipy.signal.lombscargle``, which is an O[N^2]
              implementation written in C. Note that this does not support
              heteroskedastic errors.

        assume_regular_frequency : bool, optional
            if True, assume that the input frequency is of the form
            freq = f0 + df * np.arange(N). Only referenced if method is 'auto'
            or 'fast'.
        normalization : {'standard', 'model', 'log', 'psd'}, optional
            If specified, override the normalization specified at instantiation.

        method_kwds : dict, optional
            additional keywords to pass to the lomb-scargle method

        Returns
        -------
        power : ndarray
            The Lomb-Scargle power at the specified frequency
        'u'Compute the Lomb-Scargle power at the given frequencies.

        Parameters
        ----------
        frequency : array-like or `~astropy.units.Quantity` ['frequency']
            frequencies (not angular frequencies) at which to evaluate the
            periodogram. Note that in order to use method='fast', frequencies
            must be regularly-spaced.
        method : str, optional
            specify the lomb scargle implementation to use. Options are:

            - 'auto': choose the best method based on the input
            - 'fast': use the O[N log N] fast method. Note that this requires
              evenly-spaced frequencies: by default this will be checked unless
              ``assume_regular_frequency`` is set to True.
            - 'slow': use the O[N^2] pure-python implementation
            - 'cython': use the O[N^2] cython implementation. This is slightly
              faster than method='slow', but much more memory efficient.
            - 'chi2': use the O[N^2] chi2/linear-fitting implementation
            - 'fastchi2': use the O[N log N] chi2 implementation. Note that this
              requires evenly-spaced frequencies: by default this will be checked
              unless ``assume_regular_frequency`` is set to True.
            - 'scipy': use ``scipy.signal.lombscargle``, which is an O[N^2]
              implementation written in C. Note that this does not support
              heteroskedastic errors.

        assume_regular_frequency : bool, optional
            if True, assume that the input frequency is of the form
            freq = f0 + df * np.arange(N). Only referenced if method is 'auto'
            or 'fast'.
        normalization : {'standard', 'model', 'log', 'psd'}, optional
            If specified, override the normalization specified at instantiation.

        method_kwds : dict, optional
            additional keywords to pass to the lomb-scargle method

        Returns
        -------
        power : ndarray
            The Lomb-Scargle power at the specified frequency
        'b'
        Convert the provided times (if absolute) to relative times using the
        current _tstart value. If the times provided are relative, they are
        returned without conversion (though we still do some checks).
        'u'
        Convert the provided times (if absolute) to relative times using the
        current _tstart value. If the times provided are relative, they are
        returned without conversion (though we still do some checks).
        'b' was provided as an absolute time but the LombScargle class was initialized with relative times.'u' was provided as an absolute time but the LombScargle class was initialized with relative times.'b' was provided as a relative time but the LombScargle class was initialized with absolute times.'u' was provided as a relative time but the LombScargle class was initialized with absolute times.'b'Compute the Lomb-Scargle model at the given frequency.

        The model at a particular frequency is a linear model:
        model = offset + dot(design_matrix, model_parameters)

        Parameters
        ----------
        t : array-like or `~astropy.units.Quantity` ['time']
            Times (length ``n_samples``) at which to compute the model.
        frequency : float
            the frequency for the model

        Returns
        -------
        y : np.ndarray
            The model fit corresponding to the input times
            (will have length ``n_samples``).

        See Also
        --------
        design_matrix
        offset
        model_parameters
        'u'Compute the Lomb-Scargle model at the given frequency.

        The model at a particular frequency is a linear model:
        model = offset + dot(design_matrix, model_parameters)

        Parameters
        ----------
        t : array-like or `~astropy.units.Quantity` ['time']
            Times (length ``n_samples``) at which to compute the model.
        frequency : float
            the frequency for the model

        Returns
        -------
        y : np.ndarray
            The model fit corresponding to the input times
            (will have length ``n_samples``).

        See Also
        --------
        design_matrix
        offset
        model_parameters
        'b'Return the offset of the model.

        The offset of the model is the (weighted) mean of the y values.
        Note that if self.center_data is False, the offset is 0 by definition.

        Returns
        -------
        offset : scalar

        See Also
        --------
        design_matrix
        model
        model_parameters
        'u'Return the offset of the model.

        The offset of the model is the (weighted) mean of the y values.
        Note that if self.center_data is False, the offset is 0 by definition.

        Returns
        -------
        offset : scalar

        See Also
        --------
        design_matrix
        model
        model_parameters
        'b'Compute the best-fit model parameters at the given frequency.

        The model described by these parameters is:

        .. math::

            y(t; f, \vec{\theta}) = \theta_0 + \sum_{n=1}^{\tt nterms} [\theta_{2n-1}\sin(2\pi n f t) + \theta_{2n}\cos(2\pi n f t)]

        where :math:`\vec{\theta}` is the array of parameters returned by this function.

        Parameters
        ----------
        frequency : float
            the frequency for the model
        units : bool
            If True (default), return design matrix with data units.

        Returns
        -------
        theta : np.ndarray (n_parameters,)
            The best-fit model parameters at the given frequency.

        See Also
        --------
        design_matrix
        model
        offset
        'u'Compute the best-fit model parameters at the given frequency.

        The model described by these parameters is:

        .. math::

            y(t; f, \vec{\theta}) = \theta_0 + \sum_{n=1}^{\tt nterms} [\theta_{2n-1}\sin(2\pi n f t) + \theta_{2n}\cos(2\pi n f t)]

        where :math:`\vec{\theta}` is the array of parameters returned by this function.

        Parameters
        ----------
        frequency : float
            the frequency for the model
        units : bool
            If True (default), return design matrix with data units.

        Returns
        -------
        theta : np.ndarray (n_parameters,)
            The best-fit model parameters at the given frequency.

        See Also
        --------
        design_matrix
        model
        offset
        'b'Compute the design matrix for a given frequency.

        Parameters
        ----------
        frequency : float
            the frequency for the model
        t : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time` (optional)
            Times (length ``n_samples``) at which to compute the model.
            If not specified, then the times and uncertainties of the input
            data are used.

        Returns
        -------
        X : array
            The design matrix for the model at the given frequency.
            This should have a shape of (``len(t)``, ``n_parameters``).

        See Also
        --------
        model
        model_parameters
        offset
        'u'Compute the design matrix for a given frequency.

        Parameters
        ----------
        frequency : float
            the frequency for the model
        t : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time` (optional)
            Times (length ``n_samples``) at which to compute the model.
            If not specified, then the times and uncertainties of the input
            data are used.

        Returns
        -------
        X : array
            The design matrix for the model at the given frequency.
            This should have a shape of (``len(t)``, ``n_parameters``).

        See Also
        --------
        model
        model_parameters
        offset
        'b'Expected periodogram distribution under the null hypothesis.

        This computes the expected probability distribution or cumulative
        probability distribution of periodogram power, under the null
        hypothesis of a non-varying signal with Gaussian noise. Note that
        this is not the same as the expected distribution of peak values;
        for that see the ``false_alarm_probability()`` method.

        Parameters
        ----------
        power : array-like
            The periodogram power at which to compute the distribution.
        cumulative : bool, optional
            If True, then return the cumulative distribution.

        See Also
        --------
        false_alarm_probability
        false_alarm_level

        Returns
        -------
        dist : np.ndarray
            The probability density or cumulative probability associated with
            the provided powers.
        'u'Expected periodogram distribution under the null hypothesis.

        This computes the expected probability distribution or cumulative
        probability distribution of periodogram power, under the null
        hypothesis of a non-varying signal with Gaussian noise. Note that
        this is not the same as the expected distribution of peak values;
        for that see the ``false_alarm_probability()`` method.

        Parameters
        ----------
        power : array-like
            The periodogram power at which to compute the distribution.
        cumulative : bool, optional
            If True, then return the cumulative distribution.

        See Also
        --------
        false_alarm_probability
        false_alarm_level

        Returns
        -------
        dist : np.ndarray
            The probability density or cumulative probability associated with
            the provided powers.
        'b'False alarm probability of periodogram maxima under the null hypothesis.

        This gives an estimate of the false alarm probability given the height
        of the largest peak in the periodogram, based on the null hypothesis
        of non-varying data with Gaussian noise.

        Parameters
        ----------
        power : array-like
            The periodogram value.
        method : {'baluev', 'davies', 'naive', 'bootstrap'}, optional
            The approximation method to use.
        maximum_frequency : float
            The maximum frequency of the periodogram.
        method_kwds : dict, optional
            Additional method-specific keywords.

        Returns
        -------
        false_alarm_probability : np.ndarray
            The false alarm probability

        Notes
        -----
        The true probability distribution for the largest peak cannot be
        determined analytically, so each method here provides an approximation
        to the value. The available methods are:

        - "baluev" (default): the upper-limit to the alias-free probability,
          using the approach of Baluev (2008) [1]_.
        - "davies" : the Davies upper bound from Baluev (2008) [1]_.
        - "naive" : the approximate probability based on an estimated
          effective number of independent frequencies.
        - "bootstrap" : the approximate probability based on bootstrap
          resamplings of the input data.

        Note also that for normalization='psd', the distribution can only be
        computed for periodograms constructed with errors specified.

        See Also
        --------
        distribution
        false_alarm_level

        References
        ----------
        .. [1] Baluev, R.V. MNRAS 385, 1279 (2008)
        'u'False alarm probability of periodogram maxima under the null hypothesis.

        This gives an estimate of the false alarm probability given the height
        of the largest peak in the periodogram, based on the null hypothesis
        of non-varying data with Gaussian noise.

        Parameters
        ----------
        power : array-like
            The periodogram value.
        method : {'baluev', 'davies', 'naive', 'bootstrap'}, optional
            The approximation method to use.
        maximum_frequency : float
            The maximum frequency of the periodogram.
        method_kwds : dict, optional
            Additional method-specific keywords.

        Returns
        -------
        false_alarm_probability : np.ndarray
            The false alarm probability

        Notes
        -----
        The true probability distribution for the largest peak cannot be
        determined analytically, so each method here provides an approximation
        to the value. The available methods are:

        - "baluev" (default): the upper-limit to the alias-free probability,
          using the approach of Baluev (2008) [1]_.
        - "davies" : the Davies upper bound from Baluev (2008) [1]_.
        - "naive" : the approximate probability based on an estimated
          effective number of independent frequencies.
        - "bootstrap" : the approximate probability based on bootstrap
          resamplings of the input data.

        Note also that for normalization='psd', the distribution can only be
        computed for periodograms constructed with errors specified.

        See Also
        --------
        distribution
        false_alarm_level

        References
        ----------
        .. [1] Baluev, R.V. MNRAS 385, 1279 (2008)
        'b'false alarm probability is not implemented for multiterm periodograms.'u'false alarm probability is not implemented for multiterm periodograms.'b'false alarm probability is implemented only for periodograms of centered data.'u'false alarm probability is implemented only for periodograms of centered data.'b'Level of maximum at a given false alarm probability.

        This gives an estimate of the periodogram level corresponding to a
        specified false alarm probability for the largest peak, assuming a
        null hypothesis of non-varying data with Gaussian noise.

        Parameters
        ----------
        false_alarm_probability : array-like
            The false alarm probability (0 < fap < 1).
        maximum_frequency : float
            The maximum frequency of the periodogram.
        method : {'baluev', 'davies', 'naive', 'bootstrap'}, optional
            The approximation method to use; default='baluev'.
        method_kwds : dict, optional
            Additional method-specific keywords.

        Returns
        -------
        power : np.ndarray
            The periodogram peak height corresponding to the specified
            false alarm probability.

        Notes
        -----
        The true probability distribution for the largest peak cannot be
        determined analytically, so each method here provides an approximation
        to the value. The available methods are:

        - "baluev" (default): the upper-limit to the alias-free probability,
          using the approach of Baluev (2008) [1]_.
        - "davies" : the Davies upper bound from Baluev (2008) [1]_.
        - "naive" : the approximate probability based on an estimated
          effective number of independent frequencies.
        - "bootstrap" : the approximate probability based on bootstrap
          resamplings of the input data. The number of samples can
          be set with the method-specific keyword "n_bootstraps" (default=1000).

        Note also that for normalization='psd', the distribution can only be
        computed for periodograms constructed with errors specified.

        See Also
        --------
        distribution
        false_alarm_probability

        References
        ----------
        .. [1] Baluev, R.V. MNRAS 385, 1279 (2008)
        'u'Level of maximum at a given false alarm probability.

        This gives an estimate of the periodogram level corresponding to a
        specified false alarm probability for the largest peak, assuming a
        null hypothesis of non-varying data with Gaussian noise.

        Parameters
        ----------
        false_alarm_probability : array-like
            The false alarm probability (0 < fap < 1).
        maximum_frequency : float
            The maximum frequency of the periodogram.
        method : {'baluev', 'davies', 'naive', 'bootstrap'}, optional
            The approximation method to use; default='baluev'.
        method_kwds : dict, optional
            Additional method-specific keywords.

        Returns
        -------
        power : np.ndarray
            The periodogram peak height corresponding to the specified
            false alarm probability.

        Notes
        -----
        The true probability distribution for the largest peak cannot be
        determined analytically, so each method here provides an approximation
        to the value. The available methods are:

        - "baluev" (default): the upper-limit to the alias-free probability,
          using the approach of Baluev (2008) [1]_.
        - "davies" : the Davies upper bound from Baluev (2008) [1]_.
        - "naive" : the approximate probability based on an estimated
          effective number of independent frequencies.
        - "bootstrap" : the approximate probability based on bootstrap
          resamplings of the input data. The number of samples can
          be set with the method-specific keyword "n_bootstraps" (default=1000).

        Note also that for normalization='psd', the distribution can only be
        computed for periodograms constructed with errors specified.

        See Also
        --------
        distribution
        false_alarm_probability

        References
        ----------
        .. [1] Baluev, R.V. MNRAS 385, 1279 (2008)
        'u'timeseries.periodograms.lombscargle.core'u'periodograms.lombscargle.core'u'lombscargle.core'Function Units and Quantities.numpy.coreumathnp_umathnumpy._coreFunctionQuantityFunctionUnitBaserint_ones_likeSUPPORTED_UFUNCSSUPPORTED_FUNCTIONSAbstract base class for function units.

    Function units are functions containing a physical unit, such as dB(mW).
    Most of the arithmetic operations on function units are defined in this
    base class.

    While instantiation is defined, this class should not be used directly.
    Rather, subclasses should be used that override the abstract properties
    `_default_function_unit` and `_quantity_class`, and the abstract methods
    `from_physical`, and `to_physical`.

    Parameters
    ----------
    physical_unit : `~astropy.units.Unit` or `string`
        Unit that is encapsulated within the function unit.
        If not given, dimensionless.

    function_unit :  `~astropy.units.Unit` or `string`
        By default, the same as the function unit set by the subclass.
    _default_function_unitDefault function unit corresponding to the function.

        This property should be overridden by subclasses, with, e.g.,
        `~astropy.unit.MagUnit` returning `~astropy.unit.mag`.
        _quantity_classFunction quantity class corresponding to this function unit.

        This property should be overridden by subclasses, with, e.g.,
        `~astropy.unit.MagUnit` returning `~astropy.unit.Magnitude`.
        from_physicalTransformation from value in physical to value in function units.

        This method should be overridden by subclasses.  It is used to
        provide automatic transformations using an equivalency.
        to_physicalTransformation from value in function to value in physical units.

        This method should be overridden by subclasses.  It is used to
        provide automatic transformations using an equivalency.
        30000physical_unitfunction_unit is not a physical unit.Cannot initialize '' instance with function unit '"' instance with ""function unit '"', as it is not equivalent to default function unit '"', as it is not equivalent to ""default function unit '"_physical_unit_function_unit_copyCopy oneself, possibly with a different physical unit.List of equivalencies between function and physical units.

        Uses the `from_physical` and `to_physical` methods.
        Copy the current unit with the physical unit decomposed.

        For details, see `~astropy.units.UnitBase.decompose`.
        Copy the current function unit with the physical unit in SI.Copy the current function unit with the physical unit in CGS.Get physical type corresponding to physical unit.Return the physical type of the physical unit (e.g., 'length').
        Returns `True` if this unit is equivalent to ``other``.

        Parameters
        ----------
        other : `~astropy.units.Unit`, string, or tuple
            The unit to convert to. If a tuple of units is specified, this
            method returns true if the unit matches any of those in the tuple.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to the built-in equivalencies between the
            function unit and the physical one, as well as possible global
            defaults set by, e.g., `~astropy.units.set_enabled_equivalencies`.
            Use `None` to turn off any global equivalencies.

        Returns
        -------
        bool
        other_physical_unit
        Return the converted values in the specified unit.

        Parameters
        ----------
        other : `~astropy.units.Unit`, `~astropy.units.FunctionUnitBase`, or str
            The unit to convert to.

        value : int, float, or scalar array-like, optional
            Value(s) in the current unit to be converted to the specified unit.
            If not provided, defaults to 1.0.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in meant to treat only equivalencies between different
            physical units; the built-in equivalency between the function
            unit and the physical one is automatically taken into account.

        Returns
        -------
        values : scalar or array
            Converted value(s). Input value sequences are returned as
            numpy arrays.

        Raises
        ------
        `~astropy.units.UnitsError`
            If units are inconsistent.
        other_function_unitvalue_other_physicalDid you perhaps subtract magnitudes so the unit got lost?Unit conversion operator ``<<``.Cannot multiply a function unit with a physical dimension with any unit."Cannot multiply a function unit with a physical dimension ""with any unit."Cannot divide a function unit with a physical dimension by any unit."Cannot divide a function unit with a physical dimension ""by any unit."Cannot divide a function unit with a physical dimension into any unit"into any unit"Cannot raise a function unit with a physical dimension to any power but 0 or 1."Cannot raise a function unit with a physical dimension ""to any power but 0 or 1."
        Output the unit in the given format as a string.

        The physical unit is appended, within parentheses, to the function
        unit, as in "dB(mW)", with both units set using the given format

        Parameters
        ----------
        format : `astropy.units.format.Base` subclass or str
            The name of a format or a formatter class.  If not
            provided, defaults to the generic format.
        supported_formatsFunction units cannot be written in  format. Only "format. Only " are supported.self_strpu_str$\mathrm{{\left(  \right)}}$pu_lines{{0:^s}}{{1:s}}Try to format units using a formatter.Return string representation for unit.{}("{}"{}), unit="A representation of a (scaled) function of a number with a unit.

    Function quantities are quantities whose units are functions containing a
    physical unit, such as dB(mW).  Most of the arithmetic operations on
    function quantities are defined in this base class.

    While instantiation is also defined here, this class should not be
    instantiated directly.  Rather, subclasses should be made which have
    ``_unit_class`` pointing back to the corresponding function unit class.

    Parameters
    ----------
    value : number, quantity-like, or sequence thereof
        The numerical value of the function quantity. If a number or
        a `~astropy.units.Quantity` with a function unit, it will be converted
        to ``unit`` and the physical unit will be inferred from ``unit``.
        If a `~astropy.units.Quantity` with just a physical unit, it will
        converted to the function unit, after, if necessary, converting it to
        the physical unit inferred from ``unit``.

    unit : str, `~astropy.units.UnitBase`, or `~astropy.units.FunctionUnitBase`, optional
        For an `~astropy.units.FunctionUnitBase` instance, the
        physical unit will be taken from it; for other input, it will be
        inferred from ``value``. By default, ``unit`` is set by the subclass.

    dtype : `~numpy.dtype`, optional
        The dtype of the resulting Numpy array or scalar that will
        hold the value.  If not provided, it is determined from the input,
        except that any input that cannot represent float (integer and bool)
        is converted to float.

    copy : bool, optional
        If `True` (default), then the value is copied.  Otherwise, a copy will
        only be made if ``__array__`` returns a copy, if value is a nested
        sequence, or if a copy is needed to satisfy an explicitly given
        ``dtype``.  (The `False` option is intended mostly for internal use,
        to speed up initialization where a copy is known to have been made.
        Use with care.)

    order : {'C', 'F', 'A'}, optional
        Specify the order of the array.  As in `~numpy.array`.  Ignored
        if the input does not need to be converted and ``copy=False``.

    subok : bool, optional
        If `False` (default), the returned array will be forced to be of the
        class used.  Otherwise, subclasses will be passed through.

    ndmin : int, optional
        Specifies the minimum number of dimensions that the resulting array
        should have.  Ones will be prepended to the shape as needed to meet
        this requirement.  This parameter is ignored if the input is a
        `~astropy.units.Quantity` and ``copy=False``.

    Raises
    ------
    TypeError
        If the value provided is not a Python numeric type.
    TypeError
        If the unit provided is not a `~astropy.units.FunctionUnitBase`
        or `~astropy.units.Unit` object, or a parseable string unit.
    _unit_classDefault `~astropy.units.FunctionUnitBase` subclass.

    This should be overridden by subclasses.
    40000_supported_ufuncs_supported_functionsndminvalue_unitThe physical quantity corresponding the function one._function_viewView as Quantity with function unit, dropping the physical unit.

        Use `~astropy.units.quantity.Quantity.value` for just the value.
        _new_viewReturn a copy with the physical unit in SI units.Return a copy with the physical unit in CGS units.Generate a new instance with the physical unit decomposed.

        For details, see `~astropy.units.Quantity.decompose`.
        nonsense instances require " instances require" function units, so cannot set it to '" function units, so cannot set it to"' with function quantities_maybe_new_viewView as function quantity if the unit is unchanged.

        Used for the case that self.unit.physical_unit is dimensionless,
        where multiplication and division is done using the Quantity
        equivalent, to transform them back to a FunctionQuantity if possible.
        Cannot multiply function quantities which are not dimensionless with anything."Cannot multiply function quantities which are not dimensionless ""with anything."Cannot divide function quantities which are not dimensionless by anything.Cannot divide function quantities which are not dimensionless into anything."Cannot divide function quantities which are not dimensionless ""into anything."_comparisoncomparison_funcDo a comparison between self and other, raising UnitsError when
        other cannot be converted to self because it has different physical
        unit, and returning NotImplemented when there are other errors.
        _to_own_unitcheck_precisionother_in_own_unitUnit conversion operator `<<`._wrap_functionCannot use method that uses function '' with function quantities that are not dimensionless."' with ""function quantities that are not dimensionless."a_mina_max# TODO: the following could work if helper changed relative to Quantity:# - spacing should return dimensionless, not same unit# - negative should negate unit too,# - add, subtract, comparisons can work if units added/subtracted# subclassing UnitBase or CompositeUnit was found to be problematic, requiring# a large number of overrides. Hence, define new class.#  the following four need to be set by subclasses# Make this a property so we can ensure subclasses define it.# This has to be a property because the function quantity will not be# known at unit definition time, as it gets defined after.#  the above four need to be set by subclasses# have priority over arrays, regular units, and regular quantities# any function unit should be equivalent to subclass default#  properties/methods required to behave like a unit# conversion to one's own physical unit should be fastest# when other is an equivalent function unit:# first convert physical units to other's physical units# make function unit again, in own system# convert possible difference in function unit (e.g., dex->dB)# when other is not a function unit# One can get to raw magnitudes via math that strips the dimensions off.# Include extra information in the exception to remind users of this.# If dimensionless, drop back to normal unit and retry.# Anything not like a unit, try initialising as a function quantity.# Don't know what to do with anything not like a unit.# need to strip leading and trailing "$"# If the physical unit is formatted into a multiline# string, the lines need to be adjusted so that the# functional string is aligned with the fraction line# (second one), and all other lines are indented# accordingly.# By default, try to give a representation using `Unit(<string>)`,# with string such that parsing it would give the correct FunctionUnit.# Ensure priority over ndarray, regular Unit & Quantity, and FunctionUnit.# Define functions that work on FunctionQuantity.# Convert possible string input to a (function) unit.# By default, use value's physical unit.# if iterable, see if first item has a unit# (mixed lists fail in super call below).# initialise!#  properties not found in Quantity#  methods overridden to change the behavior#  methods overridden to add additional behavior# Have to take care of, e.g., (10*u.mag).view(u.Magnitude)# "or 'nonsense'" ensures `None` breaks, just in case.# TODO: it would be more logical to have this in Quantity already,# instead of in UFUNC_HELPERS, where it cannot be overridden.# And really it should just return NotImplemented, since possibly# another argument might know what to do.#  methods overridden to change behavior# will raise a UnitsError if physical units not equivalent# Ensure Quantity methods are used only if they make sense.# For dimensionless, we can convert to regular quantities.# Override functions that are supported but do not use _wrap_function# in Quantity.b'Function Units and Quantities.'u'Function Units and Quantities.'b'FunctionQuantity'u'FunctionQuantity'b'FunctionUnitBase'u'FunctionUnitBase'b'isfinite'u'isfinite'b'isinf'u'isinf'b'isnan'u'isnan'b'signbit'u'signbit'b'rint'u'rint'b'floor'u'floor'b'ceil'u'ceil'b'trunc'u'trunc'b'_ones_like'u'_ones_like'b'ones_like'u'ones_like'b'positive'u'positive'b'clip'u'clip'b'trace'u'trace'b'round'u'round'b'Abstract base class for function units.

    Function units are functions containing a physical unit, such as dB(mW).
    Most of the arithmetic operations on function units are defined in this
    base class.

    While instantiation is defined, this class should not be used directly.
    Rather, subclasses should be used that override the abstract properties
    `_default_function_unit` and `_quantity_class`, and the abstract methods
    `from_physical`, and `to_physical`.

    Parameters
    ----------
    physical_unit : `~astropy.units.Unit` or `string`
        Unit that is encapsulated within the function unit.
        If not given, dimensionless.

    function_unit :  `~astropy.units.Unit` or `string`
        By default, the same as the function unit set by the subclass.
    'u'Abstract base class for function units.

    Function units are functions containing a physical unit, such as dB(mW).
    Most of the arithmetic operations on function units are defined in this
    base class.

    While instantiation is defined, this class should not be used directly.
    Rather, subclasses should be used that override the abstract properties
    `_default_function_unit` and `_quantity_class`, and the abstract methods
    `from_physical`, and `to_physical`.

    Parameters
    ----------
    physical_unit : `~astropy.units.Unit` or `string`
        Unit that is encapsulated within the function unit.
        If not given, dimensionless.

    function_unit :  `~astropy.units.Unit` or `string`
        By default, the same as the function unit set by the subclass.
    'b'Default function unit corresponding to the function.

        This property should be overridden by subclasses, with, e.g.,
        `~astropy.unit.MagUnit` returning `~astropy.unit.mag`.
        'u'Default function unit corresponding to the function.

        This property should be overridden by subclasses, with, e.g.,
        `~astropy.unit.MagUnit` returning `~astropy.unit.mag`.
        'b'Function quantity class corresponding to this function unit.

        This property should be overridden by subclasses, with, e.g.,
        `~astropy.unit.MagUnit` returning `~astropy.unit.Magnitude`.
        'u'Function quantity class corresponding to this function unit.

        This property should be overridden by subclasses, with, e.g.,
        `~astropy.unit.MagUnit` returning `~astropy.unit.Magnitude`.
        'b'Transformation from value in physical to value in function units.

        This method should be overridden by subclasses.  It is used to
        provide automatic transformations using an equivalency.
        'u'Transformation from value in physical to value in function units.

        This method should be overridden by subclasses.  It is used to
        provide automatic transformations using an equivalency.
        'b'Transformation from value in function to value in physical units.

        This method should be overridden by subclasses.  It is used to
        provide automatic transformations using an equivalency.
        'u'Transformation from value in function to value in physical units.

        This method should be overridden by subclasses.  It is used to
        provide automatic transformations using an equivalency.
        'b' is not a physical unit.'u' is not a physical unit.'b'function_unit'u'function_unit'b'Cannot initialize ''u'Cannot initialize ''b'' instance with function unit ''u'' instance with function unit ''b'', as it is not equivalent to default function unit ''u'', as it is not equivalent to default function unit ''b'Copy oneself, possibly with a different physical unit.'u'Copy oneself, possibly with a different physical unit.'b'List of equivalencies between function and physical units.

        Uses the `from_physical` and `to_physical` methods.
        'u'List of equivalencies between function and physical units.

        Uses the `from_physical` and `to_physical` methods.
        'b'Copy the current unit with the physical unit decomposed.

        For details, see `~astropy.units.UnitBase.decompose`.
        'u'Copy the current unit with the physical unit decomposed.

        For details, see `~astropy.units.UnitBase.decompose`.
        'b'Copy the current function unit with the physical unit in SI.'u'Copy the current function unit with the physical unit in SI.'b'Copy the current function unit with the physical unit in CGS.'u'Copy the current function unit with the physical unit in CGS.'b'Get physical type corresponding to physical unit.'u'Get physical type corresponding to physical unit.'b'Return the physical type of the physical unit (e.g., 'length').'u'Return the physical type of the physical unit (e.g., 'length').'b'
        Returns `True` if this unit is equivalent to ``other``.

        Parameters
        ----------
        other : `~astropy.units.Unit`, string, or tuple
            The unit to convert to. If a tuple of units is specified, this
            method returns true if the unit matches any of those in the tuple.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to the built-in equivalencies between the
            function unit and the physical one, as well as possible global
            defaults set by, e.g., `~astropy.units.set_enabled_equivalencies`.
            Use `None` to turn off any global equivalencies.

        Returns
        -------
        bool
        'u'
        Returns `True` if this unit is equivalent to ``other``.

        Parameters
        ----------
        other : `~astropy.units.Unit`, string, or tuple
            The unit to convert to. If a tuple of units is specified, this
            method returns true if the unit matches any of those in the tuple.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in addition to the built-in equivalencies between the
            function unit and the physical one, as well as possible global
            defaults set by, e.g., `~astropy.units.set_enabled_equivalencies`.
            Use `None` to turn off any global equivalencies.

        Returns
        -------
        bool
        'b'physical_unit'u'physical_unit'b'
        Return the converted values in the specified unit.

        Parameters
        ----------
        other : `~astropy.units.Unit`, `~astropy.units.FunctionUnitBase`, or str
            The unit to convert to.

        value : int, float, or scalar array-like, optional
            Value(s) in the current unit to be converted to the specified unit.
            If not provided, defaults to 1.0.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in meant to treat only equivalencies between different
            physical units; the built-in equivalency between the function
            unit and the physical one is automatically taken into account.

        Returns
        -------
        values : scalar or array
            Converted value(s). Input value sequences are returned as
            numpy arrays.

        Raises
        ------
        `~astropy.units.UnitsError`
            If units are inconsistent.
        'u'
        Return the converted values in the specified unit.

        Parameters
        ----------
        other : `~astropy.units.Unit`, `~astropy.units.FunctionUnitBase`, or str
            The unit to convert to.

        value : int, float, or scalar array-like, optional
            Value(s) in the current unit to be converted to the specified unit.
            If not provided, defaults to 1.0.

        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not
            directly convertible.  See :ref:`astropy:unit_equivalencies`.
            This list is in meant to treat only equivalencies between different
            physical units; the built-in equivalency between the function
            unit and the physical one is automatically taken into account.

        Returns
        -------
        values : scalar or array
            Converted value(s). Input value sequences are returned as
            numpy arrays.

        Raises
        ------
        `~astropy.units.UnitsError`
            If units are inconsistent.
        'b'Did you perhaps subtract magnitudes so the unit got lost?'u'Did you perhaps subtract magnitudes so the unit got lost?'b'Unit conversion operator ``<<``.'u'Unit conversion operator ``<<``.'b'Cannot multiply a function unit with a physical dimension with any unit.'u'Cannot multiply a function unit with a physical dimension with any unit.'b'Cannot divide a function unit with a physical dimension by any unit.'u'Cannot divide a function unit with a physical dimension by any unit.'b'Cannot divide a function unit with a physical dimension into any unit'u'Cannot divide a function unit with a physical dimension into any unit'b'Cannot raise a function unit with a physical dimension to any power but 0 or 1.'u'Cannot raise a function unit with a physical dimension to any power but 0 or 1.'b'
        Output the unit in the given format as a string.

        The physical unit is appended, within parentheses, to the function
        unit, as in "dB(mW)", with both units set using the given format

        Parameters
        ----------
        format : `astropy.units.format.Base` subclass or str
            The name of a format or a formatter class.  If not
            provided, defaults to the generic format.
        'u'
        Output the unit in the given format as a string.

        The physical unit is appended, within parentheses, to the function
        unit, as in "dB(mW)", with both units set using the given format

        Parameters
        ----------
        format : `astropy.units.format.Base` subclass or str
            The name of a format or a formatter class.  If not
            provided, defaults to the generic format.
        'b'console'b'Function units cannot be written in 'u'Function units cannot be written in 'b' format. Only 'u' format. Only 'b' are supported.'u' are supported.'b'$\mathrm{{\left( 'u'$\mathrm{{\left( 'b' \right)}}$'u' \right)}}$'b'{{0:^'u'{{0:^'b's}}{{1:s}}'u's}}{{1:s}}'b'Try to format units using a formatter.'u'Try to format units using a formatter.'b'Return string representation for unit.'u'Return string representation for unit.'b'{}("{}"{})'u'{}("{}"{})'b', unit="'u', unit="'b'A representation of a (scaled) function of a number with a unit.

    Function quantities are quantities whose units are functions containing a
    physical unit, such as dB(mW).  Most of the arithmetic operations on
    function quantities are defined in this base class.

    While instantiation is also defined here, this class should not be
    instantiated directly.  Rather, subclasses should be made which have
    ``_unit_class`` pointing back to the corresponding function unit class.

    Parameters
    ----------
    value : number, quantity-like, or sequence thereof
        The numerical value of the function quantity. If a number or
        a `~astropy.units.Quantity` with a function unit, it will be converted
        to ``unit`` and the physical unit will be inferred from ``unit``.
        If a `~astropy.units.Quantity` with just a physical unit, it will
        converted to the function unit, after, if necessary, converting it to
        the physical unit inferred from ``unit``.

    unit : str, `~astropy.units.UnitBase`, or `~astropy.units.FunctionUnitBase`, optional
        For an `~astropy.units.FunctionUnitBase` instance, the
        physical unit will be taken from it; for other input, it will be
        inferred from ``value``. By default, ``unit`` is set by the subclass.

    dtype : `~numpy.dtype`, optional
        The dtype of the resulting Numpy array or scalar that will
        hold the value.  If not provided, it is determined from the input,
        except that any input that cannot represent float (integer and bool)
        is converted to float.

    copy : bool, optional
        If `True` (default), then the value is copied.  Otherwise, a copy will
        only be made if ``__array__`` returns a copy, if value is a nested
        sequence, or if a copy is needed to satisfy an explicitly given
        ``dtype``.  (The `False` option is intended mostly for internal use,
        to speed up initialization where a copy is known to have been made.
        Use with care.)

    order : {'C', 'F', 'A'}, optional
        Specify the order of the array.  As in `~numpy.array`.  Ignored
        if the input does not need to be converted and ``copy=False``.

    subok : bool, optional
        If `False` (default), the returned array will be forced to be of the
        class used.  Otherwise, subclasses will be passed through.

    ndmin : int, optional
        Specifies the minimum number of dimensions that the resulting array
        should have.  Ones will be prepended to the shape as needed to meet
        this requirement.  This parameter is ignored if the input is a
        `~astropy.units.Quantity` and ``copy=False``.

    Raises
    ------
    TypeError
        If the value provided is not a Python numeric type.
    TypeError
        If the unit provided is not a `~astropy.units.FunctionUnitBase`
        or `~astropy.units.Unit` object, or a parseable string unit.
    'u'A representation of a (scaled) function of a number with a unit.

    Function quantities are quantities whose units are functions containing a
    physical unit, such as dB(mW).  Most of the arithmetic operations on
    function quantities are defined in this base class.

    While instantiation is also defined here, this class should not be
    instantiated directly.  Rather, subclasses should be made which have
    ``_unit_class`` pointing back to the corresponding function unit class.

    Parameters
    ----------
    value : number, quantity-like, or sequence thereof
        The numerical value of the function quantity. If a number or
        a `~astropy.units.Quantity` with a function unit, it will be converted
        to ``unit`` and the physical unit will be inferred from ``unit``.
        If a `~astropy.units.Quantity` with just a physical unit, it will
        converted to the function unit, after, if necessary, converting it to
        the physical unit inferred from ``unit``.

    unit : str, `~astropy.units.UnitBase`, or `~astropy.units.FunctionUnitBase`, optional
        For an `~astropy.units.FunctionUnitBase` instance, the
        physical unit will be taken from it; for other input, it will be
        inferred from ``value``. By default, ``unit`` is set by the subclass.

    dtype : `~numpy.dtype`, optional
        The dtype of the resulting Numpy array or scalar that will
        hold the value.  If not provided, it is determined from the input,
        except that any input that cannot represent float (integer and bool)
        is converted to float.

    copy : bool, optional
        If `True` (default), then the value is copied.  Otherwise, a copy will
        only be made if ``__array__`` returns a copy, if value is a nested
        sequence, or if a copy is needed to satisfy an explicitly given
        ``dtype``.  (The `False` option is intended mostly for internal use,
        to speed up initialization where a copy is known to have been made.
        Use with care.)

    order : {'C', 'F', 'A'}, optional
        Specify the order of the array.  As in `~numpy.array`.  Ignored
        if the input does not need to be converted and ``copy=False``.

    subok : bool, optional
        If `False` (default), the returned array will be forced to be of the
        class used.  Otherwise, subclasses will be passed through.

    ndmin : int, optional
        Specifies the minimum number of dimensions that the resulting array
        should have.  Ones will be prepended to the shape as needed to meet
        this requirement.  This parameter is ignored if the input is a
        `~astropy.units.Quantity` and ``copy=False``.

    Raises
    ------
    TypeError
        If the value provided is not a Python numeric type.
    TypeError
        If the unit provided is not a `~astropy.units.FunctionUnitBase`
        or `~astropy.units.Unit` object, or a parseable string unit.
    'b'Default `~astropy.units.FunctionUnitBase` subclass.

    This should be overridden by subclasses.
    'u'Default `~astropy.units.FunctionUnitBase` subclass.

    This should be overridden by subclasses.
    'b'The physical quantity corresponding the function one.'u'The physical quantity corresponding the function one.'b'View as Quantity with function unit, dropping the physical unit.

        Use `~astropy.units.quantity.Quantity.value` for just the value.
        'u'View as Quantity with function unit, dropping the physical unit.

        Use `~astropy.units.quantity.Quantity.value` for just the value.
        'b'Return a copy with the physical unit in SI units.'u'Return a copy with the physical unit in SI units.'b'Return a copy with the physical unit in CGS units.'u'Return a copy with the physical unit in CGS units.'b'Generate a new instance with the physical unit decomposed.

        For details, see `~astropy.units.Quantity.decompose`.
        'u'Generate a new instance with the physical unit decomposed.

        For details, see `~astropy.units.Quantity.decompose`.
        'b'nonsense'u'nonsense'b' instances require 'u' instances require 'b' function units, so cannot set it to ''u' function units, so cannot set it to ''b'' with function quantities'u'' with function quantities'b'View as function quantity if the unit is unchanged.

        Used for the case that self.unit.physical_unit is dimensionless,
        where multiplication and division is done using the Quantity
        equivalent, to transform them back to a FunctionQuantity if possible.
        'u'View as function quantity if the unit is unchanged.

        Used for the case that self.unit.physical_unit is dimensionless,
        where multiplication and division is done using the Quantity
        equivalent, to transform them back to a FunctionQuantity if possible.
        'b'Cannot multiply function quantities which are not dimensionless with anything.'u'Cannot multiply function quantities which are not dimensionless with anything.'b'Cannot divide function quantities which are not dimensionless by anything.'u'Cannot divide function quantities which are not dimensionless by anything.'b'Cannot divide function quantities which are not dimensionless into anything.'u'Cannot divide function quantities which are not dimensionless into anything.'b'Do a comparison between self and other, raising UnitsError when
        other cannot be converted to self because it has different physical
        unit, and returning NotImplemented when there are other errors.
        'u'Do a comparison between self and other, raising UnitsError when
        other cannot be converted to self because it has different physical
        unit, and returning NotImplemented when there are other errors.
        'b'Unit conversion operator `<<`.'u'Unit conversion operator `<<`.'b'_function_view'u'_function_view'b'Cannot use method that uses function ''u'Cannot use method that uses function ''b'' with function quantities that are not dimensionless.'u'' with function quantities that are not dimensionless.'u'astropy.units.function.core'u'units.function.core'u'function.core'
Distribution class and associated machinery.
astropy.utils.compat.numpycompatnumpy.core.multiarraynormalize_axis_indexnumpy.lib.function_basenumpy.lib.stride_tricksDummyArraynumpy.lib._function_base_implnumpy.lib._stride_tricks_implnumpy.lib.array_utilsFUNCTION_HELPERS1.4826022185056021.48260221850560203193936104071326553821563720703125SMAD_SCALE_FACTORA scalar value or array values with associated uncertainty distribution.

    This object will take its exact type from whatever the ``samples``
    argument is. In general this is expected to be ``NdarrayDistribution`` for
    |ndarray| input, and, e.g., ``QuantityDistribution`` for a subclass such
    as |Quantity|. But anything compatible with `numpy.asanyarray` is possible
    (generally producing ``NdarrayDistribution``).

    See also: https://docs.astropy.org/en/stable/uncertainty/

    Parameters
    ----------
    samples : array-like
        The distribution, with sampling along the *trailing* axis. If 1D, the sole
        dimension is used as the sampling axis (i.e., it is a scalar distribution).
        If an |ndarray| or subclass, the data will not be copied unless it is not
        possible to take a view (generally, only when the strides of the last axis
        are negative).

    _generated_subclassessamplesAttempted to initialize a Distribution with a scalar_get_distribution_dtypenew_dtype__array_interface__|Vtypestr_get_distribution_clssamples_clsNdarrayDistribution_DistributionReprfound , which does not have _DistributionRepr at __mro__[1]. Please raise an issue at https://github.com/astropy/astropy/issues/new/choose.", which does not have _DistributionRepr at ""__mro__[1]. Please raise an issue at ""https://github.com/astropy/astropy/issues/new/choose."_samples_clssample_dtypeDistribution does not yet support gufunc calls with 'axes'.ncore_inncore_outconvncore_result_as_distributionfunction_helperTurn result into a distribution.

        If no output is given, it will create a Distribution from the array,
        If an output is given, it should be fine as is.

        Parameters
        ----------
        result : ndarray or tuple thereof
            Array(s) which need to be turned into Distribution.
        out : Distribution, tuple of Distribution or None
            Possible output |Distribution|. Should be `None` or a tuple if result
            is a tuple.
        ncore_out: int or tuple thereof
            The number of core dimensions for the output array for a gufunc.  This
            is used to determine which axis should be used for the samples.
        axis: int or None
            The axis a gufunc operated on.  Used only if ``ncore_out`` is given.

        Returns
        -------
        out : Distribution
        _makeresult_clsthe Distribution implementation cannot handle 
        The number of samples of this distribution.  A single `int`.
        pdf_mean
        The mean of this distribution.

        Arguments are as for `numpy.mean`.
        pdf_std
        The standard deviation of this distribution.

        Arguments are as for `numpy.std`.
        pdf_var
        The variance of this distribution.

        Arguments are as for `numpy.var`.
        pdf_median
        The median of this distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        pdf_mad
        The median absolute deviation of this distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        absdiffoverwrite_inputpdf_smad
        The median absolute deviation of this distribution rescaled to match the
        standard deviation for a normal distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        pdf_percentilespercentile
        Compute percentiles of this Distribution.

        Parameters
        ----------
        percentile : float or array of float or `~astropy.units.Quantity`
            The desired percentiles of the distribution (i.e., on [0,100]).
            `~astropy.units.Quantity` will be converted to percent, meaning
            that a ``dimensionless_unscaled`` `~astropy.units.Quantity` will
            be interpreted as a quantile.

        Additional keywords are passed into `numpy.percentile`.

        Returns
        -------
        percentiles : `~astropy.units.Quantity` ['dimensionless']
            The ``fracs`` percentiles of this distribution.
        percspdf_histogram
        Compute histogram over the samples in the distribution.

        Parameters
        ----------
        All keyword arguments are passed into `astropy.stats.histogram`. Note
        That some of these options may not be valid for some multidimensional
        distributions.

        Returns
        -------
        hist : array
            The values of the histogram. Trailing dimension is the histogram
            dimension.
        bin_edges : array of dtype float
            Return the bin edges ``(length(hist)+1)``. Trailing dimension is the
            bin histogram dimension.
        distrraveled_distrnhistsbin_edgesnhistbin_edgenh_shapebe_shapeScalarDistributionvoidScalar distribution.

    This class mostly exists to make `~numpy.array2print` possible for
    all subclasses.  It is a scalar element, still with n_samples samples.
    ArrayDistributionNew view of array with the same data.

        Like `~numpy.ndarray.view` except that the result will always be a new
        `~astropy.uncertainty.Distribution` instance.  If the requested
        ``type`` is a `~astropy.uncertainty.Distribution`, then no change in
        ``dtype`` is allowed.

        distr_view can only be viewed with a dtype with itemsize {self.strides[-1]} or {self.dtype.itemsize}" can only be viewed with a dtype with ""itemsize {self.strides[-1]} or {self.dtype.itemsize}"reprarrfirstspace with n_samples=firstparendistrstrtoaddsuperlatex, \; n_{{\rm samp}}=# we set this by hand because the symbolic expression (below) requires scipy# SMAD_SCALE_FACTOR = 1 / scipy.stats.norm.ppf(0.75)# We can handle strides larger than the itemsize by stride trickery,# but the samples do have to have positive offset from each other,# so if that's not the case, we make a copy.# strides[-1] can be 0.# Do the view in two stages, since for viewing as a new class, it is good# to have with the dtype in place (e.g., for Quantity.__array_finalize__,# it is needed to create the correct StructuredUnit).# First, get the structured dtype with a single "samples" field that holds# a size n_samples array of "sample" fields with individual samples.# We need the double indirection to be able to deal with non-contiguous samples# (such as result from indexing a structured array).# Note that for a single sample, samples.strides[-1] can be 0.# Create a structured array with the new dtype. We ensure we start with a# regular ndarray, to avoid interference between our complicated dtype and# something else (such as would be the case for Quantity.__array_finalize__,# which needs the dtype to be correct for creating a StructuredUnit).# For contiguous last axis, a plain new view suffices.# But if the last axis is not contiguous, we use __array_interface__ (as in# np.lib.stridetricks.as_strided) to create a new ndarray where the last# axis is covered by a void of the same size as the structured new_dtype# (assigning it directly does not work: possible empty fields get entries).# Set our new structured dtype.# Get rid of trailing dimension of 1.# Now view as the Distribution subclass, and finalize based on the# original samples (e.g., to set the unit for QuantityDistribution).# Just hope that NdarrayDistribution can handle it.# _generated_subclasses[list] = NdarrayDistribution# We need to get rid of the top _DistributionRepr, since we add# it again below (it should always be on top).# TODO: remove the need for _DistributionRepr by defining# __array_function__ and overriding array2string.# Sanity check. This should never happen!# Create (and therefore register) new Distribution subclass for the# given samples_cls.# If not a sample dtype already, create one with a "samples" entry that holds# all the samples.  Here, we create an indirection via "sample" because# selecting an item from a structured array will necessarily give# non-consecutive samples, and these can only be dealt with samples that are# larger than a single element (plus stride tricks; see __new__). For those# cases, itemsize larger than dtype.itemsize will be passed in (note that for# the n_sample=1 case, itemsize can be 0; like itemsize=None, this will be dealt# with by "or dtype.itemsize" below).# For any input that is not a Distribution, we add an axis at the# end, to allow proper broadcasting with the distributions.# We're dealing with a gufunc, which may add an extra axis.# Ignore axes keyword for now...  TODO: remove this limitation.# Fall through to return section, wrapping distributions, unless# indicated otherwise.  TODO: use a less hacky solution?# We're done if the result was NotImplemented, which can happen# if other inputs/outputs override __array_function__;# hopefully, they can then deal with us.# Some np.linalg functions return namedtuple, which is handy to access# elements by name, but cannot be directly initialized with an iterator.# Turn the result into a Distribution if needed.# work with Distribution.  In principle, there may be another class that# But if there is ndarray (or a non-Distribution subclass of it) around,# Override __eq__ and __ne__ to pass on directly to the ufunc since# otherwise comparisons with non-distributions do not work (but# deferring if other defines __array_ufunc__ = None -- see# numpy/core/src/common/binop_override.h for the logic; we assume we# will never deal with __array_priority__ any more).  Note: there is no# problem for other comparisons, since for those, structured arrays are# not treated differently in numpy/core/src/multiarray/arrayobject.c.# numpy.percentile strips units for unclear reasons, so we have to make# a new object with units# This includes the important override of view and __getitem__# which are needed for all ndarray subclass Distributions, but not# for the scalar one.# Override view so that we stay a Distribution version of the new type.# Assume the user knows what they are doing.# This does not necessarily leave the sample axis in the right place.# Like in the creation, we go through an ndarray to ensure we have our# actual dtype and to avoid entering, e.g., Quantity.__getitem__, which# would give problems with units.# "samples" should always get back to the samples class.# Hard to get this right directly, so instead get item from the# distribution, and create a new instance.  We move the sample axis to# the end to ensure the order is right for possible subarrays.# Required for in-place operations like dist[dist < 0] += 360.# Support operations like dist[dist < 0] = 0.# Get a view of this item (non-trivial; see above).# If value is not already a Distribution, first make it an array# to help interpret possible structured dtype, and then turn it# into a Distribution with n_samples=1 (which will broadcast).# :-1] removes the ending '>'# numpy array-like# Ensure our base NdarrayDistribution is known.b'
Distribution class and associated machinery.
'u'
Distribution class and associated machinery.
'b'A scalar value or array values with associated uncertainty distribution.

    This object will take its exact type from whatever the ``samples``
    argument is. In general this is expected to be ``NdarrayDistribution`` for
    |ndarray| input, and, e.g., ``QuantityDistribution`` for a subclass such
    as |Quantity|. But anything compatible with `numpy.asanyarray` is possible
    (generally producing ``NdarrayDistribution``).

    See also: https://docs.astropy.org/en/stable/uncertainty/

    Parameters
    ----------
    samples : array-like
        The distribution, with sampling along the *trailing* axis. If 1D, the sole
        dimension is used as the sampling axis (i.e., it is a scalar distribution).
        If an |ndarray| or subclass, the data will not be copied unless it is not
        possible to take a view (generally, only when the strides of the last axis
        are negative).

    'u'A scalar value or array values with associated uncertainty distribution.

    This object will take its exact type from whatever the ``samples``
    argument is. In general this is expected to be ``NdarrayDistribution`` for
    |ndarray| input, and, e.g., ``QuantityDistribution`` for a subclass such
    as |Quantity|. But anything compatible with `numpy.asanyarray` is possible
    (generally producing ``NdarrayDistribution``).

    See also: https://docs.astropy.org/en/stable/uncertainty/

    Parameters
    ----------
    samples : array-like
        The distribution, with sampling along the *trailing* axis. If 1D, the sole
        dimension is used as the sampling axis (i.e., it is a scalar distribution).
        If an |ndarray| or subclass, the data will not be copied unless it is not
        possible to take a view (generally, only when the strides of the last axis
        are negative).

    'b'Attempted to initialize a Distribution with a scalar'u'Attempted to initialize a Distribution with a scalar'b'|V'u'|V'b'typestr'u'typestr'b'strides'u'strides'b'found 'u'found 'b', which does not have _DistributionRepr at __mro__[1]. Please raise an issue at https://github.com/astropy/astropy/issues/new/choose.'u', which does not have _DistributionRepr at __mro__[1]. Please raise an issue at https://github.com/astropy/astropy/issues/new/choose.'b'_samples_cls'u'_samples_cls'b'samples'u'samples'b'sample'u'sample'b'Distribution does not yet support gufunc calls with 'axes'.'u'Distribution does not yet support gufunc calls with 'axes'.'b'Turn result into a distribution.

        If no output is given, it will create a Distribution from the array,
        If an output is given, it should be fine as is.

        Parameters
        ----------
        result : ndarray or tuple thereof
            Array(s) which need to be turned into Distribution.
        out : Distribution, tuple of Distribution or None
            Possible output |Distribution|. Should be `None` or a tuple if result
            is a tuple.
        ncore_out: int or tuple thereof
            The number of core dimensions for the output array for a gufunc.  This
            is used to determine which axis should be used for the samples.
        axis: int or None
            The axis a gufunc operated on.  Used only if ``ncore_out`` is given.

        Returns
        -------
        out : Distribution
        'u'Turn result into a distribution.

        If no output is given, it will create a Distribution from the array,
        If an output is given, it should be fine as is.

        Parameters
        ----------
        result : ndarray or tuple thereof
            Array(s) which need to be turned into Distribution.
        out : Distribution, tuple of Distribution or None
            Possible output |Distribution|. Should be `None` or a tuple if result
            is a tuple.
        ncore_out: int or tuple thereof
            The number of core dimensions for the output array for a gufunc.  This
            is used to determine which axis should be used for the samples.
        axis: int or None
            The axis a gufunc operated on.  Used only if ``ncore_out`` is given.

        Returns
        -------
        out : Distribution
        'b'_make'u'_make'b'the Distribution implementation cannot handle 'u'the Distribution implementation cannot handle 'b'__array_ufunc__'u'__array_ufunc__'b'
        The number of samples of this distribution.  A single `int`.
        'u'
        The number of samples of this distribution.  A single `int`.
        'b'
        The mean of this distribution.

        Arguments are as for `numpy.mean`.
        'u'
        The mean of this distribution.

        Arguments are as for `numpy.mean`.
        'b'
        The standard deviation of this distribution.

        Arguments are as for `numpy.std`.
        'u'
        The standard deviation of this distribution.

        Arguments are as for `numpy.std`.
        'b'
        The variance of this distribution.

        Arguments are as for `numpy.var`.
        'u'
        The variance of this distribution.

        Arguments are as for `numpy.var`.
        'b'
        The median of this distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        'u'
        The median of this distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        'b'
        The median absolute deviation of this distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        'u'
        The median absolute deviation of this distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        'b'
        The median absolute deviation of this distribution rescaled to match the
        standard deviation for a normal distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        'u'
        The median absolute deviation of this distribution rescaled to match the
        standard deviation for a normal distribution.

        Parameters
        ----------
        out : array, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output,
            but the type (of the output) will be cast if necessary.
        'b'
        Compute percentiles of this Distribution.

        Parameters
        ----------
        percentile : float or array of float or `~astropy.units.Quantity`
            The desired percentiles of the distribution (i.e., on [0,100]).
            `~astropy.units.Quantity` will be converted to percent, meaning
            that a ``dimensionless_unscaled`` `~astropy.units.Quantity` will
            be interpreted as a quantile.

        Additional keywords are passed into `numpy.percentile`.

        Returns
        -------
        percentiles : `~astropy.units.Quantity` ['dimensionless']
            The ``fracs`` percentiles of this distribution.
        'u'
        Compute percentiles of this Distribution.

        Parameters
        ----------
        percentile : float or array of float or `~astropy.units.Quantity`
            The desired percentiles of the distribution (i.e., on [0,100]).
            `~astropy.units.Quantity` will be converted to percent, meaning
            that a ``dimensionless_unscaled`` `~astropy.units.Quantity` will
            be interpreted as a quantile.

        Additional keywords are passed into `numpy.percentile`.

        Returns
        -------
        percentiles : `~astropy.units.Quantity` ['dimensionless']
            The ``fracs`` percentiles of this distribution.
        'b'_new_view'u'_new_view'b'
        Compute histogram over the samples in the distribution.

        Parameters
        ----------
        All keyword arguments are passed into `astropy.stats.histogram`. Note
        That some of these options may not be valid for some multidimensional
        distributions.

        Returns
        -------
        hist : array
            The values of the histogram. Trailing dimension is the histogram
            dimension.
        bin_edges : array of dtype float
            Return the bin edges ``(length(hist)+1)``. Trailing dimension is the
            bin histogram dimension.
        'u'
        Compute histogram over the samples in the distribution.

        Parameters
        ----------
        All keyword arguments are passed into `astropy.stats.histogram`. Note
        That some of these options may not be valid for some multidimensional
        distributions.

        Returns
        -------
        hist : array
            The values of the histogram. Trailing dimension is the histogram
            dimension.
        bin_edges : array of dtype float
            Return the bin edges ``(length(hist)+1)``. Trailing dimension is the
            bin histogram dimension.
        'b'Scalar distribution.

    This class mostly exists to make `~numpy.array2print` possible for
    all subclasses.  It is a scalar element, still with n_samples samples.
    'u'Scalar distribution.

    This class mostly exists to make `~numpy.array2print` possible for
    all subclasses.  It is a scalar element, still with n_samples samples.
    'b'New view of array with the same data.

        Like `~numpy.ndarray.view` except that the result will always be a new
        `~astropy.uncertainty.Distribution` instance.  If the requested
        ``type`` is a `~astropy.uncertainty.Distribution`, then no change in
        ``dtype`` is allowed.

        'u'New view of array with the same data.

        Like `~numpy.ndarray.view` except that the result will always be a new
        `~astropy.uncertainty.Distribution` instance.  If the requested
        ``type`` is a `~astropy.uncertainty.Distribution`, then no change in
        ``dtype`` is allowed.

        'b' can only be viewed with a dtype with itemsize {self.strides[-1]} or {self.dtype.itemsize}'u' can only be viewed with a dtype with itemsize {self.strides[-1]} or {self.dtype.itemsize}'b' with n_samples='u' with n_samples='b'_repr_latex_'u'_repr_latex_'b', \; n_{{\rm samp}}='u', \; n_{{\rm samp}}='u'astropy.uncertainty.core'u'uncertainty.core'KW_ONLYis_dataclassenumEnumSentinelSentinel values for Parameter fields.A sentinel value signifying a missing default._UnitFieldobjcls_FValidateField_fvalidate_fvalidate_in`fvalidate`, if str, must be in `fvalidate` must be a function or Cosmological parameter (descriptor).

    Should only be used with a :class:`~astropy.cosmology.Cosmology` subclass.

    Parameters
    ----------
    default : Any (optional, keyword-only)
        Default value of the Parameter. If not given the
        Parameter must be set when initializing the cosmology.
    derived : bool (optional, keyword-only)
        Whether the Parameter is 'derived', default `False`.
        Derived parameters behave similarly to normal parameters, but are not
        sorted by the |Cosmology| signature (probably not there) and are not
        included in all methods. For reference, see ``Ode0`` in
        ``FlatFLRWMixin``, which removes :math:`\Omega_{de,0}`` as an
        independent parameter (:math:`\Omega_{de,0} \equiv 1 - \Omega_{tot}`).
    unit : unit-like or None (optional, keyword-only)
        The `~astropy.units.Unit` for the Parameter. If None (default) no
        unit as assumed.
    equivalencies : `~astropy.units.Equivalency` or sequence thereof
        Unit equivalencies for this Parameter.
    fvalidate : callable[[object, object, Any], Any] or str (optional, keyword-only)
        Function to validate the Parameter value from instances of the
        cosmology class. If "default", uses default validator to assign units
        (with equivalencies), if Parameter has units.
        For other valid string options, see ``Parameter._registry_validators``.
        'fvalidate' can also be set through a decorator with
        :meth:`~astropy.cosmology.Parameter.validator`.
    doc : str or None (optional, keyword-only)
        Parameter description.

    Examples
    --------
    For worked examples see :class:`~astropy.cosmology.FLRW`.
    Default value of the Parameter.

    By default set to ``MISSING``, which indicates the parameter must be set
    when initializing the cosmology.
    Whether the Parameter can be set, or is derived, on the cosmology.The unit of the Parameter (can be `None` for unitless).EquivalencyUnit equivalencies available when setting the parameter.Function to validate/convert values when setting the Parameter.Parameter description.The name of the Parameter on the Cosmology.

    Cannot be set directly.
    name not initializedAllows attribute setting once.

        Raises AttributeError subsequently.
        cannot assign to field setflagsMake new Parameter with custom ``fvalidate``.

        Note: ``Parameter.fvalidator`` must be the top-most descriptor decorator.

        Parameters
        ----------
        fvalidate : callable[[type, type, Any], Any]

        Returns
        -------
        `~astropy.cosmology.Parameter`
            Copy of this Parameter but with custom ``fvalidate``.
        Run the validator on this Parameter.

        Parameters
        ----------
        cosmology : `~astropy.cosmology.Cosmology` instance
        value : Any
            The object to validate.

        Returns
        -------
        Any
            The output of calling ``fvalidate(cosmology, self, value)``
            (yes, that parameter order).
        register_validatorDecorator to register a new kind of validator function.

        Parameters
        ----------
        key : str
        fvalidate : callable[[object, object, Any], Any] or None, optional
            Value validation function.

        Returns
        -------
        ``validator`` or callable[``validator``]
            if validator is None returns a function that takes and registers a
            validator. This allows ``register_validator`` to be used as a
            decorator.
        Clone this `Parameter`, changing any constructor argument.

        Parameters
        ----------
        **kw
            Passed to constructor. The current values, eg. ``fvalidate`` are
            used as the default values, so an empty ``**kw`` is an exact copy.

        Examples
        --------
        >>> p = Parameter()
        >>> p
        Parameter(derived=False, unit=None, equivalencies=[],
                  fvalidate='default', doc=None)

        >>> p.clone(unit="km")
        Parameter(derived=False, unit=Unit("km"), equivalencies=[],
                  fvalidate='default', doc=None)
        clonedReturn repr(self).fields_repr# TODO: rm this class when py3.13+ allows for `field(converter=...)`# calling `Parameter.unit` from the class# calling `Parameter.fvalidate` from the class# calling `Parameter.fvalidate` from an instance# Always store input fvalidate.# Process to the callable.# Setting# Info# Now setting a dummy attribute name. The cosmology class will call# `__set_name__`, passing the real attribute name. However, if Parameter is not# init'ed as a descriptor then this ensures that all declared fields exist.# attribute name on container cosmology class# -------------------------------------------# descriptor and property-like methods# Get from class# If the Parameter is being set as part of a dataclass constructor, then we# raise an AttributeError if the default is MISSING. This is to prevent the# Parameter from being set as the default value of the dataclass field and# erroneously included in the class' __init__ signature.# Get from instance# Raise error if setting 2nd time. The built-in Cosmology objects are frozen# dataclasses and this is redundant, however user defined cosmology classes do# not have to be frozen.# Change `self` to the default value if default is MISSING.# This is done for backwards compatibility only - so that Parameter can be used# in a dataclass and still return `self` when accessed from a class.# Accessing the Parameter object via `cosmo_cls.param_name` will be removed# in favor of `cosmo_cls.parameters["param_name"]`.# Validate value, generally setting units if present# Make the value read-only, if ndarray-like# Set the value on the cosmology# validate value# prefer the input fvalidate# Transfer over the __set_name__ stuff. If `clone` is used to make a# new descriptor, __set_name__ will be called again, overwriting this.# Get the repr, using the input fvalidate over the processed value# Only show fields that should be displayed and are not sentinel valuesb'Sentinel values for Parameter fields.'u'Sentinel values for Parameter fields.'b'A sentinel value signifying a missing default.'u'A sentinel value signifying a missing default.'b'_fvalidate_in'u'_fvalidate_in'b'`fvalidate`, if str, must be in 'u'`fvalidate`, if str, must be in 'b'`fvalidate` must be a function or 'u'`fvalidate` must be a function or 'b'_fvalidate'u'_fvalidate'b'Cosmological parameter (descriptor).

    Should only be used with a :class:`~astropy.cosmology.Cosmology` subclass.

    Parameters
    ----------
    default : Any (optional, keyword-only)
        Default value of the Parameter. If not given the
        Parameter must be set when initializing the cosmology.
    derived : bool (optional, keyword-only)
        Whether the Parameter is 'derived', default `False`.
        Derived parameters behave similarly to normal parameters, but are not
        sorted by the |Cosmology| signature (probably not there) and are not
        included in all methods. For reference, see ``Ode0`` in
        ``FlatFLRWMixin``, which removes :math:`\Omega_{de,0}`` as an
        independent parameter (:math:`\Omega_{de,0} \equiv 1 - \Omega_{tot}`).
    unit : unit-like or None (optional, keyword-only)
        The `~astropy.units.Unit` for the Parameter. If None (default) no
        unit as assumed.
    equivalencies : `~astropy.units.Equivalency` or sequence thereof
        Unit equivalencies for this Parameter.
    fvalidate : callable[[object, object, Any], Any] or str (optional, keyword-only)
        Function to validate the Parameter value from instances of the
        cosmology class. If "default", uses default validator to assign units
        (with equivalencies), if Parameter has units.
        For other valid string options, see ``Parameter._registry_validators``.
        'fvalidate' can also be set through a decorator with
        :meth:`~astropy.cosmology.Parameter.validator`.
    doc : str or None (optional, keyword-only)
        Parameter description.

    Examples
    --------
    For worked examples see :class:`~astropy.cosmology.FLRW`.
    'u'Cosmological parameter (descriptor).

    Should only be used with a :class:`~astropy.cosmology.Cosmology` subclass.

    Parameters
    ----------
    default : Any (optional, keyword-only)
        Default value of the Parameter. If not given the
        Parameter must be set when initializing the cosmology.
    derived : bool (optional, keyword-only)
        Whether the Parameter is 'derived', default `False`.
        Derived parameters behave similarly to normal parameters, but are not
        sorted by the |Cosmology| signature (probably not there) and are not
        included in all methods. For reference, see ``Ode0`` in
        ``FlatFLRWMixin``, which removes :math:`\Omega_{de,0}`` as an
        independent parameter (:math:`\Omega_{de,0} \equiv 1 - \Omega_{tot}`).
    unit : unit-like or None (optional, keyword-only)
        The `~astropy.units.Unit` for the Parameter. If None (default) no
        unit as assumed.
    equivalencies : `~astropy.units.Equivalency` or sequence thereof
        Unit equivalencies for this Parameter.
    fvalidate : callable[[object, object, Any], Any] or str (optional, keyword-only)
        Function to validate the Parameter value from instances of the
        cosmology class. If "default", uses default validator to assign units
        (with equivalencies), if Parameter has units.
        For other valid string options, see ``Parameter._registry_validators``.
        'fvalidate' can also be set through a decorator with
        :meth:`~astropy.cosmology.Parameter.validator`.
    doc : str or None (optional, keyword-only)
        Parameter description.

    Examples
    --------
    For worked examples see :class:`~astropy.cosmology.FLRW`.
    'b'Default value of the Parameter.

    By default set to ``MISSING``, which indicates the parameter must be set
    when initializing the cosmology.
    'u'Default value of the Parameter.

    By default set to ``MISSING``, which indicates the parameter must be set
    when initializing the cosmology.
    'b'Whether the Parameter can be set, or is derived, on the cosmology.'u'Whether the Parameter can be set, or is derived, on the cosmology.'b'The unit of the Parameter (can be `None` for unitless).'u'The unit of the Parameter (can be `None` for unitless).'b'Unit equivalencies available when setting the parameter.'u'Unit equivalencies available when setting the parameter.'b'Function to validate/convert values when setting the Parameter.'u'Function to validate/convert values when setting the Parameter.'b'Parameter description.'u'Parameter description.'b'The name of the Parameter on the Cosmology.

    Cannot be set directly.
    'u'The name of the Parameter on the Cosmology.

    Cannot be set directly.
    'b'__doc__'u'__doc__'b'name not initialized'u'name not initialized'b'Allows attribute setting once.

        Raises AttributeError subsequently.
        'u'Allows attribute setting once.

        Raises AttributeError subsequently.
        'b'cannot assign to field 'u'cannot assign to field 'b'setflags'u'setflags'b'Make new Parameter with custom ``fvalidate``.

        Note: ``Parameter.fvalidator`` must be the top-most descriptor decorator.

        Parameters
        ----------
        fvalidate : callable[[type, type, Any], Any]

        Returns
        -------
        `~astropy.cosmology.Parameter`
            Copy of this Parameter but with custom ``fvalidate``.
        'u'Make new Parameter with custom ``fvalidate``.

        Note: ``Parameter.fvalidator`` must be the top-most descriptor decorator.

        Parameters
        ----------
        fvalidate : callable[[type, type, Any], Any]

        Returns
        -------
        `~astropy.cosmology.Parameter`
            Copy of this Parameter but with custom ``fvalidate``.
        'b'Run the validator on this Parameter.

        Parameters
        ----------
        cosmology : `~astropy.cosmology.Cosmology` instance
        value : Any
            The object to validate.

        Returns
        -------
        Any
            The output of calling ``fvalidate(cosmology, self, value)``
            (yes, that parameter order).
        'u'Run the validator on this Parameter.

        Parameters
        ----------
        cosmology : `~astropy.cosmology.Cosmology` instance
        value : Any
            The object to validate.

        Returns
        -------
        Any
            The output of calling ``fvalidate(cosmology, self, value)``
            (yes, that parameter order).
        'b'Decorator to register a new kind of validator function.

        Parameters
        ----------
        key : str
        fvalidate : callable[[object, object, Any], Any] or None, optional
            Value validation function.

        Returns
        -------
        ``validator`` or callable[``validator``]
            if validator is None returns a function that takes and registers a
            validator. This allows ``register_validator`` to be used as a
            decorator.
        'u'Decorator to register a new kind of validator function.

        Parameters
        ----------
        key : str
        fvalidate : callable[[object, object, Any], Any] or None, optional
            Value validation function.

        Returns
        -------
        ``validator`` or callable[``validator``]
            if validator is None returns a function that takes and registers a
            validator. This allows ``register_validator`` to be used as a
            decorator.
        'b'Clone this `Parameter`, changing any constructor argument.

        Parameters
        ----------
        **kw
            Passed to constructor. The current values, eg. ``fvalidate`` are
            used as the default values, so an empty ``**kw`` is an exact copy.

        Examples
        --------
        >>> p = Parameter()
        >>> p
        Parameter(derived=False, unit=None, equivalencies=[],
                  fvalidate='default', doc=None)

        >>> p.clone(unit="km")
        Parameter(derived=False, unit=Unit("km"), equivalencies=[],
                  fvalidate='default', doc=None)
        'u'Clone this `Parameter`, changing any constructor argument.

        Parameters
        ----------
        **kw
            Passed to constructor. The current values, eg. ``fvalidate`` are
            used as the default values, so an empty ``**kw`` is an exact copy.

        Examples
        --------
        >>> p = Parameter()
        >>> p
        Parameter(derived=False, unit=None, equivalencies=[],
                  fvalidate='default', doc=None)

        >>> p.clone(unit="km")
        Parameter(derived=False, unit=Unit("km"), equivalencies=[],
                  fvalidate='default', doc=None)
        'b'fvalidate'u'fvalidate'b'Return repr(self).'u'Return repr(self).'u'cosmology._src.parameter.core'u'_src.parameter.core'u'parameter.core'astropy.timeseries.periodograms.lombscargle.coremethodsvalidate_unit_consistencyreference_objectinput_objectCompute the box least squares periodogram.

    This method is a commonly used tool for discovering transiting exoplanets
    or eclipsing binaries in photometric time series datasets. This
    implementation is based on the "box least squares (BLS)" method described
    in [1]_ and [2]_.

    Parameters
    ----------
    t : array-like, `~astropy.units.Quantity`, `~astropy.time.Time`, or `~astropy.time.TimeDelta`
        Sequence of observation times.
    y : array-like or `~astropy.units.Quantity`
        Sequence of observations associated with times ``t``.
    dy : float, array-like, or `~astropy.units.Quantity`, optional
        Error or sequence of observational errors associated with times ``t``.

    Examples
    --------
    Generate noisy data with a transit:

    >>> rand = np.random.default_rng(42)
    >>> t = rand.uniform(0, 10, 500)
    >>> y = np.ones_like(t)
    >>> y[np.abs((t + 1.0)%2.0-1)<0.08] = 1.0 - 0.1
    >>> y += 0.01 * rand.standard_normal(len(t))

    Compute the transit periodogram on a heuristically determined period grid
    and find the period with maximum power:

    >>> model = BoxLeastSquares(t, y)
    >>> results = model.autopower(0.16)
    >>> results.period[np.argmax(results.power)]  # doctest: +FLOAT_CMP
    np.float64(2.000412388152837)

    Compute the periodogram on a user-specified period grid:

    >>> periods = np.linspace(1.9, 2.1, 5)
    >>> results = model.power(periods, 0.16)
    >>> results.power  # doctest: +FLOAT_CMP
    array([0.01723948, 0.0643028 , 0.1338783 , 0.09428816, 0.03577543])

    If the inputs are AstroPy Quantities with units, the units will be
    validated and the outputs will also be Quantities with appropriate units:

    >>> from astropy import units as u
    >>> t = t * u.day
    >>> y = y * u.dimensionless_unscaled
    >>> model = BoxLeastSquares(t, y)
    >>> results = model.autopower(0.16 * u.day)
    >>> results.period.unit
    Unit("d")
    >>> results.power.unit
    Unit(dimensionless)

    References
    ----------
    .. [1] Kovacs, Zucker, & Mazeh (2002), A&A, 391, 369
        (arXiv:astro-ph/0206099)
    .. [2] Hartman & Bakos (2016), Astronomy & Computing, 17, 1
        (arXiv:1605.06811)

    autoperioddurationminimum_periodmaximum_periodminimum_n_transitfrequency_factorDetermine a suitable grid of periods.

        This method uses a set of heuristics to select a conservative period
        grid that is uniform in frequency. This grid might be too fine for
        some user's needs depending on the precision requirements or the
        sampling of the data. The grid can be made coarser by increasing
        ``frequency_factor``.

        Parameters
        ----------
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations that will be considered.
        minimum_period, maximum_period : float or `~astropy.units.Quantity` ['time'], optional
            The minimum/maximum periods to search. If not provided, these will
            be computed as described in the notes below.
        minimum_n_transit : int, optional
            If ``maximum_period`` is not provided, this is used to compute the
            maximum period to search by asserting that any systems with at
            least ``minimum_n_transits`` will be within the range of searched
            periods. Note that this is not the same as requiring that
            ``minimum_n_transits`` be required for detection. The default
            value is ``3``.
        frequency_factor : float, optional
            A factor to control the frequency spacing as described in the
            notes below. The default value is ``1.0``.

        Returns
        -------
        period : array-like or `~astropy.units.Quantity` ['time']
            The set of periods computed using these heuristics with the same
            units as ``t``.

        Notes
        -----
        The default minimum period is chosen to be twice the maximum duration
        because there won't be much sensitivity to periods shorter than that.

        The default maximum period is computed as

        .. code-block:: python

            maximum_period = (max(t) - min(t)) / minimum_n_transits

        ensuring that any systems with at least ``minimum_n_transits`` are
        within the range of searched periods.

        The frequency spacing is given by

        .. code-block:: python

            df = frequency_factor * min(duration) / (max(t) - min(t))**2

        so the grid can be made finer by decreasing ``frequency_factor`` or
        coarser by increasing ``frequency_factor``.

        _validate_durationmin_durationminimum_n_transit must be greater than 1minimum_period must be positivenf_t_unitobjectiveoversampleCompute the periodogram at set of heuristically determined periods.

        This method calls :func:`BoxLeastSquares.autoperiod` to determine
        the period grid and then :func:`BoxLeastSquares.power` to compute
        the periodogram. See those methods for documentation of the arguments.

        periodCompute the periodogram for a set of periods.

        Parameters
        ----------
        period : array-like or `~astropy.units.Quantity` ['time']
            The periods where the power should be computed
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations to test
        objective : {'likelihood', 'snr'}, optional
            The scalar that should be optimized to find the best fit phase,
            duration, and depth. This can be either ``'likelihood'`` (default)
            to optimize the log-likelihood of the model, or ``'snr'`` to
            optimize the signal-to-noise with which the transit depth is
            measured.
        method : {'fast', 'slow'}, optional
            The computational method used to compute the periodogram. This is
            mainly included for the purposes of testing and most users will
            want to use the optimized ``'fast'`` method (default) that is
            implemented in Cython.  ``'slow'`` is a brute-force method that is
            used to test the results of the ``'fast'`` method.
        oversample : int, optional
            The number of bins per duration that should be used. This sets the
            time resolution of the phase fit with larger values of
            ``oversample`` yielding a finer grid and higher computational cost.

        Returns
        -------
        results : BoxLeastSquaresResults
            The periodogram results as a :class:`BoxLeastSquaresResults`
            object.

        Raises
        ------
        ValueError
            If ``oversample`` is not an integer greater than 0 or if
            ``objective`` or ``method`` are not valid.

        _validate_period_and_durationoversample must be an int, got oversample must be greater than or equal to 1likelihoodsnrallowed_objectivesUnrecognized method ''
allowed methods are: "'\n""allowed methods are: "use_likelihoodslowallowed_methodsascontiguousarrayt_refivarperiod_fmtbls_fastblsbls_slow_format_results was provided as an absolute time but the BoxLeastSquares class was initialized with relative times."the BoxLeastSquares class was initialized " was provided as a relative time but the BoxLeastSquares class was initialized with absolute times._as_absolute_time_if_needed
        Convert the provided times to absolute times using the current _tstart
        value, if needed.
        100000t_modeltransit_timeCompute the transit model at the given period, duration, and phase.

        Parameters
        ----------
        t_model : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
            Times at which to compute the model.
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        y_model : array-like or `~astropy.units.Quantity`
            The model evaluated at the times ``t_model`` with units of ``y``.

        hpm_inm_outy_iny_outy_modelm_model_y_unitcompute_statsCompute descriptive statistics for a given transit model.

        These statistics are commonly used for vetting of transit candidates.

        Parameters
        ----------
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        stats : dict
            A dictionary containing several descriptive statistics:

            - ``depth``: The depth and uncertainty (as a tuple with two
                values) on the depth for the fiducial model.
            - ``depth_odd``: The depth and uncertainty on the depth for a
                model where the period is twice the fiducial period.
            - ``depth_even``: The depth and uncertainty on the depth for a
                model where the period is twice the fiducial period and the
                phase is offset by one orbital period.
            - ``depth_half``: The depth and uncertainty for a model with a
                period of half the fiducial period.
            - ``depth_phased``: The depth and uncertainty for a model with the
                fiducial period and the phase offset by half a period.
            - ``harmonic_amplitude``: The amplitude of the best fit sinusoidal
                model.
            - ``harmonic_delta_log_likelihood``: The difference in log
                likelihood between a sinusoidal model and the transit model.
                If ``harmonic_delta_log_likelihood`` is greater than zero, the
                sinusoidal model is preferred.
            - ``transit_times``: The mid-transit time for each transit in the
                baseline.
            - ``per_transit_count``: An array with a count of the number of
                data points in each unique transit included in the baseline.
            - ``per_transit_log_likelihood``: An array with the value of the
                log likelihood for each unique transit included in the
                baseline.

        _compute_depthvar_outvar_my_mm_oddm_evendepth_odddepth_evenm_phasedepth_phase0.25m_halfdepth_halftransit_idtransit_timesreturn_countsunique_idsunique_countscountsllllsfull_llsin_lly_unitll_unitper_transit_countper_transit_log_likelihooddepth_phasedharmonic_amplitudeharmonic_delta_log_likelihoodtransit_maskCompute which data points are in transit for a given parameter set.

        Parameters
        ----------
        t : array-like or `~astropy.units.Quantity` ['time']
            Times where the mask should be evaluated.
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        transit_mask : array-like
            A boolean array where ``True`` indicates and in transit point and
            ``False`` indicates and out-of-transit point.

        Private method used to check the consistency of the inputs.

        Parameters
        ----------
        t : array-like, `~astropy.units.Quantity`, `~astropy.time.Time`, or `~astropy.time.TimeDelta`
            Sequence of observation times.
        y : array-like or `~astropy.units.Quantity`
            Sequence of observations associated with times t.
        dy : float, array-like, or `~astropy.units.Quantity`
            Error or sequence of observational errors associated with times t.

        Returns
        -------
        t, y, dy : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
            The inputs with consistent shapes and units.

        Raises
        ------
        ValueError
            If the dimensions are incompatible or if the units of dy cannot be
            converted to the units of y.

        Private method used to check a set of test durations.

        Parameters
        ----------
        duration : float, array-like, or `~astropy.units.Quantity`
            The set of durations that will be considered.

        Returns
        -------
        duration : array-like or `~astropy.units.Quantity`
            The input reformatted with the correct shape and units.

        Raises
        ------
        ValueError
            If the units of duration cannot be converted to the units of t.

        duration must be 1-dimensionalPrivate method used to check a set of periods and durations.

        Parameters
        ----------
        period : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of test periods.
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations that will be considered.

        Returns
        -------
        period, duration : array-like or `~astropy.units.Quantity` ['time']
            The inputs reformatted with the correct shapes and units.

        Raises
        ------
        ValueError
            If the units of period or duration cannot be converted to the
            units of t.

        period must be 1-dimensionalThe maximum transit duration must be shorter than the minimum periodA private method used to wrap and add units to the periodogram.

        Parameters
        ----------
        t_ref : float
            The minimum time in the time series (a reference time).
        objective : str
            The name of the objective used in the optimization.
        period : array-like or `~astropy.units.Quantity` ['time']
            The set of trial periods.
        results : tuple
            The output of one of the periodogram implementations.

        depth_errdepth_snrlog_likelihoodThe results of a BoxLeastSquares search.

    Attributes
    ----------
    objective : str
        The scalar used to optimize to find the best fit phase, duration, and
        depth. See :func:`BoxLeastSquares.power` for more information.
    period : array-like or `~astropy.units.Quantity` ['time']
        The set of test periods.
    power : array-like or `~astropy.units.Quantity`
        The periodogram evaluated at the periods in ``period``. If
        ``objective`` is:

        * ``'likelihood'``: the values of ``power`` are the
          log likelihood maximized over phase, depth, and duration, or
        * ``'snr'``: the values of ``power`` are the signal-to-noise with
          which the depth is measured maximized over phase, depth, and
          duration.

    depth : array-like or `~astropy.units.Quantity`
        The estimated depth of the maximum power model at each period.
    depth_err : array-like or `~astropy.units.Quantity`
        The 1-sigma uncertainty on ``depth``.
    duration : array-like or `~astropy.units.Quantity` ['time']
        The maximum power duration at each period.
    transit_time : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
        The maximum power phase of the transit in units of time. This
        indicates the mid-transit time and it will always be in the range
        (0, period).
    depth_snr : array-like or `~astropy.units.Quantity`
        The signal-to-noise with which the depth is measured at maximum power.
    log_likelihood : array-like or `~astropy.units.Quantity`
        The log likelihood of the maximum power model.

    # Estimate the required frequency spacing# Because of the sparsity of a transit, this must be much finer than# the frequency resolution for a sinusoidal fit. For a sinusoidal fit,# df would be 1/baseline (see LombScargle), but here this should be# scaled proportionally to the duration in units of baseline.# If a minimum period is not provided, choose one that is twice the# maximum duration because we won't be sensitive to any periods# shorter than that.# If no maximum period is provided, choose one by requiring that# all signals with at least minimum_n_transit should be detectable.# Convert bounds to frequency# Compute the number of frequencies and the frequency grid# Check for absurdities in the ``oversample`` choice# Select the periodogram objective# Select the computational method# Format and check the input arrays# Make sure that the period and duration arrays are C-order# Select the correct implementation for the chosen method# Run the implementation# Some time formats/scales can't represent dates/times too far# off from the present, so we need to mask values offset by# more than 100,000 yr (the periodogram algorithm can return# transit times of e.g 1e300 for some periods).# Compute the depth# Evaluate the model# This a helper function that will compute the depth for several# different hypothesized transit models with different parameters# Compute the depth of the fiducial model and the two models at twice# the period# Compute the depth of the model at a phase of 0.5*period# Compute the depth of a model with a period of 0.5*period# Compute the number of points in each transit# Compute the per-transit log likelihood# Compute the log likelihood of a sine model# Format the resultsb'Compute the box least squares periodogram.

    This method is a commonly used tool for discovering transiting exoplanets
    or eclipsing binaries in photometric time series datasets. This
    implementation is based on the "box least squares (BLS)" method described
    in [1]_ and [2]_.

    Parameters
    ----------
    t : array-like, `~astropy.units.Quantity`, `~astropy.time.Time`, or `~astropy.time.TimeDelta`
        Sequence of observation times.
    y : array-like or `~astropy.units.Quantity`
        Sequence of observations associated with times ``t``.
    dy : float, array-like, or `~astropy.units.Quantity`, optional
        Error or sequence of observational errors associated with times ``t``.

    Examples
    --------
    Generate noisy data with a transit:

    >>> rand = np.random.default_rng(42)
    >>> t = rand.uniform(0, 10, 500)
    >>> y = np.ones_like(t)
    >>> y[np.abs((t + 1.0)%2.0-1)<0.08] = 1.0 - 0.1
    >>> y += 0.01 * rand.standard_normal(len(t))

    Compute the transit periodogram on a heuristically determined period grid
    and find the period with maximum power:

    >>> model = BoxLeastSquares(t, y)
    >>> results = model.autopower(0.16)
    >>> results.period[np.argmax(results.power)]  # doctest: +FLOAT_CMP
    np.float64(2.000412388152837)

    Compute the periodogram on a user-specified period grid:

    >>> periods = np.linspace(1.9, 2.1, 5)
    >>> results = model.power(periods, 0.16)
    >>> results.power  # doctest: +FLOAT_CMP
    array([0.01723948, 0.0643028 , 0.1338783 , 0.09428816, 0.03577543])

    If the inputs are AstroPy Quantities with units, the units will be
    validated and the outputs will also be Quantities with appropriate units:

    >>> from astropy import units as u
    >>> t = t * u.day
    >>> y = y * u.dimensionless_unscaled
    >>> model = BoxLeastSquares(t, y)
    >>> results = model.autopower(0.16 * u.day)
    >>> results.period.unit
    Unit("d")
    >>> results.power.unit
    Unit(dimensionless)

    References
    ----------
    .. [1] Kovacs, Zucker, & Mazeh (2002), A&A, 391, 369
        (arXiv:astro-ph/0206099)
    .. [2] Hartman & Bakos (2016), Astronomy & Computing, 17, 1
        (arXiv:1605.06811)

    'u'Compute the box least squares periodogram.

    This method is a commonly used tool for discovering transiting exoplanets
    or eclipsing binaries in photometric time series datasets. This
    implementation is based on the "box least squares (BLS)" method described
    in [1]_ and [2]_.

    Parameters
    ----------
    t : array-like, `~astropy.units.Quantity`, `~astropy.time.Time`, or `~astropy.time.TimeDelta`
        Sequence of observation times.
    y : array-like or `~astropy.units.Quantity`
        Sequence of observations associated with times ``t``.
    dy : float, array-like, or `~astropy.units.Quantity`, optional
        Error or sequence of observational errors associated with times ``t``.

    Examples
    --------
    Generate noisy data with a transit:

    >>> rand = np.random.default_rng(42)
    >>> t = rand.uniform(0, 10, 500)
    >>> y = np.ones_like(t)
    >>> y[np.abs((t + 1.0)%2.0-1)<0.08] = 1.0 - 0.1
    >>> y += 0.01 * rand.standard_normal(len(t))

    Compute the transit periodogram on a heuristically determined period grid
    and find the period with maximum power:

    >>> model = BoxLeastSquares(t, y)
    >>> results = model.autopower(0.16)
    >>> results.period[np.argmax(results.power)]  # doctest: +FLOAT_CMP
    np.float64(2.000412388152837)

    Compute the periodogram on a user-specified period grid:

    >>> periods = np.linspace(1.9, 2.1, 5)
    >>> results = model.power(periods, 0.16)
    >>> results.power  # doctest: +FLOAT_CMP
    array([0.01723948, 0.0643028 , 0.1338783 , 0.09428816, 0.03577543])

    If the inputs are AstroPy Quantities with units, the units will be
    validated and the outputs will also be Quantities with appropriate units:

    >>> from astropy import units as u
    >>> t = t * u.day
    >>> y = y * u.dimensionless_unscaled
    >>> model = BoxLeastSquares(t, y)
    >>> results = model.autopower(0.16 * u.day)
    >>> results.period.unit
    Unit("d")
    >>> results.power.unit
    Unit(dimensionless)

    References
    ----------
    .. [1] Kovacs, Zucker, & Mazeh (2002), A&A, 391, 369
        (arXiv:astro-ph/0206099)
    .. [2] Hartman & Bakos (2016), Astronomy & Computing, 17, 1
        (arXiv:1605.06811)

    'b'Determine a suitable grid of periods.

        This method uses a set of heuristics to select a conservative period
        grid that is uniform in frequency. This grid might be too fine for
        some user's needs depending on the precision requirements or the
        sampling of the data. The grid can be made coarser by increasing
        ``frequency_factor``.

        Parameters
        ----------
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations that will be considered.
        minimum_period, maximum_period : float or `~astropy.units.Quantity` ['time'], optional
            The minimum/maximum periods to search. If not provided, these will
            be computed as described in the notes below.
        minimum_n_transit : int, optional
            If ``maximum_period`` is not provided, this is used to compute the
            maximum period to search by asserting that any systems with at
            least ``minimum_n_transits`` will be within the range of searched
            periods. Note that this is not the same as requiring that
            ``minimum_n_transits`` be required for detection. The default
            value is ``3``.
        frequency_factor : float, optional
            A factor to control the frequency spacing as described in the
            notes below. The default value is ``1.0``.

        Returns
        -------
        period : array-like or `~astropy.units.Quantity` ['time']
            The set of periods computed using these heuristics with the same
            units as ``t``.

        Notes
        -----
        The default minimum period is chosen to be twice the maximum duration
        because there won't be much sensitivity to periods shorter than that.

        The default maximum period is computed as

        .. code-block:: python

            maximum_period = (max(t) - min(t)) / minimum_n_transits

        ensuring that any systems with at least ``minimum_n_transits`` are
        within the range of searched periods.

        The frequency spacing is given by

        .. code-block:: python

            df = frequency_factor * min(duration) / (max(t) - min(t))**2

        so the grid can be made finer by decreasing ``frequency_factor`` or
        coarser by increasing ``frequency_factor``.

        'u'Determine a suitable grid of periods.

        This method uses a set of heuristics to select a conservative period
        grid that is uniform in frequency. This grid might be too fine for
        some user's needs depending on the precision requirements or the
        sampling of the data. The grid can be made coarser by increasing
        ``frequency_factor``.

        Parameters
        ----------
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations that will be considered.
        minimum_period, maximum_period : float or `~astropy.units.Quantity` ['time'], optional
            The minimum/maximum periods to search. If not provided, these will
            be computed as described in the notes below.
        minimum_n_transit : int, optional
            If ``maximum_period`` is not provided, this is used to compute the
            maximum period to search by asserting that any systems with at
            least ``minimum_n_transits`` will be within the range of searched
            periods. Note that this is not the same as requiring that
            ``minimum_n_transits`` be required for detection. The default
            value is ``3``.
        frequency_factor : float, optional
            A factor to control the frequency spacing as described in the
            notes below. The default value is ``1.0``.

        Returns
        -------
        period : array-like or `~astropy.units.Quantity` ['time']
            The set of periods computed using these heuristics with the same
            units as ``t``.

        Notes
        -----
        The default minimum period is chosen to be twice the maximum duration
        because there won't be much sensitivity to periods shorter than that.

        The default maximum period is computed as

        .. code-block:: python

            maximum_period = (max(t) - min(t)) / minimum_n_transits

        ensuring that any systems with at least ``minimum_n_transits`` are
        within the range of searched periods.

        The frequency spacing is given by

        .. code-block:: python

            df = frequency_factor * min(duration) / (max(t) - min(t))**2

        so the grid can be made finer by decreasing ``frequency_factor`` or
        coarser by increasing ``frequency_factor``.

        'b'minimum_n_transit must be greater than 1'u'minimum_n_transit must be greater than 1'b'minimum_period must be positive'u'minimum_period must be positive'b'Compute the periodogram at set of heuristically determined periods.

        This method calls :func:`BoxLeastSquares.autoperiod` to determine
        the period grid and then :func:`BoxLeastSquares.power` to compute
        the periodogram. See those methods for documentation of the arguments.

        'u'Compute the periodogram at set of heuristically determined periods.

        This method calls :func:`BoxLeastSquares.autoperiod` to determine
        the period grid and then :func:`BoxLeastSquares.power` to compute
        the periodogram. See those methods for documentation of the arguments.

        'b'Compute the periodogram for a set of periods.

        Parameters
        ----------
        period : array-like or `~astropy.units.Quantity` ['time']
            The periods where the power should be computed
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations to test
        objective : {'likelihood', 'snr'}, optional
            The scalar that should be optimized to find the best fit phase,
            duration, and depth. This can be either ``'likelihood'`` (default)
            to optimize the log-likelihood of the model, or ``'snr'`` to
            optimize the signal-to-noise with which the transit depth is
            measured.
        method : {'fast', 'slow'}, optional
            The computational method used to compute the periodogram. This is
            mainly included for the purposes of testing and most users will
            want to use the optimized ``'fast'`` method (default) that is
            implemented in Cython.  ``'slow'`` is a brute-force method that is
            used to test the results of the ``'fast'`` method.
        oversample : int, optional
            The number of bins per duration that should be used. This sets the
            time resolution of the phase fit with larger values of
            ``oversample`` yielding a finer grid and higher computational cost.

        Returns
        -------
        results : BoxLeastSquaresResults
            The periodogram results as a :class:`BoxLeastSquaresResults`
            object.

        Raises
        ------
        ValueError
            If ``oversample`` is not an integer greater than 0 or if
            ``objective`` or ``method`` are not valid.

        'u'Compute the periodogram for a set of periods.

        Parameters
        ----------
        period : array-like or `~astropy.units.Quantity` ['time']
            The periods where the power should be computed
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations to test
        objective : {'likelihood', 'snr'}, optional
            The scalar that should be optimized to find the best fit phase,
            duration, and depth. This can be either ``'likelihood'`` (default)
            to optimize the log-likelihood of the model, or ``'snr'`` to
            optimize the signal-to-noise with which the transit depth is
            measured.
        method : {'fast', 'slow'}, optional
            The computational method used to compute the periodogram. This is
            mainly included for the purposes of testing and most users will
            want to use the optimized ``'fast'`` method (default) that is
            implemented in Cython.  ``'slow'`` is a brute-force method that is
            used to test the results of the ``'fast'`` method.
        oversample : int, optional
            The number of bins per duration that should be used. This sets the
            time resolution of the phase fit with larger values of
            ``oversample`` yielding a finer grid and higher computational cost.

        Returns
        -------
        results : BoxLeastSquaresResults
            The periodogram results as a :class:`BoxLeastSquaresResults`
            object.

        Raises
        ------
        ValueError
            If ``oversample`` is not an integer greater than 0 or if
            ``objective`` or ``method`` are not valid.

        'b'oversample must be an int, got 'u'oversample must be an int, got 'b'oversample must be greater than or equal to 1'u'oversample must be greater than or equal to 1'b'likelihood'u'likelihood'b'snr'u'snr'b'Unrecognized method ''u'Unrecognized method ''b''
allowed methods are: 'u''
allowed methods are: 'b'fast'u'fast'b'slow'u'slow'b' was provided as an absolute time but the BoxLeastSquares class was initialized with relative times.'u' was provided as an absolute time but the BoxLeastSquares class was initialized with relative times.'b' was provided as a relative time but the BoxLeastSquares class was initialized with absolute times.'u' was provided as a relative time but the BoxLeastSquares class was initialized with absolute times.'b'
        Convert the provided times to absolute times using the current _tstart
        value, if needed.
        'u'
        Convert the provided times to absolute times using the current _tstart
        value, if needed.
        'b'Compute the transit model at the given period, duration, and phase.

        Parameters
        ----------
        t_model : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
            Times at which to compute the model.
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        y_model : array-like or `~astropy.units.Quantity`
            The model evaluated at the times ``t_model`` with units of ``y``.

        'u'Compute the transit model at the given period, duration, and phase.

        Parameters
        ----------
        t_model : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
            Times at which to compute the model.
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        y_model : array-like or `~astropy.units.Quantity`
            The model evaluated at the times ``t_model`` with units of ``y``.

        'b'transit_time'u'transit_time'b't_model'u't_model'b'Compute descriptive statistics for a given transit model.

        These statistics are commonly used for vetting of transit candidates.

        Parameters
        ----------
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        stats : dict
            A dictionary containing several descriptive statistics:

            - ``depth``: The depth and uncertainty (as a tuple with two
                values) on the depth for the fiducial model.
            - ``depth_odd``: The depth and uncertainty on the depth for a
                model where the period is twice the fiducial period.
            - ``depth_even``: The depth and uncertainty on the depth for a
                model where the period is twice the fiducial period and the
                phase is offset by one orbital period.
            - ``depth_half``: The depth and uncertainty for a model with a
                period of half the fiducial period.
            - ``depth_phased``: The depth and uncertainty for a model with the
                fiducial period and the phase offset by half a period.
            - ``harmonic_amplitude``: The amplitude of the best fit sinusoidal
                model.
            - ``harmonic_delta_log_likelihood``: The difference in log
                likelihood between a sinusoidal model and the transit model.
                If ``harmonic_delta_log_likelihood`` is greater than zero, the
                sinusoidal model is preferred.
            - ``transit_times``: The mid-transit time for each transit in the
                baseline.
            - ``per_transit_count``: An array with a count of the number of
                data points in each unique transit included in the baseline.
            - ``per_transit_log_likelihood``: An array with the value of the
                log likelihood for each unique transit included in the
                baseline.

        'u'Compute descriptive statistics for a given transit model.

        These statistics are commonly used for vetting of transit candidates.

        Parameters
        ----------
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        stats : dict
            A dictionary containing several descriptive statistics:

            - ``depth``: The depth and uncertainty (as a tuple with two
                values) on the depth for the fiducial model.
            - ``depth_odd``: The depth and uncertainty on the depth for a
                model where the period is twice the fiducial period.
            - ``depth_even``: The depth and uncertainty on the depth for a
                model where the period is twice the fiducial period and the
                phase is offset by one orbital period.
            - ``depth_half``: The depth and uncertainty for a model with a
                period of half the fiducial period.
            - ``depth_phased``: The depth and uncertainty for a model with the
                fiducial period and the phase offset by half a period.
            - ``harmonic_amplitude``: The amplitude of the best fit sinusoidal
                model.
            - ``harmonic_delta_log_likelihood``: The difference in log
                likelihood between a sinusoidal model and the transit model.
                If ``harmonic_delta_log_likelihood`` is greater than zero, the
                sinusoidal model is preferred.
            - ``transit_times``: The mid-transit time for each transit in the
                baseline.
            - ``per_transit_count``: An array with a count of the number of
                data points in each unique transit included in the baseline.
            - ``per_transit_log_likelihood``: An array with the value of the
                log likelihood for each unique transit included in the
                baseline.

        'b'transit_times'u'transit_times'b'Compute which data points are in transit for a given parameter set.

        Parameters
        ----------
        t : array-like or `~astropy.units.Quantity` ['time']
            Times where the mask should be evaluated.
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        transit_mask : array-like
            A boolean array where ``True`` indicates and in transit point and
            ``False`` indicates and out-of-transit point.

        'u'Compute which data points are in transit for a given parameter set.

        Parameters
        ----------
        t : array-like or `~astropy.units.Quantity` ['time']
            Times where the mask should be evaluated.
        period : float or `~astropy.units.Quantity` ['time']
            The period of the transits.
        duration : float or `~astropy.units.Quantity` ['time']
            The duration of the transit.
        transit_time : float or `~astropy.units.Quantity` or `~astropy.time.Time`
            The mid-transit time of a reference transit.

        Returns
        -------
        transit_mask : array-like
            A boolean array where ``True`` indicates and in transit point and
            ``False`` indicates and out-of-transit point.

        'b'Private method used to check the consistency of the inputs.

        Parameters
        ----------
        t : array-like, `~astropy.units.Quantity`, `~astropy.time.Time`, or `~astropy.time.TimeDelta`
            Sequence of observation times.
        y : array-like or `~astropy.units.Quantity`
            Sequence of observations associated with times t.
        dy : float, array-like, or `~astropy.units.Quantity`
            Error or sequence of observational errors associated with times t.

        Returns
        -------
        t, y, dy : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
            The inputs with consistent shapes and units.

        Raises
        ------
        ValueError
            If the dimensions are incompatible or if the units of dy cannot be
            converted to the units of y.

        'u'Private method used to check the consistency of the inputs.

        Parameters
        ----------
        t : array-like, `~astropy.units.Quantity`, `~astropy.time.Time`, or `~astropy.time.TimeDelta`
            Sequence of observation times.
        y : array-like or `~astropy.units.Quantity`
            Sequence of observations associated with times t.
        dy : float, array-like, or `~astropy.units.Quantity`
            Error or sequence of observational errors associated with times t.

        Returns
        -------
        t, y, dy : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
            The inputs with consistent shapes and units.

        Raises
        ------
        ValueError
            If the dimensions are incompatible or if the units of dy cannot be
            converted to the units of y.

        'b'Private method used to check a set of test durations.

        Parameters
        ----------
        duration : float, array-like, or `~astropy.units.Quantity`
            The set of durations that will be considered.

        Returns
        -------
        duration : array-like or `~astropy.units.Quantity`
            The input reformatted with the correct shape and units.

        Raises
        ------
        ValueError
            If the units of duration cannot be converted to the units of t.

        'u'Private method used to check a set of test durations.

        Parameters
        ----------
        duration : float, array-like, or `~astropy.units.Quantity`
            The set of durations that will be considered.

        Returns
        -------
        duration : array-like or `~astropy.units.Quantity`
            The input reformatted with the correct shape and units.

        Raises
        ------
        ValueError
            If the units of duration cannot be converted to the units of t.

        'b'duration must be 1-dimensional'u'duration must be 1-dimensional'b'Private method used to check a set of periods and durations.

        Parameters
        ----------
        period : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of test periods.
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations that will be considered.

        Returns
        -------
        period, duration : array-like or `~astropy.units.Quantity` ['time']
            The inputs reformatted with the correct shapes and units.

        Raises
        ------
        ValueError
            If the units of period or duration cannot be converted to the
            units of t.

        'u'Private method used to check a set of periods and durations.

        Parameters
        ----------
        period : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of test periods.
        duration : float, array-like, or `~astropy.units.Quantity` ['time']
            The set of durations that will be considered.

        Returns
        -------
        period, duration : array-like or `~astropy.units.Quantity` ['time']
            The inputs reformatted with the correct shapes and units.

        Raises
        ------
        ValueError
            If the units of period or duration cannot be converted to the
            units of t.

        'b'period must be 1-dimensional'u'period must be 1-dimensional'b'The maximum transit duration must be shorter than the minimum period'u'The maximum transit duration must be shorter than the minimum period'b'A private method used to wrap and add units to the periodogram.

        Parameters
        ----------
        t_ref : float
            The minimum time in the time series (a reference time).
        objective : str
            The name of the objective used in the optimization.
        period : array-like or `~astropy.units.Quantity` ['time']
            The set of trial periods.
        results : tuple
            The output of one of the periodogram implementations.

        'u'A private method used to wrap and add units to the periodogram.

        Parameters
        ----------
        t_ref : float
            The minimum time in the time series (a reference time).
        objective : str
            The name of the objective used in the optimization.
        period : array-like or `~astropy.units.Quantity` ['time']
            The set of trial periods.
        results : tuple
            The output of one of the periodogram implementations.

        'b'The results of a BoxLeastSquares search.

    Attributes
    ----------
    objective : str
        The scalar used to optimize to find the best fit phase, duration, and
        depth. See :func:`BoxLeastSquares.power` for more information.
    period : array-like or `~astropy.units.Quantity` ['time']
        The set of test periods.
    power : array-like or `~astropy.units.Quantity`
        The periodogram evaluated at the periods in ``period``. If
        ``objective`` is:

        * ``'likelihood'``: the values of ``power`` are the
          log likelihood maximized over phase, depth, and duration, or
        * ``'snr'``: the values of ``power`` are the signal-to-noise with
          which the depth is measured maximized over phase, depth, and
          duration.

    depth : array-like or `~astropy.units.Quantity`
        The estimated depth of the maximum power model at each period.
    depth_err : array-like or `~astropy.units.Quantity`
        The 1-sigma uncertainty on ``depth``.
    duration : array-like or `~astropy.units.Quantity` ['time']
        The maximum power duration at each period.
    transit_time : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
        The maximum power phase of the transit in units of time. This
        indicates the mid-transit time and it will always be in the range
        (0, period).
    depth_snr : array-like or `~astropy.units.Quantity`
        The signal-to-noise with which the depth is measured at maximum power.
    log_likelihood : array-like or `~astropy.units.Quantity`
        The log likelihood of the maximum power model.

    'u'The results of a BoxLeastSquares search.

    Attributes
    ----------
    objective : str
        The scalar used to optimize to find the best fit phase, duration, and
        depth. See :func:`BoxLeastSquares.power` for more information.
    period : array-like or `~astropy.units.Quantity` ['time']
        The set of test periods.
    power : array-like or `~astropy.units.Quantity`
        The periodogram evaluated at the periods in ``period``. If
        ``objective`` is:

        * ``'likelihood'``: the values of ``power`` are the
          log likelihood maximized over phase, depth, and duration, or
        * ``'snr'``: the values of ``power`` are the signal-to-noise with
          which the depth is measured maximized over phase, depth, and
          duration.

    depth : array-like or `~astropy.units.Quantity`
        The estimated depth of the maximum power model at each period.
    depth_err : array-like or `~astropy.units.Quantity`
        The 1-sigma uncertainty on ``depth``.
    duration : array-like or `~astropy.units.Quantity` ['time']
        The maximum power duration at each period.
    transit_time : array-like, `~astropy.units.Quantity`, or `~astropy.time.Time`
        The maximum power phase of the transit in units of time. This
        indicates the mid-transit time and it will always be in the range
        (0, period).
    depth_snr : array-like or `~astropy.units.Quantity`
        The signal-to-noise with which the depth is measured at maximum power.
    log_likelihood : array-like or `~astropy.units.Quantity`
        The log likelihood of the maximum power model.

    'b'objective'u'objective'b'period'u'period'b'power'u'power'b'depth'u'depth'b'depth_err'u'depth_err'b'duration'u'duration'b'depth_snr'u'depth_snr'b'log_likelihood'u'log_likelihood'u'timeseries.periodograms.bls.core'u'periodograms.bls.core'u'bls.core'
The astropy.time package provides functionality for manipulating times and
dates. Specific emphasis is placed on supporting time scales (e.g. UTC, TAI,
UT1) and time representations (e.g. JD, MJD, ISO 8601) that are used in
astronomy.
WeakValueDictionaryastropy.externdata_info_factoryTIME_DELTA_FORMATSTIME_FORMATSTimeAstropyTimeTimeDatetimeTimeDeltaNumericTimeFromEpochTimeJDTimeUniquetime_helper.function_helpersCUSTOM_FUNCTIONSday_fracSTANDARD_TIME_SCALESTIME_DELTA_SCALESTIME_SCALESOperandTypeErrorScaleValueErrorTimeBaseTimeDeltaMissingUnitWarningTimeInfoTimeInfoBaseupdate_leap_secondstaitcbtcgtdbut1LOCAL_SCALESTIME_TYPESMULTI_HOPSGEOCENTRIC_SCALESBARYCENTRIC_SCALESROTATIONAL_SCALESTIME_DELTA_TYPESELGELBSCALE_OFFSETSgmst06IAU2006gmst00IAU2000gmst82include_tioIAU1982gst06aIAU2006Agst00aIAU2000Agst00bIAU2000Bgst94IAU1994apparentSIDEREAL_TIME_MODELS_LeapSecondsCheckNOT_STARTEDRUNNINGDONE_LEAP_SECONDS_CHECK_LEAP_SECONDS_LOCK_compress_array_dimsCompress array by allowing at most 2 * edgeitems + 1 in each dimension.

    Parameters
    ----------
    arr : array-like
        Array to compress.

    Returns
    -------
    out : array-like
        Compressed array.
    get_printoptionsedgeitemsix_idxs_ix
    Container for meta information like name, description, format.  This is
    required when the object is used as a mixin column within a table, but can
    be used as a general way to store meta information.

    This base class is common between TimeInfo and TimeDeltaInfo.
    in_subfmtout_subfmt_delta_ut1_utc_delta_tdb_tt_represent_as_dict_extra_attrsformatted_valuejd1_jd2jd1jd2serialize method must be 'formatted_value' or 'jd1_jd2'
        Return a list of arrays which can be lexically sorted to represent
        the order of the parent column.

        Returns
        -------
        arrays : list of ndarray
        jd_approxjd_remainder_statsinfo_summary_stats
        Return a new Time instance which is consistent with the input Time objects
        ``cols`` and has ``length`` rows.

        This is intended for creating an empty Time instance whose elements can
        be set in-place for table operations like join or vstack.  It checks
        that the input locations and attributes are consistent.  This is used
        when a Time object is used as a mixin column in an astropy Table.

        Parameters
        ----------
        cols : list
            List of input columns (Time objects)
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Time (or subclass)
            Empty instance of this class consistent with ``cols``

        col0_make_value_equivalentinput columns have inconsistent locations2451544.5jd2000tm_attrsGet the values for the parent ``attrs`` and return as a dict.

        By default, uses '_represent_as_dict_attrs'.
        datetime64fromisoformatdelta_ut1_utcdelta_tdb_ttTimeDeltaInfo
        Return a new TimeDelta instance which is consistent with the input Time objects
        ``cols`` and has ``length`` rows.

        This is intended for creating an empty Time instance whose elements can
        be set in-place for table operations like join or vstack.  It checks
        that the input locations and attributes are consistent.  This is used
        when a Time object is used as a mixin column in an astropy Table.

        Parameters
        ----------
        cols : list
            List of input columns (Time objects)
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Time (or subclass)
            Empty instance of this class consistent with ``cols``

        Base time class from which Time and TimeDelta inherit.20000_astropy_column_attrs_time_id_cache_init_from_vals
        Set the internal _format, scale, and _time attrs from user
        inputs.  This handles coercion into the correct shapes and
        some basic input validation.
        _make_arrayInput val and val2 have inconsistent shape; they cannot be broadcast together."Input val and val2 have inconsistent shape; ""they cannot be broadcast together."SCALESScale  is not in the allowed scales " is not in the allowed scales "data1mask1data2mask2_get_time_fmt_location
        Given the supplied val, val2, format and scale try to instantiate
        the corresponding TimeFormat class to convert the input values into
        the internal jd1 and jd2.

        If format is `None` and the input is a string-type or object array then
        guess available formats and stop when one matches.
        empty_arraycannot guess format from input values with zero-size array or all elements masked"cannot guess format from input values with zero-size array"" or all elements masked"FORMATSastropy_timeformat must be a string is not one of the allowed formats " is not one of the allowed formats "ovaloval2problems_fill_masked_valuesInput values did not match the format class Input values did not match any of the formats where the format keyword is optional:
"Input values did not match any of the formats where the format ""keyword is optional:\n"- '': 
        Get or set time format.

        The format defines the way times are represented when accessed via the
        ``.value`` attribute.  By default it is the same as the format used for
        initializing the `Time` instance, but it can be set to any other value
        that could be used for initialization.  These can be listed with::

          >>> list(Time.FORMATS)
          ['jd', 'mjd', 'decimalyear', 'unix', 'unix_tai', 'cxcsec', 'gps', 'plot_date',
           'stardate', 'datetime', 'ymdhms', 'iso', 'isot', 'yday', 'datetime64',
           'fits', 'byear', 'jyear', 'byear_str', 'jyear_str']
        Set time format.format must be one of format_cls_get_allowed_subfmtfrom_jdOutput a string representation of the Time or TimeDelta object.

        Similar to ``str(self.value)`` (which uses numpy array formatting) but
        array values are evaluated only for the items that actually are output.
        For large arrays this can be a substantial performance improvement.

        Returns
        -------
        out : str
            String representation of the time values.

        npotmprintoptions object: scale='' format='"' ""format='"' value=(must be scalar)(value is masked)unhashable type: 'Setting the location attribute post initialization will be disallowed in a future version of Astropy. Instead you should set the location when creating the Time object. In the future, this will raise an AttributeError."Setting the location attribute post initialization will be ""disallowed in a future version of Astropy. ""Instead you should set the location when creating the Time object. ""In the future, this will raise an AttributeError."Time scale._set_scale
        This is the key routine that actually does time scale conversions.
        This is not public and not connected to the read-only scale property.
        _check_leapsecxformxform_sortmultixformssys1sys2sys12_get_delta_{}_{}dt_methodget_dtconv_func
        Decimal precision when outputting seconds as floating point (int
        value between 0 and 9 inclusive).
        
        Unix wildcard pattern to select subformats for parsing string input
        times.
        
        Unix wildcard pattern to select subformats for outputting times.
        The shape of the time instances.

        Like `~numpy.ndarray.shape`, can be set to a new shape by assigning a
        tuple.  Note that if different instances share some but not all
        underlying data, setting the shape of one instance can make the other
        instance unusable.  Hence, it is strongly recommended to get new,
        reshaped instances with the ``reshape`` method.

        Raises
        ------
        ValueError
            If the new shape has the wrong total number of elements.
        AttributeError
            If the shape of the ``jd1``, ``jd2``, ``location``,
            ``delta_ut1_utc``, or ``delta_tdb_tt`` attributes cannot be changed
            without the arrays being copied.  For these cases, use the
            `Time.reshape` method (which copies any arrays that cannot be
            reshaped in-place).
        _shaped_like_inputJD is an array () but value is not (
        First of the two doubles that internally store time value(s) in JD.
        
        Second of the two doubles that internally store time value(s) in JD.
        subfmtGet time values expressed in specified output format.

        This method allows representing the ``Time`` object in the desired
        output ``format`` and optional sub-format ``subfmt``.  Available
        built-in formats include ``jd``, ``mjd``, ``iso``, and so forth. Each
        format can have its own sub-formats

        For built-in numerical formats like ``jd`` or ``unix``, ``subfmt`` can
        be one of 'float', 'long', 'decimal', 'str', or 'bytes'.  Here, 'long'
        uses ``numpy.longdouble`` for somewhat enhanced precision (with
        the enhancement depending on platform), and 'decimal'
        :class:`decimal.Decimal` for full precision.  For 'str' and 'bytes', the
        number of digits is also chosen such that time values are represented
        accurately.

        For built-in date-like string formats, one of 'date_hms', 'date_hm', or
        'date' (or 'longdate_hms', etc., for 5-digit years in
        `~astropy.time.TimeFITS`).  For sub-formats including seconds, the
        number of digits used for the fractional seconds is as set by
        `~astropy.time.Time.precision`.

        Parameters
        ----------
        format : str
            The format in which one wants the time values. Default: the current
            format.
        subfmt : str or None, optional
            Value or wildcard pattern to select the sub-format in which the
            values should be given.  The default of '*' picks the first
            available for a given format, i.e., 'float' or 'date_hms'.
            If `None`, use the instance's ``out_subfmt``.

        _select_subfmtsunexpected keyword argument 'out_subfmt'to_value() method for format  does not support passing a 'subfmt' argument" does not ""support passing a 'subfmt' argument"Time value(s) in current format.
        Insert values before the given indices in the column and return
        a new `~astropy.time.Time` or  `~astropy.time.TimeDelta` object.

        The values to be inserted must conform to the rules for in-place setting
        of ``Time`` objects (see ``Get and set values`` in the ``Time``
        documentation).

        The API signature matches the ``np.insert`` API, but is more limited.
        The specification of insert index ``obj`` must be a single integer,
        and the ``axis`` must be ``0`` for simple row insertion before the
        index.

        Parameters
        ----------
        obj : int
            Integer index before which ``values`` is inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different
            from that of quantity, ``values`` is converted to the matching type.
        axis : int, optional
            Axis along which to insert ``values``.  Default is 0, which is the
            only allowed value and will insert a row.

        Returns
        -------
        out : `~astropy.time.Time` subclass
            New time object with inserted value(s)

         object is read-only. Make a copy() or set "writeable" attribute to True." object is read-only. Make a "'copy() or set "writeable" attribute to True.'scalar  object is read-only.Returns a boolean or boolean array where two Time objects are
        element-wise equal within a time tolerance.

        This evaluates the expression below::

          abs(self - other) <= atol

        Parameters
        ----------
        other : `~astropy.time.Time`
            Time object for comparison.
        atol : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Absolute tolerance for equality with units of time (e.g. ``u.s`` or
            ``u.day``). Default is two bits in the 128-bit JD time representation,
            equivalent to about 40 picosecs.
        'atol' argument must be a Quantity or TimeDelta instance, got "'atol' argument must be a Quantity or TimeDelta instance, got " instead'other' argument must support subtraction with Time and return a value that supports comparison with "'other' argument must support subtraction with Time ""and return a value that supports comparison with "
        Return a fully independent copy the Time object, optionally changing
        the format.

        If ``format`` is supplied then the time format of the returned Time
        object will be set accordingly, otherwise it will be unchanged from the
        original.

        In this method a full copy of the internal time arrays will be made.
        The internal time arrays are normally not changeable by the user so in
        most cases the ``replicate()`` method should be used.

        Parameters
        ----------
        format : str, optional
            Time format of the copy.

        Returns
        -------
        tm : Time object
            Copy of this object
        
        Return a replica of the Time object, optionally changing the format.

        If ``format`` is supplied then the time format of the returned Time
        object will be set accordingly, otherwise it will be unchanged from the
        original.

        If ``copy`` is set to `True` then a full copy of the internal time arrays
        will be made.  By default the replica will use a reference to the
        original arrays when possible to save memory.  The internal time arrays
        are normally not changeable by the user so in most cases it should not
        be necessary to set ``copy`` to `True`.

        The convenience method copy() is available in which ``copy`` is `True`
        by default.

        Parameters
        ----------
        format : str, optional
            Time format of the replica.
        copy : bool, optional
            Return a true copy instead of using references where possible.

        Returns
        -------
        tm : Time object
            Replica of this object
        Create a new time object, possibly applying a method to the arrays.

        Parameters
        ----------
        method : str or callable
            If string, can be 'replicate'  or the name of a relevant
            `~numpy.ndarray` method. In the former case, a new time instance
            with unchanged internal data is created, while in the latter the
            method is applied to the internal ``jd1`` and ``jd2`` arrays, as
            well as to possible ``location``, ``_delta_ut1_utc``, and
            ``_delta_tdb_tt`` arrays.
            If a callable, it is directly applied to the above arrays.
            Examples: 'copy', '__getitem__', 'reshape', `~numpy.broadcast_to`.
        args : tuple
            Any positional arguments for ``method``.
        kwargs : dict
            Any keyword arguments for ``method``.  If the ``format`` keyword
            argument is present, this will be used as the Time format of the
            replica.

        Examples
        --------
        Some ways this is used internally::

            copy : ``_apply('copy')``
            replicate : ``_apply('replicate')``
            reshape : ``_apply('reshape', new_shape)``
            index or slice : ``_apply('__getitem__', item)``
            broadcast : ``_apply(np.broadcast, shape=new_shape)``
        new_formatNewFormatOWNDATA
        Overrides the default behavior of the `copy.copy` function in
        the python stdlib to behave like `Time.copy`. Does *not* make a
        copy of the JD arrays - only copies by reference.
        
        Overrides the default behavior of the `copy.deepcopy` function
        in the python stdlib to behave like `Time.copy`. Does make a
        copy of the JD arrays.
        _advanced_indexTurn argmin, argmax output into an advanced index.

        Argmin, argmax output contains indices along a given axis in an array
        shaped like the other dimensions.  To use this to get values at the
        correct location, a list is constructed in which the other axes are
        indexed sequentially.  For ``keepdims`` is ``True``, the net result is
        the same as constructing an index grid with ``np.ogrid`` and then
        replacing the ``axis`` item with ``indices`` with its shaped expanded
        at ``axis``. For ``keepdims`` is ``False``, the result is the same but
        with the ``axis`` dimension removed from all list entries.

        For ``axis`` is ``None``, this calls :func:`~numpy.unravel_index`.

        Parameters
        ----------
        indices : array
            Output of argmin or argmax.
        axis : int or None
            axis along which argmin or argmax was used.
        keepdims : bool
            Whether to construct indices that keep or remove the axis along
            which argmin or argmax was used.  Default: ``False``.

        Returns
        -------
        advanced_index : list of arrays
            Suitable for use as an advanced index.
        unravel_indexReturn indices of the minimum values along the given axis.

        This is similar to :meth:`~numpy.ndarray.argmin`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used.  See :func:`~numpy.argmin` for detailed documentation.
        approxReturn indices of the maximum values along the given axis.

        This is similar to :meth:`~numpy.ndarray.argmax`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used.  See :func:`~numpy.argmax` for detailed documentation.
        Returns the indices that would sort the time array.

        This is similar to :meth:`~numpy.ndarray.argsort`, but adapted to ensure that
        the full precision given by the two doubles ``jd1`` and ``jd2`` is used, and
        that corresponding attributes are copied.  Internally, it uses
        :func:`~numpy.lexsort`, and hence no sort method can be chosen.

        Parameters
        ----------
        axis : int, optional
            Axis along which to sort. Default is -1, which means sort along the last
            axis.
        kind : 'stable', optional
            Sorting is done with :func:`~numpy.lexsort` so this argument is ignored, but
            kept for compatibility with :func:`~numpy.argsort`. The sorting is stable,
            meaning that the order of equal elements is preserved.

        Returns
        -------
        indices : ndarray
            An array of indices that sort the time array.
        Minimum along a given axis.

        This is similar to :meth:`~numpy.ndarray.min`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.min``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        Since `Time` instances are immutable, ``out`` cannot be set to anything but ``None``."Since `Time` instances are immutable, ``out`` ""cannot be set to anything but ``None``."Maximum along a given axis.

        This is similar to :meth:`~numpy.ndarray.max`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.max``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        _ptp_implnp.ptpPeak to peak (maximum - minimum) along a given axis.

        This method is similar to the :func:`numpy.ptp` function, but
        adapted to ensure that the full precision given by the two doubles
        ``jd1`` and ``jd2`` is used.

        Note that the ``out`` argument is present only for compatibility with
        `~numpy.ptp`; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        Return a copy sorted along the specified axis.

        This is similar to :meth:`~numpy.ndarray.sort`, but internally uses
        indexing with :func:`~numpy.lexsort` to ensure that the full precision
        given by the two doubles ``jd1`` and ``jd2`` is kept, and that
        corresponding attributes are properly sorted and copied as well.

        Parameters
        ----------
        axis : int or None
            Axis to be sorted.  If ``None``, the flattened array is sorted.
            By default, sort over the last axis.
        Mean along a given axis.

        This is similar to :meth:`~numpy.ndarray.mean`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2`` is
        used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.mean``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.

        Similarly, the ``dtype`` argument is also present for compatibility
        only; it has no meaning for `Time`.

        Parameters
        ----------
        axis : None or int or tuple of ints, optional
            Axis or axes along which the means are computed. The default is to
            compute the mean of the flattened array.
        dtype : None
            Only present for compatibility with :meth:`~numpy.ndarray.mean`,
            must be `None`.
        out : None
            Only present for compatibility with :meth:`~numpy.ndarray.mean`,
            must be `None`.
        keepdims : bool, optional
            If this is set to True, the axes which are reduced are left
            in the result as dimensions with size one. With this option,
            the result will broadcast correctly against the input array.
        where : array_like of bool, optional
            Elements to include in the mean. See `~numpy.ufunc.reduce` for
            details.

        Returns
        -------
        m : Time
            A new Time instance containing the mean values
        Cannot set ``dtype`` on `Time` instanceswhere_broadcasteddivisorMean over zero elements is not supported as it would give an undefined time;see issue https://github.com/astropy/astropy/issues/6509"Mean over zero elements is not supported as it would give an undefined"" time;see issue https://github.com/astropy/astropy/issues/6509"val1Cache of all instances that share underlying data.

        Helps to ensure all cached data can be deleted if the
        underlying data is changed.
        
        Return the cache associated with this instance.
        
        Get dynamic attributes to output format or do timescale conversion.
        Cannot convert TimeDelta with undefined scale to any defined scale."Cannot convert TimeDelta with ""undefined scale to any defined scale."Cannot convert  with scale '" with scale "' to scale '_match_shape
        Ensure that `val` is matched to length of self.  If val has length 1
        then broadcast, otherwise cast to double and make sure shape matches.
        Attribute shape must match or be broadcastable to that of Time object. Typically, give either a single value or one for each time."Attribute shape must match or be broadcastable to that of ""Time object. Typically, give either a single value or ""one for each time."_time_comparisonIf other is of same class as self, compare difference in self.scale.
        Otherwise, return NotImplemented.
        Cannot compare  instances with scales '" instances with ""scales '"' and '
        If other is an incompatible object for comparison, return `False`.
        Otherwise, return `True` if the time difference between self and
        other is zero.
        
        If other is an incompatible object for comparison, return `True`.
        Otherwise, return `False` if the time difference between self and
        other is zero.
        ne
    Represent and manipulate times and dates for astronomy.

    A `Time` object is initialized with one or more times in the ``val``
    argument.  The input times in ``val`` must conform to the specified
    ``format`` and must correspond to the specified time ``scale``.  The
    optional ``val2`` time input should be supplied only for numeric input
    formats (e.g. JD) where very high precision (better than 64-bit precision)
    is required.

    The allowed values for ``format`` can be listed with::

      >>> list(Time.FORMATS)
      ['jd', 'mjd', 'decimalyear', 'unix', 'unix_tai', 'cxcsec', 'gps', 'plot_date',
       'stardate', 'datetime', 'ymdhms', 'iso', 'isot', 'yday', 'datetime64',
       'fits', 'byear', 'jyear', 'byear_str', 'jyear_str']

    See also: http://docs.astropy.org/en/stable/time/

    Parameters
    ----------
    val : sequence, ndarray, number, str, bytes, or `~astropy.time.Time` object
        Value(s) to initialize the time or times.  Bytes are decoded as ascii.
    val2 : sequence, ndarray, or number; optional
        Value(s) to initialize the time or times.  Only used for numerical
        input, to help preserve precision.
    format : str, optional
        Format of input value(s), specifying how to interpret them (e.g., ISO, JD, or
        Unix time). By default, the same format will be used for output representation.
    scale : str, optional
        Time scale of input value(s), must be one of the following:
        ('tai', 'tcb', 'tcg', 'tdb', 'tt', 'ut1', 'utc')
    precision : int, optional
        Digits of precision in string representation of time
    in_subfmt : str, optional
        Unix glob to select subformats for parsing input times
    out_subfmt : str, optional
        Unix glob to select subformat for outputting times
    location : `~astropy.coordinates.EarthLocation` or tuple, optional
        If given as an tuple, it should be able to initialize an
        an EarthLocation instance, i.e., either contain 3 items with units of
        length for geocentric coordinates, or contain a longitude, latitude,
        and an optional height for geodetic coordinates.
        Can be a single location, or one for each input time.
        If not given, assumed to be the center of the Earth for time scale
        transformations to and from the solar-system barycenter.
    copy : bool, optional
        Make a copy of the input values
    List of time scalesDict of time formatsThe location with shape  cannot be broadcast against time with shape "broadcast against time with shape ". Typically, either give a single location or one for each time."Typically, either give a single location or one for each time."Coerce setitem value into an equivalent Time object.self_locationcannot set to Time with different location: expected location="cannot set to Time with different location: expected ""location=" and got location=cannot convert value to a compatible Time object: 
        Creates a new object corresponding to the instant in time this
        method is called.

        .. note::
            "Now" is determined using the `~datetime.datetime.now`
            function, so its accuracy and precision is determined by that
            function.  Generally that means it is set by the accuracy of
            your system clock. The timezone is set to UTC.

        Returns
        -------
        nowtime : :class:`~astropy.time.Time`
            A new `Time` object (or a subclass of `Time` if this is called from
            such a subclass) at the current time.
        dtnowtime_string
        Parse a string to a Time according to a format specification.
        See `time.strptime` documentation for format specification.

        >>> Time.strptime('2012-Jun-30 23:59:60', '%Y-%b-%d %H:%M:%S')
        <Time object: scale='utc' format='isot' value=2012-06-30T23:59:60.000>

        Parameters
        ----------
        time_string : str, sequence, or ndarray
            Objects containing time data of type string
        format_string : str
            String specifying format of time_string.
        kwargs : dict
            Any keyword arguments for ``Time``.  If the ``format`` keyword
            argument is present, this will be used as the Time format.

        Returns
        -------
        time_obj : `~astropy.time.Time`
            A new `~astropy.time.Time` object corresponding to the input
            ``time_string``.

        time_arrayExpected type is string, a bytes-like object or a sequence of these. Got dtype '"Expected type is string, a bytes-like object or a sequence ""of these. Got dtype '"nditerU30op_dtypesiteratorformatted{:04}-{:02}-{:02}T{:02}:{:02}:{:02}.{:06}operandsisot
        Convert Time to a string or a numpy.array of strings according to a
        format specification.
        See `time.strftime` documentation for format specification.

        Parameters
        ----------
        format_spec : str
            Format definition of return string.

        Returns
        -------
        formatted : str or numpy.array
            String or numpy.array of strings formatted according to the given
            format string.

        formatted_stringsskisostr_kwargsmontimetupledate_tupledatetime_tuplefmtd_str{frac:0{precision}}fracseclight_travel_timebarycentricephemerisLight travel time correction to the barycentre or heliocentre.

        The frame transformations used to calculate the location of the solar
        system barycentre and the heliocentre rely on the erfa routine epv00,
        which is consistent with the JPL DE405 ephemeris to an accuracy of
        11.2 km, corresponding to a light travel time of 4 microseconds.

        The routine assumes the source(s) are at large distance, i.e., neglects
        finite-distance effects.

        Parameters
        ----------
        skycoord : `~astropy.coordinates.SkyCoord`
            The sky location to calculate the correction for.
        kind : str, optional
            ``'barycentric'`` (default) or ``'heliocentric'``
        location : `~astropy.coordinates.EarthLocation`, optional
            The location of the observatory to calculate the correction for.
            If no location is given, the ``location`` attribute of the Time
            object is used
        ephemeris : str, optional
            Solar system ephemeris to use (e.g., 'builtin', 'jpl'). By default,
            use the one set with ``astropy.coordinates.solar_system_ephemeris.set``.
            For more information, see `~astropy.coordinates.solar_system_ephemeris`.

        Returns
        -------
        time_offset : `~astropy.time.TimeDelta`
            The time offset between the barycentre or Heliocentre and Earth,
            in TDB seconds.  Should be added to the original time to get the
            time in the Solar system barycentre or the Heliocentre.
            Also, the time conversion to BJD will then include the relativistic correction as well.
        heliocentric'kind' parameter must be one of 'heliocentric' or 'barycentric'An EarthLocation needs to be set or passed in to calculate bary- or heliocentric corrections"An EarthLocation needs to be set or passed in to calculate bary- ""or heliocentric corrections"solar_system_ephemerisGiven skycoord is not transformable to the ICRSget_itrsSupplied location does not have a valid `get_itrs` methodcposgcrs_coosposrollaxistcor_valearth_rotation_angleCalculate local Earth rotation angle.

        Parameters
        ----------
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance. If the special
            string 'tio', the result will be relative to the Terrestrial
            Intermediate Origin (TIO) (i.e., the output of `~erfa.era00`).

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local Earth rotation angle with units of hourangle.

        See Also
        --------
        astropy.time.Time.sidereal_time

        References
        ----------
        IAU 2006 NFA Glossary
        (currently located at: https://syrte.obspm.fr/iauWGnfa/NFA_Glossary.html)

        Notes
        -----
        The difference between apparent sidereal time and Earth rotation angle
        is the equation of the origins, which is the angle between the Celestial
        Intermediate Origin (CIO) and the equinox. Applying apparent sidereal
        time to the hour angle yields the true apparent Right Ascension with
        respect to the equinox, while applying the Earth rotation angle yields
        the intermediate (CIRS) Right Ascension with respect to the CIO.

        The result includes the TIO locator (s'), which positions the Terrestrial
        Intermediate Origin on the equator of the Celestial Intermediate Pole (CIP)
        and is rigorously corrected for polar motion.
        (except when ``longitude='tio'``).

        tio_sid_time_or_earth_rot_angera00sidereal_timeCalculate sidereal time.

        Parameters
        ----------
        kind : str
            ``'mean'`` or ``'apparent'``, i.e., accounting for precession
            only, or also for nutation.
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance. If the special
            string  'greenwich' or 'tio', the result will be relative to longitude
            0 for models before 2000, and relative to the Terrestrial Intermediate
            Origin (TIO) for later ones (i.e., the output of the relevant ERFA
            function that calculates greenwich sidereal time).
        model : str or None; optional
            Precession (and nutation) model to use.  The available ones are:
            - {0}: {1}
            - {2}: {3}
            If `None` (default), the last (most recent) one from the appropriate
            list above is used.

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local sidereal time, with units of hourangle.

        See Also
        --------
        astropy.time.Time.earth_rotation_angle

        References
        ----------
        IAU 2006 NFA Glossary
        (currently located at: https://syrte.obspm.fr/iauWGnfa/NFA_Glossary.html)

        Notes
        -----
        The difference between apparent sidereal time and Earth rotation angle
        is the equation of the origins, which is the angle between the Celestial
        Intermediate Origin (CIO) and the equinox. Applying apparent sidereal
        time to the hour angle yields the true apparent Right Ascension with
        respect to the equinox, while applying the Earth rotation angle yields
        the intermediate (CIRS) Right Ascension with respect to the CIO.

        For the IAU precession models from 2000 onwards, the result includes the
        TIO locator (s'), which positions the Terrestrial Intermediate Origin on
        the equator of the Celestial Intermediate Pole (CIP) and is rigorously
        corrected for polar motion (except when ``longitude='tio'`` or ``'greenwich'``).

        The kind of sidereal time has to be  or available_modelsModel  not implemented for  sidereal time; available models are " sidereal time; ""available models are "model_kwargsgreenwichCalculate a local sidereal time or Earth rotation angle.

        Parameters
        ----------
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance.
        function : callable
            The ERFA function to use.
        scales : tuple of str
            The time scales that the function requires on input.
        include_tio : bool, optional
            Whether to includes the TIO locator corrected for polar motion.
            Should be `False` for pre-2000 IAU models.  Default: `True`.

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local sidereal time or Earth rotation angle, with units of hourangle.

        astropy.coordinates.builtin_frames.utilsget_polar_motionastropy.coordinates.matrix_utilitiesrotation_matrixNo longitude is given but the location for the Time object is not set."No longitude is given but the location for ""the Time object is not set."_call_erfasp00spjd_parterfa_parametersget_delta_ut1_utciers_tablereturn_statusFind UT1 - UTC differences by interpolating in IERS Table.

        Parameters
        ----------
        iers_table : `~astropy.utils.iers.IERS`, optional
            Table containing UT1-UTC differences from IERS Bulletins A
            and/or B.  Default: `~astropy.utils.iers.earth_orientation_table`
            (which in turn defaults to the combined version provided by
            `~astropy.utils.iers.IERS_Auto`).
        return_status : bool
            Whether to return status values.  If `False` (default), iers
            raises `IndexError` if any time is out of the range
            covered by the IERS table.

        Returns
        -------
        ut1_utc : float or float array
            UT1-UTC, interpolated in IERS Table
        status : int or int array
            Status values (if ``return_status=`True```)::
            ``astropy.utils.iers.FROM_IERS_B``
            ``astropy.utils.iers.FROM_IERS_A``
            ``astropy.utils.iers.FROM_IERS_A_PREDICTION``
            ``astropy.utils.iers.TIME_BEFORE_IERS_RANGE``
            ``astropy.utils.iers.TIME_BEYOND_IERS_RANGE``

        Notes
        -----
        In normal usage, UT1-UTC differences are calculated automatically
        on the first instance ut1 is needed.

        Examples
        --------
        To check in code whether any times are before the IERS table range::

            >>> from astropy.utils.iers import TIME_BEFORE_IERS_RANGE
            >>> t = Time(['1961-01-01', '2000-01-01'], scale='utc')
            >>> delta, status = t.get_delta_ut1_utc(return_status=True)  # doctest: +REMOTE_DATA
            >>> status == TIME_BEFORE_IERS_RANGE  # doctest: +REMOTE_DATA
            array([ True, False]...)
        earth_orientation_tableut1_utc_get_delta_ut1_utc
        Get ERFA DUT arg = UT1 - UTC.  This getter takes optional jd1 and
        jd2 args because it gets called that way when converting time scales.
        If delta_ut1_utc is not yet set, this will interpolate them from the
        the IERS table.
        self_utcdeltaut1utcjd1_utcjd2_utc_set_delta_ut1_utcUT1 - UTC time scale offset_get_delta_tdb_ttAccessing the delta_tdb_tt attribute is only possible for TT or TDB time scales"Accessing the delta_tdb_tt attribute is only ""possible for TT or TDB time scales"tttainjd1njd2taiutcutdtdbrxy_set_delta_tdb_ttTDB - TT time scale offsetother_is_deltaCannot subtract Time and TimeDelta instances with scales '"Cannot subtract Time and TimeDelta instances ""with scales '"Cannot subtract Time instances with scales '"Cannot subtract Time instances "self_timeCannot add Time and TimeDelta instances with scales '"Cannot add Time and TimeDelta instances "axis_normalizedsl`location` must be constant over the reduction axes.
        Wrap numpy functions.

        Parameters
        ----------
        function : callable
            Numpy function to wrap
        types : iterable of classes
            Classes that provide an ``__array_function__`` override. Can
            in principle be used to interact with other classes. Below,
            mostly passed on to `~numpy.ndarray`, which can only interact
            with subclasses.
        args : tuple
            Positional arguments provided in the function call.
        kwargs : dict
            Keyword arguments provided in the function call.
        leap_second_strictWarning for missing unit or format in TimeDelta.
    Represent the time difference between two times.

    A TimeDelta object is initialized with one or more times in the ``val``
    argument.  The input times in ``val`` must conform to the specified
    ``format``.  The optional ``val2`` time input should be supplied only for
    numeric input formats (e.g. JD) where very high precision (better than
    64-bit precision) is required.

    The allowed values for ``format`` can be listed with::

      >>> list(TimeDelta.FORMATS)
      ['sec', 'jd', 'datetime', 'quantity_str']

    Note that for time differences, the scale can be among three groups:
    geocentric ('tai', 'tt', 'tcg'), barycentric ('tcb', 'tdb'), and rotational
    ('ut1'). Within each of these, the scales for time differences are the
    same. Conversion between geocentric and barycentric is possible, as there
    is only a scale factor change, but one cannot convert to or from 'ut1', as
    this requires knowledge of the actual times, not just their difference. For
    a similar reason, 'utc' is not a valid scale for a time difference: a UTC
    day is not always 86400 seconds.

    For more information see:

    - https://docs.astropy.org/en/stable/time/
    - https://docs.astropy.org/en/stable/time/index.html#time-deltas

    Parameters
    ----------
    val : sequence, ndarray, number, `~astropy.units.Quantity` or `~astropy.time.TimeDelta` object
        Value(s) to initialize the time difference(s). Any quantities will
        be converted appropriately (with care taken to avoid rounding
        errors for regular time units).
    val2 : sequence, ndarray, number, or `~astropy.units.Quantity`; optional
        Additional values, as needed to preserve precision.
    format : str, optional
        Format of input value(s). For numerical inputs without units,
        "jd" is assumed and values are interpreted as days.
        A deprecation warning is raised in this case. To avoid the warning,
        either specify the format or add units to the input values.
    scale : str, optional
        Time scale of input value(s), must be one of the following values:
        ('tdb', 'tt', 'ut1', 'tcg', 'tcb', 'tai'). If not given (or
        ``None``), the scale is arbitrary; when added or subtracted from a
        ``Time`` instance, it will be used without conversion.
    precision : int, optional
        Digits of precision in string representation of time
    in_subfmt : str, optional
        Unix glob to select subformats for parsing input times
    out_subfmt : str, optional
        Unix glob to select subformat for outputting times
    copy : bool, optional
        Make a copy of the input values
    List of time delta scales.Dict of time delta formats._check_numeric_no_unitNumerical value without unit or explicit format passed to TimeDelta, assuming days"Numerical value without unit or explicit format passed to"" TimeDelta, assuming days"
        Convert to ``datetime.timedelta`` object.
        Scale {scale!r} is not in the allowed scales {sorted(self.SCALES)}scale_offsetoffset1offset2_add_subPerform common elements of addition / subtraction for two delta times.Cannot add TimeDelta instances with scales '"Cannot add TimeDelta instances with scales "Negation of a `TimeDelta` object.Absolute value of a `TimeDelta` object.Multiplication of `TimeDelta` objects by numbers/arrays.Multiplication of numbers/arrays with `TimeDelta` objects.Division of `TimeDelta` objects by numbers/arrays.Division by `TimeDelta` objects of numbers/arrays.
        Convert to a quantity in the specified unit.

        Parameters
        ----------
        unit : unit-like
            The unit to convert to.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not directly
            convertible (see :ref:`astropy:unit_equivalencies`). If `None`, no
            equivalencies will be applied at all, not even any set globallyq
            or within a context.

        Returns
        -------
        quantity : `~astropy.units.Quantity`
            The quantity in the units specified.

        See Also
        --------
        to_value : get the numerical value in a given unit.
        Get time delta values expressed in specified output format or unit.

        This method is flexible and handles both conversion to a specified
        ``TimeDelta`` format / sub-format AND conversion to a specified unit.
        If positional argument(s) are provided then the first one is checked
        to see if it is a valid ``TimeDelta`` format, and next it is checked
        to see if it is a valid unit or unit string.

        To convert to a ``TimeDelta`` format and optional sub-format the options
        are::

          tm = TimeDelta(1.0 * u.s)
          tm.to_value('jd')  # equivalent of tm.jd
          tm.to_value('jd', 'decimal')  # convert to 'jd' as a Decimal object
          tm.to_value('jd', subfmt='decimal')
          tm.to_value(format='jd', subfmt='decimal')

        To convert to a unit with optional equivalencies, the options are::

          tm.to_value('hr')  # convert to u.hr (hours)
          tm.to_value('hr', equivalencies=[])
          tm.to_value(unit='hr', equivalencies=[])

        The built-in `~astropy.time.TimeDelta` options for ``format`` are shown below::

          >>> list(TimeDelta.FORMATS)
          ['sec', 'jd', 'datetime', 'quantity_str']

        For the two numerical formats 'jd' and 'sec', the available ``subfmt``
        options are: {'float', 'long', 'decimal', 'str', 'bytes'}. Here, 'long'
        uses ``numpy.longdouble`` for somewhat enhanced precision (with the
        enhancement depending on platform), and 'decimal' instances of
        :class:`decimal.Decimal` for full precision.  For the 'str' and 'bytes'
        sub-formats, the number of digits is also chosen such that time values
        are represented accurately.  Default: as set by ``out_subfmt`` (which by
        default picks the first available for a given format, i.e., 'float').

        Parameters
        ----------
        format : str, optional
            The format in which one wants the `~astropy.time.TimeDelta` values.
            Default: the current format.
        subfmt : str, optional
            Possible sub-format in which the values should be given. Default: as
            set by ``out_subfmt`` (which by default picks the first available
            for a given format, i.e., 'float' or 'date_hms').
        unit : `~astropy.units.UnitBase` instance or str, optional
            The unit in which the value should be given.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not directly
            convertible (see :ref:`astropy:unit_equivalencies`). If `None`, no
            equivalencies will be applied at all, not even any set globally or
            within a context.

        Returns
        -------
        value : ndarray or scalar
            The value in the format or units specified.

        See Also
        --------
        to : Convert to a `~astropy.units.Quantity` instance in a given unit.
        value : The time value in the current format.

        to_value() missing required format or unit argumentallowed_kwargsbad() got an unexpected keyword argument '"() got an unexpected keyword argument"cannot specify 'subfmt' and positional argument that is not a valid format"cannot specify 'subfmt' and positional argument that is not a ""valid format"first argument is not one of the known formats ("first argument is not one of the known ""formats (") and failed to parse as a unit.Coerce setitem value into an equivalent TimeDelta object.cannot convert value to a compatible TimeDelta object: Returns a boolean or boolean array where two TimeDelta objects are
        element-wise equal within a time tolerance.

        This effectively evaluates the expression below::

          abs(self - other) <= atol + rtol * abs(other)

        Parameters
        ----------
        other : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Quantity or TimeDelta object for comparison.
        atol : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Absolute tolerance for equality with units of time (e.g. ``u.s`` or
            ``u.day``). Default is one bit in the 128-bit JD time representation,
            equivalent to about 20 picosecs.
        rtol : float
            Relative tolerance for equality
        other_day'other' argument must support conversion to days: 
    Take ``val`` and convert/reshape to an array.  If ``copy`` is `True`
    then copy input values.

    Returns
    -------
    val : ndarray
        Array version of ``val``.
    OSUMaV for op_stringUnsupported operand type(s): '"and '"If the current ERFA leap second table is out of date, try to update it.

    Uses `astropy.utils.iers.LeapSeconds.auto_open` to try to find an
    up-to-date table.  See that routine for the definition of "out of date".

    In order to make it safe to call this any time, all exceptions are turned
    into warnings,

    Parameters
    ----------
    files : list of path-like, optional
        List of files/URLs to attempt to open.  By default, uses defined by
        `astropy.utils.iers.LeapSeconds.auto_open`, which includes the table
        used by ERFA itself, so if that is up to date, nothing will happen.

    Returns
    -------
    n_update : int
        Number of items updated.

    LeapSecondsauto_openleap_secondsleap-second auto-update failed due to the following exception: # Below, import TimeFromEpoch to avoid breaking code that followed the old# example of making a custom timescale in the documentation.# For time scale changes, we need L_G and L_B, which are stored in erfam.h as#   /* L_G = 1 - d(TT)/d(TCG) */#   define ERFA_ELG (6.969290134e-10)#   /* L_B = 1 - d(TDB)/d(TCB), and TDB (s) at TAI 1977/1/1.0 */#   define ERFA_ELB (1.550519768e-8)# These are exposed in erfa as erfa.ELG and erfa.ELB.# Implied: d(TT)/d(TCG) = 1-L_G# and      d(TCG)/d(TT) = 1/(1-L_G) = 1 + (1-(1-L_G))/(1-L_G) = 1 + L_G/(1-L_G)# scale offsets as second = first + first * scale_offset[(first,second)]# triple-level dictionary, yay!# No thread has reached the check# A thread is running update_leap_seconds (_LEAP_SECONDS_LOCK is held)# update_leap_seconds has completed# Build up a list of index arrays for each dimension, allowing no more than# 2 * edgeitems + 1 elements in each dimension.# The middle [edgeitems] value does not matter as it gets replaced# by ... in the output.# Use the magic np.ix_ function to effectively treat each index array as a# slicing operator.# The usual tuple of attributes needed for serialization is replaced# by a property, since Time can be serialized different ways.# When serializing, write out the `value` attribute using the column name.# If ``True`` for a context, then use formatted ``value`` attribute# (e.g. the ISO time string).  If ``False`` then use float jd1 and jd2.# When Time has mean, std, min, max methods:# funcs = [lambda x: getattr(x, stat)() for stat_name in MixinInfo._stats])# Initialize as JD but revert to desired format and out_subfmt (if needed)# Not relevant for Time# Check that location is consistent for all Time objects# This is the method used by __setitem__ to ensure that the right side# has a consistent location (and coerce data if necessary, but that does# not happen in this case since `col` is already a Time object).  If this# passes then any subsequent table operations via setitem will work.# Make a new Time object with the desired shape and attributes# Arbitrary JD value J2000.0 that will work with ERFA# Set remaining info attributes# TODO: refactor these special cases into the TimeFormat classes?# The datetime64 format requires special handling for ECSV (see #12840).# The `value` has numpy dtype datetime64 but this is not an allowed# datatype for ECSV. Instead convert to a string representation.# The datetime format is serialized as ISO with no loss of precision.# See comment above. May need to convert string back to datetime64.# Note that _serialize_context is not set here so we just look for the# string value directly.# Convert back to datetime objects for datetime format.# Make sure that reverse arithmetic (e.g., TimeDelta.__rmul__)# gets called over the __mul__ of Numpy arrays.# Declare that Time can be used as a Table column by defining the# attribute where column attributes will be stored.# For pickling, we remove the cache from what's pickled# Coerce val into an array# If val2 is not None, ensure consistency# If either of the input val, val2 are masked arrays then# find the masked elements and fill them.# Parse / convert input values into internal jd1, jd2 based on format# Hack from #9969 to allow passing the location value that has been# collected by the TimeAstropyTime format class up to the Time level.# TODO: find a nicer way.# If any inputs were masked then mask both jd1 and jd2 accordingly,# using a shared mask.  From above, ``mask`` must be either Python# bool False or an bool ndarray with the correct shape.# Ensure that if the class is already masked, we do not lose it.# Ensure we share the mask (it may have been broadcast).# If val and val2 broadcasted shape is (0,) (i.e. empty array input) then we# cannot guess format from the input values. But a quantity is fine (as# long as it has time units, but that will be checked later).# AstropyTime is a pseudo-format that isn't in the TIME_FORMATS registry,# but try to guess it at the end.# If ``format`` specified then there is only one possibility, so raise# immediately and include the upstream exception message to make it# easier for user to see what is wrong.# Get the new TimeFormat object to contain time in new format.  Possibly# coerce in/out_subfmt to '*' (default) if existing subfmt values are# not valid in the new format.# Compress time object by allowing at most 2 * npo["edgeitems"] + 1# in each dimension. Then force numpy to use "summary mode" of# showing only the edge items by setting the size threshold to 0.# TODO: use np.core.arrayprint._leading_trailing if we have support for# np.concatenate. See #8610.# since astropy 6.1.0# If doing a transform involving UTC then check that the leap# seconds table is up to date.# Determine the chain of scale transformations to get from the current# scale to the new scale.  MULTI_HOPS contains a dict of all# transformations (xforms) that require intermediate xforms.# The MULTI_HOPS dict is keyed by (sys1, sys2) in alphabetical order.# If we made the reverse xform then reverse it now.# Transform the jd1,2 pairs through the chain of scale xforms.# Some xforms require an additional delta_ argument that is# provided through Time methods.  These values may be supplied by# the user or computed based on available approximations.  The# get_delta_ methods are available for only one combination of# sys1, sys2 though the property applies for both xform directions.# Setting the out_subfmt property here does validation of ``val``# We have to keep track of arrays that were already reshaped,# since we may have to return those to their original shape if a later# shape-setting fails.# In-place reshape of data/attributes.  Need to access _time.jd1/2 not# self.jd1/2 because the latter are not guaranteed to be the actual# data, and in fact should not be directly changeable from the public# API.# Ensure the mask is independent.# For new-style, we do not treat masked scalars differently from arrays.# zero-dimensional array, is it safe to unbox?  The tricky comparison# of the mask is for the case that value is structured; otherwise, we# could just use np.ma.is_masked(value).# existing test doesn't want datetime64 converted# Unpack but keep field names; .item() doesn't# Still don't get python types in the fields# TODO: add a precision argument (but ensure it is keyword argument# only, to make life easier for TimeDelta.to_value()).# Some TimeFormat subclasses may not be able to handle being passes# on a out_subfmt. This includes some core classes like# TimeBesselianEpochString that do not have any allowed subfmts. But# those do deal with `self.out_subfmt` internally, so if subfmt is# the same, we do not pass it on.# Try validating subfmt, e.g. for formats like 'jyear_str' that# do not implement out_subfmt in to_value() (because there are# no allowed subformats).  If subfmt is not valid this gives the# same exception as would have occurred if the call to# `to_value()` had succeeded.# Subfmt was valid, so fall back to the original exception to see# if it was lack of support for out_subfmt as a call arg.# Some unforeseen exception so raise.# Take a view of any existing mask, so we can set it to readonly.# Validate inputs: obj arg is integer, axis=0, self is not a scalar, and# For non-Time object, use numpy to help figure out the length.  (Note annoying# case of a string input that has a length which is not the length we want).# This uses the Time setting machinery to coerce and validate as necessary.# Any use of setitem results in immediate cache invalidation# Setting invalidates transform deltas# Finally directly set the jd1/2 values.  Locations are known to match.# Note: use 2 bits instead of 1 bit based on experience in precision# tests, since taking the difference with a UTC time means one has# to do a scale change.# Separate these out so user sees where the problem is# Get a new instance of our class and set its attributes directly.# Optional ndarray attributes.# Apply the method to any value arrays (though skip if there is# only an array scalar and the method would return a view,# since in that case nothing would change).# Copy other 'info' attr only if it has actually been defined and the# time object is not a scalar (issue #10688).# Make the new internal _time object corresponding to the format# in the copy.  If the format is unchanged this process is lightweight# and does not create any new arrays.# Finally, if we do not own our data, we link caches, so that# those can be cleared as needed if any instance is written to.# First get the minimum at normal precision.# Approx is very close to the true minimum, and by subtracting it at# full precision, all numbers near 0 can be represented correctly,# so we can be sure we get the true minimum.# The below is effectively what would be done for# dt = (self - self.__class__(approx, format='jd')).jd# which translates to:# approx_jd1, approx_jd2 = day_frac(approx, 0.)# dt = (self.jd1 - approx_jd1) + (self.jd2 - approx_jd2)# For procedure, see comment on argmin.# lazyproperty will do the actual storing of the result.# Prevent future modification of cached array-like object# allowed ones done above (self.SCALES)# Should raise AttributeError# be conservative and copy# check the value can be broadcast to the shape of self.# Let other have a go.# Other will also not be able to do it, so raise a TypeError# immediately, allowing us to explain why it doesn't work.# Update _time formatting parameters if explicitly specified# check the location can be broadcast to self's shape.# If there is a vector location then broadcast to the Time shape# and then select with ``item``# Make sure locations are compatible.  Location can be either None or# a Location object.# call `now` immediately to be sure it's ASAP# ensure sky location is ICRS compatible# get location of observatory in ITRS coordinates at this Time# convert to heliocentric coordinates, aligned with ICRS# first we need to convert to GCRS coordinates with the correct# obstime, since ICRS coordinates have no frame time# convert to barycentric (BCRS) coordinates, aligned with ICRS# get unit ICRS vector to star# Move X,Y,Z to last dimension, to enable possible broadcasting below.# calculate light travel time correction# (docstring is formatted below)# Sanity check on input; default unit is degree.# TODO: this duplicates part of coordinates.erfa_astrom.ErfaAstrom.apio;# maybe posisble to factor out to one or the other.# Form the rotation matrix, CIRS to apparent [HA,Dec].# Solve for angle.# TODO: allow erfa functions to be used on Time with __array_ufunc__.# Property for ERFA DUT arg = UT1 - UTC# Sec. 4.3.1: the arg DUT is the quantity delta_UT1 = UT1 - UTC in# seconds. It is obtained from tables published by the IERS.# jd1, jd2 are normally set (see above), except if delta_ut1_utc# is access directly; ensure we behave as expected for that case# interpolate UT1-UTC in IERS table# if we interpolated using UT1 jds, we may be off by one# second near leap seconds (and very slightly off elsewhere)# calculate UTC using the offset we got; the ERFA routine# is tolerant of leap seconds, so will do this right# calculate a better estimate using the nearly correct UTC# Matches Quantity but also TimeDelta.# Note can't use @property because _get_delta_tdb_tt is explicitly# called with the optional jd1 and jd2 args.# Property for ERFA DTR arg = TDB - TT# If jd1 and jd2 are not provided (which is the case for property# attribute access) then require that the time scale is TT or TDB.# Otherwise the computations here are not correct.# First go from the current input time (which is either# TDB or TT) to an approximate UT1.  Since TT and TDB are# pretty close (few msec?), assume TT.  Similarly, since the# UT1 terms are very small, use UTC instead of UT1.# subtract 0.5, so UT is fraction of the day from midnight# Assume geocentric.# Geodetic params needed for d_tdb_tt()# T      - Tdelta = T# T      - T      = Tdelta# T - Tdelta# Check other is really a TimeDelta or something that can initialize.# we need a constant scale to calculate, which is guaranteed for# TimeDelta, but not for Time (which can be UTC)# remove attributes that are invalidated by changing time# T - T# the scales should be compatible (e.g., cannot convert TDB to LOCAL)# set up TimeDelta, subtraction to be done shortly# Go back to left-side scale if needed# T      + Tdelta = T# T      + T      = error# ideally, we calculate in the scale of the Time item, since that is# what we want the output in, but this may not be possible, since# TimeDelta cannot be converted arbitrarily# Reverse addition is possible: <something-Tdelta-ish> + T# but there is no case of <something> - T, so no __rsub__.# TODO: this could likely go through to_value, as long as that# had an **kwargs part that was just passed on to _time.# For TimeDelta, there can only be a change in scale factor,# which is written as time2 - time1 = scale_offset * time1# If not a TimeDelta then see if it can be turned into a TimeDelta.# the scales should be compatible (e.g., cannot convert TDB to TAI)# adjust the scale of other if the scale of self is set (or no scales)# If other is a Time then use Time.__add__ to do the calculation.# TimeDelta - Time is an error# Check needed since otherwise the self.jd1 * other multiplication# would enter here again (via __rmul__)# If other is something consistent with a dimensionless quantity# (could just be a float or an array), then we can just multiple in.# If not consistent with a dimensionless quantity, try downgrading# self to a quantity and see if things work.# The various ways we could multiply all failed;# returning NotImplemented to give other a final chance.# Cannot do __mul__(1./other) as that looses precision# (could just be a float or an array), then we can just divide in.# The various ways we could divide all failed;# Here, we do not have to worry about returning NotImplemented,# since other has already had a chance to look at us.# Validate keyword arguments.# Handle a valid format as first positional argument or keyword. This will also# accept a subfmt keyword if supplied.# Super-class will error with duplicate arguments, etc.# Handle subfmt keyword with no format and no args.# At this point any positional argument must be a unit so try parsing as such.# If it fails then give an informative exception.# TODO: deprecate providing equivalencies as a positional argument. This is# quite non-obvious in this context.# Allow only float64, string or object arrays as input# (object is for datetime, maybe add more specific test later?)# This also ensures the right byteorder for float64 (closes #2942).# There are three ways we can get here:# 1. First call (NOT_STARTED).# 2. Re-entrant call (RUNNING). We skip the initialisation#    and don't worry about leap second errors.# 3. Another thread which raced with the first call#    (RUNNING). The first thread has relinquished the#    lock to us, so initialization is complete.b'
The astropy.time package provides functionality for manipulating times and
dates. Specific emphasis is placed on supporting time scales (e.g. UTC, TAI,
UT1) and time representations (e.g. JD, MJD, ISO 8601) that are used in
astronomy.
'u'
The astropy.time package provides functionality for manipulating times and
dates. Specific emphasis is placed on supporting time scales (e.g. UTC, TAI,
UT1) and time representations (e.g. JD, MJD, ISO 8601) that are used in
astronomy.
'b'STANDARD_TIME_SCALES'u'STANDARD_TIME_SCALES'b'TIME_DELTA_SCALES'u'TIME_DELTA_SCALES'b'TIME_SCALES'u'TIME_SCALES'b'OperandTypeError'u'OperandTypeError'b'ScaleValueError'u'ScaleValueError'b'TimeBase'u'TimeBase'b'TimeDeltaMissingUnitWarning'u'TimeDeltaMissingUnitWarning'b'TimeInfo'u'TimeInfo'b'TimeInfoBase'u'TimeInfoBase'b'update_leap_seconds'u'update_leap_seconds'b'tai'u'tai'b'tcb'u'tcb'b'tcg'u'tcg'b'tdb'u'tdb'b'tt'u'tt'b'ut1'u'ut1'b'local'u'local'b'scales'u'scales'b'IAU2006'u'IAU2006'b'IAU2000'u'IAU2000'b'include_tio'u'include_tio'b'IAU1982'u'IAU1982'b'IAU2006A'u'IAU2006A'b'IAU2000A'u'IAU2000A'b'IAU2000B'u'IAU2000B'b'IAU1994'u'IAU1994'b'apparent'u'apparent'b'Compress array by allowing at most 2 * edgeitems + 1 in each dimension.

    Parameters
    ----------
    arr : array-like
        Array to compress.

    Returns
    -------
    out : array-like
        Compressed array.
    'u'Compress array by allowing at most 2 * edgeitems + 1 in each dimension.

    Parameters
    ----------
    arr : array-like
        Array to compress.

    Returns
    -------
    out : array-like
        Compressed array.
    'b'edgeitems'u'edgeitems'b'
    Container for meta information like name, description, format.  This is
    required when the object is used as a mixin column within a table, but can
    be used as a general way to store meta information.

    This base class is common between TimeInfo and TimeDeltaInfo.
    'u'
    Container for meta information like name, description, format.  This is
    required when the object is used as a mixin column within a table, but can
    be used as a general way to store meta information.

    This base class is common between TimeInfo and TimeDeltaInfo.
    'b'in_subfmt'u'in_subfmt'b'out_subfmt'u'out_subfmt'b'location'u'location'b'_delta_ut1_utc'u'_delta_ut1_utc'b'_delta_tdb_tt'u'_delta_tdb_tt'b'formatted_value'u'formatted_value'b'jd1_jd2'u'jd1_jd2'b'jd1'u'jd1'b'jd2'u'jd2'b'serialize method must be 'formatted_value' or 'jd1_jd2''u'serialize method must be 'formatted_value' or 'jd1_jd2''b'
        Return a list of arrays which can be lexically sorted to represent
        the order of the parent column.

        Returns
        -------
        arrays : list of ndarray
        'u'
        Return a list of arrays which can be lexically sorted to represent
        the order of the parent column.

        Returns
        -------
        arrays : list of ndarray
        'b'val2'u'val2'b'
        Return a new Time instance which is consistent with the input Time objects
        ``cols`` and has ``length`` rows.

        This is intended for creating an empty Time instance whose elements can
        be set in-place for table operations like join or vstack.  It checks
        that the input locations and attributes are consistent.  This is used
        when a Time object is used as a mixin column in an astropy Table.

        Parameters
        ----------
        cols : list
            List of input columns (Time objects)
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Time (or subclass)
            Empty instance of this class consistent with ``cols``

        'u'
        Return a new Time instance which is consistent with the input Time objects
        ``cols`` and has ``length`` rows.

        This is intended for creating an empty Time instance whose elements can
        be set in-place for table operations like join or vstack.  It checks
        that the input locations and attributes are consistent.  This is used
        when a Time object is used as a mixin column in an astropy Table.

        Parameters
        ----------
        cols : list
            List of input columns (Time objects)
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Time (or subclass)
            Empty instance of this class consistent with ``cols``

        'b'input columns have inconsistent locations'u'input columns have inconsistent locations'b'Get the values for the parent ``attrs`` and return as a dict.

        By default, uses '_represent_as_dict_attrs'.
        'u'Get the values for the parent ``attrs`` and return as a dict.

        By default, uses '_represent_as_dict_attrs'.
        'b'datetime64'u'datetime64'b'datetime'u'datetime'b'
        Return a new TimeDelta instance which is consistent with the input Time objects
        ``cols`` and has ``length`` rows.

        This is intended for creating an empty Time instance whose elements can
        be set in-place for table operations like join or vstack.  It checks
        that the input locations and attributes are consistent.  This is used
        when a Time object is used as a mixin column in an astropy Table.

        Parameters
        ----------
        cols : list
            List of input columns (Time objects)
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Time (or subclass)
            Empty instance of this class consistent with ``cols``

        'u'
        Return a new TimeDelta instance which is consistent with the input Time objects
        ``cols`` and has ``length`` rows.

        This is intended for creating an empty Time instance whose elements can
        be set in-place for table operations like join or vstack.  It checks
        that the input locations and attributes are consistent.  This is used
        when a Time object is used as a mixin column in an astropy Table.

        Parameters
        ----------
        cols : list
            List of input columns (Time objects)
        length : int
            Length of the output column object
        metadata_conflicts : str ('warn'|'error'|'silent')
            How to handle metadata conflicts
        name : str
            Output column name

        Returns
        -------
        col : Time (or subclass)
            Empty instance of this class consistent with ``cols``

        'b'Base time class from which Time and TimeDelta inherit.'u'Base time class from which Time and TimeDelta inherit.'b'_id_cache'u'_id_cache'b'cache'u'cache'b'
        Set the internal _format, scale, and _time attrs from user
        inputs.  This handles coercion into the correct shapes and
        some basic input validation.
        'u'
        Set the internal _format, scale, and _time attrs from user
        inputs.  This handles coercion into the correct shapes and
        some basic input validation.
        'b'Input val and val2 have inconsistent shape; they cannot be broadcast together.'u'Input val and val2 have inconsistent shape; they cannot be broadcast together.'b'Scale 'u'Scale 'b' is not in the allowed scales 'u' is not in the allowed scales 'b'_location'u'_location'b'
        Given the supplied val, val2, format and scale try to instantiate
        the corresponding TimeFormat class to convert the input values into
        the internal jd1 and jd2.

        If format is `None` and the input is a string-type or object array then
        guess available formats and stop when one matches.
        'u'
        Given the supplied val, val2, format and scale try to instantiate
        the corresponding TimeFormat class to convert the input values into
        the internal jd1 and jd2.

        If format is `None` and the input is a string-type or object array then
        guess available formats and stop when one matches.
        'b'cannot guess format from input values with zero-size array or all elements masked'u'cannot guess format from input values with zero-size array or all elements masked'b'astropy_time'u'astropy_time'b'format must be a string'u'format must be a string'b' is not one of the allowed formats 'u' is not one of the allowed formats 'b'Input values did not match the format class 'u'Input values did not match the format class 'b'Input values did not match any of the formats where the format keyword is optional:
'u'Input values did not match any of the formats where the format keyword is optional:
'b'- ''u'- ''b'': 'u'': 'b'
        Get or set time format.

        The format defines the way times are represented when accessed via the
        ``.value`` attribute.  By default it is the same as the format used for
        initializing the `Time` instance, but it can be set to any other value
        that could be used for initialization.  These can be listed with::

          >>> list(Time.FORMATS)
          ['jd', 'mjd', 'decimalyear', 'unix', 'unix_tai', 'cxcsec', 'gps', 'plot_date',
           'stardate', 'datetime', 'ymdhms', 'iso', 'isot', 'yday', 'datetime64',
           'fits', 'byear', 'jyear', 'byear_str', 'jyear_str']
        'u'
        Get or set time format.

        The format defines the way times are represented when accessed via the
        ``.value`` attribute.  By default it is the same as the format used for
        initializing the `Time` instance, but it can be set to any other value
        that could be used for initialization.  These can be listed with::

          >>> list(Time.FORMATS)
          ['jd', 'mjd', 'decimalyear', 'unix', 'unix_tai', 'cxcsec', 'gps', 'plot_date',
           'stardate', 'datetime', 'ymdhms', 'iso', 'isot', 'yday', 'datetime64',
           'fits', 'byear', 'jyear', 'byear_str', 'jyear_str']
        'b'Set time format.'u'Set time format.'b'format must be one of 'u'format must be one of 'b'Output a string representation of the Time or TimeDelta object.

        Similar to ``str(self.value)`` (which uses numpy array formatting) but
        array values are evaluated only for the items that actually are output.
        For large arrays this can be a substantial performance improvement.

        Returns
        -------
        out : str
            String representation of the time values.

        'u'Output a string representation of the Time or TimeDelta object.

        Similar to ``str(self.value)`` (which uses numpy array formatting) but
        array values are evaluated only for the items that actually are output.
        For large arrays this can be a substantial performance improvement.

        Returns
        -------
        out : str
            String representation of the time values.

        'b'threshold'u'threshold'b' object: scale=''u' object: scale=''b'' format=''u'' format=''b'' value='u'' value='b'(must be scalar)'u'(must be scalar)'b'(value is masked)'u'(value is masked)'b'unhashable type: ''u'unhashable type: ''b'Setting the location attribute post initialization will be disallowed in a future version of Astropy. Instead you should set the location when creating the Time object. In the future, this will raise an AttributeError.'u'Setting the location attribute post initialization will be disallowed in a future version of Astropy. Instead you should set the location when creating the Time object. In the future, this will raise an AttributeError.'b'Time scale.'u'Time scale.'b'
        This is the key routine that actually does time scale conversions.
        This is not public and not connected to the read-only scale property.
        'u'
        This is the key routine that actually does time scale conversions.
        This is not public and not connected to the read-only scale property.
        'b'_get_delta_{}_{}'u'_get_delta_{}_{}'b'
        Decimal precision when outputting seconds as floating point (int
        value between 0 and 9 inclusive).
        'u'
        Decimal precision when outputting seconds as floating point (int
        value between 0 and 9 inclusive).
        'b'
        Unix wildcard pattern to select subformats for parsing string input
        times.
        'u'
        Unix wildcard pattern to select subformats for parsing string input
        times.
        'b'
        Unix wildcard pattern to select subformats for outputting times.
        'u'
        Unix wildcard pattern to select subformats for outputting times.
        'b'The shape of the time instances.

        Like `~numpy.ndarray.shape`, can be set to a new shape by assigning a
        tuple.  Note that if different instances share some but not all
        underlying data, setting the shape of one instance can make the other
        instance unusable.  Hence, it is strongly recommended to get new,
        reshaped instances with the ``reshape`` method.

        Raises
        ------
        ValueError
            If the new shape has the wrong total number of elements.
        AttributeError
            If the shape of the ``jd1``, ``jd2``, ``location``,
            ``delta_ut1_utc``, or ``delta_tdb_tt`` attributes cannot be changed
            without the arrays being copied.  For these cases, use the
            `Time.reshape` method (which copies any arrays that cannot be
            reshaped in-place).
        'u'The shape of the time instances.

        Like `~numpy.ndarray.shape`, can be set to a new shape by assigning a
        tuple.  Note that if different instances share some but not all
        underlying data, setting the shape of one instance can make the other
        instance unusable.  Hence, it is strongly recommended to get new,
        reshaped instances with the ``reshape`` method.

        Raises
        ------
        ValueError
            If the new shape has the wrong total number of elements.
        AttributeError
            If the shape of the ``jd1``, ``jd2``, ``location``,
            ``delta_ut1_utc``, or ``delta_tdb_tt`` attributes cannot be changed
            without the arrays being copied.  For these cases, use the
            `Time.reshape` method (which copies any arrays that cannot be
            reshaped in-place).
        'b'JD is an array ('u'JD is an array ('b') but value is not ('u') but value is not ('b'
        First of the two doubles that internally store time value(s) in JD.
        'u'
        First of the two doubles that internally store time value(s) in JD.
        'b'
        Second of the two doubles that internally store time value(s) in JD.
        'u'
        Second of the two doubles that internally store time value(s) in JD.
        'b'Get time values expressed in specified output format.

        This method allows representing the ``Time`` object in the desired
        output ``format`` and optional sub-format ``subfmt``.  Available
        built-in formats include ``jd``, ``mjd``, ``iso``, and so forth. Each
        format can have its own sub-formats

        For built-in numerical formats like ``jd`` or ``unix``, ``subfmt`` can
        be one of 'float', 'long', 'decimal', 'str', or 'bytes'.  Here, 'long'
        uses ``numpy.longdouble`` for somewhat enhanced precision (with
        the enhancement depending on platform), and 'decimal'
        :class:`decimal.Decimal` for full precision.  For 'str' and 'bytes', the
        number of digits is also chosen such that time values are represented
        accurately.

        For built-in date-like string formats, one of 'date_hms', 'date_hm', or
        'date' (or 'longdate_hms', etc., for 5-digit years in
        `~astropy.time.TimeFITS`).  For sub-formats including seconds, the
        number of digits used for the fractional seconds is as set by
        `~astropy.time.Time.precision`.

        Parameters
        ----------
        format : str
            The format in which one wants the time values. Default: the current
            format.
        subfmt : str or None, optional
            Value or wildcard pattern to select the sub-format in which the
            values should be given.  The default of '*' picks the first
            available for a given format, i.e., 'float' or 'date_hms'.
            If `None`, use the instance's ``out_subfmt``.

        'u'Get time values expressed in specified output format.

        This method allows representing the ``Time`` object in the desired
        output ``format`` and optional sub-format ``subfmt``.  Available
        built-in formats include ``jd``, ``mjd``, ``iso``, and so forth. Each
        format can have its own sub-formats

        For built-in numerical formats like ``jd`` or ``unix``, ``subfmt`` can
        be one of 'float', 'long', 'decimal', 'str', or 'bytes'.  Here, 'long'
        uses ``numpy.longdouble`` for somewhat enhanced precision (with
        the enhancement depending on platform), and 'decimal'
        :class:`decimal.Decimal` for full precision.  For 'str' and 'bytes', the
        number of digits is also chosen such that time values are represented
        accurately.

        For built-in date-like string formats, one of 'date_hms', 'date_hm', or
        'date' (or 'longdate_hms', etc., for 5-digit years in
        `~astropy.time.TimeFITS`).  For sub-formats including seconds, the
        number of digits used for the fractional seconds is as set by
        `~astropy.time.Time.precision`.

        Parameters
        ----------
        format : str
            The format in which one wants the time values. Default: the current
            format.
        subfmt : str or None, optional
            Value or wildcard pattern to select the sub-format in which the
            values should be given.  The default of '*' picks the first
            available for a given format, i.e., 'float' or 'date_hms'.
            If `None`, use the instance's ``out_subfmt``.

        'b'unexpected keyword argument 'out_subfmt''u'unexpected keyword argument 'out_subfmt''b'to_value() method for format 'u'to_value() method for format 'b' does not support passing a 'subfmt' argument'u' does not support passing a 'subfmt' argument'b'Time value(s) in current format.'u'Time value(s) in current format.'b'
        Insert values before the given indices in the column and return
        a new `~astropy.time.Time` or  `~astropy.time.TimeDelta` object.

        The values to be inserted must conform to the rules for in-place setting
        of ``Time`` objects (see ``Get and set values`` in the ``Time``
        documentation).

        The API signature matches the ``np.insert`` API, but is more limited.
        The specification of insert index ``obj`` must be a single integer,
        and the ``axis`` must be ``0`` for simple row insertion before the
        index.

        Parameters
        ----------
        obj : int
            Integer index before which ``values`` is inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different
            from that of quantity, ``values`` is converted to the matching type.
        axis : int, optional
            Axis along which to insert ``values``.  Default is 0, which is the
            only allowed value and will insert a row.

        Returns
        -------
        out : `~astropy.time.Time` subclass
            New time object with inserted value(s)

        'u'
        Insert values before the given indices in the column and return
        a new `~astropy.time.Time` or  `~astropy.time.TimeDelta` object.

        The values to be inserted must conform to the rules for in-place setting
        of ``Time`` objects (see ``Get and set values`` in the ``Time``
        documentation).

        The API signature matches the ``np.insert`` API, but is more limited.
        The specification of insert index ``obj`` must be a single integer,
        and the ``axis`` must be ``0`` for simple row insertion before the
        index.

        Parameters
        ----------
        obj : int
            Integer index before which ``values`` is inserted.
        values : array-like
            Value(s) to insert.  If the type of ``values`` is different
            from that of quantity, ``values`` is converted to the matching type.
        axis : int, optional
            Axis along which to insert ``values``.  Default is 0, which is the
            only allowed value and will insert a row.

        Returns
        -------
        out : `~astropy.time.Time` subclass
            New time object with inserted value(s)

        'b' object is read-only. Make a copy() or set "writeable" attribute to True.'u' object is read-only. Make a copy() or set "writeable" attribute to True.'b'scalar 'u'scalar 'b' object is read-only.'u' object is read-only.'b'Returns a boolean or boolean array where two Time objects are
        element-wise equal within a time tolerance.

        This evaluates the expression below::

          abs(self - other) <= atol

        Parameters
        ----------
        other : `~astropy.time.Time`
            Time object for comparison.
        atol : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Absolute tolerance for equality with units of time (e.g. ``u.s`` or
            ``u.day``). Default is two bits in the 128-bit JD time representation,
            equivalent to about 40 picosecs.
        'u'Returns a boolean or boolean array where two Time objects are
        element-wise equal within a time tolerance.

        This evaluates the expression below::

          abs(self - other) <= atol

        Parameters
        ----------
        other : `~astropy.time.Time`
            Time object for comparison.
        atol : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Absolute tolerance for equality with units of time (e.g. ``u.s`` or
            ``u.day``). Default is two bits in the 128-bit JD time representation,
            equivalent to about 40 picosecs.
        'b''atol' argument must be a Quantity or TimeDelta instance, got 'u''atol' argument must be a Quantity or TimeDelta instance, got 'b' instead'u' instead'b''other' argument must support subtraction with Time and return a value that supports comparison with 'u''other' argument must support subtraction with Time and return a value that supports comparison with 'b'
        Return a fully independent copy the Time object, optionally changing
        the format.

        If ``format`` is supplied then the time format of the returned Time
        object will be set accordingly, otherwise it will be unchanged from the
        original.

        In this method a full copy of the internal time arrays will be made.
        The internal time arrays are normally not changeable by the user so in
        most cases the ``replicate()`` method should be used.

        Parameters
        ----------
        format : str, optional
            Time format of the copy.

        Returns
        -------
        tm : Time object
            Copy of this object
        'u'
        Return a fully independent copy the Time object, optionally changing
        the format.

        If ``format`` is supplied then the time format of the returned Time
        object will be set accordingly, otherwise it will be unchanged from the
        original.

        In this method a full copy of the internal time arrays will be made.
        The internal time arrays are normally not changeable by the user so in
        most cases the ``replicate()`` method should be used.

        Parameters
        ----------
        format : str, optional
            Time format of the copy.

        Returns
        -------
        tm : Time object
            Copy of this object
        'b'
        Return a replica of the Time object, optionally changing the format.

        If ``format`` is supplied then the time format of the returned Time
        object will be set accordingly, otherwise it will be unchanged from the
        original.

        If ``copy`` is set to `True` then a full copy of the internal time arrays
        will be made.  By default the replica will use a reference to the
        original arrays when possible to save memory.  The internal time arrays
        are normally not changeable by the user so in most cases it should not
        be necessary to set ``copy`` to `True`.

        The convenience method copy() is available in which ``copy`` is `True`
        by default.

        Parameters
        ----------
        format : str, optional
            Time format of the replica.
        copy : bool, optional
            Return a true copy instead of using references where possible.

        Returns
        -------
        tm : Time object
            Replica of this object
        'u'
        Return a replica of the Time object, optionally changing the format.

        If ``format`` is supplied then the time format of the returned Time
        object will be set accordingly, otherwise it will be unchanged from the
        original.

        If ``copy`` is set to `True` then a full copy of the internal time arrays
        will be made.  By default the replica will use a reference to the
        original arrays when possible to save memory.  The internal time arrays
        are normally not changeable by the user so in most cases it should not
        be necessary to set ``copy`` to `True`.

        The convenience method copy() is available in which ``copy`` is `True`
        by default.

        Parameters
        ----------
        format : str, optional
            Time format of the replica.
        copy : bool, optional
            Return a true copy instead of using references where possible.

        Returns
        -------
        tm : Time object
            Replica of this object
        'b'replicate'u'replicate'b'Create a new time object, possibly applying a method to the arrays.

        Parameters
        ----------
        method : str or callable
            If string, can be 'replicate'  or the name of a relevant
            `~numpy.ndarray` method. In the former case, a new time instance
            with unchanged internal data is created, while in the latter the
            method is applied to the internal ``jd1`` and ``jd2`` arrays, as
            well as to possible ``location``, ``_delta_ut1_utc``, and
            ``_delta_tdb_tt`` arrays.
            If a callable, it is directly applied to the above arrays.
            Examples: 'copy', '__getitem__', 'reshape', `~numpy.broadcast_to`.
        args : tuple
            Any positional arguments for ``method``.
        kwargs : dict
            Any keyword arguments for ``method``.  If the ``format`` keyword
            argument is present, this will be used as the Time format of the
            replica.

        Examples
        --------
        Some ways this is used internally::

            copy : ``_apply('copy')``
            replicate : ``_apply('replicate')``
            reshape : ``_apply('reshape', new_shape)``
            index or slice : ``_apply('__getitem__', item)``
            broadcast : ``_apply(np.broadcast, shape=new_shape)``
        'u'Create a new time object, possibly applying a method to the arrays.

        Parameters
        ----------
        method : str or callable
            If string, can be 'replicate'  or the name of a relevant
            `~numpy.ndarray` method. In the former case, a new time instance
            with unchanged internal data is created, while in the latter the
            method is applied to the internal ``jd1`` and ``jd2`` arrays, as
            well as to possible ``location``, ``_delta_ut1_utc``, and
            ``_delta_tdb_tt`` arrays.
            If a callable, it is directly applied to the above arrays.
            Examples: 'copy', '__getitem__', 'reshape', `~numpy.broadcast_to`.
        args : tuple
            Any positional arguments for ``method``.
        kwargs : dict
            Any keyword arguments for ``method``.  If the ``format`` keyword
            argument is present, this will be used as the Time format of the
            replica.

        Examples
        --------
        Some ways this is used internally::

            copy : ``_apply('copy')``
            replicate : ``_apply('replicate')``
            reshape : ``_apply('reshape', new_shape)``
            index or slice : ``_apply('__getitem__', item)``
            broadcast : ``_apply(np.broadcast, shape=new_shape)``
        'b'OWNDATA'u'OWNDATA'b'
        Overrides the default behavior of the `copy.copy` function in
        the python stdlib to behave like `Time.copy`. Does *not* make a
        copy of the JD arrays - only copies by reference.
        'u'
        Overrides the default behavior of the `copy.copy` function in
        the python stdlib to behave like `Time.copy`. Does *not* make a
        copy of the JD arrays - only copies by reference.
        'b'
        Overrides the default behavior of the `copy.deepcopy` function
        in the python stdlib to behave like `Time.copy`. Does make a
        copy of the JD arrays.
        'u'
        Overrides the default behavior of the `copy.deepcopy` function
        in the python stdlib to behave like `Time.copy`. Does make a
        copy of the JD arrays.
        'b'Turn argmin, argmax output into an advanced index.

        Argmin, argmax output contains indices along a given axis in an array
        shaped like the other dimensions.  To use this to get values at the
        correct location, a list is constructed in which the other axes are
        indexed sequentially.  For ``keepdims`` is ``True``, the net result is
        the same as constructing an index grid with ``np.ogrid`` and then
        replacing the ``axis`` item with ``indices`` with its shaped expanded
        at ``axis``. For ``keepdims`` is ``False``, the result is the same but
        with the ``axis`` dimension removed from all list entries.

        For ``axis`` is ``None``, this calls :func:`~numpy.unravel_index`.

        Parameters
        ----------
        indices : array
            Output of argmin or argmax.
        axis : int or None
            axis along which argmin or argmax was used.
        keepdims : bool
            Whether to construct indices that keep or remove the axis along
            which argmin or argmax was used.  Default: ``False``.

        Returns
        -------
        advanced_index : list of arrays
            Suitable for use as an advanced index.
        'u'Turn argmin, argmax output into an advanced index.

        Argmin, argmax output contains indices along a given axis in an array
        shaped like the other dimensions.  To use this to get values at the
        correct location, a list is constructed in which the other axes are
        indexed sequentially.  For ``keepdims`` is ``True``, the net result is
        the same as constructing an index grid with ``np.ogrid`` and then
        replacing the ``axis`` item with ``indices`` with its shaped expanded
        at ``axis``. For ``keepdims`` is ``False``, the result is the same but
        with the ``axis`` dimension removed from all list entries.

        For ``axis`` is ``None``, this calls :func:`~numpy.unravel_index`.

        Parameters
        ----------
        indices : array
            Output of argmin or argmax.
        axis : int or None
            axis along which argmin or argmax was used.
        keepdims : bool
            Whether to construct indices that keep or remove the axis along
            which argmin or argmax was used.  Default: ``False``.

        Returns
        -------
        advanced_index : list of arrays
            Suitable for use as an advanced index.
        'b'Return indices of the minimum values along the given axis.

        This is similar to :meth:`~numpy.ndarray.argmin`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used.  See :func:`~numpy.argmin` for detailed documentation.
        'u'Return indices of the minimum values along the given axis.

        This is similar to :meth:`~numpy.ndarray.argmin`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used.  See :func:`~numpy.argmin` for detailed documentation.
        'b'Return indices of the maximum values along the given axis.

        This is similar to :meth:`~numpy.ndarray.argmax`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used.  See :func:`~numpy.argmax` for detailed documentation.
        'u'Return indices of the maximum values along the given axis.

        This is similar to :meth:`~numpy.ndarray.argmax`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used.  See :func:`~numpy.argmax` for detailed documentation.
        'b'Returns the indices that would sort the time array.

        This is similar to :meth:`~numpy.ndarray.argsort`, but adapted to ensure that
        the full precision given by the two doubles ``jd1`` and ``jd2`` is used, and
        that corresponding attributes are copied.  Internally, it uses
        :func:`~numpy.lexsort`, and hence no sort method can be chosen.

        Parameters
        ----------
        axis : int, optional
            Axis along which to sort. Default is -1, which means sort along the last
            axis.
        kind : 'stable', optional
            Sorting is done with :func:`~numpy.lexsort` so this argument is ignored, but
            kept for compatibility with :func:`~numpy.argsort`. The sorting is stable,
            meaning that the order of equal elements is preserved.

        Returns
        -------
        indices : ndarray
            An array of indices that sort the time array.
        'u'Returns the indices that would sort the time array.

        This is similar to :meth:`~numpy.ndarray.argsort`, but adapted to ensure that
        the full precision given by the two doubles ``jd1`` and ``jd2`` is used, and
        that corresponding attributes are copied.  Internally, it uses
        :func:`~numpy.lexsort`, and hence no sort method can be chosen.

        Parameters
        ----------
        axis : int, optional
            Axis along which to sort. Default is -1, which means sort along the last
            axis.
        kind : 'stable', optional
            Sorting is done with :func:`~numpy.lexsort` so this argument is ignored, but
            kept for compatibility with :func:`~numpy.argsort`. The sorting is stable,
            meaning that the order of equal elements is preserved.

        Returns
        -------
        indices : ndarray
            An array of indices that sort the time array.
        'b'Minimum along a given axis.

        This is similar to :meth:`~numpy.ndarray.min`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.min``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        'u'Minimum along a given axis.

        This is similar to :meth:`~numpy.ndarray.min`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.min``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        'b'Since `Time` instances are immutable, ``out`` cannot be set to anything but ``None``.'u'Since `Time` instances are immutable, ``out`` cannot be set to anything but ``None``.'b'Maximum along a given axis.

        This is similar to :meth:`~numpy.ndarray.max`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.max``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        'u'Maximum along a given axis.

        This is similar to :meth:`~numpy.ndarray.max`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2``
        is used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.max``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        'b'np.ptp'u'np.ptp'b'Peak to peak (maximum - minimum) along a given axis.

        This method is similar to the :func:`numpy.ptp` function, but
        adapted to ensure that the full precision given by the two doubles
        ``jd1`` and ``jd2`` is used.

        Note that the ``out`` argument is present only for compatibility with
        `~numpy.ptp`; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        'u'Peak to peak (maximum - minimum) along a given axis.

        This method is similar to the :func:`numpy.ptp` function, but
        adapted to ensure that the full precision given by the two doubles
        ``jd1`` and ``jd2`` is used.

        Note that the ``out`` argument is present only for compatibility with
        `~numpy.ptp`; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.
        'b'Return a copy sorted along the specified axis.

        This is similar to :meth:`~numpy.ndarray.sort`, but internally uses
        indexing with :func:`~numpy.lexsort` to ensure that the full precision
        given by the two doubles ``jd1`` and ``jd2`` is kept, and that
        corresponding attributes are properly sorted and copied as well.

        Parameters
        ----------
        axis : int or None
            Axis to be sorted.  If ``None``, the flattened array is sorted.
            By default, sort over the last axis.
        'u'Return a copy sorted along the specified axis.

        This is similar to :meth:`~numpy.ndarray.sort`, but internally uses
        indexing with :func:`~numpy.lexsort` to ensure that the full precision
        given by the two doubles ``jd1`` and ``jd2`` is kept, and that
        corresponding attributes are properly sorted and copied as well.

        Parameters
        ----------
        axis : int or None
            Axis to be sorted.  If ``None``, the flattened array is sorted.
            By default, sort over the last axis.
        'b'Mean along a given axis.

        This is similar to :meth:`~numpy.ndarray.mean`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2`` is
        used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.mean``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.

        Similarly, the ``dtype`` argument is also present for compatibility
        only; it has no meaning for `Time`.

        Parameters
        ----------
        axis : None or int or tuple of ints, optional
            Axis or axes along which the means are computed. The default is to
            compute the mean of the flattened array.
        dtype : None
            Only present for compatibility with :meth:`~numpy.ndarray.mean`,
            must be `None`.
        out : None
            Only present for compatibility with :meth:`~numpy.ndarray.mean`,
            must be `None`.
        keepdims : bool, optional
            If this is set to True, the axes which are reduced are left
            in the result as dimensions with size one. With this option,
            the result will broadcast correctly against the input array.
        where : array_like of bool, optional
            Elements to include in the mean. See `~numpy.ufunc.reduce` for
            details.

        Returns
        -------
        m : Time
            A new Time instance containing the mean values
        'u'Mean along a given axis.

        This is similar to :meth:`~numpy.ndarray.mean`, but adapted to ensure
        that the full precision given by the two doubles ``jd1`` and ``jd2`` is
        used, and that corresponding attributes are copied.

        Note that the ``out`` argument is present only for compatibility with
        ``np.mean``; since `Time` instances are immutable, it is not possible
        to have an actual ``out`` to store the result in.

        Similarly, the ``dtype`` argument is also present for compatibility
        only; it has no meaning for `Time`.

        Parameters
        ----------
        axis : None or int or tuple of ints, optional
            Axis or axes along which the means are computed. The default is to
            compute the mean of the flattened array.
        dtype : None
            Only present for compatibility with :meth:`~numpy.ndarray.mean`,
            must be `None`.
        out : None
            Only present for compatibility with :meth:`~numpy.ndarray.mean`,
            must be `None`.
        keepdims : bool, optional
            If this is set to True, the axes which are reduced are left
            in the result as dimensions with size one. With this option,
            the result will broadcast correctly against the input array.
        where : array_like of bool, optional
            Elements to include in the mean. See `~numpy.ufunc.reduce` for
            details.

        Returns
        -------
        m : Time
            A new Time instance containing the mean values
        'b'Cannot set ``dtype`` on `Time` instances'u'Cannot set ``dtype`` on `Time` instances'b'Mean over zero elements is not supported as it would give an undefined time;see issue https://github.com/astropy/astropy/issues/6509'u'Mean over zero elements is not supported as it would give an undefined time;see issue https://github.com/astropy/astropy/issues/6509'b'Cache of all instances that share underlying data.

        Helps to ensure all cached data can be deleted if the
        underlying data is changed.
        'u'Cache of all instances that share underlying data.

        Helps to ensure all cached data can be deleted if the
        underlying data is changed.
        'b'
        Return the cache associated with this instance.
        'u'
        Return the cache associated with this instance.
        'b'
        Get dynamic attributes to output format or do timescale conversion.
        'u'
        Get dynamic attributes to output format or do timescale conversion.
        'b'Cannot convert TimeDelta with undefined scale to any defined scale.'u'Cannot convert TimeDelta with undefined scale to any defined scale.'b'Cannot convert 'u'Cannot convert 'b' with scale ''u' with scale ''b'' to scale ''u'' to scale ''b'
        Ensure that `val` is matched to length of self.  If val has length 1
        then broadcast, otherwise cast to double and make sure shape matches.
        'u'
        Ensure that `val` is matched to length of self.  If val has length 1
        then broadcast, otherwise cast to double and make sure shape matches.
        'b'Attribute shape must match or be broadcastable to that of Time object. Typically, give either a single value or one for each time.'u'Attribute shape must match or be broadcastable to that of Time object. Typically, give either a single value or one for each time.'b'If other is of same class as self, compare difference in self.scale.
        Otherwise, return NotImplemented.
        'u'If other is of same class as self, compare difference in self.scale.
        Otherwise, return NotImplemented.
        'b'Cannot compare 'u'Cannot compare 'b' instances with scales ''u' instances with scales ''b'' and ''u'' and ''b'
        If other is an incompatible object for comparison, return `False`.
        Otherwise, return `True` if the time difference between self and
        other is zero.
        'u'
        If other is an incompatible object for comparison, return `False`.
        Otherwise, return `True` if the time difference between self and
        other is zero.
        'b'
        If other is an incompatible object for comparison, return `True`.
        Otherwise, return `False` if the time difference between self and
        other is zero.
        'u'
        If other is an incompatible object for comparison, return `True`.
        Otherwise, return `False` if the time difference between self and
        other is zero.
        'b'
    Represent and manipulate times and dates for astronomy.

    A `Time` object is initialized with one or more times in the ``val``
    argument.  The input times in ``val`` must conform to the specified
    ``format`` and must correspond to the specified time ``scale``.  The
    optional ``val2`` time input should be supplied only for numeric input
    formats (e.g. JD) where very high precision (better than 64-bit precision)
    is required.

    The allowed values for ``format`` can be listed with::

      >>> list(Time.FORMATS)
      ['jd', 'mjd', 'decimalyear', 'unix', 'unix_tai', 'cxcsec', 'gps', 'plot_date',
       'stardate', 'datetime', 'ymdhms', 'iso', 'isot', 'yday', 'datetime64',
       'fits', 'byear', 'jyear', 'byear_str', 'jyear_str']

    See also: http://docs.astropy.org/en/stable/time/

    Parameters
    ----------
    val : sequence, ndarray, number, str, bytes, or `~astropy.time.Time` object
        Value(s) to initialize the time or times.  Bytes are decoded as ascii.
    val2 : sequence, ndarray, or number; optional
        Value(s) to initialize the time or times.  Only used for numerical
        input, to help preserve precision.
    format : str, optional
        Format of input value(s), specifying how to interpret them (e.g., ISO, JD, or
        Unix time). By default, the same format will be used for output representation.
    scale : str, optional
        Time scale of input value(s), must be one of the following:
        ('tai', 'tcb', 'tcg', 'tdb', 'tt', 'ut1', 'utc')
    precision : int, optional
        Digits of precision in string representation of time
    in_subfmt : str, optional
        Unix glob to select subformats for parsing input times
    out_subfmt : str, optional
        Unix glob to select subformat for outputting times
    location : `~astropy.coordinates.EarthLocation` or tuple, optional
        If given as an tuple, it should be able to initialize an
        an EarthLocation instance, i.e., either contain 3 items with units of
        length for geocentric coordinates, or contain a longitude, latitude,
        and an optional height for geodetic coordinates.
        Can be a single location, or one for each input time.
        If not given, assumed to be the center of the Earth for time scale
        transformations to and from the solar-system barycenter.
    copy : bool, optional
        Make a copy of the input values
    'u'
    Represent and manipulate times and dates for astronomy.

    A `Time` object is initialized with one or more times in the ``val``
    argument.  The input times in ``val`` must conform to the specified
    ``format`` and must correspond to the specified time ``scale``.  The
    optional ``val2`` time input should be supplied only for numeric input
    formats (e.g. JD) where very high precision (better than 64-bit precision)
    is required.

    The allowed values for ``format`` can be listed with::

      >>> list(Time.FORMATS)
      ['jd', 'mjd', 'decimalyear', 'unix', 'unix_tai', 'cxcsec', 'gps', 'plot_date',
       'stardate', 'datetime', 'ymdhms', 'iso', 'isot', 'yday', 'datetime64',
       'fits', 'byear', 'jyear', 'byear_str', 'jyear_str']

    See also: http://docs.astropy.org/en/stable/time/

    Parameters
    ----------
    val : sequence, ndarray, number, str, bytes, or `~astropy.time.Time` object
        Value(s) to initialize the time or times.  Bytes are decoded as ascii.
    val2 : sequence, ndarray, or number; optional
        Value(s) to initialize the time or times.  Only used for numerical
        input, to help preserve precision.
    format : str, optional
        Format of input value(s), specifying how to interpret them (e.g., ISO, JD, or
        Unix time). By default, the same format will be used for output representation.
    scale : str, optional
        Time scale of input value(s), must be one of the following:
        ('tai', 'tcb', 'tcg', 'tdb', 'tt', 'ut1', 'utc')
    precision : int, optional
        Digits of precision in string representation of time
    in_subfmt : str, optional
        Unix glob to select subformats for parsing input times
    out_subfmt : str, optional
        Unix glob to select subformat for outputting times
    location : `~astropy.coordinates.EarthLocation` or tuple, optional
        If given as an tuple, it should be able to initialize an
        an EarthLocation instance, i.e., either contain 3 items with units of
        length for geocentric coordinates, or contain a longitude, latitude,
        and an optional height for geodetic coordinates.
        Can be a single location, or one for each input time.
        If not given, assumed to be the center of the Earth for time scale
        transformations to and from the solar-system barycenter.
    copy : bool, optional
        Make a copy of the input values
    'b'List of time scales'u'List of time scales'b'Dict of time formats'u'Dict of time formats'b'The location with shape 'u'The location with shape 'b' cannot be broadcast against time with shape 'u' cannot be broadcast against time with shape 'b'. Typically, either give a single location or one for each time.'u'. Typically, either give a single location or one for each time.'b'Coerce setitem value into an equivalent Time object.'u'Coerce setitem value into an equivalent Time object.'b'cannot set to Time with different location: expected location='u'cannot set to Time with different location: expected location='b' and got location='u' and got location='b'cannot convert value to a compatible Time object: 'u'cannot convert value to a compatible Time object: 'b'
        Creates a new object corresponding to the instant in time this
        method is called.

        .. note::
            "Now" is determined using the `~datetime.datetime.now`
            function, so its accuracy and precision is determined by that
            function.  Generally that means it is set by the accuracy of
            your system clock. The timezone is set to UTC.

        Returns
        -------
        nowtime : :class:`~astropy.time.Time`
            A new `Time` object (or a subclass of `Time` if this is called from
            such a subclass) at the current time.
        'u'
        Creates a new object corresponding to the instant in time this
        method is called.

        .. note::
            "Now" is determined using the `~datetime.datetime.now`
            function, so its accuracy and precision is determined by that
            function.  Generally that means it is set by the accuracy of
            your system clock. The timezone is set to UTC.

        Returns
        -------
        nowtime : :class:`~astropy.time.Time`
            A new `Time` object (or a subclass of `Time` if this is called from
            such a subclass) at the current time.
        'b'
        Parse a string to a Time according to a format specification.
        See `time.strptime` documentation for format specification.

        >>> Time.strptime('2012-Jun-30 23:59:60', '%Y-%b-%d %H:%M:%S')
        <Time object: scale='utc' format='isot' value=2012-06-30T23:59:60.000>

        Parameters
        ----------
        time_string : str, sequence, or ndarray
            Objects containing time data of type string
        format_string : str
            String specifying format of time_string.
        kwargs : dict
            Any keyword arguments for ``Time``.  If the ``format`` keyword
            argument is present, this will be used as the Time format.

        Returns
        -------
        time_obj : `~astropy.time.Time`
            A new `~astropy.time.Time` object corresponding to the input
            ``time_string``.

        'u'
        Parse a string to a Time according to a format specification.
        See `time.strptime` documentation for format specification.

        >>> Time.strptime('2012-Jun-30 23:59:60', '%Y-%b-%d %H:%M:%S')
        <Time object: scale='utc' format='isot' value=2012-06-30T23:59:60.000>

        Parameters
        ----------
        time_string : str, sequence, or ndarray
            Objects containing time data of type string
        format_string : str
            String specifying format of time_string.
        kwargs : dict
            Any keyword arguments for ``Time``.  If the ``format`` keyword
            argument is present, this will be used as the Time format.

        Returns
        -------
        time_obj : `~astropy.time.Time`
            A new `~astropy.time.Time` object corresponding to the input
            ``time_string``.

        'b'Expected type is string, a bytes-like object or a sequence of these. Got dtype ''u'Expected type is string, a bytes-like object or a sequence of these. Got dtype ''b'U30'u'U30'b'{:04}-{:02}-{:02}T{:02}:{:02}:{:02}.{:06}'u'{:04}-{:02}-{:02}T{:02}:{:02}:{:02}.{:06}'b'isot'u'isot'b'
        Convert Time to a string or a numpy.array of strings according to a
        format specification.
        See `time.strftime` documentation for format specification.

        Parameters
        ----------
        format_spec : str
            Format definition of return string.

        Returns
        -------
        formatted : str or numpy.array
            String or numpy.array of strings formatted according to the given
            format string.

        'u'
        Convert Time to a string or a numpy.array of strings according to a
        format specification.
        See `time.strftime` documentation for format specification.

        Parameters
        ----------
        format_spec : str
            Format definition of return string.

        Returns
        -------
        formatted : str or numpy.array
            String or numpy.array of strings formatted according to the given
            format string.

        'b'iso'u'iso'b'mon'u'mon'b'{frac:0{precision}}'u'{frac:0{precision}}'b'fracsec'u'fracsec'b'barycentric'u'barycentric'b'Light travel time correction to the barycentre or heliocentre.

        The frame transformations used to calculate the location of the solar
        system barycentre and the heliocentre rely on the erfa routine epv00,
        which is consistent with the JPL DE405 ephemeris to an accuracy of
        11.2 km, corresponding to a light travel time of 4 microseconds.

        The routine assumes the source(s) are at large distance, i.e., neglects
        finite-distance effects.

        Parameters
        ----------
        skycoord : `~astropy.coordinates.SkyCoord`
            The sky location to calculate the correction for.
        kind : str, optional
            ``'barycentric'`` (default) or ``'heliocentric'``
        location : `~astropy.coordinates.EarthLocation`, optional
            The location of the observatory to calculate the correction for.
            If no location is given, the ``location`` attribute of the Time
            object is used
        ephemeris : str, optional
            Solar system ephemeris to use (e.g., 'builtin', 'jpl'). By default,
            use the one set with ``astropy.coordinates.solar_system_ephemeris.set``.
            For more information, see `~astropy.coordinates.solar_system_ephemeris`.

        Returns
        -------
        time_offset : `~astropy.time.TimeDelta`
            The time offset between the barycentre or Heliocentre and Earth,
            in TDB seconds.  Should be added to the original time to get the
            time in the Solar system barycentre or the Heliocentre.
            Also, the time conversion to BJD will then include the relativistic correction as well.
        'u'Light travel time correction to the barycentre or heliocentre.

        The frame transformations used to calculate the location of the solar
        system barycentre and the heliocentre rely on the erfa routine epv00,
        which is consistent with the JPL DE405 ephemeris to an accuracy of
        11.2 km, corresponding to a light travel time of 4 microseconds.

        The routine assumes the source(s) are at large distance, i.e., neglects
        finite-distance effects.

        Parameters
        ----------
        skycoord : `~astropy.coordinates.SkyCoord`
            The sky location to calculate the correction for.
        kind : str, optional
            ``'barycentric'`` (default) or ``'heliocentric'``
        location : `~astropy.coordinates.EarthLocation`, optional
            The location of the observatory to calculate the correction for.
            If no location is given, the ``location`` attribute of the Time
            object is used
        ephemeris : str, optional
            Solar system ephemeris to use (e.g., 'builtin', 'jpl'). By default,
            use the one set with ``astropy.coordinates.solar_system_ephemeris.set``.
            For more information, see `~astropy.coordinates.solar_system_ephemeris`.

        Returns
        -------
        time_offset : `~astropy.time.TimeDelta`
            The time offset between the barycentre or Heliocentre and Earth,
            in TDB seconds.  Should be added to the original time to get the
            time in the Solar system barycentre or the Heliocentre.
            Also, the time conversion to BJD will then include the relativistic correction as well.
        'b'heliocentric'u'heliocentric'b''kind' parameter must be one of 'heliocentric' or 'barycentric''u''kind' parameter must be one of 'heliocentric' or 'barycentric''b'An EarthLocation needs to be set or passed in to calculate bary- or heliocentric corrections'u'An EarthLocation needs to be set or passed in to calculate bary- or heliocentric corrections'b'Given skycoord is not transformable to the ICRS'u'Given skycoord is not transformable to the ICRS'b'Supplied location does not have a valid `get_itrs` method'u'Supplied location does not have a valid `get_itrs` method'b'Calculate local Earth rotation angle.

        Parameters
        ----------
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance. If the special
            string 'tio', the result will be relative to the Terrestrial
            Intermediate Origin (TIO) (i.e., the output of `~erfa.era00`).

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local Earth rotation angle with units of hourangle.

        See Also
        --------
        astropy.time.Time.sidereal_time

        References
        ----------
        IAU 2006 NFA Glossary
        (currently located at: https://syrte.obspm.fr/iauWGnfa/NFA_Glossary.html)

        Notes
        -----
        The difference between apparent sidereal time and Earth rotation angle
        is the equation of the origins, which is the angle between the Celestial
        Intermediate Origin (CIO) and the equinox. Applying apparent sidereal
        time to the hour angle yields the true apparent Right Ascension with
        respect to the equinox, while applying the Earth rotation angle yields
        the intermediate (CIRS) Right Ascension with respect to the CIO.

        The result includes the TIO locator (s'), which positions the Terrestrial
        Intermediate Origin on the equator of the Celestial Intermediate Pole (CIP)
        and is rigorously corrected for polar motion.
        (except when ``longitude='tio'``).

        'u'Calculate local Earth rotation angle.

        Parameters
        ----------
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance. If the special
            string 'tio', the result will be relative to the Terrestrial
            Intermediate Origin (TIO) (i.e., the output of `~erfa.era00`).

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local Earth rotation angle with units of hourangle.

        See Also
        --------
        astropy.time.Time.sidereal_time

        References
        ----------
        IAU 2006 NFA Glossary
        (currently located at: https://syrte.obspm.fr/iauWGnfa/NFA_Glossary.html)

        Notes
        -----
        The difference between apparent sidereal time and Earth rotation angle
        is the equation of the origins, which is the angle between the Celestial
        Intermediate Origin (CIO) and the equinox. Applying apparent sidereal
        time to the hour angle yields the true apparent Right Ascension with
        respect to the equinox, while applying the Earth rotation angle yields
        the intermediate (CIRS) Right Ascension with respect to the CIO.

        The result includes the TIO locator (s'), which positions the Terrestrial
        Intermediate Origin on the equator of the Celestial Intermediate Pole (CIP)
        and is rigorously corrected for polar motion.
        (except when ``longitude='tio'``).

        'b'tio'u'tio'b'Calculate sidereal time.

        Parameters
        ----------
        kind : str
            ``'mean'`` or ``'apparent'``, i.e., accounting for precession
            only, or also for nutation.
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance. If the special
            string  'greenwich' or 'tio', the result will be relative to longitude
            0 for models before 2000, and relative to the Terrestrial Intermediate
            Origin (TIO) for later ones (i.e., the output of the relevant ERFA
            function that calculates greenwich sidereal time).
        model : str or None; optional
            Precession (and nutation) model to use.  The available ones are:
            - {0}: {1}
            - {2}: {3}
            If `None` (default), the last (most recent) one from the appropriate
            list above is used.

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local sidereal time, with units of hourangle.

        See Also
        --------
        astropy.time.Time.earth_rotation_angle

        References
        ----------
        IAU 2006 NFA Glossary
        (currently located at: https://syrte.obspm.fr/iauWGnfa/NFA_Glossary.html)

        Notes
        -----
        The difference between apparent sidereal time and Earth rotation angle
        is the equation of the origins, which is the angle between the Celestial
        Intermediate Origin (CIO) and the equinox. Applying apparent sidereal
        time to the hour angle yields the true apparent Right Ascension with
        respect to the equinox, while applying the Earth rotation angle yields
        the intermediate (CIRS) Right Ascension with respect to the CIO.

        For the IAU precession models from 2000 onwards, the result includes the
        TIO locator (s'), which positions the Terrestrial Intermediate Origin on
        the equator of the Celestial Intermediate Pole (CIP) and is rigorously
        corrected for polar motion (except when ``longitude='tio'`` or ``'greenwich'``).

        'u'Calculate sidereal time.

        Parameters
        ----------
        kind : str
            ``'mean'`` or ``'apparent'``, i.e., accounting for precession
            only, or also for nutation.
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance. If the special
            string  'greenwich' or 'tio', the result will be relative to longitude
            0 for models before 2000, and relative to the Terrestrial Intermediate
            Origin (TIO) for later ones (i.e., the output of the relevant ERFA
            function that calculates greenwich sidereal time).
        model : str or None; optional
            Precession (and nutation) model to use.  The available ones are:
            - {0}: {1}
            - {2}: {3}
            If `None` (default), the last (most recent) one from the appropriate
            list above is used.

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local sidereal time, with units of hourangle.

        See Also
        --------
        astropy.time.Time.earth_rotation_angle

        References
        ----------
        IAU 2006 NFA Glossary
        (currently located at: https://syrte.obspm.fr/iauWGnfa/NFA_Glossary.html)

        Notes
        -----
        The difference between apparent sidereal time and Earth rotation angle
        is the equation of the origins, which is the angle between the Celestial
        Intermediate Origin (CIO) and the equinox. Applying apparent sidereal
        time to the hour angle yields the true apparent Right Ascension with
        respect to the equinox, while applying the Earth rotation angle yields
        the intermediate (CIRS) Right Ascension with respect to the CIO.

        For the IAU precession models from 2000 onwards, the result includes the
        TIO locator (s'), which positions the Terrestrial Intermediate Origin on
        the equator of the Celestial Intermediate Pole (CIP) and is rigorously
        corrected for polar motion (except when ``longitude='tio'`` or ``'greenwich'``).

        'b'The kind of sidereal time has to be 'u'The kind of sidereal time has to be 'b' or 'u' or 'b'Model 'u'Model 'b' not implemented for 'u' not implemented for 'b' sidereal time; available models are 'u' sidereal time; available models are 'b'greenwich'u'greenwich'b'Calculate a local sidereal time or Earth rotation angle.

        Parameters
        ----------
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance.
        function : callable
            The ERFA function to use.
        scales : tuple of str
            The time scales that the function requires on input.
        include_tio : bool, optional
            Whether to includes the TIO locator corrected for polar motion.
            Should be `False` for pre-2000 IAU models.  Default: `True`.

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local sidereal time or Earth rotation angle, with units of hourangle.

        'u'Calculate a local sidereal time or Earth rotation angle.

        Parameters
        ----------
        longitude : `~astropy.units.Quantity`, `~astropy.coordinates.EarthLocation`, str, or None; optional
            The longitude on the Earth at which to compute the Earth rotation
            angle (taken from a location as needed).  If `None` (default), taken
            from the ``location`` attribute of the Time instance.
        function : callable
            The ERFA function to use.
        scales : tuple of str
            The time scales that the function requires on input.
        include_tio : bool, optional
            Whether to includes the TIO locator corrected for polar motion.
            Should be `False` for pre-2000 IAU models.  Default: `True`.

        Returns
        -------
        `~astropy.coordinates.Longitude`
            Local sidereal time or Earth rotation angle, with units of hourangle.

        'b'No longitude is given but the location for the Time object is not set.'u'No longitude is given but the location for the Time object is not set.'b'Find UT1 - UTC differences by interpolating in IERS Table.

        Parameters
        ----------
        iers_table : `~astropy.utils.iers.IERS`, optional
            Table containing UT1-UTC differences from IERS Bulletins A
            and/or B.  Default: `~astropy.utils.iers.earth_orientation_table`
            (which in turn defaults to the combined version provided by
            `~astropy.utils.iers.IERS_Auto`).
        return_status : bool
            Whether to return status values.  If `False` (default), iers
            raises `IndexError` if any time is out of the range
            covered by the IERS table.

        Returns
        -------
        ut1_utc : float or float array
            UT1-UTC, interpolated in IERS Table
        status : int or int array
            Status values (if ``return_status=`True```)::
            ``astropy.utils.iers.FROM_IERS_B``
            ``astropy.utils.iers.FROM_IERS_A``
            ``astropy.utils.iers.FROM_IERS_A_PREDICTION``
            ``astropy.utils.iers.TIME_BEFORE_IERS_RANGE``
            ``astropy.utils.iers.TIME_BEYOND_IERS_RANGE``

        Notes
        -----
        In normal usage, UT1-UTC differences are calculated automatically
        on the first instance ut1 is needed.

        Examples
        --------
        To check in code whether any times are before the IERS table range::

            >>> from astropy.utils.iers import TIME_BEFORE_IERS_RANGE
            >>> t = Time(['1961-01-01', '2000-01-01'], scale='utc')
            >>> delta, status = t.get_delta_ut1_utc(return_status=True)  # doctest: +REMOTE_DATA
            >>> status == TIME_BEFORE_IERS_RANGE  # doctest: +REMOTE_DATA
            array([ True, False]...)
        'u'Find UT1 - UTC differences by interpolating in IERS Table.

        Parameters
        ----------
        iers_table : `~astropy.utils.iers.IERS`, optional
            Table containing UT1-UTC differences from IERS Bulletins A
            and/or B.  Default: `~astropy.utils.iers.earth_orientation_table`
            (which in turn defaults to the combined version provided by
            `~astropy.utils.iers.IERS_Auto`).
        return_status : bool
            Whether to return status values.  If `False` (default), iers
            raises `IndexError` if any time is out of the range
            covered by the IERS table.

        Returns
        -------
        ut1_utc : float or float array
            UT1-UTC, interpolated in IERS Table
        status : int or int array
            Status values (if ``return_status=`True```)::
            ``astropy.utils.iers.FROM_IERS_B``
            ``astropy.utils.iers.FROM_IERS_A``
            ``astropy.utils.iers.FROM_IERS_A_PREDICTION``
            ``astropy.utils.iers.TIME_BEFORE_IERS_RANGE``
            ``astropy.utils.iers.TIME_BEYOND_IERS_RANGE``

        Notes
        -----
        In normal usage, UT1-UTC differences are calculated automatically
        on the first instance ut1 is needed.

        Examples
        --------
        To check in code whether any times are before the IERS table range::

            >>> from astropy.utils.iers import TIME_BEFORE_IERS_RANGE
            >>> t = Time(['1961-01-01', '2000-01-01'], scale='utc')
            >>> delta, status = t.get_delta_ut1_utc(return_status=True)  # doctest: +REMOTE_DATA
            >>> status == TIME_BEFORE_IERS_RANGE  # doctest: +REMOTE_DATA
            array([ True, False]...)
        'b'
        Get ERFA DUT arg = UT1 - UTC.  This getter takes optional jd1 and
        jd2 args because it gets called that way when converting time scales.
        If delta_ut1_utc is not yet set, this will interpolate them from the
        the IERS table.
        'u'
        Get ERFA DUT arg = UT1 - UTC.  This getter takes optional jd1 and
        jd2 args because it gets called that way when converting time scales.
        If delta_ut1_utc is not yet set, this will interpolate them from the
        the IERS table.
        'b'UT1 - UTC time scale offset'u'UT1 - UTC time scale offset'b'Accessing the delta_tdb_tt attribute is only possible for TT or TDB time scales'u'Accessing the delta_tdb_tt attribute is only possible for TT or TDB time scales'b'TDB - TT time scale offset'u'TDB - TT time scale offset'b'Cannot subtract Time and TimeDelta instances with scales ''u'Cannot subtract Time and TimeDelta instances with scales ''b'Cannot subtract Time instances with scales ''u'Cannot subtract Time instances with scales ''b'Cannot add Time and TimeDelta instances with scales ''u'Cannot add Time and TimeDelta instances with scales ''b'`location` must be constant over the reduction axes.'u'`location` must be constant over the reduction axes.'b'
        Wrap numpy functions.

        Parameters
        ----------
        function : callable
            Numpy function to wrap
        types : iterable of classes
            Classes that provide an ``__array_function__`` override. Can
            in principle be used to interact with other classes. Below,
            mostly passed on to `~numpy.ndarray`, which can only interact
            with subclasses.
        args : tuple
            Positional arguments provided in the function call.
        kwargs : dict
            Keyword arguments provided in the function call.
        'u'
        Wrap numpy functions.

        Parameters
        ----------
        function : callable
            Numpy function to wrap
        types : iterable of classes
            Classes that provide an ``__array_function__`` override. Can
            in principle be used to interact with other classes. Below,
            mostly passed on to `~numpy.ndarray`, which can only interact
            with subclasses.
        args : tuple
            Positional arguments provided in the function call.
        kwargs : dict
            Keyword arguments provided in the function call.
        'b'Warning for missing unit or format in TimeDelta.'u'Warning for missing unit or format in TimeDelta.'b'
    Represent the time difference between two times.

    A TimeDelta object is initialized with one or more times in the ``val``
    argument.  The input times in ``val`` must conform to the specified
    ``format``.  The optional ``val2`` time input should be supplied only for
    numeric input formats (e.g. JD) where very high precision (better than
    64-bit precision) is required.

    The allowed values for ``format`` can be listed with::

      >>> list(TimeDelta.FORMATS)
      ['sec', 'jd', 'datetime', 'quantity_str']

    Note that for time differences, the scale can be among three groups:
    geocentric ('tai', 'tt', 'tcg'), barycentric ('tcb', 'tdb'), and rotational
    ('ut1'). Within each of these, the scales for time differences are the
    same. Conversion between geocentric and barycentric is possible, as there
    is only a scale factor change, but one cannot convert to or from 'ut1', as
    this requires knowledge of the actual times, not just their difference. For
    a similar reason, 'utc' is not a valid scale for a time difference: a UTC
    day is not always 86400 seconds.

    For more information see:

    - https://docs.astropy.org/en/stable/time/
    - https://docs.astropy.org/en/stable/time/index.html#time-deltas

    Parameters
    ----------
    val : sequence, ndarray, number, `~astropy.units.Quantity` or `~astropy.time.TimeDelta` object
        Value(s) to initialize the time difference(s). Any quantities will
        be converted appropriately (with care taken to avoid rounding
        errors for regular time units).
    val2 : sequence, ndarray, number, or `~astropy.units.Quantity`; optional
        Additional values, as needed to preserve precision.
    format : str, optional
        Format of input value(s). For numerical inputs without units,
        "jd" is assumed and values are interpreted as days.
        A deprecation warning is raised in this case. To avoid the warning,
        either specify the format or add units to the input values.
    scale : str, optional
        Time scale of input value(s), must be one of the following values:
        ('tdb', 'tt', 'ut1', 'tcg', 'tcb', 'tai'). If not given (or
        ``None``), the scale is arbitrary; when added or subtracted from a
        ``Time`` instance, it will be used without conversion.
    precision : int, optional
        Digits of precision in string representation of time
    in_subfmt : str, optional
        Unix glob to select subformats for parsing input times
    out_subfmt : str, optional
        Unix glob to select subformat for outputting times
    copy : bool, optional
        Make a copy of the input values
    'u'
    Represent the time difference between two times.

    A TimeDelta object is initialized with one or more times in the ``val``
    argument.  The input times in ``val`` must conform to the specified
    ``format``.  The optional ``val2`` time input should be supplied only for
    numeric input formats (e.g. JD) where very high precision (better than
    64-bit precision) is required.

    The allowed values for ``format`` can be listed with::

      >>> list(TimeDelta.FORMATS)
      ['sec', 'jd', 'datetime', 'quantity_str']

    Note that for time differences, the scale can be among three groups:
    geocentric ('tai', 'tt', 'tcg'), barycentric ('tcb', 'tdb'), and rotational
    ('ut1'). Within each of these, the scales for time differences are the
    same. Conversion between geocentric and barycentric is possible, as there
    is only a scale factor change, but one cannot convert to or from 'ut1', as
    this requires knowledge of the actual times, not just their difference. For
    a similar reason, 'utc' is not a valid scale for a time difference: a UTC
    day is not always 86400 seconds.

    For more information see:

    - https://docs.astropy.org/en/stable/time/
    - https://docs.astropy.org/en/stable/time/index.html#time-deltas

    Parameters
    ----------
    val : sequence, ndarray, number, `~astropy.units.Quantity` or `~astropy.time.TimeDelta` object
        Value(s) to initialize the time difference(s). Any quantities will
        be converted appropriately (with care taken to avoid rounding
        errors for regular time units).
    val2 : sequence, ndarray, number, or `~astropy.units.Quantity`; optional
        Additional values, as needed to preserve precision.
    format : str, optional
        Format of input value(s). For numerical inputs without units,
        "jd" is assumed and values are interpreted as days.
        A deprecation warning is raised in this case. To avoid the warning,
        either specify the format or add units to the input values.
    scale : str, optional
        Time scale of input value(s), must be one of the following values:
        ('tdb', 'tt', 'ut1', 'tcg', 'tcb', 'tai'). If not given (or
        ``None``), the scale is arbitrary; when added or subtracted from a
        ``Time`` instance, it will be used without conversion.
    precision : int, optional
        Digits of precision in string representation of time
    in_subfmt : str, optional
        Unix glob to select subformats for parsing input times
    out_subfmt : str, optional
        Unix glob to select subformat for outputting times
    copy : bool, optional
        Make a copy of the input values
    'b'List of time delta scales.'u'List of time delta scales.'b'Dict of time delta formats.'u'Dict of time delta formats.'b'Numerical value without unit or explicit format passed to TimeDelta, assuming days'u'Numerical value without unit or explicit format passed to TimeDelta, assuming days'b'
        Convert to ``datetime.timedelta`` object.
        'u'
        Convert to ``datetime.timedelta`` object.
        'b'Scale {scale!r} is not in the allowed scales {sorted(self.SCALES)}'u'Scale {scale!r} is not in the allowed scales {sorted(self.SCALES)}'b'Perform common elements of addition / subtraction for two delta times.'u'Perform common elements of addition / subtraction for two delta times.'b'Cannot add TimeDelta instances with scales ''u'Cannot add TimeDelta instances with scales ''b'Negation of a `TimeDelta` object.'u'Negation of a `TimeDelta` object.'b'Absolute value of a `TimeDelta` object.'u'Absolute value of a `TimeDelta` object.'b'Multiplication of `TimeDelta` objects by numbers/arrays.'u'Multiplication of `TimeDelta` objects by numbers/arrays.'b'Multiplication of numbers/arrays with `TimeDelta` objects.'u'Multiplication of numbers/arrays with `TimeDelta` objects.'b'Division of `TimeDelta` objects by numbers/arrays.'u'Division of `TimeDelta` objects by numbers/arrays.'b'Division by `TimeDelta` objects of numbers/arrays.'u'Division by `TimeDelta` objects of numbers/arrays.'b'
        Convert to a quantity in the specified unit.

        Parameters
        ----------
        unit : unit-like
            The unit to convert to.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not directly
            convertible (see :ref:`astropy:unit_equivalencies`). If `None`, no
            equivalencies will be applied at all, not even any set globallyq
            or within a context.

        Returns
        -------
        quantity : `~astropy.units.Quantity`
            The quantity in the units specified.

        See Also
        --------
        to_value : get the numerical value in a given unit.
        'u'
        Convert to a quantity in the specified unit.

        Parameters
        ----------
        unit : unit-like
            The unit to convert to.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not directly
            convertible (see :ref:`astropy:unit_equivalencies`). If `None`, no
            equivalencies will be applied at all, not even any set globallyq
            or within a context.

        Returns
        -------
        quantity : `~astropy.units.Quantity`
            The quantity in the units specified.

        See Also
        --------
        to_value : get the numerical value in a given unit.
        'b'Get time delta values expressed in specified output format or unit.

        This method is flexible and handles both conversion to a specified
        ``TimeDelta`` format / sub-format AND conversion to a specified unit.
        If positional argument(s) are provided then the first one is checked
        to see if it is a valid ``TimeDelta`` format, and next it is checked
        to see if it is a valid unit or unit string.

        To convert to a ``TimeDelta`` format and optional sub-format the options
        are::

          tm = TimeDelta(1.0 * u.s)
          tm.to_value('jd')  # equivalent of tm.jd
          tm.to_value('jd', 'decimal')  # convert to 'jd' as a Decimal object
          tm.to_value('jd', subfmt='decimal')
          tm.to_value(format='jd', subfmt='decimal')

        To convert to a unit with optional equivalencies, the options are::

          tm.to_value('hr')  # convert to u.hr (hours)
          tm.to_value('hr', equivalencies=[])
          tm.to_value(unit='hr', equivalencies=[])

        The built-in `~astropy.time.TimeDelta` options for ``format`` are shown below::

          >>> list(TimeDelta.FORMATS)
          ['sec', 'jd', 'datetime', 'quantity_str']

        For the two numerical formats 'jd' and 'sec', the available ``subfmt``
        options are: {'float', 'long', 'decimal', 'str', 'bytes'}. Here, 'long'
        uses ``numpy.longdouble`` for somewhat enhanced precision (with the
        enhancement depending on platform), and 'decimal' instances of
        :class:`decimal.Decimal` for full precision.  For the 'str' and 'bytes'
        sub-formats, the number of digits is also chosen such that time values
        are represented accurately.  Default: as set by ``out_subfmt`` (which by
        default picks the first available for a given format, i.e., 'float').

        Parameters
        ----------
        format : str, optional
            The format in which one wants the `~astropy.time.TimeDelta` values.
            Default: the current format.
        subfmt : str, optional
            Possible sub-format in which the values should be given. Default: as
            set by ``out_subfmt`` (which by default picks the first available
            for a given format, i.e., 'float' or 'date_hms').
        unit : `~astropy.units.UnitBase` instance or str, optional
            The unit in which the value should be given.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not directly
            convertible (see :ref:`astropy:unit_equivalencies`). If `None`, no
            equivalencies will be applied at all, not even any set globally or
            within a context.

        Returns
        -------
        value : ndarray or scalar
            The value in the format or units specified.

        See Also
        --------
        to : Convert to a `~astropy.units.Quantity` instance in a given unit.
        value : The time value in the current format.

        'u'Get time delta values expressed in specified output format or unit.

        This method is flexible and handles both conversion to a specified
        ``TimeDelta`` format / sub-format AND conversion to a specified unit.
        If positional argument(s) are provided then the first one is checked
        to see if it is a valid ``TimeDelta`` format, and next it is checked
        to see if it is a valid unit or unit string.

        To convert to a ``TimeDelta`` format and optional sub-format the options
        are::

          tm = TimeDelta(1.0 * u.s)
          tm.to_value('jd')  # equivalent of tm.jd
          tm.to_value('jd', 'decimal')  # convert to 'jd' as a Decimal object
          tm.to_value('jd', subfmt='decimal')
          tm.to_value(format='jd', subfmt='decimal')

        To convert to a unit with optional equivalencies, the options are::

          tm.to_value('hr')  # convert to u.hr (hours)
          tm.to_value('hr', equivalencies=[])
          tm.to_value(unit='hr', equivalencies=[])

        The built-in `~astropy.time.TimeDelta` options for ``format`` are shown below::

          >>> list(TimeDelta.FORMATS)
          ['sec', 'jd', 'datetime', 'quantity_str']

        For the two numerical formats 'jd' and 'sec', the available ``subfmt``
        options are: {'float', 'long', 'decimal', 'str', 'bytes'}. Here, 'long'
        uses ``numpy.longdouble`` for somewhat enhanced precision (with the
        enhancement depending on platform), and 'decimal' instances of
        :class:`decimal.Decimal` for full precision.  For the 'str' and 'bytes'
        sub-formats, the number of digits is also chosen such that time values
        are represented accurately.  Default: as set by ``out_subfmt`` (which by
        default picks the first available for a given format, i.e., 'float').

        Parameters
        ----------
        format : str, optional
            The format in which one wants the `~astropy.time.TimeDelta` values.
            Default: the current format.
        subfmt : str, optional
            Possible sub-format in which the values should be given. Default: as
            set by ``out_subfmt`` (which by default picks the first available
            for a given format, i.e., 'float' or 'date_hms').
        unit : `~astropy.units.UnitBase` instance or str, optional
            The unit in which the value should be given.
        equivalencies : list of tuple
            A list of equivalence pairs to try if the units are not directly
            convertible (see :ref:`astropy:unit_equivalencies`). If `None`, no
            equivalencies will be applied at all, not even any set globally or
            within a context.

        Returns
        -------
        value : ndarray or scalar
            The value in the format or units specified.

        See Also
        --------
        to : Convert to a `~astropy.units.Quantity` instance in a given unit.
        value : The time value in the current format.

        'b'to_value() missing required format or unit argument'u'to_value() missing required format or unit argument'b'subfmt'u'subfmt'b'() got an unexpected keyword argument ''u'() got an unexpected keyword argument ''b'cannot specify 'subfmt' and positional argument that is not a valid format'u'cannot specify 'subfmt' and positional argument that is not a valid format'b'first argument is not one of the known formats ('u'first argument is not one of the known formats ('b') and failed to parse as a unit.'u') and failed to parse as a unit.'b'Coerce setitem value into an equivalent TimeDelta object.'u'Coerce setitem value into an equivalent TimeDelta object.'b'cannot convert value to a compatible TimeDelta object: 'u'cannot convert value to a compatible TimeDelta object: 'b'Returns a boolean or boolean array where two TimeDelta objects are
        element-wise equal within a time tolerance.

        This effectively evaluates the expression below::

          abs(self - other) <= atol + rtol * abs(other)

        Parameters
        ----------
        other : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Quantity or TimeDelta object for comparison.
        atol : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Absolute tolerance for equality with units of time (e.g. ``u.s`` or
            ``u.day``). Default is one bit in the 128-bit JD time representation,
            equivalent to about 20 picosecs.
        rtol : float
            Relative tolerance for equality
        'u'Returns a boolean or boolean array where two TimeDelta objects are
        element-wise equal within a time tolerance.

        This effectively evaluates the expression below::

          abs(self - other) <= atol + rtol * abs(other)

        Parameters
        ----------
        other : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Quantity or TimeDelta object for comparison.
        atol : `~astropy.units.Quantity` or `~astropy.time.TimeDelta`
            Absolute tolerance for equality with units of time (e.g. ``u.s`` or
            ``u.day``). Default is one bit in the 128-bit JD time representation,
            equivalent to about 20 picosecs.
        rtol : float
            Relative tolerance for equality
        'b''other' argument must support conversion to days: 'u''other' argument must support conversion to days: 'b'
    Take ``val`` and convert/reshape to an array.  If ``copy`` is `True`
    then copy input values.

    Returns
    -------
    val : ndarray
        Array version of ``val``.
    'u'
    Take ``val`` and convert/reshape to an array.  If ``copy`` is `True`
    then copy input values.

    Returns
    -------
    val : ndarray
        Array version of ``val``.
    'b'OSUMaV'u'OSUMaV'b' for 'u' for 'b'Unsupported operand type(s)'u'Unsupported operand type(s)'b': ''u': ''b'If the current ERFA leap second table is out of date, try to update it.

    Uses `astropy.utils.iers.LeapSeconds.auto_open` to try to find an
    up-to-date table.  See that routine for the definition of "out of date".

    In order to make it safe to call this any time, all exceptions are turned
    into warnings,

    Parameters
    ----------
    files : list of path-like, optional
        List of files/URLs to attempt to open.  By default, uses defined by
        `astropy.utils.iers.LeapSeconds.auto_open`, which includes the table
        used by ERFA itself, so if that is up to date, nothing will happen.

    Returns
    -------
    n_update : int
        Number of items updated.

    'u'If the current ERFA leap second table is out of date, try to update it.

    Uses `astropy.utils.iers.LeapSeconds.auto_open` to try to find an
    up-to-date table.  See that routine for the definition of "out of date".

    In order to make it safe to call this any time, all exceptions are turned
    into warnings,

    Parameters
    ----------
    files : list of path-like, optional
        List of files/URLs to attempt to open.  By default, uses defined by
        `astropy.utils.iers.LeapSeconds.auto_open`, which includes the table
        used by ERFA itself, so if that is up to date, nothing will happen.

    Returns
    -------
    n_update : int
        Number of items updated.

    'b'leap-second auto-update failed due to the following exception: 'u'leap-second auto-update failed due to the following exception: 'u'astropy.time.core'u'time.core'
This module contains the convolution and filter functionalities of astropy.

A few conceptual notes:
A filter kernel is mainly characterized by its response function. In the 1D
case we speak of "impulse response function", in the 2D case we call it "point
spread function". This response function is given for every kernel by an
astropy `FittableModel`, which is evaluated on a grid to obtain a filter array,
which can then be applied to binned data.

The model is centered on the array and should have an amplitude such that the array
integrates to one per default.

Currently only symmetric 2D kernels are supported.
KernelArithmeticErroradd_kernel_arrays_1Dadd_kernel_arrays_2Ddiscretize_modelkernel_arithmetics
    Convolution kernel base class.

    Parameters
    ----------
    array : ndarray
        Kernel array.
    _arraytruncation
        Absolute deviation of the sum of the kernel array values from
        one.
        is_bool
        Indicates if kernel is bool.

        If the kernel is bool the multiplication in the convolution could
        be omitted, to increase the performance.
        
        Kernel response model.
        
        Kernel dimension.
        
        Index of the kernel center.
        axes_sizeintegral
        Normalize the filter kernel.

        Parameters
        ----------
        mode : {'integral', 'peak'}
            One of the following modes:
                * 'integral' (default)
                    Kernel is normalized such that its integral = 1.
                * 'peak'
                    Kernel is normalized such that its peak = 1.
        peakinvalid mode, must be 'integral' or 'peak'The kernel cannot be normalized because it sums to zero._kernel_sum
        Shape of the kernel array.
        
        Indicates if the filter kernel is separable.

        A 2D filter is separable, when its filter array can be written as the
        outer product of two 1D arrays.

        If a filter kernel is separable, higher dimension convolutions will be
        performed by applying the 1D filter array consecutively on every dimension.
        This is significantly faster, than using a filter array with the same
        dimension.
        
        Filter kernel array.
        
        Add two filter kernels.
        
        Subtract two filter kernels.
        
        Multiply kernel with number or convolve two kernels.
        
        Array representation of the kernel.
        
    Base class for 1D filter kernels.

    Parameters
    ----------
    model : `~astropy.modeling.FittableModel`
        Model to be evaluated.
    x_size : int or None, optional
        Size of the kernel array. Default = 8*width+1.
        Only used if ``array`` is None.
    array : ndarray or None, optional
        Kernel array.
    width : number
        Width of the filter kernel.
    mode : str, optional
        One of the following discretization modes:
            * 'center' (default)
                Discretize model by taking the value
                at the center of the bin.
            * 'linear_interp'
                Discretize model by linearly interpolating
                between the values at the corners of the bin.
            * 'oversample'
                Discretize model by taking the average
                on an oversampled grid.
            * 'integrate'
                Discretize model by integrating the
                model over the bin.
    factor : number, optional
        Factor of oversampling. Default factor = 10.
    x_sizeArray argument not allowed for kernel models._default_sizex_size should be an integerMust specify either array or model.
    Base class for 2D filter kernels.

    Parameters
    ----------
    model : `~astropy.modeling.FittableModel`
        Model to be evaluated.
    x_size : int, optional
        Size in x direction of the kernel array. Default = 8*width + 1.
        Only used if ``array`` is None.
    y_size : int, optional
        Size in y direction of the kernel array. Default = 8*width + 1.
        Only used if ``array`` is None,
    array : ndarray or None, optional
        Kernel array. Default is None.
    mode : str, optional
        One of the following discretization modes:
            * 'center' (default)
                Discretize model by taking the value
                at the center of the bin.
            * 'linear_interp'
                Discretize model by performing a bilinear interpolation
                between the values at the corners of the bin.
            * 'oversample'
                Discretize model by taking the average
                on an oversampled grid.
            * 'integrate'
                Discretize model by integrating the
                model over the bin.
    width : number
        Width of the filter kernel.
    factor : number, optional
        Factor of oversampling. Default factor = 10.
    y_sizey_size should be an integery_rangeoperation
    Add, subtract or multiply two kernels.

    Parameters
    ----------
    kernel : `astropy.convolution.Kernel`
        Kernel instance.
    value : `astropy.convolution.Kernel`, float, or int
        Value to operate with.
    operation : {'add', 'sub', 'mul'}
        One of the following operations:
            * 'add'
                Add two kernels
            * 'sub'
                Subtract two kernels
            * 'mul'
                Multiply kernel with number or convolve two kernels.
    new_arrayKernel operation not supported. Maybe you want to use convolve(kernel1, kernel2) instead."Kernel operation not supported. Maybe you want ""to use convolve(kernel1, kernel2) instead."new_kernelKernel operation not supported.# numpy should not try to do any arithmetic# Warn the user for kernels that sum to zero# Initialize from model# Reject "array" keyword for kernel models, to avoid them not being# populated as expected.# Set ranges where to evaluate the model# even kernel# odd kernel# Initialize from array# 1D kernels# 2D kernels# kernel and numberb'
This module contains the convolution and filter functionalities of astropy.

A few conceptual notes:
A filter kernel is mainly characterized by its response function. In the 1D
case we speak of "impulse response function", in the 2D case we call it "point
spread function". This response function is given for every kernel by an
astropy `FittableModel`, which is evaluated on a grid to obtain a filter array,
which can then be applied to binned data.

The model is centered on the array and should have an amplitude such that the array
integrates to one per default.

Currently only symmetric 2D kernels are supported.
'u'
This module contains the convolution and filter functionalities of astropy.

A few conceptual notes:
A filter kernel is mainly characterized by its response function. In the 1D
case we speak of "impulse response function", in the 2D case we call it "point
spread function". This response function is given for every kernel by an
astropy `FittableModel`, which is evaluated on a grid to obtain a filter array,
which can then be applied to binned data.

The model is centered on the array and should have an amplitude such that the array
integrates to one per default.

Currently only symmetric 2D kernels are supported.
'b'Kernel'u'Kernel'b'Kernel1D'u'Kernel1D'b'Kernel2D'u'Kernel2D'b'kernel_arithmetics'u'kernel_arithmetics'b'
    Convolution kernel base class.

    Parameters
    ----------
    array : ndarray
        Kernel array.
    'u'
    Convolution kernel base class.

    Parameters
    ----------
    array : ndarray
        Kernel array.
    'b'
        Absolute deviation of the sum of the kernel array values from
        one.
        'u'
        Absolute deviation of the sum of the kernel array values from
        one.
        'b'
        Indicates if kernel is bool.

        If the kernel is bool the multiplication in the convolution could
        be omitted, to increase the performance.
        'u'
        Indicates if kernel is bool.

        If the kernel is bool the multiplication in the convolution could
        be omitted, to increase the performance.
        'b'
        Kernel response model.
        'u'
        Kernel response model.
        'b'
        Kernel dimension.
        'u'
        Kernel dimension.
        'b'
        Index of the kernel center.
        'u'
        Index of the kernel center.
        'b'integral'u'integral'b'
        Normalize the filter kernel.

        Parameters
        ----------
        mode : {'integral', 'peak'}
            One of the following modes:
                * 'integral' (default)
                    Kernel is normalized such that its integral = 1.
                * 'peak'
                    Kernel is normalized such that its peak = 1.
        'u'
        Normalize the filter kernel.

        Parameters
        ----------
        mode : {'integral', 'peak'}
            One of the following modes:
                * 'integral' (default)
                    Kernel is normalized such that its integral = 1.
                * 'peak'
                    Kernel is normalized such that its peak = 1.
        'b'peak'u'peak'b'invalid mode, must be 'integral' or 'peak''u'invalid mode, must be 'integral' or 'peak''b'The kernel cannot be normalized because it sums to zero.'u'The kernel cannot be normalized because it sums to zero.'b'
        Shape of the kernel array.
        'u'
        Shape of the kernel array.
        'b'
        Indicates if the filter kernel is separable.

        A 2D filter is separable, when its filter array can be written as the
        outer product of two 1D arrays.

        If a filter kernel is separable, higher dimension convolutions will be
        performed by applying the 1D filter array consecutively on every dimension.
        This is significantly faster, than using a filter array with the same
        dimension.
        'u'
        Indicates if the filter kernel is separable.

        A 2D filter is separable, when its filter array can be written as the
        outer product of two 1D arrays.

        If a filter kernel is separable, higher dimension convolutions will be
        performed by applying the 1D filter array consecutively on every dimension.
        This is significantly faster, than using a filter array with the same
        dimension.
        'b'
        Filter kernel array.
        'u'
        Filter kernel array.
        'b'
        Add two filter kernels.
        'u'
        Add two filter kernels.
        'b'add'u'add'b'
        Subtract two filter kernels.
        'u'
        Subtract two filter kernels.
        'b'sub'u'sub'b'
        Multiply kernel with number or convolve two kernels.
        'u'
        Multiply kernel with number or convolve two kernels.
        'b'mul'u'mul'b'
        Array representation of the kernel.
        'u'
        Array representation of the kernel.
        'u'
    Base class for 1D filter kernels.

    Parameters
    ----------
    model : `~astropy.modeling.FittableModel`
        Model to be evaluated.
    x_size : int or None, optional
        Size of the kernel array. Default = 8*width+1.
        Only used if ``array`` is None.
    array : ndarray or None, optional
        Kernel array.
    width : number
        Width of the filter kernel.
    mode : str, optional
        One of the following discretization modes:
            * 'center' (default)
                Discretize model by taking the value
                at the center of the bin.
            * 'linear_interp'
                Discretize model by linearly interpolating
                between the values at the corners of the bin.
            * 'oversample'
                Discretize model by taking the average
                on an oversampled grid.
            * 'integrate'
                Discretize model by integrating the
                model over the bin.
    factor : number, optional
        Factor of oversampling. Default factor = 10.
    'b'Array argument not allowed for kernel models.'u'Array argument not allowed for kernel models.'b'x_size should be an integer'u'x_size should be an integer'b'Must specify either array or model.'u'Must specify either array or model.'u'
    Base class for 2D filter kernels.

    Parameters
    ----------
    model : `~astropy.modeling.FittableModel`
        Model to be evaluated.
    x_size : int, optional
        Size in x direction of the kernel array. Default = 8*width + 1.
        Only used if ``array`` is None.
    y_size : int, optional
        Size in y direction of the kernel array. Default = 8*width + 1.
        Only used if ``array`` is None,
    array : ndarray or None, optional
        Kernel array. Default is None.
    mode : str, optional
        One of the following discretization modes:
            * 'center' (default)
                Discretize model by taking the value
                at the center of the bin.
            * 'linear_interp'
                Discretize model by performing a bilinear interpolation
                between the values at the corners of the bin.
            * 'oversample'
                Discretize model by taking the average
                on an oversampled grid.
            * 'integrate'
                Discretize model by integrating the
                model over the bin.
    width : number
        Width of the filter kernel.
    factor : number, optional
        Factor of oversampling. Default factor = 10.
    'b'y_size should be an integer'u'y_size should be an integer'b'
    Add, subtract or multiply two kernels.

    Parameters
    ----------
    kernel : `astropy.convolution.Kernel`
        Kernel instance.
    value : `astropy.convolution.Kernel`, float, or int
        Value to operate with.
    operation : {'add', 'sub', 'mul'}
        One of the following operations:
            * 'add'
                Add two kernels
            * 'sub'
                Subtract two kernels
            * 'mul'
                Multiply kernel with number or convolve two kernels.
    'u'
    Add, subtract or multiply two kernels.

    Parameters
    ----------
    kernel : `astropy.convolution.Kernel`
        Kernel instance.
    value : `astropy.convolution.Kernel`, float, or int
        Value to operate with.
    operation : {'add', 'sub', 'mul'}
        One of the following operations:
            * 'add'
                Add two kernels
            * 'sub'
                Subtract two kernels
            * 'mul'
                Multiply kernel with number or convolve two kernels.
    'b'Kernel operation not supported. Maybe you want to use convolve(kernel1, kernel2) instead.'u'Kernel operation not supported. Maybe you want to use convolve(kernel1, kernel2) instead.'b'Kernel operation not supported.'u'Kernel operation not supported.'u'astropy.convolution.core'u'convolution.core'Classes for handling metadata.MetaAttribute
    A descriptor for classes that have a ``meta`` property.

    This can be set to any valid :class:`~collections.abc.Mapping`.

    Parameters
    ----------
    doc : `str`, optional
        Documentation for the attribute of the class.
        Default is ``""``.

        .. versionadded:: 1.2

    copy : `bool`, optional
        If ``True`` the value is deepcopied before setting, otherwise it
        is saved as reference.
        Default is ``True``.

        .. versionadded:: 1.2

    default_factory : Callable[[], Mapping], optional keyword-only
        The factory to use to create the default value of the ``meta``
        attribute.  This must be a callable that returns a `Mapping` object.
        Default is `OrderedDict`, creating an empty `OrderedDict`.

        .. versionadded:: 6.0

    Examples
    --------
    ``MetaData`` can be used as a descriptor to define a ``meta`` attribute`.

        >>> class Foo:
        ...     meta = MetaData()
        ...     def __init__(self, meta=None):
        ...         self.meta = meta

    ``Foo`` can be instantiated with a ``meta`` argument.

        >>> foo = Foo(meta={'a': 1, 'b': 2})
        >>> foo.meta
        {'a': 1, 'b': 2}

    The default value of ``meta`` is an empty :class:`~collections.OrderedDict`.
    This can be set by passing ``None`` to the ``meta`` argument.

        >>> foo = Foo()
        >>> foo.meta
        OrderedDict()

    If an :class:`~collections.OrderedDict` is not a good default metadata type then
    the ``default_factory`` keyword can be used to set the default to a different
    `Mapping` type, when the class is defined.'

        >>> class Bar:
        ...     meta = MetaData(default_factory=dict)
        ...     def __init__(self, meta=None):
        ...         self.meta = meta

        >>> Bar().meta
        {}

    When accessed from the class ``.meta`` returns `None` since metadata is
    on the class' instances, not the class itself.

        >>> print(Foo.meta)
        None
    _default_factorymeta attribute must be dict-like__dataclass_params__
    Descriptor to define custom attribute which gets stored in the object
    ``meta`` dict and can have a defined default.

    This descriptor is intended to provide a convenient way to add attributes
    to a subclass of a complex class such as ``Table`` or ``NDData``.

    This requires that the object has an attribute ``meta`` which is a
    dict-like object.  The value of the MetaAttribute will be stored in a
    new dict meta['__attributes__'] that is created when required.

    Classes that define MetaAttributes are encouraged to support initializing
    the attributes via the class ``__init__``.  For example::

        for attr in list(kwargs):
            descr = getattr(self.__class__, attr, None)
            if isinstance(descr, MetaAttribute):
                setattr(self, attr, kwargs.pop(attr))

    The name of a ``MetaAttribute`` cannot be the same as any of the following:

    - Keyword argument in the owner class ``__init__``
    - Method or attribute of the "parent class", where the parent class is
      taken to be ``owner.__mro__[1]``.

    Parameters
    ----------
    default : Any, optional
        Default value for the attribute, by default `None`.
    __attributes__VAR_POSITIONAL not allowed as  default=# class attribute access. Often, descriptors just return `self`, but if the# owning class is a `dataclass`, the expectation is that the default is# returned. In our case, this is None, triggering the creation of a dict-like in# `__set__`.# instance attribute access# The 'default' value is `None`, but we want to set it to an empty `Mapping`# if it is `None` so that we can always assume it is a `Mapping` and not have# to check for `None` everywhere.# We don't want to allow setting the meta attribute to a non-dict-like object.# NOTE: with mypyc compilation this can be removed.# This is called when the dataclass is instantiated with a `meta` argument.# When called without an instance, return self to allow access# to descriptor attributes.# If default is None and value has not been set already then return None# without doing touching meta['__attributes__'] at all. This helps e.g.# with the Table._hidden_columns attribute so it doesn't auto-create# meta['__attributes__'] always.# Get the __attributes__ dict and create if not there already.# Return either specified default or None# Remove this attribute from meta['__attributes__'] if it exists.# If this was the last attribute then remove the meta key as well# Reject names from existing params or best guess at parent classb'Classes for handling metadata.'u'Classes for handling metadata.'b'MetaAttribute'u'MetaAttribute'b'MetaData'u'MetaData'b'
    A descriptor for classes that have a ``meta`` property.

    This can be set to any valid :class:`~collections.abc.Mapping`.

    Parameters
    ----------
    doc : `str`, optional
        Documentation for the attribute of the class.
        Default is ``""``.

        .. versionadded:: 1.2

    copy : `bool`, optional
        If ``True`` the value is deepcopied before setting, otherwise it
        is saved as reference.
        Default is ``True``.

        .. versionadded:: 1.2

    default_factory : Callable[[], Mapping], optional keyword-only
        The factory to use to create the default value of the ``meta``
        attribute.  This must be a callable that returns a `Mapping` object.
        Default is `OrderedDict`, creating an empty `OrderedDict`.

        .. versionadded:: 6.0

    Examples
    --------
    ``MetaData`` can be used as a descriptor to define a ``meta`` attribute`.

        >>> class Foo:
        ...     meta = MetaData()
        ...     def __init__(self, meta=None):
        ...         self.meta = meta

    ``Foo`` can be instantiated with a ``meta`` argument.

        >>> foo = Foo(meta={'a': 1, 'b': 2})
        >>> foo.meta
        {'a': 1, 'b': 2}

    The default value of ``meta`` is an empty :class:`~collections.OrderedDict`.
    This can be set by passing ``None`` to the ``meta`` argument.

        >>> foo = Foo()
        >>> foo.meta
        OrderedDict()

    If an :class:`~collections.OrderedDict` is not a good default metadata type then
    the ``default_factory`` keyword can be used to set the default to a different
    `Mapping` type, when the class is defined.'

        >>> class Bar:
        ...     meta = MetaData(default_factory=dict)
        ...     def __init__(self, meta=None):
        ...         self.meta = meta

        >>> Bar().meta
        {}

    When accessed from the class ``.meta`` returns `None` since metadata is
    on the class' instances, not the class itself.

        >>> print(Foo.meta)
        None
    'u'
    A descriptor for classes that have a ``meta`` property.

    This can be set to any valid :class:`~collections.abc.Mapping`.

    Parameters
    ----------
    doc : `str`, optional
        Documentation for the attribute of the class.
        Default is ``""``.

        .. versionadded:: 1.2

    copy : `bool`, optional
        If ``True`` the value is deepcopied before setting, otherwise it
        is saved as reference.
        Default is ``True``.

        .. versionadded:: 1.2

    default_factory : Callable[[], Mapping], optional keyword-only
        The factory to use to create the default value of the ``meta``
        attribute.  This must be a callable that returns a `Mapping` object.
        Default is `OrderedDict`, creating an empty `OrderedDict`.

        .. versionadded:: 6.0

    Examples
    --------
    ``MetaData`` can be used as a descriptor to define a ``meta`` attribute`.

        >>> class Foo:
        ...     meta = MetaData()
        ...     def __init__(self, meta=None):
        ...         self.meta = meta

    ``Foo`` can be instantiated with a ``meta`` argument.

        >>> foo = Foo(meta={'a': 1, 'b': 2})
        >>> foo.meta
        {'a': 1, 'b': 2}

    The default value of ``meta`` is an empty :class:`~collections.OrderedDict`.
    This can be set by passing ``None`` to the ``meta`` argument.

        >>> foo = Foo()
        >>> foo.meta
        OrderedDict()

    If an :class:`~collections.OrderedDict` is not a good default metadata type then
    the ``default_factory`` keyword can be used to set the default to a different
    `Mapping` type, when the class is defined.'

        >>> class Bar:
        ...     meta = MetaData(default_factory=dict)
        ...     def __init__(self, meta=None):
        ...         self.meta = meta

        >>> Bar().meta
        {}

    When accessed from the class ``.meta`` returns `None` since metadata is
    on the class' instances, not the class itself.

        >>> print(Foo.meta)
        None
    'b'_meta'u'_meta'b'meta attribute must be dict-like'u'meta attribute must be dict-like'b'
    Descriptor to define custom attribute which gets stored in the object
    ``meta`` dict and can have a defined default.

    This descriptor is intended to provide a convenient way to add attributes
    to a subclass of a complex class such as ``Table`` or ``NDData``.

    This requires that the object has an attribute ``meta`` which is a
    dict-like object.  The value of the MetaAttribute will be stored in a
    new dict meta['__attributes__'] that is created when required.

    Classes that define MetaAttributes are encouraged to support initializing
    the attributes via the class ``__init__``.  For example::

        for attr in list(kwargs):
            descr = getattr(self.__class__, attr, None)
            if isinstance(descr, MetaAttribute):
                setattr(self, attr, kwargs.pop(attr))

    The name of a ``MetaAttribute`` cannot be the same as any of the following:

    - Keyword argument in the owner class ``__init__``
    - Method or attribute of the "parent class", where the parent class is
      taken to be ``owner.__mro__[1]``.

    Parameters
    ----------
    default : Any, optional
        Default value for the attribute, by default `None`.
    'u'
    Descriptor to define custom attribute which gets stored in the object
    ``meta`` dict and can have a defined default.

    This descriptor is intended to provide a convenient way to add attributes
    to a subclass of a complex class such as ``Table`` or ``NDData``.

    This requires that the object has an attribute ``meta`` which is a
    dict-like object.  The value of the MetaAttribute will be stored in a
    new dict meta['__attributes__'] that is created when required.

    Classes that define MetaAttributes are encouraged to support initializing
    the attributes via the class ``__init__``.  For example::

        for attr in list(kwargs):
            descr = getattr(self.__class__, attr, None)
            if isinstance(descr, MetaAttribute):
                setattr(self, attr, kwargs.pop(attr))

    The name of a ``MetaAttribute`` cannot be the same as any of the following:

    - Keyword argument in the owner class ``__init__``
    - Method or attribute of the "parent class", where the parent class is
      taken to be ``owner.__mro__[1]``.

    Parameters
    ----------
    default : Any, optional
        Default value for the attribute, by default `None`.
    'b'__attributes__'u'__attributes__'b' not allowed as 'u' not allowed as 'b' default='u' default='u'astropy.utils.metadata.core'u'utils.metadata.core'u'metadata.core'MappingProxyTypeUnifiedReadWriteMethodastropy.cosmology.ioastropy.cosmology._src.funcs.comparison_FlatCosmoT_with_signatureDecorator to precompute the class' signature.

    This provides around a 20x speedup for future calls of ``inspect.signature(cls)``.
    `Cosmology` has a lot of I/O methods that use the signature, so this is a
    significant speedup for those methods.

    Note that CPython does not promise that this precomputation is a stable feature.
    If it is removed, the worst that will happen is that the signature will be
    computed on the fly, the speedup will be lost, and this decorator can be
    deprecated.
    __signature__Decorator for the dataclass transform.

    Returns
    -------
    cls : type
        The `cls` transformed into a frozen `~dataclasses.dataclass`.
        The ``__eq__`` method is custom (``eq=False``).
        The signature is precomputed and added to the class.
    slots_NameFieldBase-class for all Cosmologies.

    Parameters
    ----------
    *args
        Arguments into the cosmology; used by subclasses, not this base class.
    name : str or None (optional, keyword-only)
        The name of the cosmology.
    meta : dict or None (optional, keyword-only)
        Metadata for the cosmology, e.g., a reference.
    **kwargs
        Arguments into the cosmology; used by subclasses, not this base class.

    Notes
    -----
    Class instances are static -- you cannot (and should not) change the
    values of the parameters.  That is, all of the above attributes
    (except meta) are read only.

    For details on how to create performant custom subclasses, see the
    documentation on :ref:`astropy-cosmology-fast-integrals`.

    Cosmology subclasses are automatically registered in a global registry
    and with various I/O methods. To turn off or change this registration,
    override the ``_register_cls`` classmethod in the subclass.
    The name of the cosmology realization, e.g. 'Planck2018' or `None`._parametersImmutable mapping of the Parameters.

    If accessed from the class, this returns a mapping of the Parameter
    objects themselves.  If accessed from an instance, this returns a
    mapping of the values of the Parameters.
    _parameters_derivedImmutable mapping of the derived Parameters.

    If accessed from the class, this returns a mapping of the Parameter
    objects themselves.  If accessed from an instance, this returns a
    mapping of the values of the Parameters.
    _parameters_allSignatureall_paramsisabstract_register_clsastropy.cosmology._src.io.builtin.yamlregister_cosmology_yamlPost-initialization, for subclasses to override if they need.Return bool; `True` if the cosmology is flat.

        This is abstract and must be defined in subclasses.
        is_flat is not implementedReturns a copy of this object with updated parameters, as specified.

        This cannot be used to change the type of the cosmology, so ``clone()``
        cannot be used to change between flat and non-flat cosmologies.

        Parameters
        ----------
        meta : mapping or None (optional, keyword-only)
            Metadata that will update the current metadata.
        **kwargs
            Cosmology parameter (and name) modifications. If any parameter is
            changed and a new name is not given, the name will be set to "[old
            name] (modified)".

        Returns
        -------
        newcosmo : `~astropy.cosmology.Cosmology` subclass instance
            A new instance of this class with updated parameters as specified.
            If no arguments are given, then a reference to this object is
            returned instead of copy.

        Examples
        --------
        To make a copy of the ``Planck13`` cosmology with a different matter
        density (``Om0``), and a new name:

            >>> from astropy.cosmology import Planck13
            >>> Planck13.clone(name="Modified Planck 2013", Om0=0.35)
            FlatLambdaCDM(name='Modified Planck 2013', H0=<Quantity 67.77 km / (Mpc s)>,
                          Om0=0.35, ...

        If no name is specified, the new name will note the modification.

            >>> Planck13.clone(Om0=0.35).name
            'Planck13 (modified)'
         (modified)_modname_init_has_kwargsCheck equivalence between Cosmologies.

        Two cosmologies may be equivalent even if not the same class.
        For example, an instance of ``LambdaCDM`` might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like ``FlatLambdaCDM``.

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object to which to compare.
        format : bool or None or str, optional keyword-only
            Whether to allow, before equivalence is checked, the object to be
            converted to a |Cosmology|. This allows, e.g. a |Table| to be
            equivalent to a Cosmology.
            `False` (default) will not allow conversion. `True` or `None` will,
            and will use the auto-identification to try to infer the correct
            format. A `str` is assumed to be the correct format to use when
            converting.
            ``format`` is broadcast to match the shape of ``other``.
            Note that the cosmology arguments are not broadcast against
            ``format``, so it cannot determine the output shape.

        Returns
        -------
        bool
            True if cosmologies are equivalent, False otherwise.

        Examples
        --------
        Two cosmologies may be equivalent even if not of the same class.
        In this examples the ``LambdaCDM`` has ``Ode0`` set to the same value
        calculated in ``FlatLambdaCDM``.

            >>> import astropy.units as u
            >>> from astropy.cosmology import LambdaCDM, FlatLambdaCDM
            >>> cosmo1 = LambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, 0.7)
            >>> cosmo2 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
            >>> cosmo1.is_equivalent(cosmo2)
            True

        While in this example, the cosmologies are not equivalent.

            >>> cosmo3 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, Tcmb0=3 * u.K)
            >>> cosmo3.is_equivalent(cosmo2)
            False

        Also, using the keyword argument, the notion of equivalence is extended
        to any Python object that can be converted to a |Cosmology|.

            >>> from astropy.cosmology import Planck18
            >>> tbl = Planck18.to_format("astropy.table")
            >>> Planck18.is_equivalent(tbl, format=True)
            True

        The list of valid formats, e.g. the |Table| in this example, may be
        checked with ``Cosmology.from_format.list_formats()``.

        As can be seen in the list of formats, not all formats can be
        auto-identified by ``Cosmology.from_format.registry``. Objects of
        these kinds can still be checked for equivalence, but the correct
        format string must be used.

            >>> tbl = Planck18.to_format("yaml")
            >>> Planck18.is_equivalent(tbl, format="yaml")
            True
        astropy.cosmology._src.funcsCosmology equivalence. Use ``.is_equivalent()`` for actual check!

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object in which to compare.

        Returns
        -------
        bool or `NotImplemented`
            `NotImplemented` if ``other`` is from a different class.
            `True` if ``other`` is of the same class and has matching parameters
            and parameter values.
            `False` otherwise.
        Check equality between Cosmologies.

        Checks the Parameters and immutable fields (i.e. not "meta").

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object in which to compare.

        Returns
        -------
        bool
            `True` if Parameters and names are the same, `False` otherwise.
        Return a string representation of the cosmology.name="", name_strparam_strs__astropy_table__Return a `~astropy.table.Table` of type ``cls``.

        Parameters
        ----------
        cls : type
            Astropy ``Table`` class or subclass.
        copy : bool
            Ignored.
        **kwargs : dict, optional
            Additional keyword arguments. Passed to ``self.to_format()``.
            See ``Cosmology.to_format.help("astropy.table")`` for allowed kwargs.

        Returns
        -------
        `astropy.table.Table` or subclass instance
            Instance of type ``cls``.
        Mixin class for flat cosmologies.

    Do NOT instantiate directly. Note that all instances of
    ``FlatCosmologyMixin`` are flat, but not all flat cosmologies are
    instances of ``FlatCosmologyMixin``. As example, ``LambdaCDM`` **may**
    be flat (for the a specific set of parameter values), but
    ``FlatLambdaCDM`` **will** be flat.
    _get_nonflat_clsklsFind the corresponding non-flat class.

        The class' bases are searched recursively.

        Parameters
        ----------
        kls : :class:`astropy.cosmology.Cosmology` class or None, optional
            If `None` (default) this class is searched instead of `kls`.

        Raises
        ------
        TypeError
            If more than one non-flat class is found at the same level of the
            inheritance. This is similar to the error normally raised by Python
            for an inconsistent method resolution order.

        Returns
        -------
        type
            A :class:`Cosmology` subclass this class inherits from that is not a
            :class:`FlatCosmologyMixin` subclass.
        _klscannot create a consistent non-flat class resolution order for "cannot create a consistent non-flat class resolution order ""for " with bases  at the same inheritance level.Return the corresponding non-flat class.Return `True`, the cosmology is flat.Return the equivalent non-flat-class instance of this cosmology.Returns a copy of this object with updated parameters, as specified.

        This cannot be used to change the type of the cosmology, except for
        changing to the non-flat version of this cosmology.

        Parameters
        ----------
        meta : mapping or None (optional, keyword-only)
            Metadata that will update the current metadata.
        to_nonflat : bool, optional keyword-only
            Whether to change to the non-flat version of this cosmology.
        **kwargs
            Cosmology parameter (and name) modifications. If any parameter is
            changed and a new name is not given, the name will be set to "[old
            name] (modified)".

        Returns
        -------
        newcosmo : `~astropy.cosmology.Cosmology` subclass instance
            A new instance of this class with updated parameters as specified.
            If no arguments are given, then a reference to this object is
            returned instead of copy.

        Examples
        --------
        To make a copy of the ``Planck13`` cosmology with a different matter
        density (``Om0``), and a new name:

            >>> from astropy.cosmology import Planck13
            >>> Planck13.clone(name="Modified Planck 2013", Om0=0.35)
            FlatLambdaCDM(name='Modified Planck 2013', H0=<Quantity 67.77 km / (Mpc s)>,
                          Om0=0.35, ...

        If no name is specified, the new name will note the modification.

            >>> Planck13.clone(Om0=0.35).name
            'Planck13 (modified)'

        The keyword 'to_nonflat' can be used to clone on the non-flat equivalent
        cosmology. For :class:`~astropy.cosmology.FLRW` cosmologies this means
        ``Ode0`` can be modified:

            >>> Planck13.clone(to_nonflat=True, Ode0=1)
            LambdaCDM(name='Planck13 (modified)', H0=<Quantity 67.77 km / (Mpc s)>,
                      Om0=0.30712, Ode0=1.0, ...
        Flat-|Cosmology| equivalence.

        Use `astropy.cosmology.cosmology_equal` with
        ``allow_equivalent=True`` for actual checks!

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance
            The object to which to compare for equivalence.

        Returns
        -------
        bool or `NotImplemented`
            `True` if ``other`` is of the same class / non-flat class (e.g.
            |FlatLambdaCDM| and |LambdaCDM|) has matching parameters and
            parameter values.
            `False` if ``other`` is of the same class but has different
            parameters.
            `NotImplemented` otherwise.
        params_eq# Originally authored by Andrew Becker (becker@astro.washington.edu),# and modified by Neil Crighton (neilcrighton@gmail.com), Roban Kramer# (robanhk@gmail.com), and Nathaniel Starkman (n.starkman@mail.utoronto.ca).# Many of these adapted from Hogg 1999, astro-ph/9905116# and Linder 2003, PRL 90, 91301# registry of cosmology classes with {key=name : value=class}# dataclass transformation# clear the signature cache# add the new signature to the class# TODO: replace with `field(converter=lambda x: None if x is None else str(x))` when#       the `converter` argument is available in `field` (py3.13, maybe?).#       See https://peps.python.org/pep-0712/# Called from the class. `dataclass` uses this to create ``__init__``.# Called from the instance# Unified I/O object interchange methods# Unified I/O read and write methods# -------------------# Registration# skip abstract classes# register class# register to YAML# noqa: B027# Quick return check, taking advantage of the Cosmology immutability.# There are changed parameter or metadata values.# The name needs to be changed accordingly, if it wasn't already.# mix new meta into existing, preferring the former.# Check if nothing has changed.# TODO! or should return self?# comparison methods# `is_equivalent` allows `other` to be any object and returns False# if `other` cannot be converted to a Cosmology, rather than# raising an Exception.# allows other.__equiv__# Check all parameters in 'other' match those in 'self' and 'other' has# no extra parameters (latter part should never happen b/c same class)# We do not use `self.parameters == other.parameters` because it does not work# for aggregating the truthiness of arrays, e.g. `m_nu`.# allows other.__eq__# non-Parameter checks: name# check all parameters in 'other' match those in 'self' and 'other'# has no extra parameters (latter part should never happen b/c same# class). We do not use `self.parameters == other.parameters` because# it does not work for aggregating the truthiness of arrays, e.g. `m_nu`.# TODO! element-wise when there are array cosmologies# Manipulate the dataclass fields for fields that are not created by `dataclass.fields`# and thus do not have a mechanism for setting "compare", "repr", etc.# Determine the non-flat class.# This will raise a TypeError if the MRO is inconsistent.# TODO! make metaclass-method# Find non-flat classes# e.g. subclassing FlatLambdaCDM# e.g. FlatFLRWMixin(FlatCosmologyMixin)# super gets from Cosmology# check if `other` is the non-flat version of this class this makes the# assumption that any further subclass of a flat cosmo keeps the same# physics.# Check if have equivalent parameters and all parameters in `other`# match those in `self`` and `other`` has no extra parameters.# no extra parameters# equal# flatness checkb'_FlatCosmoT'u'_FlatCosmoT'b'Decorator to precompute the class' signature.

    This provides around a 20x speedup for future calls of ``inspect.signature(cls)``.
    `Cosmology` has a lot of I/O methods that use the signature, so this is a
    significant speedup for those methods.

    Note that CPython does not promise that this precomputation is a stable feature.
    If it is removed, the worst that will happen is that the signature will be
    computed on the fly, the speedup will be lost, and this decorator can be
    deprecated.
    'u'Decorator to precompute the class' signature.

    This provides around a 20x speedup for future calls of ``inspect.signature(cls)``.
    `Cosmology` has a lot of I/O methods that use the signature, so this is a
    significant speedup for those methods.

    Note that CPython does not promise that this precomputation is a stable feature.
    If it is removed, the worst that will happen is that the signature will be
    computed on the fly, the speedup will be lost, and this decorator can be
    deprecated.
    'b'Decorator for the dataclass transform.

    Returns
    -------
    cls : type
        The `cls` transformed into a frozen `~dataclasses.dataclass`.
        The ``__eq__`` method is custom (``eq=False``).
        The signature is precomputed and added to the class.
    'u'Decorator for the dataclass transform.

    Returns
    -------
    cls : type
        The `cls` transformed into a frozen `~dataclasses.dataclass`.
        The ``__eq__`` method is custom (``eq=False``).
        The signature is precomputed and added to the class.
    'b'Base-class for all Cosmologies.

    Parameters
    ----------
    *args
        Arguments into the cosmology; used by subclasses, not this base class.
    name : str or None (optional, keyword-only)
        The name of the cosmology.
    meta : dict or None (optional, keyword-only)
        Metadata for the cosmology, e.g., a reference.
    **kwargs
        Arguments into the cosmology; used by subclasses, not this base class.

    Notes
    -----
    Class instances are static -- you cannot (and should not) change the
    values of the parameters.  That is, all of the above attributes
    (except meta) are read only.

    For details on how to create performant custom subclasses, see the
    documentation on :ref:`astropy-cosmology-fast-integrals`.

    Cosmology subclasses are automatically registered in a global registry
    and with various I/O methods. To turn off or change this registration,
    override the ``_register_cls`` classmethod in the subclass.
    'u'Base-class for all Cosmologies.

    Parameters
    ----------
    *args
        Arguments into the cosmology; used by subclasses, not this base class.
    name : str or None (optional, keyword-only)
        The name of the cosmology.
    meta : dict or None (optional, keyword-only)
        Metadata for the cosmology, e.g., a reference.
    **kwargs
        Arguments into the cosmology; used by subclasses, not this base class.

    Notes
    -----
    Class instances are static -- you cannot (and should not) change the
    values of the parameters.  That is, all of the above attributes
    (except meta) are read only.

    For details on how to create performant custom subclasses, see the
    documentation on :ref:`astropy-cosmology-fast-integrals`.

    Cosmology subclasses are automatically registered in a global registry
    and with various I/O methods. To turn off or change this registration,
    override the ``_register_cls`` classmethod in the subclass.
    'b'The name of the cosmology realization, e.g. 'Planck2018' or `None`.'u'The name of the cosmology realization, e.g. 'Planck2018' or `None`.'b'_parameters'u'_parameters'b'Immutable mapping of the Parameters.

    If accessed from the class, this returns a mapping of the Parameter
    objects themselves.  If accessed from an instance, this returns a
    mapping of the values of the Parameters.
    'u'Immutable mapping of the Parameters.

    If accessed from the class, this returns a mapping of the Parameter
    objects themselves.  If accessed from an instance, this returns a
    mapping of the values of the Parameters.
    'b'_parameters_derived'u'_parameters_derived'b'Immutable mapping of the derived Parameters.

    If accessed from the class, this returns a mapping of the Parameter
    objects themselves.  If accessed from an instance, this returns a
    mapping of the values of the Parameters.
    'u'Immutable mapping of the derived Parameters.

    If accessed from the class, this returns a mapping of the Parameter
    objects themselves.  If accessed from an instance, this returns a
    mapping of the values of the Parameters.
    'b'Post-initialization, for subclasses to override if they need.'u'Post-initialization, for subclasses to override if they need.'b'Return bool; `True` if the cosmology is flat.

        This is abstract and must be defined in subclasses.
        'u'Return bool; `True` if the cosmology is flat.

        This is abstract and must be defined in subclasses.
        'b'is_flat is not implemented'u'is_flat is not implemented'b'Returns a copy of this object with updated parameters, as specified.

        This cannot be used to change the type of the cosmology, so ``clone()``
        cannot be used to change between flat and non-flat cosmologies.

        Parameters
        ----------
        meta : mapping or None (optional, keyword-only)
            Metadata that will update the current metadata.
        **kwargs
            Cosmology parameter (and name) modifications. If any parameter is
            changed and a new name is not given, the name will be set to "[old
            name] (modified)".

        Returns
        -------
        newcosmo : `~astropy.cosmology.Cosmology` subclass instance
            A new instance of this class with updated parameters as specified.
            If no arguments are given, then a reference to this object is
            returned instead of copy.

        Examples
        --------
        To make a copy of the ``Planck13`` cosmology with a different matter
        density (``Om0``), and a new name:

            >>> from astropy.cosmology import Planck13
            >>> Planck13.clone(name="Modified Planck 2013", Om0=0.35)
            FlatLambdaCDM(name='Modified Planck 2013', H0=<Quantity 67.77 km / (Mpc s)>,
                          Om0=0.35, ...

        If no name is specified, the new name will note the modification.

            >>> Planck13.clone(Om0=0.35).name
            'Planck13 (modified)'
        'u'Returns a copy of this object with updated parameters, as specified.

        This cannot be used to change the type of the cosmology, so ``clone()``
        cannot be used to change between flat and non-flat cosmologies.

        Parameters
        ----------
        meta : mapping or None (optional, keyword-only)
            Metadata that will update the current metadata.
        **kwargs
            Cosmology parameter (and name) modifications. If any parameter is
            changed and a new name is not given, the name will be set to "[old
            name] (modified)".

        Returns
        -------
        newcosmo : `~astropy.cosmology.Cosmology` subclass instance
            A new instance of this class with updated parameters as specified.
            If no arguments are given, then a reference to this object is
            returned instead of copy.

        Examples
        --------
        To make a copy of the ``Planck13`` cosmology with a different matter
        density (``Om0``), and a new name:

            >>> from astropy.cosmology import Planck13
            >>> Planck13.clone(name="Modified Planck 2013", Om0=0.35)
            FlatLambdaCDM(name='Modified Planck 2013', H0=<Quantity 67.77 km / (Mpc s)>,
                          Om0=0.35, ...

        If no name is specified, the new name will note the modification.

            >>> Planck13.clone(Om0=0.35).name
            'Planck13 (modified)'
        'b' (modified)'u' (modified)'b'Check equivalence between Cosmologies.

        Two cosmologies may be equivalent even if not the same class.
        For example, an instance of ``LambdaCDM`` might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like ``FlatLambdaCDM``.

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object to which to compare.
        format : bool or None or str, optional keyword-only
            Whether to allow, before equivalence is checked, the object to be
            converted to a |Cosmology|. This allows, e.g. a |Table| to be
            equivalent to a Cosmology.
            `False` (default) will not allow conversion. `True` or `None` will,
            and will use the auto-identification to try to infer the correct
            format. A `str` is assumed to be the correct format to use when
            converting.
            ``format`` is broadcast to match the shape of ``other``.
            Note that the cosmology arguments are not broadcast against
            ``format``, so it cannot determine the output shape.

        Returns
        -------
        bool
            True if cosmologies are equivalent, False otherwise.

        Examples
        --------
        Two cosmologies may be equivalent even if not of the same class.
        In this examples the ``LambdaCDM`` has ``Ode0`` set to the same value
        calculated in ``FlatLambdaCDM``.

            >>> import astropy.units as u
            >>> from astropy.cosmology import LambdaCDM, FlatLambdaCDM
            >>> cosmo1 = LambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, 0.7)
            >>> cosmo2 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
            >>> cosmo1.is_equivalent(cosmo2)
            True

        While in this example, the cosmologies are not equivalent.

            >>> cosmo3 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, Tcmb0=3 * u.K)
            >>> cosmo3.is_equivalent(cosmo2)
            False

        Also, using the keyword argument, the notion of equivalence is extended
        to any Python object that can be converted to a |Cosmology|.

            >>> from astropy.cosmology import Planck18
            >>> tbl = Planck18.to_format("astropy.table")
            >>> Planck18.is_equivalent(tbl, format=True)
            True

        The list of valid formats, e.g. the |Table| in this example, may be
        checked with ``Cosmology.from_format.list_formats()``.

        As can be seen in the list of formats, not all formats can be
        auto-identified by ``Cosmology.from_format.registry``. Objects of
        these kinds can still be checked for equivalence, but the correct
        format string must be used.

            >>> tbl = Planck18.to_format("yaml")
            >>> Planck18.is_equivalent(tbl, format="yaml")
            True
        'u'Check equivalence between Cosmologies.

        Two cosmologies may be equivalent even if not the same class.
        For example, an instance of ``LambdaCDM`` might have :math:`\Omega_0=1`
        and :math:`\Omega_k=0` and therefore be flat, like ``FlatLambdaCDM``.

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object to which to compare.
        format : bool or None or str, optional keyword-only
            Whether to allow, before equivalence is checked, the object to be
            converted to a |Cosmology|. This allows, e.g. a |Table| to be
            equivalent to a Cosmology.
            `False` (default) will not allow conversion. `True` or `None` will,
            and will use the auto-identification to try to infer the correct
            format. A `str` is assumed to be the correct format to use when
            converting.
            ``format`` is broadcast to match the shape of ``other``.
            Note that the cosmology arguments are not broadcast against
            ``format``, so it cannot determine the output shape.

        Returns
        -------
        bool
            True if cosmologies are equivalent, False otherwise.

        Examples
        --------
        Two cosmologies may be equivalent even if not of the same class.
        In this examples the ``LambdaCDM`` has ``Ode0`` set to the same value
        calculated in ``FlatLambdaCDM``.

            >>> import astropy.units as u
            >>> from astropy.cosmology import LambdaCDM, FlatLambdaCDM
            >>> cosmo1 = LambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, 0.7)
            >>> cosmo2 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3)
            >>> cosmo1.is_equivalent(cosmo2)
            True

        While in this example, the cosmologies are not equivalent.

            >>> cosmo3 = FlatLambdaCDM(70 * (u.km/u.s/u.Mpc), 0.3, Tcmb0=3 * u.K)
            >>> cosmo3.is_equivalent(cosmo2)
            False

        Also, using the keyword argument, the notion of equivalence is extended
        to any Python object that can be converted to a |Cosmology|.

            >>> from astropy.cosmology import Planck18
            >>> tbl = Planck18.to_format("astropy.table")
            >>> Planck18.is_equivalent(tbl, format=True)
            True

        The list of valid formats, e.g. the |Table| in this example, may be
        checked with ``Cosmology.from_format.list_formats()``.

        As can be seen in the list of formats, not all formats can be
        auto-identified by ``Cosmology.from_format.registry``. Objects of
        these kinds can still be checked for equivalence, but the correct
        format string must be used.

            >>> tbl = Planck18.to_format("yaml")
            >>> Planck18.is_equivalent(tbl, format="yaml")
            True
        'b'Cosmology equivalence. Use ``.is_equivalent()`` for actual check!

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object in which to compare.

        Returns
        -------
        bool or `NotImplemented`
            `NotImplemented` if ``other`` is from a different class.
            `True` if ``other`` is of the same class and has matching parameters
            and parameter values.
            `False` otherwise.
        'u'Cosmology equivalence. Use ``.is_equivalent()`` for actual check!

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object in which to compare.

        Returns
        -------
        bool or `NotImplemented`
            `NotImplemented` if ``other`` is from a different class.
            `True` if ``other`` is of the same class and has matching parameters
            and parameter values.
            `False` otherwise.
        'b'Check equality between Cosmologies.

        Checks the Parameters and immutable fields (i.e. not "meta").

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object in which to compare.

        Returns
        -------
        bool
            `True` if Parameters and names are the same, `False` otherwise.
        'u'Check equality between Cosmologies.

        Checks the Parameters and immutable fields (i.e. not "meta").

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance, positional-only
            The object in which to compare.

        Returns
        -------
        bool
            `True` if Parameters and names are the same, `False` otherwise.
        'b'Return a string representation of the cosmology.'u'Return a string representation of the cosmology.'b'name="'u'name="'b'", 'u'", 'b'Return a `~astropy.table.Table` of type ``cls``.

        Parameters
        ----------
        cls : type
            Astropy ``Table`` class or subclass.
        copy : bool
            Ignored.
        **kwargs : dict, optional
            Additional keyword arguments. Passed to ``self.to_format()``.
            See ``Cosmology.to_format.help("astropy.table")`` for allowed kwargs.

        Returns
        -------
        `astropy.table.Table` or subclass instance
            Instance of type ``cls``.
        'u'Return a `~astropy.table.Table` of type ``cls``.

        Parameters
        ----------
        cls : type
            Astropy ``Table`` class or subclass.
        copy : bool
            Ignored.
        **kwargs : dict, optional
            Additional keyword arguments. Passed to ``self.to_format()``.
            See ``Cosmology.to_format.help("astropy.table")`` for allowed kwargs.

        Returns
        -------
        `astropy.table.Table` or subclass instance
            Instance of type ``cls``.
        'b'Mixin class for flat cosmologies.

    Do NOT instantiate directly. Note that all instances of
    ``FlatCosmologyMixin`` are flat, but not all flat cosmologies are
    instances of ``FlatCosmologyMixin``. As example, ``LambdaCDM`` **may**
    be flat (for the a specific set of parameter values), but
    ``FlatLambdaCDM`` **will** be flat.
    'u'Mixin class for flat cosmologies.

    Do NOT instantiate directly. Note that all instances of
    ``FlatCosmologyMixin`` are flat, but not all flat cosmologies are
    instances of ``FlatCosmologyMixin``. As example, ``LambdaCDM`` **may**
    be flat (for the a specific set of parameter values), but
    ``FlatLambdaCDM`` **will** be flat.
    'b'Find the corresponding non-flat class.

        The class' bases are searched recursively.

        Parameters
        ----------
        kls : :class:`astropy.cosmology.Cosmology` class or None, optional
            If `None` (default) this class is searched instead of `kls`.

        Raises
        ------
        TypeError
            If more than one non-flat class is found at the same level of the
            inheritance. This is similar to the error normally raised by Python
            for an inconsistent method resolution order.

        Returns
        -------
        type
            A :class:`Cosmology` subclass this class inherits from that is not a
            :class:`FlatCosmologyMixin` subclass.
        'u'Find the corresponding non-flat class.

        The class' bases are searched recursively.

        Parameters
        ----------
        kls : :class:`astropy.cosmology.Cosmology` class or None, optional
            If `None` (default) this class is searched instead of `kls`.

        Raises
        ------
        TypeError
            If more than one non-flat class is found at the same level of the
            inheritance. This is similar to the error normally raised by Python
            for an inconsistent method resolution order.

        Returns
        -------
        type
            A :class:`Cosmology` subclass this class inherits from that is not a
            :class:`FlatCosmologyMixin` subclass.
        'b'cannot create a consistent non-flat class resolution order for 'u'cannot create a consistent non-flat class resolution order for 'b' with bases 'u' with bases 'b' at the same inheritance level.'u' at the same inheritance level.'b'Return the corresponding non-flat class.'u'Return the corresponding non-flat class.'b'Return `True`, the cosmology is flat.'u'Return `True`, the cosmology is flat.'b'Return the equivalent non-flat-class instance of this cosmology.'u'Return the equivalent non-flat-class instance of this cosmology.'b'Returns a copy of this object with updated parameters, as specified.

        This cannot be used to change the type of the cosmology, except for
        changing to the non-flat version of this cosmology.

        Parameters
        ----------
        meta : mapping or None (optional, keyword-only)
            Metadata that will update the current metadata.
        to_nonflat : bool, optional keyword-only
            Whether to change to the non-flat version of this cosmology.
        **kwargs
            Cosmology parameter (and name) modifications. If any parameter is
            changed and a new name is not given, the name will be set to "[old
            name] (modified)".

        Returns
        -------
        newcosmo : `~astropy.cosmology.Cosmology` subclass instance
            A new instance of this class with updated parameters as specified.
            If no arguments are given, then a reference to this object is
            returned instead of copy.

        Examples
        --------
        To make a copy of the ``Planck13`` cosmology with a different matter
        density (``Om0``), and a new name:

            >>> from astropy.cosmology import Planck13
            >>> Planck13.clone(name="Modified Planck 2013", Om0=0.35)
            FlatLambdaCDM(name='Modified Planck 2013', H0=<Quantity 67.77 km / (Mpc s)>,
                          Om0=0.35, ...

        If no name is specified, the new name will note the modification.

            >>> Planck13.clone(Om0=0.35).name
            'Planck13 (modified)'

        The keyword 'to_nonflat' can be used to clone on the non-flat equivalent
        cosmology. For :class:`~astropy.cosmology.FLRW` cosmologies this means
        ``Ode0`` can be modified:

            >>> Planck13.clone(to_nonflat=True, Ode0=1)
            LambdaCDM(name='Planck13 (modified)', H0=<Quantity 67.77 km / (Mpc s)>,
                      Om0=0.30712, Ode0=1.0, ...
        'u'Returns a copy of this object with updated parameters, as specified.

        This cannot be used to change the type of the cosmology, except for
        changing to the non-flat version of this cosmology.

        Parameters
        ----------
        meta : mapping or None (optional, keyword-only)
            Metadata that will update the current metadata.
        to_nonflat : bool, optional keyword-only
            Whether to change to the non-flat version of this cosmology.
        **kwargs
            Cosmology parameter (and name) modifications. If any parameter is
            changed and a new name is not given, the name will be set to "[old
            name] (modified)".

        Returns
        -------
        newcosmo : `~astropy.cosmology.Cosmology` subclass instance
            A new instance of this class with updated parameters as specified.
            If no arguments are given, then a reference to this object is
            returned instead of copy.

        Examples
        --------
        To make a copy of the ``Planck13`` cosmology with a different matter
        density (``Om0``), and a new name:

            >>> from astropy.cosmology import Planck13
            >>> Planck13.clone(name="Modified Planck 2013", Om0=0.35)
            FlatLambdaCDM(name='Modified Planck 2013', H0=<Quantity 67.77 km / (Mpc s)>,
                          Om0=0.35, ...

        If no name is specified, the new name will note the modification.

            >>> Planck13.clone(Om0=0.35).name
            'Planck13 (modified)'

        The keyword 'to_nonflat' can be used to clone on the non-flat equivalent
        cosmology. For :class:`~astropy.cosmology.FLRW` cosmologies this means
        ``Ode0`` can be modified:

            >>> Planck13.clone(to_nonflat=True, Ode0=1)
            LambdaCDM(name='Planck13 (modified)', H0=<Quantity 67.77 km / (Mpc s)>,
                      Om0=0.30712, Ode0=1.0, ...
        'b'Flat-|Cosmology| equivalence.

        Use `astropy.cosmology.cosmology_equal` with
        ``allow_equivalent=True`` for actual checks!

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance
            The object to which to compare for equivalence.

        Returns
        -------
        bool or `NotImplemented`
            `True` if ``other`` is of the same class / non-flat class (e.g.
            |FlatLambdaCDM| and |LambdaCDM|) has matching parameters and
            parameter values.
            `False` if ``other`` is of the same class but has different
            parameters.
            `NotImplemented` otherwise.
        'u'Flat-|Cosmology| equivalence.

        Use `astropy.cosmology.cosmology_equal` with
        ``allow_equivalent=True`` for actual checks!

        Parameters
        ----------
        other : `~astropy.cosmology.Cosmology` subclass instance
            The object to which to compare for equivalence.

        Returns
        -------
        bool or `NotImplemented`
            `True` if ``other`` is of the same class / non-flat class (e.g.
            |FlatLambdaCDM| and |LambdaCDM|) has matching parameters and
            parameter values.
            `False` if ``other`` is of the same class but has different
            parameters.
            `NotImplemented` otherwise.
        'u'astropy.cosmology._src.core'u'cosmology._src.core'u'_src.core'UnifiedInputRegistryUnifiedOutputRegistryPATH_TYPES_expand_user_in_argsex_userRead-only Unified Registry.

    .. versionadded:: 5.0

    Examples
    --------
    First let's start by creating a read-only registry.

    .. code-block:: python

        >>> from astropy.io.registry import UnifiedInputRegistry
        >>> read_reg = UnifiedInputRegistry()

    There is nothing in this registry. Let's make a reader for the
    :class:`~astropy.table.Table` class::

        from astropy.table import Table

        def my_table_reader(filename, some_option=1):
            # Read in the table by any means necessary
            return table  # should be an instance of Table

    Such a function can then be registered with the I/O registry::

        read_reg.register_reader('my-table-format', Table, my_table_reader)

    Note that we CANNOT then read in a table with::

        d = Table.read('my_table_file.mtf', format='my-table-format')

    Why? because ``Table.read`` uses Astropy's default global registry and this
    is a separate registry.
    Instead we can read by the read method on the registry::

        d = read_reg.read(Table, 'my_table_file.mtf', format='my-table-format')

    Read
        Register a reader function.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that will be used to
            specify the data type when reading.
        data_class : class
            The class of the object that the reader produces.
        function : function
            The function to read in a data object.
        force : bool, optional
            Whether to override any existing function if already present.
            Default is ``False``.
        priority : int, optional
            The priority of the reader, used to compare possible formats when
            trying to determine the best reader to use. Higher priorities are
            preferred over lower priorities, with the default priority being 0
            (negative numbers are allowed though).
        Reader for format '' and class '' is already defined" is already defined"
        Unregister a reader function.

        Parameters
        ----------
        data_format : str
            The data format identifier.
        data_class : class
            The class of the object that the reader produces.
        No reader defined for format '"' and class"Get reader for ``data_format``.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that is used to
            specify the data type when reading/writing.
        data_class : class
            The class of the object that can be written.

        Returns
        -------
        reader : callable
            The registered reader function for this format and class.
        readersreader_formatreader_class'.

The available formats are:

"'.\n\nThe available formats"" are:\n\n"
        Read in data.

        Parameters
        ----------
        cls : class
        *args
            The arguments passed to this method depend on the format.
        format : str or None
        cache : bool
            Whether to cache the results of reading in the data.
        **kwargs
            The arguments passed to this method depend on the format.

        Returns
        -------
        object or None
            The output of the registered reader.
        isdirWrite-only Registry.

    .. versionadded:: 5.0
    
        Register a table writer function.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that will be used to
            specify the data type when writing.
        data_class : class
            The class of the object that can be written.
        function : function
            The function to write out a data object.
        force : bool, optional
            Whether to override any existing function if already present.
            Default is ``False``.
        priority : int, optional
            The priority of the writer, used to compare possible formats when trying
            to determine the best writer to use. Higher priorities are preferred
            over lower priorities, with the default priority being 0 (negative
            numbers are allowed though).
        Writer for format '
        Unregister a writer function.

        Parameters
        ----------
        data_format : str
            The data format identifier.
        data_class : class
            The class of the object that can be written.
        No writer defined for format 'Get writer for ``data_format``.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that is used to
            specify the data type when reading/writing.
        data_class : class
            The class of the object that can be written.

        Returns
        -------
        writer : callable
            The registered writer function for this format and class.
        writerswriter_formatwriter_class
        Write out data.

        Parameters
        ----------
        data : object
            The data to write.
        *args
            The arguments passed to this method depend on the format.
        format : str or None
        **kwargs
            The arguments passed to this method depend on the format.

        Returns
        -------
        object or None
            The output of the registered writer. Most often `None`.

            .. versionadded:: 4.3
        Unified I/O Registry.

    .. versionadded:: 5.0
    
        Get the list of registered I/O formats as a `~astropy.table.Table`.

        Parameters
        ----------
        data_class : class, optional
            Filter readers/writer to match data class (default = all classes).

        readwrite : str or None, optional
            Search only for readers (``"Read"``) or writers (``"Write"``).
            If None search for both.  Default is None.

            .. versionadded:: 1.3

        Returns
        -------
        format_table : :class:`~astropy.table.Table`
            Table of available I/O formats.
        # TODO! include bytes# Conservatively attempt to apply `os.path.expanduser` to the first# argument, which can be either a path or the contents of a table.# set _identifiers# Read methods# Expand a tilde-prefixed path if present in args[0]# path might be a os.PathLike object# We need to keep track the original path in case it uses a# relative path to the parquet binary# User has read with a subclass where only the parent class is# registered.  This returns the parent class, so try coercing# to desired subclass.# Write Methodsb'UnifiedIORegistry'u'UnifiedIORegistry'b'UnifiedInputRegistry'u'UnifiedInputRegistry'b'UnifiedOutputRegistry'u'UnifiedOutputRegistry'b'Read-only Unified Registry.

    .. versionadded:: 5.0

    Examples
    --------
    First let's start by creating a read-only registry.

    .. code-block:: python

        >>> from astropy.io.registry import UnifiedInputRegistry
        >>> read_reg = UnifiedInputRegistry()

    There is nothing in this registry. Let's make a reader for the
    :class:`~astropy.table.Table` class::

        from astropy.table import Table

        def my_table_reader(filename, some_option=1):
            # Read in the table by any means necessary
            return table  # should be an instance of Table

    Such a function can then be registered with the I/O registry::

        read_reg.register_reader('my-table-format', Table, my_table_reader)

    Note that we CANNOT then read in a table with::

        d = Table.read('my_table_file.mtf', format='my-table-format')

    Why? because ``Table.read`` uses Astropy's default global registry and this
    is a separate registry.
    Instead we can read by the read method on the registry::

        d = read_reg.read(Table, 'my_table_file.mtf', format='my-table-format')

    'u'Read-only Unified Registry.

    .. versionadded:: 5.0

    Examples
    --------
    First let's start by creating a read-only registry.

    .. code-block:: python

        >>> from astropy.io.registry import UnifiedInputRegistry
        >>> read_reg = UnifiedInputRegistry()

    There is nothing in this registry. Let's make a reader for the
    :class:`~astropy.table.Table` class::

        from astropy.table import Table

        def my_table_reader(filename, some_option=1):
            # Read in the table by any means necessary
            return table  # should be an instance of Table

    Such a function can then be registered with the I/O registry::

        read_reg.register_reader('my-table-format', Table, my_table_reader)

    Note that we CANNOT then read in a table with::

        d = Table.read('my_table_file.mtf', format='my-table-format')

    Why? because ``Table.read`` uses Astropy's default global registry and this
    is a separate registry.
    Instead we can read by the read method on the registry::

        d = read_reg.read(Table, 'my_table_file.mtf', format='my-table-format')

    'b'_readers'u'_readers'b'Read'u'Read'b'
        Register a reader function.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that will be used to
            specify the data type when reading.
        data_class : class
            The class of the object that the reader produces.
        function : function
            The function to read in a data object.
        force : bool, optional
            Whether to override any existing function if already present.
            Default is ``False``.
        priority : int, optional
            The priority of the reader, used to compare possible formats when
            trying to determine the best reader to use. Higher priorities are
            preferred over lower priorities, with the default priority being 0
            (negative numbers are allowed though).
        'u'
        Register a reader function.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that will be used to
            specify the data type when reading.
        data_class : class
            The class of the object that the reader produces.
        function : function
            The function to read in a data object.
        force : bool, optional
            Whether to override any existing function if already present.
            Default is ``False``.
        priority : int, optional
            The priority of the reader, used to compare possible formats when
            trying to determine the best reader to use. Higher priorities are
            preferred over lower priorities, with the default priority being 0
            (negative numbers are allowed though).
        'b'Reader for format ''u'Reader for format ''b'' and class ''u'' and class ''b'' is already defined'u'' is already defined'b'
        Unregister a reader function.

        Parameters
        ----------
        data_format : str
            The data format identifier.
        data_class : class
            The class of the object that the reader produces.
        'u'
        Unregister a reader function.

        Parameters
        ----------
        data_format : str
            The data format identifier.
        data_class : class
            The class of the object that the reader produces.
        'b'No reader defined for format ''u'No reader defined for format ''b'Get reader for ``data_format``.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that is used to
            specify the data type when reading/writing.
        data_class : class
            The class of the object that can be written.

        Returns
        -------
        reader : callable
            The registered reader function for this format and class.
        'u'Get reader for ``data_format``.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that is used to
            specify the data type when reading/writing.
        data_class : class
            The class of the object that can be written.

        Returns
        -------
        reader : callable
            The registered reader function for this format and class.
        'b''.

The available formats are:

'u''.

The available formats are:

'b'
        Read in data.

        Parameters
        ----------
        cls : class
        *args
            The arguments passed to this method depend on the format.
        format : str or None
        cache : bool
            Whether to cache the results of reading in the data.
        **kwargs
            The arguments passed to this method depend on the format.

        Returns
        -------
        object or None
            The output of the registered reader.
        'u'
        Read in data.

        Parameters
        ----------
        cls : class
        *args
            The arguments passed to this method depend on the format.
        format : str or None
        cache : bool
            Whether to cache the results of reading in the data.
        **kwargs
            The arguments passed to this method depend on the format.

        Returns
        -------
        object or None
            The output of the registered reader.
        'b'filename'u'filename'b'Write-only Registry.

    .. versionadded:: 5.0
    'u'Write-only Registry.

    .. versionadded:: 5.0
    'b'_writers'u'_writers'b'
        Register a table writer function.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that will be used to
            specify the data type when writing.
        data_class : class
            The class of the object that can be written.
        function : function
            The function to write out a data object.
        force : bool, optional
            Whether to override any existing function if already present.
            Default is ``False``.
        priority : int, optional
            The priority of the writer, used to compare possible formats when trying
            to determine the best writer to use. Higher priorities are preferred
            over lower priorities, with the default priority being 0 (negative
            numbers are allowed though).
        'u'
        Register a table writer function.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that will be used to
            specify the data type when writing.
        data_class : class
            The class of the object that can be written.
        function : function
            The function to write out a data object.
        force : bool, optional
            Whether to override any existing function if already present.
            Default is ``False``.
        priority : int, optional
            The priority of the writer, used to compare possible formats when trying
            to determine the best writer to use. Higher priorities are preferred
            over lower priorities, with the default priority being 0 (negative
            numbers are allowed though).
        'b'Writer for format ''u'Writer for format ''b'
        Unregister a writer function.

        Parameters
        ----------
        data_format : str
            The data format identifier.
        data_class : class
            The class of the object that can be written.
        'u'
        Unregister a writer function.

        Parameters
        ----------
        data_format : str
            The data format identifier.
        data_class : class
            The class of the object that can be written.
        'b'No writer defined for format ''u'No writer defined for format ''b'Get writer for ``data_format``.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that is used to
            specify the data type when reading/writing.
        data_class : class
            The class of the object that can be written.

        Returns
        -------
        writer : callable
            The registered writer function for this format and class.
        'u'Get writer for ``data_format``.

        Parameters
        ----------
        data_format : str
            The data format identifier. This is the string that is used to
            specify the data type when reading/writing.
        data_class : class
            The class of the object that can be written.

        Returns
        -------
        writer : callable
            The registered writer function for this format and class.
        'b'
        Write out data.

        Parameters
        ----------
        data : object
            The data to write.
        *args
            The arguments passed to this method depend on the format.
        format : str or None
        **kwargs
            The arguments passed to this method depend on the format.

        Returns
        -------
        object or None
            The output of the registered writer. Most often `None`.

            .. versionadded:: 4.3
        'u'
        Write out data.

        Parameters
        ----------
        data : object
            The data to write.
        *args
            The arguments passed to this method depend on the format.
        format : str or None
        **kwargs
            The arguments passed to this method depend on the format.

        Returns
        -------
        object or None
            The output of the registered writer. Most often `None`.

            .. versionadded:: 4.3
        'b'Unified I/O Registry.

    .. versionadded:: 5.0
    'u'Unified I/O Registry.

    .. versionadded:: 5.0
    'b'
        Get the list of registered I/O formats as a `~astropy.table.Table`.

        Parameters
        ----------
        data_class : class, optional
            Filter readers/writer to match data class (default = all classes).

        readwrite : str or None, optional
            Search only for readers (``"Read"``) or writers (``"Write"``).
            If None search for both.  Default is None.

            .. versionadded:: 1.3

        Returns
        -------
        format_table : :class:`~astropy.table.Table`
            Table of available I/O formats.
        'u'
        Get the list of registered I/O formats as a `~astropy.table.Table`.

        Parameters
        ----------
        data_class : class, optional
            Filter readers/writer to match data class (default = all classes).

        readwrite : str or None, optional
            Search only for readers (``"Read"``) or writers (``"Write"``).
            If None search for both.  Default is None.

            .. versionadded:: 1.3

        Returns
        -------
        format_table : :class:`~astropy.table.Table`
            Table of available I/O formats.
        'u'astropy.io.registry.core'u'io.registry.core'u'registry.core'
This module defines base classes for all models.  The base class of all
models is `~astropy.modeling.Model`. `~astropy.modeling.FittableModel` is
the base class for all fittable models. Fittable models can be linear or
nonlinear in a regression analysis sense.

All models provide a `__call__` method which performs the transformation in
a purely mathematical way, i.e. the models are unitless.  Model instances can
represent either a single model, or a "model set" representing multiple copies
of the same type of model, but with potentially different values of the
parameters in each model making up the set.
dequeastropy.nddata.utilsadd_arrayextract_arrayastropy.utils.codegenInputParameterError_tofloatparam_repr_oneline_ConstraintsDict_SpecialOperatorsDictcombine_labelsget_inputs_and_paramsmake_binary_operator_evalquantity_asanyarrayFittable1DModelFittable2DModelFittableModelModelModelDefinitionErrorbind_bounding_boxbind_compound_bounding_box_model_oper
    Returns a function that evaluates a given Python arithmetic operator
    between two models.  The operator should be given as a string, like ``'+'``
    or ``'**'``.
    Used for incorrect models definitions._ModelMeta
    Metaclass for Model.

    Currently just handles auto-generating the param_names list based on
    Parameter descriptors declared at the class-level of Model subclasses.
    _is_dynamic
    This flag signifies whether this class was created in the "normal" way,
    with a class statement in the body of a module, as opposed to a call to
    `type` or some other metaclass constructor, such that the resulting class
    does not belong to a specific module.  This is important for pickling of
    dynamic classes.

    This flag is always forced to False for new classes, so code that creates
    dynamic classes should manually set it to True on those classes when
    creating them.
    **_fix_inputsopermethods_parameters_opermethodopercalltbase_param_names_create_inverse_property_create_bounding_box_propertypdict_handle_special_methods
        Custom repr for Model subclasses.
        _format_cls_repr_repr_pretty_
        Repr for IPython's pretty printer.

        By default IPython "pretty prints" classes, so we need to implement
        this so that IPython displays the custom repr for Models.
        _abc_
        The name of this model class--equivalent to ``cls.__name__``.

        This attribute is provided for symmetry with the
        `~astropy.modeling.Model.name` attribute of model instances.
        _is_concrete
        A class-level property that determines whether the class is a concrete
        implementation of a Model--i.e. it is not some abstract base class or
        internal implementation detail (i.e. begins with '_').
        
        Creates a copy of this model class with a new name, inputs or outputs.

        The new class is technically a subclass of the original class, so that
        instance and type checks will still work.  For example::

            >>> from astropy.modeling.models import Rotation2D
            >>> SkyRotation = Rotation2D.rename('SkyRotation')
            >>> SkyRotation
            <class 'astropy.modeling.core.SkyRotation'>
            Name: SkyRotation (Rotation2D)
            N_inputs: 2
            N_outputs: 2
            Fittable parameters: ('angle',)
            >>> issubclass(SkyRotation, Rotation2D)
            True
            >>> r = SkyRotation(90)
            >>> isinstance(r, Rotation2D)
            True
        Expected 'inputs' to be a tuple of strings. expects  inputsExpected 'outputs' to be a tuple of strings. outputsinverse_inverse
        Takes any bounding_box defined on a concrete Model subclass (either
        as a fixed tuple or a property or method) and wraps it in the generic
        getter/setter interface for the bounding_box attribute.
        _create_bounding_box_subclass_bounding_box
        For Models that take optional arguments for defining their bounding
        box, we create a subclass of ModelBoundingBox with a ``__call__`` method
        that supports those additional arguments.

        Takes the function's Signature as an argument since that is already
        computed in _create_bounding_box_property, so no need to duplicate that
        effort.
        The bounding_box method for  is not correctly defined: If defined as a method all arguments to that method (besides self) must be keyword arguments with default values that can be used to compute a default bounding box." is not correctly ""defined: If defined as a method all arguments to that ""method (besides self) must be keyword arguments with ""default values that can be used to compute a default ""bounding box."update_wrapperEvaluate this model on the supplied inputs.model_set_axiswith_bounding_boxinputs_mapnew_inputsnew_callparam_nameparam_valnew_initkeywords
        Internal implementation of ``__repr__``.

        This is separated out for ease of use by subclasses that wish to
        override the default ``__repr__`` while keeping the same basic
        formatting.
        format_inheritance -> NameN_inputsN_outputsdefault_keywordsFittable parameters
    Base class for all models.

    This is an abstract class and should not be instantiated directly.

    The following initialization arguments apply to the majority of Model
    subclasses by default (exceptions include specialized utility models
    like `~astropy.modeling.mappings.Mapping`).  Parametric models take all
    their parameters as arguments, followed by any of the following optional
    keyword arguments:

    Parameters
    ----------
    name : str, optional
        A human-friendly name associated with this model instance
        (particularly useful for identifying the individual components of a
        compound model).

    meta : dict, optional
        An optional dict of user-defined metadata to attach to this model.
        How this is used and interpreted is up to the user or individual use
        case.

    n_models : int, optional
        If given an integer greater than 1, a *model set* is instantiated
        instead of a single model.  This affects how the parameter arguments
        are interpreted.  In this case each parameter must be given as a list
        or array--elements of this array are taken along the first axis (or
        ``model_set_axis`` if specified), such that the Nth element is the
        value of that parameter for the Nth model in the set.

        See the section on model sets in the documentation for more details.

    model_set_axis : int, optional
        This argument only applies when creating a model set (i.e. ``n_models >
        1``).  It changes how parameter values are interpreted.  Normally the
        first axis of each input parameter array (properly the 0th axis) is
        taken as the axis corresponding to the model sets.  However, any axis
        of an input array may be taken as this "model set axis".  This accepts
        negative integers as well--for example use ``model_set_axis=-1`` if the
        last (most rapidly changing) axis should be associated with the model
        sets. Also, ``model_set_axis=False`` can be used to tell that a given
        input should be used to evaluate all the models in the model set.

    fixed : dict, optional
        Dictionary ``{parameter_name: bool}`` setting the fixed constraint
        for one or more parameters.  `True` means the parameter is held fixed
        during fitting and is prevented from updates once an instance of the
        model has been created.

        Alternatively the `~astropy.modeling.Parameter.fixed` property of a
        parameter may be used to lock or unlock individual parameters.

    tied : dict, optional
        Dictionary ``{parameter_name: callable}`` of parameters which are
        linked to some other parameter. The dictionary values are callables
        providing the linking relationship.

        Alternatively the `~astropy.modeling.Parameter.tied` property of a
        parameter may be used to set the ``tied`` constraint on individual
        parameters.

    bounds : dict, optional
        A dictionary ``{parameter_name: value}`` of lower and upper bounds of
        parameters. Keys are parameter names. Values are a list or a tuple
        of length 2 giving the desired range for the parameter.

        Alternatively the `~astropy.modeling.Parameter.min` and
        `~astropy.modeling.Parameter.max` or
        ~astropy.modeling.Parameter.bounds` properties of a parameter may be
        used to set bounds on individual parameters.

    eqcons : list, optional
        List of functions of length n such that ``eqcons[j](x0, *args) == 0.0``
        in a successfully optimized problem.

    ineqcons : list, optional
        List of functions of length n such that ``ieqcons[j](x0, *args) >=
        0.0`` is a successfully optimized problem.

    Examples
    --------
    >>> from astropy.modeling import models
    >>> def tie_center(model):
    ...         mean = 50 * model.stddev
    ...         return mean
    >>> tied_parameters = {'mean': tie_center}

    Specify that ``'mean'`` is a tied parameter in one of two ways:

    >>> g1 = models.Gaussian1D(amplitude=10, mean=5, stddev=.3,
    ...                        tied=tied_parameters)

    or

    >>> g1 = models.Gaussian1D(amplitude=10, mean=5, stddev=.3)
    >>> g1.mean.tied
    False
    >>> g1.mean.tied = tie_center
    >>> g1.mean.tied
    <function tie_center at 0x...>

    Fixed parameters:

    >>> g1 = models.Gaussian1D(amplitude=10, mean=5, stddev=.3,
    ...                        fixed={'stddev': True})
    >>> g1.stddev.fixed
    True

    or

    >>> g1 = models.Gaussian1D(amplitude=10, mean=5, stddev=.3)
    >>> g1.stddev.fixed
    False
    >>> g1.stddev.fixed = True
    >>> g1.stddev.fixed
    True
    constraintsparameter_constraints
    Primarily for informational purposes, these are the types of constraints
    that can be set on a model's parameters.
    eqconsineqconsmodel_constraints
    Primarily for informational purposes, these are the types of constraints
    that constrain model evaluation.
    
    Names of the parameters that describe models of this type.

    The parameters in this tuple are in the same order they should be passed in
    when initializing a model of a specific type.  Some types of models, such
    as polynomial models, have a different number of parameters depending on
    some other property of the model, such as the degree.

    When defining a custom model class the value of this attribute is
    automatically set by the `~astropy.modeling.Parameter` attributes defined
    in the class body.
    standard_broadcastingfittablelinear A boolean flag to indicate whether a model is separable.A dict-like object to store optional information._user_inverse_user_bounding_box_has_inverse_bounding_box_n_models_input_units_strict_input_units_allow_dimensionless_cov_matrix_stds_default_inputs_outputsparnamenewpar_initialize_constraints_initialize_setters_initialize_parameters_initialize_slices_initialize_unit_support_constraints_cache_inputs_outputs
        This exists to inject defaults for settable properties for models
        originating from `~astropy.modeling.custom_model`.
        _settable_propertiessettersExpected  number of inputs, got  number of outputs, got The number of inputs.The number of outputs._calculate_separability_matrix
        This is a hook which customises the behavior of modeling.separable.

        This allows complex subclasses to customise the separability matrix.
        If it returns `NotImplemented` the default behavior is used.
        
        Convert self._input_units_strict and
        self.input_units_allow_dimensionless to dictionaries
        mapping input name to a boolean value.
        input_units_strict
        Enforce strict units on inputs to evaluate. If this is set to True,
        input values to evaluate will be in the exact units specified by
        input_units. If the input quantities are convertible to input_units,
        they are converted. If this is a dictionary then it should map input
        name to a bool to set strict input units for that parameter.
        input_units_allow_dimensionless
        Allow dimensionless input (and corresponding output). If this is True,
        input values to evaluate will gain the units specified in input_units. If
        this is a dictionary then it should map input name to a bool to allow
        dimensionless numbers for that input.
        Only has an effect if input_units is defined.
        uses_quantity
        True if this model has been created with `~astropy.units.Quantity`
        objects or if there are no parameters.

        This can be used to determine if this model should be evaluated with
        `~astropy.units.Quantity` or regular floats.
        _param_setspisq_format_repr_format_str_strip_onesintup_param_metricseshapevshapeesizeValue for parameter  does not match shape or size
expected by model (" does not match shape or size\nexpected"" by model (") vs (' parameter should be given as a Quantity because it was originally initialized as a Quantity"' parameter should be given as a"" Quantity because it was originally ""initialized as a Quantity"_pre_evaluate
        Model specific input setup that needs to occur prior to model evaluation.
        broadcasted_shapesget_bounding_boxwith_bbox
        Return the ``bounding_box`` of a model if it exists or ``None``
        otherwise.

        Parameters
        ----------
        with_bbox :
            The value of the ``with_bounding_box`` keyword argument
            when calling the model. Default is `True` for usage when
            looking up the model's ``bounding_box`` without risk of error.
        _argnamesThe inputs used to determine input_shape for bounding_box evaluation._validate_input_shapeargnamescheck_model_set_axisPerform basic validation of a single model input's shape.

        The shape has the minimum dimensions for the given model_set_axis.

        Returns the shape of the input if validation succeeds.
        For model_set_axis=, all inputs must be at least ", all inputs must be at ""least "-dimensional.Input argument '' does not have the correct dimensions in model_set_axis="' does not have the correct dimensions"" in model_set_axis=" for a model set with n_models=" for a model set with"" n_models="_validate_input_shapes
        Perform basic validation of model inputs
            --that they are mutually broadcastable and that they have
            the minimum dimensions for the given model_set_axis.

        If validation succeeds, returns the total shape that will result from
        broadcasting the input arrays with each other.
        all_shapesAll inputs must have identical shapes or must be scalars.Get input shape for bounding_box evaluation._generic_evaluateGeneric model evaluation routine.

        Selects and evaluates model with or without bounding_box enforcement.
        _post_evaluate
        Model specific post evaluation processing of outputs.
        _process_output_units
        Evaluate this model using the given input(s) and the parameter values
        that were specified when the model was instantiated.
        _get_renamed_inputs_as_positional_keyword2positionalallkeysn_argsn_all_argsMissing input arguments - expected Too many input arguments - expected new_argsUser-provided name for this model instance.Assign a (new) name to this model.
        The index of the model set axis--that is the axis of a parameter array
        that pertains to which model a parameter value pertains to--as
        specified when the model was initialized.

        See the documentation on :ref:`astropy:modeling-model-sets`
        for more details.
        _model_set_axisparam_sets
        Return parameters as a pset.

        This is a list with one item per parameter set, which is an array of
        that parameter's values across all parameter sets, with the last axis
        associated with the parameter set.
        
        A flattened array of all parameter values in all parameter sets.

        Fittable parameters maintain this list and fitters modify it.
        _parameters_to_array
        Assigning to this attribute updates the parameters array rather than
        replacing it.
        Input parameter values not compatible with the model parameters array: "Input parameter values not compatible with the model ""parameters array: "_array_to_parameterssync_constraints
        This is a boolean property that indicates whether or not accessing constraints
        automatically check the constituent models current values. It defaults to True
        on creation of a model, but for fitting purposes it should be set to False
        for performance reasons.
        _sync_constraintssync_constraints only accepts True or False as valueshas_fixedhas_boundshas_tied
        A ``dict`` mapping parameter names to their fixed constraint.
        
        A ``dict`` mapping parameter names to their upper and lower bounds as
        ``(min, max)`` tuples or ``[min, max]`` lists.
        tied
        A ``dict`` mapping parameter names to their tied constraint.
        
        Whether the model has any fixed constraints.
        
        Whether the model has any bounds constraints.
        
        Whether the model has any tied constraints.
        List of parameter equality constraints._mconstraintsList of parameter inequality constraints.
        Returns True if the model has an analytic or user
        inverse defined.
        
        Returns a new `~astropy.modeling.Model` instance which performs the
        inverse transform, if an analytic inverse is defined for this model.

        Even on models that don't have an inverse defined, this property can be
        set with a manually-defined inverse, such a pre-computed or
        experimentally determined inverse (often given as a
        `~astropy.modeling.polynomial.PolynomialModel`, but not by
        requirement).

        A custom inverse can be deleted with ``del model.inverse``.  In this
        case the model's inverse is reset to its default, if a default exists
        (otherwise the default is to raise `NotImplementedError`).

        Note to authors of `~astropy.modeling.Model` subclasses:  To define an
        inverse for a model simply override this property to return the
        appropriate model representing the inverse.  The machinery that will
        make the inverse manually-overridable is added automatically by the
        base class.
        No analytical or user-supplied inverse transform has been implemented for this model."No analytical or user-supplied inverse transform ""has been implemented for this model."The inverse attribute may be assigned a Model instance or None (where None explicitly forces the model to have no inverse."The inverse attribute may be assigned a Model instance ""or None (where None explicitly forces the model to have ""no inverse."
        Resets the model's inverse to its default (if one exists, otherwise
        the model will have no inverse).
        has_user_inverse
        A flag indicating whether or not a custom inverse model has been
        assigned to this model by a user, via assignment to ``model.inverse``.
        
        A `tuple` of length `n_inputs` defining the bounding box limits, or
        raise `NotImplementedError` for no bounding_box.

        The default limits are given by a ``bounding_box`` property or method
        defined in the class body of a specific model.  If not defined then
        this property just raises `NotImplementedError` by default (but may be
        assigned a custom value by a user).  ``bounding_box`` can be set
        manually to an array-like object of shape ``(model.n_inputs, 2)``. For
        further usage, see :ref:`astropy:bounding-boxes`

        The limits are ordered according to the `numpy` ``'C'`` indexing
        convention, and are the reverse of the model input order,
        e.g. for inputs ``('x', 'y', 'z')``, ``bounding_box`` is defined:

        * for 1D: ``(x_low, x_high)``
        * for 2D: ``((y_low, y_high), (x_low, x_high))``
        * for 3D: ``((z_low, z_high), (y_low, y_high), (x_low, x_high))``

        Examples
        --------
        Setting the ``bounding_box`` limits for a 1D and 2D model:

        >>> from astropy.modeling.models import Gaussian1D, Gaussian2D
        >>> model_1d = Gaussian1D()
        >>> model_2d = Gaussian2D(x_stddev=1, y_stddev=1)
        >>> model_1d.bounding_box = (-5, 5)
        >>> model_2d.bounding_box = ((-6, 6), (-5, 5))

        Setting the bounding_box limits for a user-defined 3D
        `~astropy.modeling.custom_model`:

        >>> from astropy.modeling.models import custom_model
        >>> def const3d(x, y, z, amp=1):
        ...    return amp
        ...
        >>> Const3D = custom_model(const3d)
        >>> model_3d = Const3D()
        >>> model_3d.bounding_box = ((-6, 6), (-5, 5), (-4, 4))

        To reset ``bounding_box`` to its default limits just delete the
        user-defined value--this will reset it back to the default defined
        on the class:

        >>> del model_1d.bounding_box

        To disable the bounding box entireQ '  ~b    